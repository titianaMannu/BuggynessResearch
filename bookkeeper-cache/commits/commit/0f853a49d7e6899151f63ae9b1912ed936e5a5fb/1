{"sha":"0f853a49d7e6899151f63ae9b1912ed936e5a5fb","node_id":"MDY6Q29tbWl0MTU3NTk1NjowZjg1M2E0OWQ3ZTY4OTkxNTFmNjNhZTliMTkxMmVkOTM2ZTVhNWZi","commit":{"author":{"name":"Sijie Guo","email":"sijie@apache.org","date":"2013-10-11T06:36:27Z"},"committer":{"name":"Sijie Guo","email":"sijie@apache.org","date":"2013-10-11T06:36:27Z"},"message":"BOOKKEEPER-658: ledger cache refactor (Robin Dhamankar via sijie)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1531203 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"8c6e629b9b46c5b466892dfcac1d802b5477fc3a","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/8c6e629b9b46c5b466892dfcac1d802b5477fc3a"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/0f853a49d7e6899151f63ae9b1912ed936e5a5fb","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/0f853a49d7e6899151f63ae9b1912ed936e5a5fb","html_url":"https://github.com/apache/bookkeeper/commit/0f853a49d7e6899151f63ae9b1912ed936e5a5fb","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/comments","author":{"login":"sijie","id":1217863,"node_id":"MDQ6VXNlcjEyMTc4NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1217863?v=4","gravatar_id":"","url":"https://api.github.com/users/sijie","html_url":"https://github.com/sijie","followers_url":"https://api.github.com/users/sijie/followers","following_url":"https://api.github.com/users/sijie/following{/other_user}","gists_url":"https://api.github.com/users/sijie/gists{/gist_id}","starred_url":"https://api.github.com/users/sijie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sijie/subscriptions","organizations_url":"https://api.github.com/users/sijie/orgs","repos_url":"https://api.github.com/users/sijie/repos","events_url":"https://api.github.com/users/sijie/events{/privacy}","received_events_url":"https://api.github.com/users/sijie/received_events","type":"User","site_admin":false},"committer":{"login":"sijie","id":1217863,"node_id":"MDQ6VXNlcjEyMTc4NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1217863?v=4","gravatar_id":"","url":"https://api.github.com/users/sijie","html_url":"https://github.com/sijie","followers_url":"https://api.github.com/users/sijie/followers","following_url":"https://api.github.com/users/sijie/following{/other_user}","gists_url":"https://api.github.com/users/sijie/gists{/gist_id}","starred_url":"https://api.github.com/users/sijie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sijie/subscriptions","organizations_url":"https://api.github.com/users/sijie/orgs","repos_url":"https://api.github.com/users/sijie/repos","events_url":"https://api.github.com/users/sijie/events{/privacy}","received_events_url":"https://api.github.com/users/sijie/received_events","type":"User","site_admin":false},"parents":[{"sha":"8dafa943a1d5a1cf562d94cc6d2f656e0c0be17e","url":"https://api.github.com/repos/apache/bookkeeper/commits/8dafa943a1d5a1cf562d94cc6d2f656e0c0be17e","html_url":"https://github.com/apache/bookkeeper/commit/8dafa943a1d5a1cf562d94cc6d2f656e0c0be17e"}],"stats":{"total":1892,"additions":1042,"deletions":850},"files":[{"sha":"9deda2cd6cff93f1ead81235325a9c46197f2f0b","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -162,6 +162,8 @@ Trunk (unreleased changes)\n \n       BOOKKEEPER-645: Bookkeeper shell command to get a list of readonly bookies (rakesh via sijie)\n \n+      BOOKKEEPER-658: ledger cache refactor (Robin Dhamankar via sijie)\n+\n     NEW FEATURE:\n \n       BOOKKEEPER-562: Ability to tell if a ledger is closed or not (fpj)"},{"sha":"84082a66d96ec628177c5a53003efbf603a13137","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -745,7 +745,7 @@ public static void main(String argv[]) throws Exception {\n      * @return file object.\n      */\n     private File getLedgerFile(long ledgerId) {\n-        String ledgerName = LedgerCacheImpl.getLedgerName(ledgerId);\n+        String ledgerName = IndexPersistenceMgr.getLedgerName(ledgerId);\n         File lf = null;\n         for (File d : ledgerDirectories) {\n             lf = new File(d, ledgerName);"},{"sha":"5b8ddf1e3e9a7826230b39e907fa390f5919b81a","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","status":"modified","additions":6,"deletions":5,"changes":11,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -21,19 +21,20 @@\n \n package org.apache.bookkeeper.bookie;\n \n+import static com.google.common.base.Charsets.UTF_8;\n+\n import java.io.File;\n import java.io.IOException;\n import java.io.RandomAccessFile;\n-import java.nio.ByteBuffer;\n import java.nio.BufferUnderflowException;\n+import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n \n-import static com.google.common.base.Charsets.UTF_8;\n-import com.google.common.annotations.VisibleForTesting;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.google.common.annotations.VisibleForTesting;\n+\n /**\n  * This is the file handle for a ledger's index file that maps entry ids to location.\n  * It is used by LedgerCache.\n@@ -291,7 +292,7 @@ public synchronized void moveToNewLocation(File newFile, long size) throws IOExc\n             if (size > fc.size()) {\n                 size = fc.size();\n             }\n-            File rlocFile = new File(newFile.getParentFile(), newFile.getName() + LedgerCacheImpl.RLOC);\n+            File rlocFile = new File(newFile.getParentFile(), newFile.getName() + IndexPersistenceMgr.RLOC);\n             if (!rlocFile.exists()) {\n                 checkParents(rlocFile);\n                 if (!rlocFile.createNewFile()) {"},{"sha":"b2fa7b775ab20b5b7b4c4f3ec1b598bdb1c95cc3","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","status":"added","additions":404,"deletions":0,"changes":404,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -0,0 +1,404 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Iterator;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+class IndexInMemPageMgr {\n+    private final static Logger LOG = LoggerFactory.getLogger(IndexInMemPageMgr.class);\n+\n+    final int pageSize;\n+    final int pageLimit;\n+    final int entriesPerPage;\n+    final HashMap<Long, HashMap<Long, LedgerEntryPage>> pages;\n+\n+    // The number of pages that have actually been used\n+    private int pageCount = 0;\n+\n+    // The persistence manager that this page manager uses to\n+    // flush and read pages\n+    private final IndexPersistenceMgr indexPersistenceManager;\n+\n+    /**\n+     * the list of potentially dirty ledgers\n+     */\n+    LinkedList<Long> dirtyLedgers = new LinkedList<Long>();\n+    /**\n+     * the list of potentially clean ledgers\n+     */\n+    LinkedList<Long> cleanLedgers = new LinkedList<Long>();\n+\n+    public IndexInMemPageMgr(int pageSize,\n+                             int entriesPerPage,\n+                             ServerConfiguration conf, \n+                             IndexPersistenceMgr indexPersistenceManager) {\n+        this.pageSize = pageSize;\n+        this.entriesPerPage = entriesPerPage;\n+        this.indexPersistenceManager = indexPersistenceManager;\n+        this.pages = new HashMap<Long, HashMap<Long, LedgerEntryPage>>();\n+\n+        if (conf.getPageLimit() <= 0) {\n+            // allocate half of the memory to the page cache\n+            this.pageLimit = (int) ((Runtime.getRuntime().maxMemory() / 3) / this.pageSize);\n+        } else {\n+            this.pageLimit = conf.getPageLimit();\n+        }\n+        LOG.info(\"maxMemory = {}, pageSize = {}, pageLimit = {}\", new Object[] { Runtime.getRuntime().maxMemory(),\n+                        pageSize, pageLimit });\n+    }\n+\n+    /**\n+     * @return page size used in ledger cache\n+     */\n+    public int getPageSize() {\n+        return pageSize;\n+    }\n+\n+    /**\n+     * @return entries per page used in ledger cache\n+     */\n+    public int getEntriesPerPage() {\n+        return entriesPerPage;\n+    }\n+\n+    /**\n+     * @return page limitation in ledger cache\n+     */\n+    public int getPageLimit() {\n+        return pageLimit;\n+    }\n+\n+    /**\n+     * @return number of page used in ledger cache\n+     */\n+    public int getNumUsedPages() {\n+        return pageCount;\n+    }\n+\n+    public int getNumCleanLedgers() {\n+        return cleanLedgers.size();\n+    }\n+\n+    public int getNumDirtyLedgers() {\n+        return dirtyLedgers.size();\n+    }\n+\n+    private void putIntoTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table, LedgerEntryPage lep) {\n+        HashMap<Long, LedgerEntryPage> map = table.get(lep.getLedger());\n+        if (map == null) {\n+            map = new HashMap<Long, LedgerEntryPage>();\n+            table.put(lep.getLedger(), map);\n+        }\n+        map.put(lep.getFirstEntry(), lep);\n+    }\n+\n+    private static LedgerEntryPage getFromTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table,\n+                                                Long ledger, Long firstEntry) {\n+        HashMap<Long, LedgerEntryPage> map = table.get(ledger);\n+        if (map != null) {\n+            return map.get(firstEntry);\n+        }\n+        return null;\n+    }\n+\n+    synchronized protected LedgerEntryPage getLedgerEntryPage(Long ledger, Long firstEntry, boolean onlyDirty) {\n+        LedgerEntryPage lep = getFromTable(pages, ledger, firstEntry);\n+        if (lep == null) {\n+            return null;\n+        }\n+\n+        lep.usePage();\n+\n+        if (onlyDirty && lep.isClean()) {\n+            return null;\n+        } else {\n+            return lep;\n+        }\n+    }\n+\n+    /** \n+     * Grab ledger entry page whose first entry is <code>pageEntry</code>.\n+     *\n+     * If the page doesn't existed before, we allocate a memory page.\n+     * Otherwise, we grab a clean page and read it from disk.\n+     *\n+     * @param ledger\n+     *          Ledger Id\n+     * @param pageEntry\n+     *          Start entry of this entry page.\n+     */\n+    private LedgerEntryPage grabLedgerEntryPage(long ledger, long pageEntry) throws IOException {\n+        LedgerEntryPage lep = grabCleanPage(ledger, pageEntry);\n+        try {\n+            // should update page before we put it into table\n+            // otherwise we would put an empty page in it\n+            indexPersistenceManager.updatePage(lep);\n+            synchronized (this) {\n+                putIntoTable(pages, lep);\n+            }\n+        } catch (IOException ie) {\n+            // if we grab a clean page, but failed to update the page\n+            // we are exhausting the count of ledger entry pages.\n+            // since this page will be never used, so we need to decrement\n+            // page count of ledger cache.\n+            lep.releasePage();\n+            synchronized (this) {\n+                --pageCount;\n+            }\n+            throw ie;\n+        }\n+        return lep;\n+    }\n+\n+    void removePagesForLedger(long ledgerId) {\n+        // remove pages first to avoid page flushed when deleting file info\n+        synchronized (this) {\n+            Map<Long, LedgerEntryPage> lpages = pages.remove(ledgerId);\n+            if (null != lpages) {\n+                pageCount -= lpages.size();\n+                if (pageCount < 0) {\n+                    LOG.error(\"Page count of ledger cache has been decremented to be less than zero.\");\n+                }\n+            }\n+        }\n+    }\n+\n+    long getLastEntryInMem(long ledgerId) {\n+        long lastEntry = 0;\n+        // Find the last entry in the cache\n+        synchronized (this) {\n+            Map<Long, LedgerEntryPage> map = pages.get(ledgerId);\n+            if (map != null) {\n+                for (LedgerEntryPage lep : map.values()) {\n+                    if (lep.getFirstEntry() + entriesPerPage < lastEntry) {\n+                        continue;\n+                    }\n+                    lep.usePage();\n+                    long highest = lep.getLastEntry();\n+                    if (highest > lastEntry) {\n+                        lastEntry = highest;\n+                    }\n+                    lep.releasePage();\n+                }\n+            }\n+        }\n+        return lastEntry;\n+    }\n+\n+    private LedgerEntryPage grabCleanPage(long ledger, long entry) throws IOException {\n+        if (entry % entriesPerPage != 0) {\n+            throw new IllegalArgumentException(entry + \" is not a multiple of \" + entriesPerPage);\n+        }\n+        outerLoop: while (true) {\n+            synchronized (this) {\n+                if (pageCount < pageLimit) {\n+                    // let's see if we can allocate something\n+                    LedgerEntryPage lep = new LedgerEntryPage(pageSize, entriesPerPage);\n+                    lep.setLedger(ledger);\n+                    lep.setFirstEntry(entry);\n+\n+                    // note, this will not block since it is a new page\n+                    lep.usePage();\n+                    pageCount++;\n+                    return lep;\n+                }\n+            }\n+\n+            synchronized (cleanLedgers) {\n+                if (cleanLedgers.isEmpty()) {\n+                    flushOneOrMoreLedgers(false);\n+                    synchronized (this) {\n+                        for (Long l : pages.keySet()) {\n+                            cleanLedgers.add(l);\n+                        }\n+                    }\n+                }\n+                synchronized (this) {\n+                    // if ledgers deleted between checking pageCount and putting\n+                    // ledgers into cleanLedgers list, the cleanLedgers list would be empty.\n+                    // so give it a chance to go back to check pageCount again because\n+                    // deleteLedger would decrement pageCount to return the number of pages\n+                    // occupied by deleted ledgers.\n+                    if (cleanLedgers.isEmpty()) {\n+                        continue outerLoop;\n+                    }\n+                    Long cleanLedger = cleanLedgers.getFirst();\n+                    Map<Long, LedgerEntryPage> map = pages.get(cleanLedger);\n+                    while (map == null || map.isEmpty()) {\n+                        cleanLedgers.removeFirst();\n+                        if (cleanLedgers.isEmpty()) {\n+                            continue outerLoop;\n+                        }\n+                        cleanLedger = cleanLedgers.getFirst();\n+                        map = pages.get(cleanLedger);\n+                    }\n+                    Iterator<Map.Entry<Long, LedgerEntryPage>> it = map.entrySet().iterator();\n+                    LedgerEntryPage lep = it.next().getValue();\n+                    while ((lep.inUse() || !lep.isClean())) {\n+                        if (!it.hasNext()) {\n+                            // no clean page found in this ledger\n+                            cleanLedgers.removeFirst();\n+                            continue outerLoop;\n+                        }\n+                        lep = it.next().getValue();\n+                    }\n+                    it.remove();\n+                    if (map.isEmpty()) {\n+                        pages.remove(lep.getLedger());\n+                    }\n+                    lep.usePage();\n+                    lep.zeroPage();\n+                    lep.setLedger(ledger);\n+                    lep.setFirstEntry(entry);\n+                    return lep;\n+                }\n+            }\n+        }\n+    }\n+\n+    void flushOneOrMoreLedgers(boolean doAll) throws IOException {\n+        synchronized (dirtyLedgers) {\n+            if (dirtyLedgers.isEmpty()) {\n+                synchronized (this) {\n+                    for (Long l : pages.keySet()) {\n+                        if (LOG.isTraceEnabled()) {\n+                            LOG.trace(\"Adding {} to dirty pages\", Long.toHexString(l));\n+                        }\n+                        dirtyLedgers.add(l);\n+                    }\n+                }\n+            }\n+            if (dirtyLedgers.isEmpty()) {\n+                return;\n+            }\n+\n+            indexPersistenceManager.relocateIndexFileIfDirFull(dirtyLedgers);\n+\n+            while (!dirtyLedgers.isEmpty()) {\n+                Long l = dirtyLedgers.removeFirst();\n+\n+                flushSpecificLedger(l);\n+\n+                if (!doAll) {\n+                    break;\n+                }\n+                // Yield. if we are doing all the ledgers we don't want to block other flushes that\n+                // need to happen\n+                try {\n+                    dirtyLedgers.wait(1);\n+                } catch (InterruptedException e) {\n+                    // just pass it on\n+                    Thread.currentThread().interrupt();\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * Flush a specified ledger\n+     *\n+     * @param l \n+     *          Ledger Id\n+     * @throws IOException\n+     */\n+    private void flushSpecificLedger(long l) throws IOException {\n+        LinkedList<Long> firstEntryList;\n+        synchronized(this) {\n+            HashMap<Long, LedgerEntryPage> pageMap = pages.get(l);\n+            if (pageMap == null || pageMap.isEmpty()) {\n+                indexPersistenceManager.flushLedgerHeader(l);\n+                return;\n+            }\n+            firstEntryList = new LinkedList<Long>();\n+            for(Map.Entry<Long, LedgerEntryPage> entry: pageMap.entrySet()) {\n+                LedgerEntryPage lep = entry.getValue();\n+                if (lep.isClean()) {\n+                    LOG.trace(\"Page is clean {}\", lep);\n+                    continue;\n+                }\n+                firstEntryList.add(lep.getFirstEntry());\n+            }\n+        }\n+\n+        if (firstEntryList.size() == 0) {\n+            LOG.debug(\"Nothing to flush for ledger {}.\", l);\n+            // nothing to do\n+            return;\n+        }\n+\n+        // Now flush all the pages of a ledger\n+        List<LedgerEntryPage> entries = new ArrayList<LedgerEntryPage>(firstEntryList.size());\n+        try {\n+            for(Long firstEntry: firstEntryList) {\n+                LedgerEntryPage lep = getLedgerEntryPage(l, firstEntry, true);\n+                if (lep != null) {\n+                    entries.add(lep);\n+                }\n+            }\n+            indexPersistenceManager.flushLedgerEntries(l, entries);\n+        } finally {\n+            for(LedgerEntryPage lep: entries) {\n+                lep.releasePage();\n+            }\n+        }\n+    }\n+\n+    void putEntryOffset(long ledger, long entry, long offset) throws IOException {\n+        int offsetInPage = (int) (entry % entriesPerPage);\n+        // find the id of the first entry of the page that has the entry\n+        // we are looking for\n+        long pageEntry = entry - offsetInPage;\n+        LedgerEntryPage lep = getLedgerEntryPage(ledger, pageEntry, false);\n+        if (lep == null) {\n+            lep = grabLedgerEntryPage(ledger, pageEntry);\n+        }\n+        lep.setOffset(offset, offsetInPage * 8);\n+        lep.releasePage();\n+    }\n+\n+    long getEntryOffset(long ledger, long entry) throws IOException {\n+        int offsetInPage = (int) (entry % entriesPerPage);\n+        // find the id of the first entry of the page that has the entry\n+        // we are looking for\n+        long pageEntry = entry - offsetInPage;\n+        LedgerEntryPage lep = getLedgerEntryPage(ledger, pageEntry, false);\n+        try {\n+            if (lep == null) {\n+                lep = grabLedgerEntryPage(ledger, pageEntry);\n+            }\n+            return lep.getOffset(offsetInPage * 8);\n+        } finally {\n+            if (lep != null) {\n+                lep.releasePage();\n+            }\n+        }\n+    }\n+}"},{"sha":"eb0ded8b66c2b075d6b3d6287166b054ce9a734b","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","status":"added","additions":547,"deletions":0,"changes":547,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -0,0 +1,547 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map.Entry;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+\n+import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;\n+import org.apache.bookkeeper.bookie.LedgerDirsManager.NoWritableLedgerDirException;\n+import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.apache.bookkeeper.util.SnapshotMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+\n+public class IndexPersistenceMgr {\n+    private final static Logger LOG = LoggerFactory.getLogger(IndexPersistenceMgr.class);\n+\n+    private static final String IDX = \".idx\";\n+    static final String RLOC = \".rloc\";\n+\n+    @VisibleForTesting\n+    public static final String getLedgerName(long ledgerId) {\n+        int parent = (int) (ledgerId & 0xff);\n+        int grandParent = (int) ((ledgerId & 0xff00) >> 8);\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(Integer.toHexString(grandParent));\n+        sb.append('/');\n+        sb.append(Integer.toHexString(parent));\n+        sb.append('/');\n+        sb.append(Long.toHexString(ledgerId));\n+        sb.append(IDX);\n+        return sb.toString();\n+    }\n+\n+    final HashMap<Long, FileInfo> fileInfoCache = new HashMap<Long, FileInfo>();\n+    final int openFileLimit;\n+    final int pageSize;\n+    final int entriesPerPage;\n+\n+    // Manage all active ledgers in LedgerManager\n+    // so LedgerManager has knowledge to garbage collect inactive/deleted ledgers\n+    final SnapshotMap<Long, Boolean> activeLedgers;\n+    private LedgerDirsManager ledgerDirsManager;\n+    final LinkedList<Long> openLedgers = new LinkedList<Long>();\n+    final private AtomicBoolean shouldRelocateIndexFile = new AtomicBoolean(false);\n+\n+    public IndexPersistenceMgr(int pageSize,\n+                               int entriesPerPage,\n+                               ServerConfiguration conf,\n+                               SnapshotMap<Long, Boolean> activeLedgers,\n+                               LedgerDirsManager ledgerDirsManager) throws IOException {\n+        this.openFileLimit = conf.getOpenFileLimit();\n+        this.activeLedgers = activeLedgers;\n+        this.ledgerDirsManager = ledgerDirsManager;\n+        this.pageSize = pageSize;\n+        this.entriesPerPage = entriesPerPage;\n+        LOG.info(\"openFileLimit = {}\", openFileLimit);\n+        // Retrieve all of the active ledgers.\n+        getActiveLedgers();\n+        ledgerDirsManager.addLedgerDirsListener(getLedgerDirsListener());\n+    }\n+\n+    FileInfo getFileInfo(Long ledger, byte masterKey[]) throws IOException {\n+        synchronized (fileInfoCache) {\n+            FileInfo fi = fileInfoCache.get(ledger);\n+            if (fi == null) {\n+                File lf = findIndexFile(ledger);\n+                if (lf == null) {\n+                    if (masterKey == null) {\n+                        throw new Bookie.NoLedgerException(ledger);\n+                    }\n+                    lf = getNewLedgerIndexFile(ledger, null);\n+                    // A new ledger index file has been created for this Bookie.\n+                    // Add this new ledger to the set of active ledgers.\n+                    LOG.debug(\"New ledger index file created for ledgerId: {}\", ledger);\n+                    activeLedgers.put(ledger, true);\n+                }\n+                evictFileInfoIfNecessary();\n+                fi = new FileInfo(lf, masterKey);\n+                fileInfoCache.put(ledger, fi);\n+                openLedgers.add(ledger);\n+            }\n+            if (fi != null) {\n+                fi.use();\n+            }\n+            return fi;\n+        }\n+    }\n+\n+    /**\n+     * Get a new index file for ledger excluding directory <code>excludedDir</code>.\n+     *\n+     * @param ledger\n+     *          Ledger id.\n+     * @param excludedDir\n+     *          The ledger directory to exclude.\n+     * @return new index file object.\n+     * @throws NoWritableLedgerDirException if there is no writable dir available.\n+     */\n+    private File getNewLedgerIndexFile(Long ledger, File excludedDir)\n+                    throws NoWritableLedgerDirException {\n+        File dir = ledgerDirsManager.pickRandomWritableDir(excludedDir);\n+        String ledgerName = getLedgerName(ledger);\n+        return new File(dir, ledgerName);\n+    }\n+\n+    /**\n+     * This method will look within the ledger directories for the ledger index\n+     * files. That will comprise the set of active ledgers this particular\n+     * BookieServer knows about that have not yet been deleted by the BookKeeper\n+     * Client. This is called only once during initialization.\n+     */\n+    private void getActiveLedgers() throws IOException {\n+        // Ledger index files are stored in a file hierarchy with a parent and\n+        // grandParent directory. We'll have to go two levels deep into these\n+        // directories to find the index files.\n+        for (File ledgerDirectory : ledgerDirsManager.getAllLedgerDirs()) {\n+            for (File grandParent : ledgerDirectory.listFiles()) {\n+                if (grandParent.isDirectory()) {\n+                    for (File parent : grandParent.listFiles()) {\n+                        if (parent.isDirectory()) {\n+                            for (File index : parent.listFiles()) {\n+                                if (!index.isFile()\n+                                        || (!index.getName().endsWith(IDX) && !index.getName().endsWith(RLOC))) {\n+                                    continue;\n+                                }\n+\n+                                // We've found a ledger index file. The file\n+                                // name is the HexString representation of the\n+                                // ledgerId.\n+                                String ledgerIdInHex = index.getName().replace(RLOC, \"\").replace(IDX, \"\");\n+                                if (index.getName().endsWith(RLOC)) {\n+                                    if (findIndexFile(Long.parseLong(ledgerIdInHex)) != null) {\n+                                        if (!index.delete()) {\n+                                            LOG.warn(\"Deleting the rloc file \" + index + \" failed\");\n+                                        }\n+                                        continue;\n+                                    } else {\n+                                        File dest = new File(index.getParentFile(), ledgerIdInHex + IDX);\n+                                        if (!index.renameTo(dest)) {\n+                                            throw new IOException(\"Renaming rloc file \" + index\n+                                                    + \" to index file has failed\");\n+                                        }\n+                                    }\n+                                }\n+                                activeLedgers.put(Long.parseLong(ledgerIdInHex, 16), true);\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This method is called whenever a ledger is deleted by the BookKeeper Client\n+     * and we want to remove all relevant data for it stored in the LedgerCache.\n+     */\n+    void removeLedger(long ledgerId) throws IOException {\n+        // Delete the ledger's index file and close the FileInfo\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(ledgerId, null);\n+            fi.close(false);\n+            fi.delete();\n+        } finally {\n+            // should release use count\n+            // otherwise the file channel would not be closed.\n+            if (null != fi) {\n+                fi.release();\n+            }\n+        }\n+\n+        // Remove it from the active ledger manager\n+        activeLedgers.remove(ledgerId);\n+\n+        // Now remove it from all the other lists and maps.\n+        // These data structures need to be synchronized first before removing entries.\n+        synchronized (fileInfoCache) {\n+            fileInfoCache.remove(ledgerId);\n+        }\n+        synchronized (openLedgers) {\n+            openLedgers.remove(ledgerId);\n+        }\n+    }\n+\n+    private File findIndexFile(long ledgerId) throws IOException {\n+        String ledgerName = getLedgerName(ledgerId);\n+        for (File d : ledgerDirsManager.getAllLedgerDirs()) {\n+            File lf = new File(d, ledgerName);\n+            if (lf.exists()) {\n+                return lf;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    boolean ledgerExists(long ledgerId) throws IOException {\n+        synchronized (fileInfoCache) {\n+            FileInfo fi = fileInfoCache.get(ledgerId);\n+            if (fi == null) {\n+                File lf = findIndexFile(ledgerId);\n+                if (lf == null) {\n+                    return false;\n+                }\n+            }\n+        }\n+        return true;\n+    }\n+\n+    int getNumOpenLedgers() {\n+        return openLedgers.size();\n+    }\n+\n+    // evict file info if necessary\n+    private void evictFileInfoIfNecessary() throws IOException {\n+        synchronized (fileInfoCache) {\n+            if (openLedgers.size() > openFileLimit) {\n+                long ledgerToRemove = openLedgers.removeFirst();\n+                // TODO Add a statistic here, we don't care really which\n+                // ledger is evicted, but the rate at which they get evicted \n+                fileInfoCache.remove(ledgerToRemove).close(true);\n+            }\n+        }\n+    }\n+\n+    void close() throws IOException {\n+        synchronized (fileInfoCache) {\n+            for (Entry<Long, FileInfo> fileInfo : fileInfoCache.entrySet()) {\n+                FileInfo value = fileInfo.getValue();\n+                if (value != null) {\n+                    value.close(true);\n+                }\n+            }\n+            fileInfoCache.clear();\n+        }\n+    }\n+\n+    byte[] readMasterKey(long ledgerId) throws IOException, BookieException {\n+        synchronized (fileInfoCache) {\n+            FileInfo fi = fileInfoCache.get(ledgerId);\n+            if (fi == null) {\n+                File lf = findIndexFile(ledgerId);\n+                if (lf == null) {\n+                    throw new Bookie.NoLedgerException(ledgerId);\n+                }\n+                evictFileInfoIfNecessary();\n+                fi = new FileInfo(lf, null);\n+                byte[] key = fi.getMasterKey();\n+                fileInfoCache.put(ledgerId, fi);\n+                openLedgers.add(ledgerId);\n+                return key;\n+            }\n+            return fi.getMasterKey();\n+        }\n+    }\n+\n+    void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(ledgerId, masterKey);\n+        } finally {\n+            if (null != fi) {\n+                fi.release();\n+            }\n+        }\n+    }\n+\n+    boolean setFenced(long ledgerId) throws IOException {\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(ledgerId, null);\n+            return fi.setFenced();\n+        } finally {\n+            if (null != fi) {\n+                fi.release();\n+            }\n+        }\n+    }\n+\n+    boolean isFenced(long ledgerId) throws IOException {\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(ledgerId, null);\n+            return fi.isFenced();\n+        } finally {\n+            if (null != fi) {\n+                fi.release();\n+            }\n+        }\n+    }\n+\n+    int getOpenFileLimit() {\n+        return openFileLimit;\n+    }\n+\n+    private LedgerDirsListener getLedgerDirsListener() {\n+        return new LedgerDirsListener() {\n+            @Override\n+            public void diskFull(File disk) {\n+                // If the current entry log disk is full, then create new entry\n+                // log.\n+                shouldRelocateIndexFile.set(true);\n+            }\n+\n+            @Override\n+            public void diskFailed(File disk) {\n+                // Nothing to handle here. Will be handled in Bookie\n+            }\n+\n+            @Override\n+            public void allDisksFull() {\n+                // Nothing to handle here. Will be handled in Bookie\n+            }\n+\n+            @Override\n+            public void fatalError() {\n+                // Nothing to handle here. Will be handled in Bookie\n+            }\n+        };\n+    }\n+\n+    void relocateIndexFileIfDirFull(Collection<Long> dirtyLedgers) throws IOException {\n+        if (shouldRelocateIndexFile.get()) {\n+            // if some new dir detected as full, then move all corresponding\n+            // open index files to new location\n+            for (Long l : dirtyLedgers) {\n+                FileInfo fi = null;\n+                try {\n+                    fi = getFileInfo(l, null);\n+                    File currentDir = getLedgerDirForLedger(fi);\n+                    if (ledgerDirsManager.isDirFull(currentDir)) {\n+                        moveLedgerIndexFile(l, fi);\n+                    }\n+                } finally {\n+                    if (null != fi) {\n+                        fi.release();\n+                    }\n+                }\n+            }\n+            shouldRelocateIndexFile.set(false);\n+        }\n+    }\n+\n+    /**\n+     * Get the ledger directory that the ledger index belongs to.\n+     *\n+     * @param fi File info of a ledger\n+     * @return ledger directory that the ledger belongs to.\n+     */\n+    private File getLedgerDirForLedger(FileInfo fi) {\n+        return fi.getLf().getParentFile().getParentFile().getParentFile();\n+    }\n+\n+    private void moveLedgerIndexFile(Long l, FileInfo fi) throws NoWritableLedgerDirException, IOException {\n+        File newLedgerIndexFile = getNewLedgerIndexFile(l, getLedgerDirForLedger(fi));\n+        fi.moveToNewLocation(newLedgerIndexFile, fi.getSizeSinceLastwrite());\n+    }\n+\n+    void flushLedgerHeader(long ledger) throws IOException {\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(ledger, null);\n+            fi.flushHeader();\n+        } catch (Bookie.NoLedgerException nle) {\n+            // ledger has been deleted\n+            return;\n+        } finally {\n+            if (null != fi) {\n+                fi.release();\n+            }\n+        }\n+        return;\n+    }\n+\n+    void flushLedgerEntries(long l, List<LedgerEntryPage> entries) throws IOException {\n+        FileInfo fi = null;\n+        try {\n+            Collections.sort(entries, new Comparator<LedgerEntryPage>() {\n+                @Override\n+                public int compare(LedgerEntryPage o1, LedgerEntryPage o2) {\n+                    return (int) (o1.getFirstEntry() - o2.getFirstEntry());\n+                }\n+            });\n+            ArrayList<Integer> versions = new ArrayList<Integer>(entries.size());\n+            try {\n+                fi = getFileInfo(l, null);\n+            } catch (Bookie.NoLedgerException nle) {\n+                // ledger has been deleted\n+                return;\n+            }\n+\n+            // flush the header if necessary\n+            fi.flushHeader();\n+            int start = 0;\n+            long lastOffset = -1;\n+            for (int i = 0; i < entries.size(); i++) {\n+                versions.add(i, entries.get(i).getVersion());\n+                if (lastOffset != -1 && (entries.get(i).getFirstEntry() - lastOffset) != entriesPerPage) {\n+                    // send up a sequential list\n+                    int count = i - start;\n+                    if (count == 0) {\n+                        LOG.warn(\"Count cannot possibly be zero!\");\n+                    }\n+                    writeBuffers(l, entries, fi, start, count);\n+                    start = i;\n+                }\n+                lastOffset = entries.get(i).getFirstEntry();\n+            }\n+            if (entries.size() - start == 0 && entries.size() != 0) {\n+                LOG.warn(\"Nothing to write, but there were entries!\");\n+            }\n+            writeBuffers(l, entries, fi, start, entries.size() - start);\n+            synchronized (this) {\n+                for (int i = 0; i < entries.size(); i++) {\n+                    LedgerEntryPage lep = entries.get(i);\n+                    lep.setClean(versions.get(i));\n+                }\n+            }\n+        } finally {\n+            if (fi != null) {\n+                fi.release();\n+            }\n+        }\n+    }\n+\n+    private void writeBuffers(Long ledger,\n+                              List<LedgerEntryPage> entries, FileInfo fi,\n+                              int start, int count) throws IOException {\n+        if (LOG.isTraceEnabled()) {\n+            LOG.trace(\"Writing {} buffers of {}\", count, Long.toHexString(ledger));\n+        }\n+        if (count == 0) {\n+            return;\n+        }\n+        ByteBuffer buffs[] = new ByteBuffer[count];\n+        for (int j = 0; j < count; j++) {\n+            buffs[j] = entries.get(start + j).getPageToWrite();\n+            if (entries.get(start + j).getLedger() != ledger) {\n+                throw new IOException(\"Writing to \" + ledger + \" but page belongs to \"\n+                                + entries.get(start + j).getLedger());\n+            }\n+        }\n+        long totalWritten = 0;\n+        while (buffs[buffs.length - 1].remaining() > 0) {\n+            long rc = fi.write(buffs, entries.get(start + 0).getFirstEntry() * 8);\n+            if (rc <= 0) {\n+                throw new IOException(\"Short write to ledger \" + ledger + \" rc = \" + rc);\n+            }\n+            totalWritten += rc;\n+        }\n+        if (totalWritten != (long) count * (long) pageSize) {\n+            throw new IOException(\"Short write to ledger \" + ledger + \" wrote \" + totalWritten\n+                            + \" expected \" + count * pageSize);\n+        }\n+    }\n+\n+    void updatePage(LedgerEntryPage lep) throws IOException {\n+        if (!lep.isClean()) {\n+            throw new IOException(\"Trying to update a dirty page\");\n+        }\n+        FileInfo fi = null;\n+        try {\n+            fi = getFileInfo(lep.getLedger(), null);\n+            long pos = lep.getFirstEntry() * 8;\n+            if (pos >= fi.size()) {\n+                lep.zeroPage();\n+            } else {\n+                lep.readPage(fi);\n+            }\n+        } finally {\n+            if (fi != null) {\n+                fi.release();\n+            }\n+        }\n+    }\n+\n+    long getPersistEntryBeyondInMem(long ledgerId, long lastEntryInMem) throws IOException {\n+        FileInfo fi = null;\n+        long lastEntry = lastEntryInMem;\n+        try {\n+            fi = getFileInfo(ledgerId, null);\n+            long size = fi.size();\n+            // make sure the file size is aligned with index entry size\n+            // otherwise we may read incorret data\n+            if (0 != size % 8) {\n+                LOG.warn(\"Index file of ledger {} is not aligned with index entry size.\", ledgerId);\n+                size = size - size % 8;\n+            }\n+            // we may not have the last entry in the cache\n+            if (size > lastEntry * 8) {\n+                ByteBuffer bb = ByteBuffer.allocate(pageSize);\n+                long position = size - pageSize;\n+                if (position < 0) {\n+                    position = 0;\n+                }\n+                fi.read(bb, position);\n+                bb.flip();\n+                long startingEntryId = position / 8;\n+                for (int i = entriesPerPage - 1; i >= 0; i--) {\n+                    if (bb.getLong(i * 8) != 0) {\n+                        if (lastEntry < startingEntryId + i) {\n+                            lastEntry = startingEntryId + i;\n+                        }\n+                        break;\n+                    }\n+                }\n+            }\n+        } finally {\n+            if (fi != null) {\n+                fi.release();\n+            }\n+        }\n+        return lastEntry;\n+    }\n+\n+}"},{"sha":"51373b9fb5b0d710134ab8c88aaa9a05512802ac","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","status":"modified","additions":39,"deletions":780,"changes":819,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -21,26 +21,10 @@\n \n package org.apache.bookkeeper.bookie;\n \n-import java.io.File;\n import java.io.IOException;\n-import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.Comparator;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicBoolean;\n \n-import com.google.common.annotations.VisibleForTesting;\n-\n-import org.apache.bookkeeper.util.SnapshotMap;\n-import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;\n-import org.apache.bookkeeper.bookie.LedgerDirsManager.NoWritableLedgerDirException;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.apache.bookkeeper.util.SnapshotMap;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -50,55 +34,28 @@\n  */\n public class LedgerCacheImpl implements LedgerCache {\n     private final static Logger LOG = LoggerFactory.getLogger(LedgerCacheImpl.class);\n-    private static final String IDX = \".idx\";\n-    static final String RLOC = \".rloc\";\n \n-    private LedgerDirsManager ledgerDirsManager;\n-    final private AtomicBoolean shouldRelocateIndexFile = new AtomicBoolean(false);\n+    private final IndexInMemPageMgr indexPageManager;\n+    private final IndexPersistenceMgr indexPersistenceManager;\n+    private final int pageSize;\n+    private final int entriesPerPage;\n \n     public LedgerCacheImpl(ServerConfiguration conf, SnapshotMap<Long, Boolean> activeLedgers,\n-            LedgerDirsManager ledgerDirsManager)\n-            throws IOException {\n-        this.ledgerDirsManager = ledgerDirsManager;\n-        this.openFileLimit = conf.getOpenFileLimit();\n+                    LedgerDirsManager ledgerDirsManager) throws IOException {\n         this.pageSize = conf.getPageSize();\n         this.entriesPerPage = pageSize / 8;\n-\n-        if (conf.getPageLimit() <= 0) {\n-            // allocate half of the memory to the page cache\n-            this.pageLimit = (int)((Runtime.getRuntime().maxMemory() / 3) / this.pageSize);\n-        } else {\n-            this.pageLimit = conf.getPageLimit();\n-        }\n-        LOG.info(\"maxMemory = \" + Runtime.getRuntime().maxMemory());\n-        LOG.info(\"openFileLimit is \" + openFileLimit + \", pageSize is \" + pageSize + \", pageLimit is \" + pageLimit);\n-        this.activeLedgers = activeLedgers;\n-        // Retrieve all of the active ledgers.\n-        getActiveLedgers();\n-        ledgerDirsManager.addLedgerDirsListener(getLedgerDirsListener());\n+        this.indexPersistenceManager = new IndexPersistenceMgr(pageSize, entriesPerPage, conf, activeLedgers,\n+                        ledgerDirsManager);\n+        this.indexPageManager = new IndexInMemPageMgr(pageSize, entriesPerPage, conf, indexPersistenceManager);\n     }\n-    /**\n-     * the list of potentially clean ledgers\n-     */\n-    LinkedList<Long> cleanLedgers = new LinkedList<Long>();\n-\n-    /**\n-     * the list of potentially dirty ledgers\n-     */\n-    LinkedList<Long> dirtyLedgers = new LinkedList<Long>();\n \n-    HashMap<Long, FileInfo> fileInfoCache = new HashMap<Long, FileInfo>();\n-\n-    LinkedList<Long> openLedgers = new LinkedList<Long>();\n-\n-    // Manage all active ledgers in LedgerManager\n-    // so LedgerManager has knowledge to garbage collect inactive/deleted ledgers\n-    final SnapshotMap<Long, Boolean> activeLedgers;\n+    IndexPersistenceMgr getIndexPersistenceManager() {\n+        return indexPersistenceManager;\n+    }\n \n-    final int openFileLimit;\n-    final int pageSize;\n-    final int pageLimit;\n-    final int entriesPerPage;\n+    IndexInMemPageMgr getIndexPageManager() {\n+        return indexPageManager;\n+    }\n \n     /**\n      * @return page size used in ledger cache\n@@ -107,612 +64,33 @@ public int getPageSize() {\n         return pageSize;\n     }\n \n-    /**\n-     * @return entries per page used in ledger cache\n-     */\n-    public int getEntriesPerPage() {\n-        return entriesPerPage;\n-    }\n-\n-    /**\n-     * @return page limitation in ledger cache\n-     */\n-    public int getPageLimit() {\n-        return pageLimit;\n-    }\n-\n-    // The number of pages that have actually been used\n-    private int pageCount = 0;\n-    HashMap<Long, HashMap<Long,LedgerEntryPage>> pages = new HashMap<Long, HashMap<Long,LedgerEntryPage>>();\n-\n-    /**\n-     * @return number of page used in ledger cache\n-     */\n-    public int getNumUsedPages() {\n-        return pageCount;\n-    }\n-\n-    private void putIntoTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table, LedgerEntryPage lep) {\n-        HashMap<Long, LedgerEntryPage> map = table.get(lep.getLedger());\n-        if (map == null) {\n-            map = new HashMap<Long, LedgerEntryPage>();\n-            table.put(lep.getLedger(), map);\n-        }\n-        map.put(lep.getFirstEntry(), lep);\n-    }\n-\n-    private static LedgerEntryPage getFromTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table,\n-                                                Long ledger, Long firstEntry) {\n-        HashMap<Long, LedgerEntryPage> map = table.get(ledger);\n-        if (map != null) {\n-            return map.get(firstEntry);\n-        }\n-        return null;\n-    }\n-\n-    synchronized protected LedgerEntryPage getLedgerEntryPage(Long ledger, Long firstEntry, boolean onlyDirty) {\n-        LedgerEntryPage lep = getFromTable(pages, ledger, firstEntry);\n-        if (lep == null) {\n-            return null;\n-        }\n-\n-        lep.usePage();\n-\n-        if (onlyDirty && lep.isClean()) {\n-            return null;\n-        } else {\n-            return lep;\n-        }\n-    }\n-\n-    /** \n-     * Grab ledger entry page whose first entry is <code>pageEntry</code>.\n-     *\n-     * If the page doesn't existed before, we allocate a memory page.\n-     * Otherwise, we grab a clean page and read it from disk.\n-     *\n-     * @param ledger\n-     *          Ledger Id\n-     * @param pageEntry\n-     *          Start entry of this entry page.\n-     */\n-    private LedgerEntryPage grabLedgerEntryPage(long ledger, long pageEntry) throws IOException {\n-        LedgerEntryPage lep = grabCleanPage(ledger, pageEntry);\n-        try {\n-            // should update page before we put it into table\n-            // otherwise we would put an empty page in it\n-            updatePage(lep);\n-            synchronized(this) {\n-                putIntoTable(pages, lep);\n-            }   \n-        } catch (IOException ie) {\n-            // if we grab a clean page, but failed to update the page\n-            // we are exhausting the count of ledger entry pages.\n-            // since this page will be never used, so we need to decrement\n-            // page count of ledger cache.\n-            lep.releasePage();\n-            synchronized (this) {\n-                --pageCount;\n-            }\n-            throw ie; \n-        }   \n-        return lep;\n-    }\n-\n     @Override\n     public void putEntryOffset(long ledger, long entry, long offset) throws IOException {\n-        int offsetInPage = (int) (entry % entriesPerPage);\n-        // find the id of the first entry of the page that has the entry\n-        // we are looking for\n-        long pageEntry = entry-offsetInPage;\n-        LedgerEntryPage lep = getLedgerEntryPage(ledger, pageEntry, false);\n-        if (lep == null) {\n-            lep = grabLedgerEntryPage(ledger, pageEntry); \n-        }\n-        lep.setOffset(offset, offsetInPage*8);\n-        lep.releasePage();\n+        indexPageManager.putEntryOffset(ledger, entry, offset);\n     }\n \n     @Override\n     public long getEntryOffset(long ledger, long entry) throws IOException {\n-        int offsetInPage = (int) (entry%entriesPerPage);\n-        // find the id of the first entry of the page that has the entry\n-        // we are looking for\n-        long pageEntry = entry-offsetInPage;\n-        LedgerEntryPage lep = getLedgerEntryPage(ledger, pageEntry, false);\n-        try {\n-            if (lep == null) {\n-                lep = grabLedgerEntryPage(ledger, pageEntry);\n-            }\n-            return lep.getOffset(offsetInPage*8);\n-        } finally {\n-            if (lep != null) {\n-                lep.releasePage();\n-            }\n-        }\n-    }\n-\n-    @VisibleForTesting\n-    public static final String getLedgerName(long ledgerId) {\n-        int parent = (int) (ledgerId & 0xff);\n-        int grandParent = (int) ((ledgerId & 0xff00) >> 8);\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(Integer.toHexString(grandParent));\n-        sb.append('/');\n-        sb.append(Integer.toHexString(parent));\n-        sb.append('/');\n-        sb.append(Long.toHexString(ledgerId));\n-        sb.append(IDX);\n-        return sb.toString();\n-    }\n-\n-    FileInfo getFileInfo(Long ledger, byte masterKey[]) throws IOException {\n-        synchronized(fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledger);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledger);\n-                if (lf == null) {\n-                    if (masterKey == null) {\n-                        throw new Bookie.NoLedgerException(ledger);\n-                    }\n-                    lf = getNewLedgerIndexFile(ledger, null);\n-                    // A new ledger index file has been created for this Bookie.\n-                    // Add this new ledger to the set of active ledgers.\n-                    LOG.debug(\"New ledger index file created for ledgerId: {}\", ledger);\n-                    activeLedgers.put(ledger, true);\n-                }\n-                evictFileInfoIfNecessary();\n-                fi = new FileInfo(lf, masterKey);\n-                fileInfoCache.put(ledger, fi);\n-                openLedgers.add(ledger);\n-            }\n-            if (fi != null) {\n-                fi.use();\n-            }\n-            return fi;\n-        }\n-    }\n-\n-    /**\n-     * Get a new index file for ledger excluding directory <code>excludedDir</code>.\n-     *\n-     * @param ledger\n-     *          Ledger id.\n-     * @param excludedDir\n-     *          The ledger directory to exclude.\n-     * @return new index file object.\n-     * @throws NoWritableLedgerDirException if there is no writable dir available.\n-     */\n-    private File getNewLedgerIndexFile(Long ledger, File excludedDir)\n-    throws NoWritableLedgerDirException {\n-        File dir = ledgerDirsManager.pickRandomWritableDir(excludedDir);\n-        String ledgerName = getLedgerName(ledger);\n-        return new File(dir, ledgerName);\n-    }\n-\n-    private void updatePage(LedgerEntryPage lep) throws IOException {\n-        if (!lep.isClean()) {\n-            throw new IOException(\"Trying to update a dirty page\");\n-        }\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(lep.getLedger(), null);\n-            long pos = lep.getFirstEntry()*8;\n-            if (pos >= fi.size()) {\n-                lep.zeroPage();\n-            } else {\n-                lep.readPage(fi);\n-            }\n-        } finally {\n-            if (fi != null) {\n-                fi.release();\n-            }\n-        }\n-    }\n-\n-    private LedgerDirsListener getLedgerDirsListener() {\n-        return new LedgerDirsListener() {\n-            @Override\n-            public void diskFull(File disk) {\n-                // If the current entry log disk is full, then create new entry\n-                // log.\n-                shouldRelocateIndexFile.set(true);\n-            }\n-\n-            @Override\n-            public void diskFailed(File disk) {\n-                // Nothing to handle here. Will be handled in Bookie\n-            }\n-\n-            @Override\n-            public void allDisksFull() {\n-                // Nothing to handle here. Will be handled in Bookie\n-            }\n-\n-            @Override\n-            public void fatalError() {\n-                // Nothing to handle here. Will be handled in Bookie\n-            }\n-        };\n+        return indexPageManager.getEntryOffset(ledger, entry);\n     }\n \n     @Override\n     public void flushLedger(boolean doAll) throws IOException {\n-        synchronized(dirtyLedgers) {\n-            if (dirtyLedgers.isEmpty()) {\n-                synchronized(this) {\n-                    for(Long l: pages.keySet()) {\n-                        if (LOG.isTraceEnabled()) {\n-                            LOG.trace(\"Adding {} to dirty pages\", Long.toHexString(l));\n-                        }\n-                        dirtyLedgers.add(l);\n-                    }\n-                }\n-            }\n-            if (dirtyLedgers.isEmpty()) {\n-                return;\n-            }\n-\n-            if (shouldRelocateIndexFile.get()) {\n-                // if some new dir detected as full, then move all corresponding\n-                // open index files to new location\n-                for (Long l : dirtyLedgers) {\n-                    FileInfo fi = null;\n-                    try {\n-                        fi = getFileInfo(l, null);\n-                        File currentDir = getLedgerDirForLedger(fi);\n-                        if (ledgerDirsManager.isDirFull(currentDir)) {\n-                            moveLedgerIndexFile(l, fi);\n-                        }\n-                    } finally {\n-                        if (null != fi) {\n-                            fi.release();\n-                        }\n-                    }\n-                }\n-                shouldRelocateIndexFile.set(false);\n-            }\n-\n-            while(!dirtyLedgers.isEmpty()) {\n-                Long l = dirtyLedgers.removeFirst();\n-\n-                flushLedger(l);\n-\n-                if (!doAll) {\n-                    break;\n-                }\n-                // Yield. if we are doing all the ledgers we don't want to block other flushes that\n-                // need to happen\n-                try {\n-                    dirtyLedgers.wait(1);\n-                } catch (InterruptedException e) {\n-                    // just pass it on\n-                    Thread.currentThread().interrupt();\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Get the ledger directory that the ledger index belongs to.\n-     *\n-     * @param fi File info of a ledger\n-     * @return ledger directory that the ledger belongs to.\n-     */\n-    private File getLedgerDirForLedger(FileInfo fi) {\n-        return fi.getLf().getParentFile().getParentFile().getParentFile();\n-    }\n-\n-    private void moveLedgerIndexFile(Long l, FileInfo fi) throws NoWritableLedgerDirException, IOException {\n-        File newLedgerIndexFile = getNewLedgerIndexFile(l, getLedgerDirForLedger(fi));\n-        fi.moveToNewLocation(newLedgerIndexFile, fi.getSizeSinceLastwrite());\n-    }\n-\n-    /**\n-     * Flush a specified ledger\n-     *\n-     * @param l\n-     *          Ledger Id\n-     * @throws IOException\n-     */\n-    private void flushLedger(long l) throws IOException {\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(l, null);\n-            flushLedger(l, fi);\n-        } catch (Bookie.NoLedgerException nle) {\n-            // ledger has been deleted\n-        } finally {\n-            if (null != fi) {\n-                fi.release();\n-            }\n-        }\n-    }\n-\n-    private void flushLedger(long l, FileInfo fi) throws IOException {\n-        LinkedList<Long> firstEntryList;\n-        synchronized(this) {\n-            HashMap<Long, LedgerEntryPage> pageMap = pages.get(l);\n-            if (pageMap == null || pageMap.isEmpty()) {\n-                fi.flushHeader();\n-                return;\n-            }\n-            firstEntryList = new LinkedList<Long>();\n-            for(Map.Entry<Long, LedgerEntryPage> entry: pageMap.entrySet()) {\n-                LedgerEntryPage lep = entry.getValue();\n-                if (lep.isClean()) {\n-                    LOG.trace(\"Page is clean {}\", lep);\n-                    continue;\n-                }\n-                firstEntryList.add(lep.getFirstEntry());\n-            }\n-        }\n-\n-        if (firstEntryList.size() == 0) {\n-            LOG.debug(\"Nothing to flush for ledger {}.\", l);\n-            // nothing to do\n-            return;\n-        }\n-\n-        // Now flush all the pages of a ledger\n-        List<LedgerEntryPage> entries = new ArrayList<LedgerEntryPage>(firstEntryList.size());\n-        try {\n-            for(Long firstEntry: firstEntryList) {\n-                LedgerEntryPage lep = getLedgerEntryPage(l, firstEntry, true);\n-                if (lep != null) {\n-                    entries.add(lep);\n-                }\n-            }\n-            Collections.sort(entries, new Comparator<LedgerEntryPage>() {\n-                    @Override\n-                    public int compare(LedgerEntryPage o1, LedgerEntryPage o2) {\n-                    return (int)(o1.getFirstEntry()-o2.getFirstEntry());\n-                    }\n-                    });\n-            ArrayList<Integer> versions = new ArrayList<Integer>(entries.size());\n-            // flush the header if necessary\n-            fi.flushHeader();\n-            int start = 0;\n-            long lastOffset = -1;\n-            for(int i = 0; i < entries.size(); i++) {\n-                versions.add(i, entries.get(i).getVersion());\n-                if (lastOffset != -1 && (entries.get(i).getFirstEntry() - lastOffset) != entriesPerPage) {\n-                    // send up a sequential list\n-                    int count = i - start;\n-                    if (count == 0) {\n-                        LOG.warn(\"Count cannot possibly be zero!\");\n-                    }\n-                    writeBuffers(l, entries, fi, start, count);\n-                    start = i;\n-                }\n-                lastOffset = entries.get(i).getFirstEntry();\n-            }\n-            if (entries.size()-start == 0 && entries.size() != 0) {\n-                LOG.warn(\"Nothing to write, but there were entries!\");\n-            }\n-            writeBuffers(l, entries, fi, start, entries.size()-start);\n-            synchronized(this) {\n-                for(int i = 0; i < entries.size(); i++) {\n-                    LedgerEntryPage lep = entries.get(i);\n-                    lep.setClean(versions.get(i));\n-                }\n-            }\n-        } finally {\n-            for(LedgerEntryPage lep: entries) {\n-                lep.releasePage();\n-            }\n-        }\n-    }\n-\n-    private void writeBuffers(Long ledger,\n-                              List<LedgerEntryPage> entries, FileInfo fi,\n-                              int start, int count) throws IOException {\n-        if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"Writing {} buffers of {}\", count, Long.toHexString(ledger));\n-        }\n-        if (count == 0) {\n-            return;\n-        }\n-        ByteBuffer buffs[] = new ByteBuffer[count];\n-        for(int j = 0; j < count; j++) {\n-            buffs[j] = entries.get(start+j).getPageToWrite();\n-            if (entries.get(start+j).getLedger() != ledger) {\n-                throw new IOException(\"Writing to \" + ledger + \" but page belongs to \"\n-                                      + entries.get(start+j).getLedger());\n-            }\n-        }\n-        long totalWritten = 0;\n-        while(buffs[buffs.length-1].remaining() > 0) {\n-            long rc = fi.write(buffs, entries.get(start+0).getFirstEntry()*8);\n-            if (rc <= 0) {\n-                throw new IOException(\"Short write to ledger \" + ledger + \" rc = \" + rc);\n-            }\n-            totalWritten += rc;\n-        }\n-        if (totalWritten != (long)count * (long)pageSize) {\n-            throw new IOException(\"Short write to ledger \" + ledger + \" wrote \" + totalWritten\n-                                  + \" expected \" + count * pageSize);\n-        }\n-    }\n-    private LedgerEntryPage grabCleanPage(long ledger, long entry) throws IOException {\n-        if (entry % entriesPerPage != 0) {\n-            throw new IllegalArgumentException(entry + \" is not a multiple of \" + entriesPerPage);\n-        }\n-        outerLoop:\n-        while(true) {\n-            synchronized(this) {\n-                if (pageCount  < pageLimit) {\n-                    // let's see if we can allocate something\n-                    LedgerEntryPage lep = new LedgerEntryPage(pageSize, entriesPerPage);\n-                    lep.setLedger(ledger);\n-                    lep.setFirstEntry(entry);\n-\n-                    // note, this will not block since it is a new page\n-                    lep.usePage();\n-                    pageCount++;\n-                    return lep;\n-                }\n-            }\n-\n-            synchronized(cleanLedgers) {\n-                if (cleanLedgers.isEmpty()) {\n-                    flushLedger(false);\n-                    synchronized(this) {\n-                        for(Long l: pages.keySet()) {\n-                            cleanLedgers.add(l);\n-                        }\n-                    }\n-                }\n-                synchronized(this) {\n-                    // if ledgers deleted between checking pageCount and putting\n-                    // ledgers into cleanLedgers list, the cleanLedgers list would be empty.\n-                    // so give it a chance to go back to check pageCount again because\n-                    // deleteLedger would decrement pageCount to return the number of pages\n-                    // occupied by deleted ledgers.\n-                    if (cleanLedgers.isEmpty()) {\n-                        continue outerLoop;\n-                    }\n-                    Long cleanLedger = cleanLedgers.getFirst();\n-                    Map<Long, LedgerEntryPage> map = pages.get(cleanLedger);\n-                    while (map == null || map.isEmpty()) {\n-                        cleanLedgers.removeFirst();\n-                        if (cleanLedgers.isEmpty()) {\n-                            continue outerLoop; \n-                        }\n-                        cleanLedger = cleanLedgers.getFirst();\n-                        map = pages.get(cleanLedger);\n-                    }\n-                    Iterator<Map.Entry<Long, LedgerEntryPage>> it = map.entrySet().iterator();\n-                    LedgerEntryPage lep = it.next().getValue();\n-                    while((lep.inUse() || !lep.isClean())) {\n-                        if (!it.hasNext()) {\n-                            // no clean page found in this ledger\n-                            cleanLedgers.removeFirst();\n-                            continue outerLoop;\n-                        }\n-                        lep = it.next().getValue();\n-                    }\n-                    it.remove();\n-                    if (map.isEmpty()) {\n-                        pages.remove(lep.getLedger());\n-                    }\n-                    lep.usePage();\n-                    lep.zeroPage();\n-                    lep.setLedger(ledger);\n-                    lep.setFirstEntry(entry);\n-                    return lep;\n-                }\n-            }\n-        }\n+        indexPageManager.flushOneOrMoreLedgers(doAll);\n     }\n \n     @Override\n     public long getLastEntry(long ledgerId) throws IOException {\n-        long lastEntry = 0;\n-        // Find the last entry in the cache\n-        synchronized(this) {\n-            Map<Long, LedgerEntryPage> map = pages.get(ledgerId);\n-            if (map != null) {\n-                for(LedgerEntryPage lep: map.values()) {\n-                    if (lep.getFirstEntry() + entriesPerPage < lastEntry) {\n-                        continue;\n-                    }\n-                    lep.usePage();\n-                    long highest = lep.getLastEntry();\n-                    if (highest > lastEntry) {\n-                        lastEntry = highest;\n-                    }\n-                    lep.releasePage();\n-                }\n-            }\n-        }\n-\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(ledgerId, null);\n-            long size = fi.size();\n-            // make sure the file size is aligned with index entry size\n-            // otherwise we may read incorret data\n-            if (0 != size % 8) {\n-                LOG.warn(\"Index file of ledger {} is not aligned with index entry size.\", ledgerId);\n-                size = size - size % 8;\n-            }\n-            // we may not have the last entry in the cache\n-            if (size > lastEntry*8) {\n-                ByteBuffer bb = ByteBuffer.allocate(getPageSize());\n-                long position = size - getPageSize();\n-                if (position < 0) {\n-                    position = 0;\n-                }\n-                fi.read(bb, position);\n-                bb.flip();\n-                long startingEntryId = position/8;\n-                for(int i = getEntriesPerPage()-1; i >= 0; i--) {\n-                    if (bb.getLong(i*8) != 0) {\n-                        if (lastEntry < startingEntryId+i) {\n-                            lastEntry = startingEntryId+i;\n-                        }\n-                        break;\n-                    }\n-                }\n-            }\n-        } finally {\n-            if (fi != null) {\n-                fi.release();\n-            }\n-        }\n-\n+        // Get the highest entry from the pages that are in memory\n+        long lastEntryInMem = indexPageManager.getLastEntryInMem(ledgerId);\n+        // Some index pages may have been evicted from memory, retrieve the last entry\n+        // from the persistent store. We will check if there could be an entry beyond the\n+        // last in mem entry and only then attempt to get the last persisted entry from the file\n+        // The latter is just an optimization\n+        long lastEntry = indexPersistenceManager.getPersistEntryBeyondInMem(ledgerId, lastEntryInMem);\n         return lastEntry;\n     }\n \n-    /**\n-     * This method will look within the ledger directories for the ledger index\n-     * files. That will comprise the set of active ledgers this particular\n-     * BookieServer knows about that have not yet been deleted by the BookKeeper\n-     * Client. This is called only once during initialization.\n-     */\n-    private void getActiveLedgers() throws IOException {\n-        // Ledger index files are stored in a file hierarchy with a parent and\n-        // grandParent directory. We'll have to go two levels deep into these\n-        // directories to find the index files.\n-        for (File ledgerDirectory : ledgerDirsManager.getAllLedgerDirs()) {\n-            for (File grandParent : ledgerDirectory.listFiles()) {\n-                if (grandParent.isDirectory()) {\n-                    for (File parent : grandParent.listFiles()) {\n-                        if (parent.isDirectory()) {\n-                            for (File index : parent.listFiles()) {\n-                                if (!index.isFile()\n-                                        || (!index.getName().endsWith(IDX) && !index.getName().endsWith(RLOC))) {\n-                                    continue;\n-                                }\n-\n-                                // We've found a ledger index file. The file\n-                                // name is the HexString representation of the\n-                                // ledgerId.\n-                                String ledgerIdInHex = index.getName().replace(RLOC, \"\").replace(IDX, \"\");\n-                                if (index.getName().endsWith(RLOC)) {\n-                                    if (findIndexFile(Long.parseLong(ledgerIdInHex)) != null) {\n-                                        if (!index.delete()) {\n-                                            LOG.warn(\"Deleting the rloc file \" + index + \" failed\");\n-                                        }\n-                                        continue;\n-                                    } else {\n-                                        File dest = new File(index.getParentFile(), ledgerIdInHex + IDX);\n-                                        if (!index.renameTo(dest)) {\n-                                            throw new IOException(\"Renaming rloc file \" + index\n-                                                    + \" to index file has failed\");\n-                                        }\n-                                    }\n-                                }\n-                                activeLedgers.put(Long.parseLong(ledgerIdInHex, 16), true);\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-    }\n-\n     /**\n      * This method is called whenever a ledger is deleted by the BookKeeper Client\n      * and we want to remove all relevant data for it stored in the LedgerCache.\n@@ -721,144 +99,33 @@ private void getActiveLedgers() throws IOException {\n     public void deleteLedger(long ledgerId) throws IOException {\n         LOG.debug(\"Deleting ledgerId: {}\", ledgerId);\n \n-        // remove pages first to avoid page flushed when deleting file info\n-        synchronized(this) {\n-            Map<Long, LedgerEntryPage> lpages = pages.remove(ledgerId);\n-            if (null != lpages) {\n-                pageCount -= lpages.size();\n-                if (pageCount < 0) {\n-                    LOG.error(\"Page count of ledger cache has been decremented to be less than zero.\");\n-                }\n-            }\n-        }\n-        // Delete the ledger's index file and close the FileInfo\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(ledgerId, null);\n-            fi.close(false);\n-            fi.delete();\n-        } finally {\n-            // should release use count\n-            // otherwise the file channel would not be closed.\n-            if (null != fi) {\n-                fi.release();\n-            }\n-        }\n-\n-        // Remove it from the active ledger manager\n-        activeLedgers.remove(ledgerId);\n-\n-        // Now remove it from all the other lists and maps.\n-        // These data structures need to be synchronized first before removing entries.\n-        synchronized(fileInfoCache) {\n-            fileInfoCache.remove(ledgerId);\n-        }\n-        synchronized(cleanLedgers) {\n-            cleanLedgers.remove(ledgerId);\n-        }\n-        synchronized(dirtyLedgers) {\n-            dirtyLedgers.remove(ledgerId);\n-        }\n-        synchronized(openLedgers) {\n-            openLedgers.remove(ledgerId);\n-        }\n-    }\n-\n-    private File findIndexFile(long ledgerId) throws IOException {\n-        String ledgerName = getLedgerName(ledgerId);\n-        for (File d : ledgerDirsManager.getAllLedgerDirs()) {\n-            File lf = new File(d, ledgerName);\n-            if (lf.exists()) {\n-                return lf;\n-            }\n-        }\n-        return null;\n+        indexPageManager.removePagesForLedger(ledgerId);\n+        indexPersistenceManager.removeLedger(ledgerId);\n     }\n \n     @Override\n     public byte[] readMasterKey(long ledgerId) throws IOException, BookieException {\n-        synchronized(fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledgerId);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledgerId);\n-                if (lf == null) {\n-                    throw new Bookie.NoLedgerException(ledgerId);\n-                }\n-                evictFileInfoIfNecessary();        \n-                fi = new FileInfo(lf, null);\n-                byte[] key = fi.getMasterKey();\n-                fileInfoCache.put(ledgerId, fi);\n-                openLedgers.add(ledgerId);\n-                return key;\n-            }\n-            return fi.getMasterKey();\n-        }\n-    }\n-\n-    // evict file info if necessary\n-    private void evictFileInfoIfNecessary() throws IOException {\n-        synchronized (fileInfoCache) {\n-            if (openLedgers.size() > openFileLimit) {\n-                long ledgerToRemove = openLedgers.removeFirst();\n-                // TODO Add a statistic here, we don't care really which\n-                // ledger is evicted, but the rate at which they get evicted\n-                LOG.debug(\"Ledger {} is evicted from file info cache.\",\n-                          ledgerToRemove);\n-                fileInfoCache.remove(ledgerToRemove).close(true);\n-            }\n-        }\n+        return indexPersistenceManager.readMasterKey(ledgerId);\n     }\n \n     @Override\n     public boolean setFenced(long ledgerId) throws IOException {\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(ledgerId, null);\n-            return fi.setFenced();\n-        } finally {\n-            if (null != fi) {\n-                fi.release();\n-            }\n-        }\n+        return indexPersistenceManager.setFenced(ledgerId);\n     }\n \n     @Override\n     public boolean isFenced(long ledgerId) throws IOException {\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(ledgerId, null);\n-            return fi.isFenced();\n-        } finally {\n-            if (null != fi) {\n-                fi.release();\n-            }\n-        }\n+        return indexPersistenceManager.isFenced(ledgerId);\n     }\n \n     @Override\n     public void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {\n-        FileInfo fi = null;\n-        try {\n-            fi = getFileInfo(ledgerId, masterKey);\n-        } finally {\n-            if (null != fi) {\n-                fi.release();\n-            }\n-        }\n+        indexPersistenceManager.setMasterKey(ledgerId, masterKey);\n     }\n \n     @Override\n     public boolean ledgerExists(long ledgerId) throws IOException {\n-        synchronized(fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledgerId);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledgerId);\n-                if (lf == null) {\n-                    return false;\n-                }\n-            }\n-        }\n-        return true;\n+        return indexPersistenceManager.ledgerExists(ledgerId);\n     }\n \n     @Override\n@@ -876,7 +143,7 @@ public boolean isHidden() {\n \n             @Override\n             public int getPageCount() {\n-                return LedgerCacheImpl.this.getNumUsedPages();\n+                return LedgerCacheImpl.this.indexPageManager.getNumUsedPages();\n             }\n \n             @Override\n@@ -886,41 +153,33 @@ public int getPageSize() {\n \n             @Override\n             public int getOpenFileLimit() {\n-                return openFileLimit;\n+                return LedgerCacheImpl.this.indexPersistenceManager.getOpenFileLimit();\n             }\n \n             @Override\n             public int getPageLimit() {\n-                return LedgerCacheImpl.this.getPageLimit();\n+                return LedgerCacheImpl.this.indexPageManager.getPageLimit();\n             }\n \n             @Override\n             public int getNumCleanLedgers() {\n-                return cleanLedgers.size();\n+                return LedgerCacheImpl.this.indexPageManager.getNumCleanLedgers();\n             }\n \n             @Override\n             public int getNumDirtyLedgers() {\n-                return dirtyLedgers.size();\n+                return LedgerCacheImpl.this.indexPageManager.getNumDirtyLedgers();\n             }\n \n             @Override\n             public int getNumOpenLedgers() {\n-                return openLedgers.size();\n+                return LedgerCacheImpl.this.indexPersistenceManager.getNumOpenLedgers();\n             }\n         };\n     }\n \n     @Override\n     public void close() throws IOException {\n-        synchronized (fileInfoCache) {\n-            for (Entry<Long, FileInfo> fileInfo : fileInfoCache.entrySet()) {\n-                FileInfo value = fileInfo.getValue();\n-                if (value != null) {\n-                    value.close(true);\n-                }\n-            }\n-            fileInfoCache.clear();\n-        }\n+        indexPersistenceManager.close();\n     }\n }"},{"sha":"a47733290881652ed0600b6d0e91d842c8fa5c4a","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieJournalTest.java","status":"modified","additions":10,"deletions":21,"changes":31,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieJournalTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieJournalTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieJournalTest.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -21,35 +21,24 @@\n  *\n  */\n \n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.fail;\n+\n import java.io.File;\n-import java.io.RandomAccessFile;\n import java.io.IOException;\n+import java.io.RandomAccessFile;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n-import java.util.ArrayList;\n-import java.util.Enumeration;\n-import java.util.Random;\n-import java.util.Set;\n import java.util.Arrays;\n+import java.util.Random;\n \n-import org.apache.bookkeeper.conf.ServerConfiguration;\n-import org.apache.bookkeeper.client.AsyncCallback.AddCallback;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeperTestClient;\n-import org.apache.bookkeeper.client.LedgerEntry;\n import org.apache.bookkeeper.client.ClientUtil;\n import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.client.AsyncCallback.ReadCallback;\n-import org.apache.bookkeeper.client.BookKeeper.DigestType;\n-import org.apache.bookkeeper.proto.BookieServer;\n+import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.junit.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n-import org.junit.Before;\n-import org.junit.Test;\n-import static org.junit.Assert.*;\n \n public class BookieJournalTest {\n     static Logger LOG = LoggerFactory.getLogger(BookieJournalTest.class);\n@@ -59,7 +48,7 @@\n     private void writeIndexFileForLedger(File indexDir, long ledgerId,\n                                          byte[] masterKey)\n             throws Exception {\n-        File fn = new File(indexDir, LedgerCacheImpl.getLedgerName(ledgerId));\n+        File fn = new File(indexDir, IndexPersistenceMgr.getLedgerName(ledgerId));\n         fn.getParentFile().mkdirs();\n         FileInfo fi = new FileInfo(fn, masterKey);\n         // force creation of index file\n@@ -70,7 +59,7 @@ private void writeIndexFileForLedger(File indexDir, long ledgerId,\n     private void writePartialIndexFileForLedger(File indexDir, long ledgerId,\n                                                 byte[] masterKey, boolean truncateToMasterKey)\n             throws Exception {\n-        File fn = new File(indexDir, LedgerCacheImpl.getLedgerName(ledgerId));\n+        File fn = new File(indexDir, IndexPersistenceMgr.getLedgerName(ledgerId));\n         fn.getParentFile().mkdirs();\n         FileInfo fi = new FileInfo(fn, masterKey);\n         // force creation of index file"},{"sha":"aed5ea44a9ffa1012533ec6e3c2c34c1a915a7e9","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/LedgerCacheTest.java","status":"modified","additions":5,"deletions":6,"changes":11,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/LedgerCacheTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/LedgerCacheTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/LedgerCacheTest.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -25,6 +25,8 @@\n import java.io.IOException;\n import java.nio.ByteBuffer;\n \n+import junit.framework.TestCase;\n+\n import org.apache.bookkeeper.bookie.Bookie.NoLedgerException;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.apache.bookkeeper.meta.LedgerManagerFactory;\n@@ -38,12 +40,9 @@\n import org.junit.Assert;\n import org.junit.Before;\n import org.junit.Test;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import junit.framework.TestCase;\n-\n /**\n  * LedgerCache related test cases\n  */\n@@ -266,11 +265,11 @@ public void testLedgerCacheFlushFailureOnDiskFull() throws Exception {\n         // Create ledger index file\n         ledgerStorage.setMasterKey(1, \"key\".getBytes());\n \n-        FileInfo fileInfo = ledgerCache.getFileInfo(Long.valueOf(1), null);\n+        FileInfo fileInfo = ledgerCache.getIndexPersistenceManager().getFileInfo(Long.valueOf(1), null);\n \n         // Simulate the flush failure\n         FileInfo newFileInfo = new FileInfo(fileInfo.getLf(), fileInfo.getMasterKey());\n-        ledgerCache.fileInfoCache.put(Long.valueOf(1), newFileInfo);\n+        ledgerCache.getIndexPersistenceManager().fileInfoCache.put(Long.valueOf(1), newFileInfo);\n         // Add entries\n         ledgerStorage.addEntry(generateEntry(1, 1));\n         ledgerStorage.addEntry(generateEntry(1, 2));\n@@ -364,7 +363,7 @@ public void testIndexPageEvictionWriteOrder() throws Exception {\n     public void testSyncThreadNPE() throws IOException {\n         newLedgerCache();\n         try {\n-            ((LedgerCacheImpl) ledgerCache).getLedgerEntryPage(0L, 0L, true);\n+            ((LedgerCacheImpl) ledgerCache).getIndexPageManager().getLedgerEntryPage(0L, 0L, true);\n         } catch (Exception e) {\n             LOG.error(\"Exception when trying to get a ledger entry page\", e);\n             fail(\"Shouldn't have thrown an exception\");"},{"sha":"cba0c30d1428a6ff91091f87219a5ea99b953963","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/UpgradeTest.java","status":"modified","additions":12,"deletions":17,"changes":29,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/UpgradeTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/UpgradeTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/UpgradeTest.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -21,33 +21,28 @@\n \n package org.apache.bookkeeper.bookie;\n \n-import java.util.Arrays;\n-\n-import java.nio.ByteBuffer;\n-import java.nio.channels.FileChannel;\n+import static org.junit.Assert.assertTrue;\n+import static org.junit.Assert.fail;\n \n+import java.io.BufferedWriter;\n import java.io.File;\n-import java.io.IOException;\n-\n import java.io.FileOutputStream;\n import java.io.OutputStreamWriter;\n-import java.io.BufferedWriter;\n import java.io.PrintStream;\n import java.io.RandomAccessFile;\n-\n-import org.junit.Before;\n-import org.junit.After;\n-import org.junit.Test;\n-import static org.junit.Assert.*;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n \n import org.apache.bookkeeper.client.ClientUtil;\n import org.apache.bookkeeper.client.LedgerHandle;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n-\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.bookkeeper.test.ZooKeeperUtil;\n import org.apache.bookkeeper.test.PortManager;\n-\n+import org.apache.bookkeeper.test.ZooKeeperUtil;\n+import org.apache.zookeeper.ZooKeeper;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -75,7 +70,7 @@ static void writeLedgerDir(File dir,\n             throws Exception {\n         long ledgerId = 1;\n \n-        File fn = new File(dir, LedgerCacheImpl.getLedgerName(ledgerId));\n+        File fn = new File(dir, IndexPersistenceMgr.getLedgerName(ledgerId));\n         fn.getParentFile().mkdirs();\n         FileInfo fi = new FileInfo(fn, masterKey);\n         // force creation of index file"},{"sha":"5f462bc107f6b875c177c8f410d61b5797d1e5b2","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/replication/AuditorPeriodicCheckTest.java","status":"modified","additions":16,"deletions":20,"changes":36,"blob_url":"https://github.com/apache/bookkeeper/blob/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/replication/AuditorPeriodicCheckTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/0f853a49d7e6899151f63ae9b1912ed936e5a5fb/bookkeeper-server/src/test/java/org/apache/bookkeeper/replication/AuditorPeriodicCheckTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/replication/AuditorPeriodicCheckTest.java?ref=0f853a49d7e6899151f63ae9b1912ed936e5a5fb","patch":"@@ -20,41 +20,37 @@\n  */\n package org.apache.bookkeeper.replication;\n \n-import org.apache.bookkeeper.test.BookKeeperClusterTestCase;\n-\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.ArrayList;\n-import java.util.LinkedList;\n import java.io.File;\n import java.io.FileOutputStream;\n import java.io.FilenameFilter;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n+import org.apache.bookkeeper.bookie.Bookie;\n import org.apache.bookkeeper.bookie.BookieAccessor;\n-import org.apache.bookkeeper.util.StringUtils;\n-import org.apache.bookkeeper.zookeeper.ZooKeeperWatcherBase;\n+import org.apache.bookkeeper.bookie.IndexPersistenceMgr;\n+import org.apache.bookkeeper.client.AsyncCallback.AddCallback;\n+import org.apache.bookkeeper.client.BKException;\n import org.apache.bookkeeper.client.BookKeeper.DigestType;\n import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.AsyncCallback.AddCallback;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.apache.bookkeeper.meta.LedgerManagerFactory;\n import org.apache.bookkeeper.meta.LedgerUnderreplicationManager;\n-\n+import org.apache.bookkeeper.test.BookKeeperClusterTestCase;\n+import org.apache.bookkeeper.util.StringUtils;\n import org.apache.bookkeeper.util.ZkUtils;\n-import org.apache.bookkeeper.bookie.Bookie;\n-import org.apache.bookkeeper.bookie.LedgerCacheImpl;\n+import org.apache.bookkeeper.zookeeper.ZooKeeperWatcherBase;\n import org.apache.zookeeper.ZooKeeper;\n-import org.junit.Before;\n import org.junit.After;\n+import org.junit.Before;\n import org.junit.Test;\n-import static org.junit.Assert.assertEquals;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -191,7 +187,7 @@ public void testIndexCorruption() throws Exception {\n         ledgerDir = Bookie.getCurrentDirectory(ledgerDir);\n \n         // corrupt of entryLogs\n-        File index = new File(ledgerDir, LedgerCacheImpl.getLedgerName(ledgerToCorrupt));\n+        File index = new File(ledgerDir, IndexPersistenceMgr.getLedgerName(ledgerToCorrupt));\n         LOG.info(\"file to corrupt{}\" , index);\n         ByteBuffer junk = ByteBuffer.allocate(1024*1024);\n         FileOutputStream out = new FileOutputStream(index);"}]}

