{"sha":"261bb8f671dc233d3b604b3355bb20d82edac539","node_id":"MDY6Q29tbWl0MTU3NTk1NjoyNjFiYjhmNjcxZGMyMzNkM2I2MDRiMzM1NWJiMjBkODJlZGFjNTM5","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-03-07T12:14:45Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-03-07T12:14:45Z"},"message":"BOOKKEEPER-717: journal should look forward to group time-out entries (sijie via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1575243 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"3ea36a4addb1af729b6f0ac2e4ebe87bf7f1197f","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/3ea36a4addb1af729b6f0ac2e4ebe87bf7f1197f"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/261bb8f671dc233d3b604b3355bb20d82edac539","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/261bb8f671dc233d3b604b3355bb20d82edac539","html_url":"https://github.com/apache/bookkeeper/commit/261bb8f671dc233d3b604b3355bb20d82edac539","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/261bb8f671dc233d3b604b3355bb20d82edac539/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"653dd6d733e9022a6189a2c8546bb8e3afa22715","url":"https://api.github.com/repos/apache/bookkeeper/commits/653dd6d733e9022a6189a2c8546bb8e3afa22715","html_url":"https://github.com/apache/bookkeeper/commit/653dd6d733e9022a6189a2c8546bb8e3afa22715"}],"stats":{"total":122,"additions":80,"deletions":42},"files":[{"sha":"cee65966051bea7c681e82c40f7d1a225b11dc8f","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/261bb8f671dc233d3b604b3355bb20d82edac539/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/261bb8f671dc233d3b604b3355bb20d82edac539/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=261bb8f671dc233d3b604b3355bb20d82edac539","patch":"@@ -168,6 +168,8 @@ Trunk (unreleased changes)\n \n         BOOKKEEPER-654: Bookkeeper client operations are allowed even after its closure, bk#close() (sijie via ivank)\n \n+        BOOKKEEPER-717: journal should look forward to group time-out entries (sijie via ivank)\n+\n       hedwig-server:\n \n         BOOKKEEPER-601: readahead cache size isn't updated correctly (sijie via fpj)"},{"sha":"f5d22e12b02521945b5056c0e8945aab50283c63","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","status":"modified","additions":29,"deletions":18,"changes":47,"blob_url":"https://github.com/apache/bookkeeper/blob/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","raw_url":"https://github.com/apache/bookkeeper/raw/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java?ref=261bb8f671dc233d3b604b3355bb20d82edac539","patch":"@@ -137,19 +137,19 @@ public String toString() {\n             this.curMark = new LogMark(logId, logPosition);\n         }\n \n-        synchronized void setCurLogMark(long logId, long logPosition) {\n+        void setCurLogMark(long logId, long logPosition) {\n             curMark.setLogMark(logId, logPosition);\n         }\n \n-        synchronized LastLogMark markLog() {\n+        LastLogMark markLog() {\n             return new LastLogMark(curMark.getLogFileId(), curMark.getLogFileOffset());\n         }\n \n-        synchronized LogMark getCurMark() {\n+        LogMark getCurMark() {\n             return curMark;\n         }\n \n-        synchronized void rollLog(LastLogMark lastMark) throws NoWritableLedgerDirException {\n+        void rollLog(LastLogMark lastMark) throws NoWritableLedgerDirException {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n             // we should record <logId, logPosition> marked in markLog\n@@ -184,7 +184,7 @@ synchronized void rollLog(LastLogMark lastMark) throws NoWritableLedgerDirExcept\n          * The last mark should first be max journal log id,\n          * and then max log position in max journal log.\n          */\n-        synchronized void readLog() {\n+        void readLog() {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n             LogMark mark = new LogMark();\n@@ -204,7 +204,7 @@ synchronized void readLog() {\n                     bb.clear();\n                     mark.readLogMark(bb);\n                     if (curMark.compare(mark) < 0) {\n-                        curMark.setLogMark(mark.getLogFileId(), mark.logFileOffset);\n+                        curMark.setLogMark(mark.getLogFileId(), mark.getLogFileOffset());\n                     }\n                 } catch (IOException e) {\n                     LOG.error(\"Problems reading from \" + file + \" (this is okay if it is the first time starting this bookie\");\n@@ -452,11 +452,11 @@ void shutdown() throws InterruptedException {\n \n     final File journalDirectory;\n     final ServerConfiguration conf;\n-    ForceWriteThread forceWriteThread;\n-    // should we group force writes\n-    private final boolean enableGroupForceWrites;\n+    final ForceWriteThread forceWriteThread;\n     // Time after which we will stop grouping and issue the flush\n     private final long maxGroupWaitInMSec;\n+    // Threshold after which we flush any buffered journal entries\n+    private final long bufferedEntriesThreshold;\n     // Threshold after which we flush any buffered journal writes\n     private final long bufferedWritesThreshold;\n     // should we flush if the queue is empty\n@@ -472,8 +472,8 @@ void shutdown() throws InterruptedException {\n     private final ExecutorService cbThreadPool;\n \n     // journal entry queue to commit\n-    LinkedBlockingQueue<QueueEntry> queue = new LinkedBlockingQueue<QueueEntry>();\n-    LinkedBlockingQueue<ForceWriteRequest> forceWriteRequests = new LinkedBlockingQueue<ForceWriteRequest>();\n+    final LinkedBlockingQueue<QueueEntry> queue = new LinkedBlockingQueue<QueueEntry>();\n+    final LinkedBlockingQueue<ForceWriteRequest> forceWriteRequests = new LinkedBlockingQueue<ForceWriteRequest>();\n \n     volatile boolean running = true;\n     private final LedgerDirsManager ledgerDirsManager;\n@@ -487,16 +487,16 @@ public Journal(ServerConfiguration conf, LedgerDirsManager ledgerDirsManager) {\n         this.journalPreAllocSize = conf.getJournalPreAllocSizeMB() * MB;\n         this.journalWriteBufferSize = conf.getJournalWriteBufferSizeKB() * KB;\n         this.maxBackupJournals = conf.getMaxBackupJournals();\n-        this.enableGroupForceWrites = conf.getJournalAdaptiveGroupWrites();\n-        this.forceWriteThread = new ForceWriteThread(this, enableGroupForceWrites);\n+        this.forceWriteThread = new ForceWriteThread(this, conf.getJournalAdaptiveGroupWrites());\n         this.maxGroupWaitInMSec = conf.getJournalMaxGroupWaitMSec();\n         this.bufferedWritesThreshold = conf.getJournalBufferedWritesThreshold();\n+        this.bufferedEntriesThreshold = conf.getJournalBufferedEntriesThreshold();\n         this.cbThreadPool = Executors.newFixedThreadPool(conf.getNumJournalCallbackThreads(),\n                                                          new DaemonThreadFactory());\n \n         // Unless there is a cap on the max wait (which requires group force writes)\n         // we cannot skip flushing for queue empty\n-        this.flushWhenQueueEmpty = !enableGroupForceWrites || conf.getJournalFlushWhenQueueEmpty();\n+        this.flushWhenQueueEmpty = maxGroupWaitInMSec <= 0 || conf.getJournalFlushWhenQueueEmpty();\n \n         this.removePagesFromCache = conf.getJournalRemovePagesFromCache();\n         // read last log mark\n@@ -679,7 +679,7 @@ public int getJournalQueueLength() {\n      * new journal file using current timestamp, and continue persistence logic.\n      * Those journals will be garbage collected in SyncThread.\n      * </p>\n-     * @see Bookie#SyncThread\n+     * @see org.apache.bookkeeper.bookie.SyncThread\n      */\n     @Override\n     public void run() {\n@@ -695,6 +695,7 @@ public void run() {\n             long logId = journalIds.isEmpty() ? System.currentTimeMillis() : journalIds.get(journalIds.size() - 1);\n             BufferedChannel bc = null;\n             long lastFlushPosition = 0;\n+            boolean groupWhenTimeout = false;\n \n             QueueEntry qe = null;\n             while (true) {\n@@ -723,10 +724,19 @@ public void run() {\n                         boolean shouldFlush = false;\n                         // We should issue a forceWrite if any of the three conditions below holds good\n                         // 1. If the oldest pending entry has been pending for longer than the max wait time\n-                        if (enableGroupForceWrites && (MathUtils.elapsedMSec(toFlush.getFirst().enqueueTime) > maxGroupWaitInMSec)) {\n+                        if (maxGroupWaitInMSec > 0 && !groupWhenTimeout && (MathUtils.elapsedMSec(toFlush.getFirst().enqueueTime) > maxGroupWaitInMSec)) {\n+                            groupWhenTimeout = true;\n+                        } else if (maxGroupWaitInMSec > 0 && groupWhenTimeout && qe != null && MathUtils.elapsedMSec(qe.enqueueTime) < maxGroupWaitInMSec) {\n+                            // when group timeout, it would be better to look forward, as there might be lots of entries already timeout\n+                            // due to a previous slow write (writing to filesystem which impacted by force write).\n+                            // Group those entries in the queue\n+                            // a) already timeout\n+                            // b) limit the number of entries to group\n+                            groupWhenTimeout = false;\n                             shouldFlush = true;\n-                        } else if ((bc.position() > lastFlushPosition + bufferedWritesThreshold)) {\n-                            // 2. If we have buffered more than the buffWriteThreshold\n+                        } else if ((bufferedEntriesThreshold > 0 && toFlush.size() > bufferedEntriesThreshold) ||\n+                                (bc.position() > lastFlushPosition + bufferedWritesThreshold)) {\n+                            // 2. If we have buffered more than the buffWriteThreshold or bufferedEntriesThreshold\n                             shouldFlush = true;\n                         } else if (qe == null) {\n                             // We should get here only if we flushWhenQueueEmpty is true else we would wait\n@@ -767,6 +777,7 @@ public void run() {\n                 if (qe == null) { // no more queue entry\n                     continue;\n                 }\n+\n                 lenBuff.clear();\n                 lenBuff.putInt(qe.entry.remaining());\n                 lenBuff.flip();"},{"sha":"4bf1e050754a974cbdc63a97c7d778b63647a51a","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","status":"modified","additions":10,"deletions":10,"changes":20,"blob_url":"https://github.com/apache/bookkeeper/blob/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","raw_url":"https://github.com/apache/bookkeeper/raw/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java?ref=261bb8f671dc233d3b604b3355bb20d82edac539","patch":"@@ -33,46 +33,46 @@ public LogMark() {\n     }\n \n     public LogMark(LogMark other) {\n-        setLogMark(other.logFileId, other.logFileOffset);\n+        setLogMark(other.getLogFileId(), other.getLogFileOffset());\n     }\n \n     public LogMark(long logFileId, long logFileOffset) {\n         setLogMark(logFileId, logFileOffset);\n     }\n \n-    public long getLogFileId() {\n+    public synchronized long getLogFileId() {\n         return logFileId;\n     }\n \n-    public long getLogFileOffset() {\n+    public synchronized long getLogFileOffset() {\n         return logFileOffset;\n     }\n \n-    public void readLogMark(ByteBuffer bb) {\n+    public synchronized void readLogMark(ByteBuffer bb) {\n         logFileId = bb.getLong();\n         logFileOffset = bb.getLong();\n     }\n \n-    public void writeLogMark(ByteBuffer bb) {\n+    public synchronized void writeLogMark(ByteBuffer bb) {\n         bb.putLong(logFileId);\n         bb.putLong(logFileOffset);\n     }\n \n-    public void setLogMark(long logFileId, long logFileOffset) {\n+    public synchronized void setLogMark(long logFileId, long logFileOffset) {\n         this.logFileId = logFileId;\n         this.logFileOffset = logFileOffset;\n     }\n \n-    public int compare(LogMark other) {\n-        long ret = this.logFileId - other.logFileId;\n+    public synchronized int compare(LogMark other) {\n+        long ret = this.logFileId - other.getLogFileId();\n         if (ret == 0) {\n-            ret = this.logFileOffset - other.logFileOffset;\n+            ret = this.logFileOffset - other.getLogFileOffset();\n         }\n         return (ret < 0)? -1 : ((ret > 0)? 1 : 0);\n     }\n \n     @Override\n-    public String toString() {\n+    public synchronized String toString() {\n         StringBuilder sb = new StringBuilder();\n \n         sb.append(\"LogMark: logFileId - \").append(logFileId)"},{"sha":"cfe9a03dcec2bffc43b6f2ee9919ca87bd58fc0d","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","status":"modified","additions":39,"deletions":14,"changes":53,"blob_url":"https://github.com/apache/bookkeeper/blob/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/261bb8f671dc233d3b604b3355bb20d82edac539/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java?ref=261bb8f671dc233d3b604b3355bb20d82edac539","patch":"@@ -57,6 +57,7 @@\n     protected final static String JOURNAL_ADAPTIVE_GROUP_WRITES = \"journalAdaptiveGroupWrites\";\n     protected final static String JOURNAL_MAX_GROUP_WAIT_MSEC = \"journalMaxGroupWaitMSec\";\n     protected final static String JOURNAL_BUFFERED_WRITES_THRESHOLD = \"journalBufferedWritesThreshold\";\n+    protected final static String JOURNAL_BUFFERED_ENTRIES_THRESHOLD = \"journalBufferedEntriesThreshold\";\n     protected final static String JOURNAL_FLUSH_WHEN_QUEUE_EMPTY = \"journalFlushWhenQueueEmpty\";\n     protected final static String JOURNAL_REMOVE_FROM_PAGE_CACHE = \"journalRemoveFromPageCache\";\n     protected final static String JOURNAL_PRE_ALLOC_SIZE = \"journalPreAllocSizeMB\";\n@@ -485,19 +486,19 @@ public ServerConfiguration setLedgerDirNames(String[] ledgerDirs) {\n         return ledgerDirs;\n     }\n \n-    /** \n+    /**\n      * Get dir name to store index files.\n-     *   \n+     *\n      * @return ledger index dir name, if no index dirs provided return null\n-     */  \n+     */\n     public String[] getIndexDirNames() {\n         if (!this.containsKey(INDEX_DIRS)) {\n             return null;\n         }\n         return this.getStringArray(INDEX_DIRS);\n-    }   \n+    }\n \n-    /** \n+    /**\n      * Set dir name to store index files.\n      *\n      * @param indexDirs\n@@ -718,18 +719,18 @@ public ServerConfiguration setMajorCompactionInterval(long interval) {\n         setProperty(MAJOR_COMPACTION_INTERVAL, interval);\n         return this;\n     }\n-    \n+\n     /**\n      * Set the grace period which the rereplication worker will wait before\n      * fencing and rereplicating a ledger fragment which is still being written\n      * to, on bookie failure.\n-     * \n-     * The grace period allows the writer to detect the bookie failure, and\n-     * start replicating the ledger fragment. If the writer writes nothing\n+     *\n+     * The grace period allows the writer to detect the bookie failure, and and\n+     * start writing to another ledger fragment. If the writer writes nothing\n      * during the grace period, the rereplication worker assumes that it has\n-     * crashed and fences the ledger, preventing any further writes to that \n-     * ledger.\n-     * \n+     * crashed and therefore fences the ledger, preventing any further writes to\n+     * that ledger.\n+     *\n      * @see org.apache.bookkeeper.client.BookKeeper#openLedger\n      * \n      * @param waitTime time to wait before replicating ledger fragment\n@@ -885,14 +886,38 @@ public long getJournalMaxGroupWaitMSec() {\n     }\n \n     /**\n-     * Maximum latency to impose on a journal write to achieve grouping\n+     * Maximum bytes to buffer to impose on a journal write to achieve grouping\n      *\n-     * @return max wait for grouping\n+     * @return max bytes to buffer\n      */\n     public long getJournalBufferedWritesThreshold() {\n         return getLong(JOURNAL_BUFFERED_WRITES_THRESHOLD, 512 * 1024);\n     }\n \n+    /**\n+     * Maximum entries to buffer to impose on a journal write to achieve grouping.\n+     * Use {@link #getJournalBufferedWritesThreshold()} if this is set to zero or\n+     * less than zero.\n+     *\n+     * @return max entries to buffer.\n+     */\n+    public long getJournalBufferedEntriesThreshold() {\n+        return getLong(JOURNAL_BUFFERED_ENTRIES_THRESHOLD, 0);\n+    }\n+\n+    /**\n+     * Set maximum entries to buffer to impose on a journal write to achieve grouping.\n+     * Use {@link #getJournalBufferedWritesThreshold()} set this to zero or less than\n+     * zero.\n+     *\n+     * @param maxEntries\n+     *          maximum entries to buffer.\n+     * @return server configuration.\n+     */\n+    public ServerConfiguration setJournalBufferedEntriesThreshold(int maxEntries) {\n+        setProperty(JOURNAL_BUFFERED_ENTRIES_THRESHOLD, maxEntries);\n+        return this;\n+    }\n \n     /**\n      * Set if we should flush the journal when queue is empty"}]}

