{"sha":"2d427e8d4b2c1d889ab5586e28e198c140a10489","node_id":"MDY6Q29tbWl0MTU3NTk1NjoyZDQyN2U4ZDRiMmMxZDg4OWFiNTU4NmUyOGUxOThjMTQwYTEwNDg5","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-03-07T17:39:37Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-03-07T17:39:37Z"},"message":"BOOKKEEPER-363: Re-distributing topics among newly added hubs. (aniruddha via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1575338 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"e7a8aa33d120d8ab80e2fe3543d8fb11a105783d","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/e7a8aa33d120d8ab80e2fe3543d8fb11a105783d"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/2d427e8d4b2c1d889ab5586e28e198c140a10489","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/2d427e8d4b2c1d889ab5586e28e198c140a10489","html_url":"https://github.com/apache/bookkeeper/commit/2d427e8d4b2c1d889ab5586e28e198c140a10489","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/2d427e8d4b2c1d889ab5586e28e198c140a10489/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"9d4ce1671cd6731b9b9652399c24a91c34e0bc65","url":"https://api.github.com/repos/apache/bookkeeper/commits/9d4ce1671cd6731b9b9652399c24a91c34e0bc65","html_url":"https://github.com/apache/bookkeeper/commit/9d4ce1671cd6731b9b9652399c24a91c34e0bc65"}],"stats":{"total":756,"additions":701,"deletions":55},"files":[{"sha":"3f8a328cde5e83cb2147837eaac6d7a9c725d04f","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -182,6 +182,8 @@ Trunk (unreleased changes)\n \n         BOOKKEEPER-683: TestSubAfterCloseSub fails on 4.2 (jiannan via ivank)\n \n+        BOOKKEEPER-363: Re-distributing topics among newly added hubs. (aniruddha via ivank)\n+\n       hedwig-client:\n \n         BOOKKEEPER-598: Fails to compile - RESUBSCRIBE_EXCEPTION conflict (Matthew Farrellee via sijie)"},{"sha":"237c7dec646a12202b15e56607836f4fce82acab","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","status":"modified","additions":71,"deletions":33,"changes":104,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -27,15 +27,16 @@\n import java.util.LinkedList;\n import java.util.List;\n \n+import org.apache.bookkeeper.util.ReflectionUtils;\n import org.apache.commons.configuration.ConfigurationException;\n import org.apache.commons.lang.StringUtils;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.bookkeeper.util.ReflectionUtils;\n import org.apache.hedwig.conf.AbstractConfiguration;\n import org.apache.hedwig.server.meta.MetadataManagerFactory;\n+import org.apache.hedwig.server.topics.HubLoad;\n import org.apache.hedwig.util.HedwigSocketAddress;\n \n+import com.google.protobuf.ByteString;\n+\n public class ServerConfiguration extends AbstractConfiguration {\n     public final static String REGION = \"region\";\n     protected final static String MAX_MESSAGE_SIZE = \"max_message_size\";\n@@ -75,6 +76,9 @@\n     protected final static String NUM_DELIVERY_THREADS = \"num_delivery_threads\";\n \n     protected final static String MAX_ENTRIES_PER_LEDGER = \"max_entries_per_ledger\";\n+    protected final static String REBALANCE_TOLERANCE_PERCENTAGE = \"rebalance_tolerance\";\n+    protected final static String REBALANCE_MAX_SHED = \"rebalance_max_shed\";\n+    protected final static String REBALANCE_INTERVAL_SEC = \"rebalance_interval_sec\";\n \n     // manager related settings\n     protected final static String METADATA_MANAGER_BASED_TOPIC_MANAGER_ENABLED = \"metadata_manager_based_topic_manager_enabled\";\n@@ -153,7 +157,7 @@ public ByteString getMyRegionByteString() {\n \n     /**\n      * Maximum number of messages to read ahead. Default is 10.\n-     * \n+     *\n      * @return int\n      */\n     public int getReadAheadCount() {\n@@ -162,7 +166,7 @@ public int getReadAheadCount() {\n \n     /**\n      * Maximum number of bytes to read ahead. Default is 4MB.\n-     * \n+     *\n      * @return long\n      */\n     public long getReadAheadSizeBytes() {\n@@ -172,7 +176,7 @@ public long getReadAheadSizeBytes() {\n     /**\n      * Maximum cache size. By default is the smallest of 2G or\n      * half the heap size.\n-     * \n+     *\n      * @return long\n      */\n     public long getMaximumCacheSize() {\n@@ -193,16 +197,16 @@ public long getCacheEntryTTL() {\n \n     /**\n      * After a scan of a log fails, how long before we retry (in msec)\n-     * \n+     *\n      * @return long\n      */\n     public long getScanBackoffPeriodMs() {\n         return conf.getLong(SCAN_BACKOFF_MSEC, 1000);\n     }\n-    \n+\n     /**\n      * Returns server port.\n-     * \n+     *\n      * @return int\n      */\n     public int getServerPort() {\n@@ -211,7 +215,7 @@ public int getServerPort() {\n \n     /**\n      * Returns SSL server port.\n-     * \n+     *\n      * @return int\n      */\n     public int getSSLServerPort() {\n@@ -220,7 +224,7 @@ public int getSSLServerPort() {\n \n     /**\n      * Returns ZooKeeper path prefix.\n-     * \n+     *\n      * @return string\n      */\n     public String getZkPrefix() {\n@@ -263,7 +267,7 @@ public HedwigSocketAddress getServerAddr() {\n \n     /**\n      * Return ZooKeeper list of servers. Default is localhost.\n-     * \n+     *\n      * @return String\n      */\n     public String getZkHost() {\n@@ -276,16 +280,16 @@ public String getZkHost() {\n \n     /**\n      * Return ZooKeeper session timeout. Default is 2s.\n-     * \n+     *\n      * @return int\n      */\n     public int getZkTimeout() {\n         return conf.getInt(ZK_TIMEOUT, 2000);\n     }\n \n-    /** \n+    /**\n      * Returns true if read-ahead enabled. Default is true.\n-     * \n+     *\n      * @return boolean\n      */\n     public boolean getReadAheadEnabled() {\n@@ -296,16 +300,16 @@ public boolean getReadAheadEnabled() {\n \n     /**\n      * Returns true if standalone. Default is false.\n-     * \n+     *\n      * @return boolean\n      */\n     public boolean isStandalone() {\n         return conf.getBoolean(STANDALONE, false);\n     }\n \n     /**\n-     * Returns list of regions. \n-     * \n+     * Returns list of regions.\n+     *\n      * @return List<String>\n      */\n     public List<String> getRegions() {\n@@ -317,7 +321,7 @@ public boolean isStandalone() {\n \n     /**\n      *  Returns the name of the SSL certificate if available as a resource.\n-     * \n+     *\n      * @return String\n      */\n     public String getCertName() {\n@@ -326,7 +330,7 @@ public String getCertName() {\n \n     /**\n      * This is the path to the SSL certificate if it is available as a file.\n-     * \n+     *\n      * @return String\n      */\n     public String getCertPath() {\n@@ -351,7 +355,7 @@ public InputStream getCertStream() throws FileNotFoundException, ConfigurationEx\n     /**\n      * Returns the password used for BookKeeper ledgers. Default\n      * is the empty string.\n-     * \n+     *\n      * @return\n      */\n     public String getPassword() {\n@@ -360,7 +364,7 @@ public String getPassword() {\n \n     /**\n      * Returns true if SSL is enabled. Default is false.\n-     * \n+     *\n      * @return boolean\n      */\n     public boolean isSSLEnabled() {\n@@ -372,7 +376,7 @@ public boolean isSSLEnabled() {\n      * information about consumed messages. A value greater than\n      * one avoids persisting information about consumed messages\n      * upon every consumed message. Default is 50.\n-     * \n+     *\n      * @return int\n      */\n     public int getConsumeInterval() {\n@@ -383,7 +387,7 @@ public int getConsumeInterval() {\n      * Returns the interval to release a topic. If this\n      * parameter is greater than zero, then schedule a\n      * task to release an owned topic. Default is 0 (never released).\n-     * \n+     *\n      * @return int\n      */\n     public int getRetentionSecs() {\n@@ -422,18 +426,18 @@ public int getInitNumTopics() {\n \n     /**\n      * True if SSL is enabled across regions.\n-     * \n+     *\n      * @return boolean\n      */\n     public boolean isInterRegionSSLEnabled() {\n         return conf.getBoolean(INTER_REGION_SSL_ENABLED, false);\n     }\n \n     /**\n-     * This parameter is used to determine how often we run the \n-     * SubscriptionManager's Messages Consumed timer task thread \n+     * This parameter is used to determine how often we run the\n+     * SubscriptionManager's Messages Consumed timer task thread\n      * (in milliseconds).\n-     * \n+     *\n      * @return int\n      */\n     public int getMessagesConsumedThreadRunInterval() {\n@@ -444,7 +448,7 @@ public int getMessagesConsumedThreadRunInterval() {\n      * This parameter is used to determine how often we run a thread\n      * to retry those failed remote subscriptions in asynchronous mode\n      * (in milliseconds).\n-     * \n+     *\n      * @return int\n      */\n     public int getRetryRemoteSubscribeThreadRunInterval() {\n@@ -455,7 +459,7 @@ public int getRetryRemoteSubscribeThreadRunInterval() {\n      * This parameter is for setting the default maximum number of messages which\n      * can be delivered to a subscriber without being consumed.\n      * we pause messages delivery to a subscriber when reaching the window size\n-     * \n+     *\n      * @return int\n      */\n     public int getDefaultMessageWindowSize() {\n@@ -466,7 +470,7 @@ public int getDefaultMessageWindowSize() {\n      * This parameter is used when Bookkeeper is the persistence\n      * store and indicates what the ensemble size is (i.e. how\n      * many bookie servers to stripe the ledger entries across).\n-     * \n+     *\n      * @return int\n      */\n     public int getBkEnsembleSize() {\n@@ -478,7 +482,7 @@ public int getBkEnsembleSize() {\n      * This parameter is used when Bookkeeper is the persistence store\n      * and indicates what the quorum size is (i.e. how many redundant\n      * copies of each ledger entry is written).\n-     * \n+     *\n      * @return int\n      * @deprecated please use #getBkWriteQuorumSize() and #getBkAckQuorumSize()\n      */\n@@ -525,6 +529,33 @@ public long getMaxEntriesPerLedger() {\n         return conf.getLong(MAX_ENTRIES_PER_LEDGER, 0L);\n     }\n \n+    /**\n+     * Get the tolerance percentage for the rebalancer. The rebalancer will not\n+     * shed load if it's current load is less than average + average*tolerancePercentage/100.0\n+     *\n+     * @return the tolerance percentage for the rebalancer.\n+     */\n+    public double getRebalanceTolerance() {\n+        return conf.getDouble(REBALANCE_TOLERANCE_PERCENTAGE, 10.0);\n+    }\n+\n+    /**\n+     * Get the maximum load the rebalancer can shed at once. Default is 50.\n+     * @return\n+     */\n+    public HubLoad getRebalanceMaxShed() {\n+        return new HubLoad(conf.getLong(REBALANCE_MAX_SHED, 50));\n+    }\n+\n+    /**\n+     * Get the interval(in seconds) between rebalancing attempts. The default is\n+     * 5 minutes.\n+     * @return\n+     */\n+    public long getRebalanceInterval() {\n+        return conf.getLong(REBALANCE_INTERVAL_SEC, 300);\n+    }\n+\n     /*\n      * Is this a valid configuration that we can run with? This code might grow\n      * over time.\n@@ -553,7 +584,14 @@ public void validate() throws ConfigurationException {\n             throw new ConfigurationException(\"BK write quorum size (\" + getBkWriteQuorumSize()\n                                              + \") is less than the ack quorum size (\" + getBkAckQuorumSize() + \")\");\n         }\n-\n+        // Validate that the rebalance tolerance percentage is not negative.\n+        if (getRebalanceTolerance() < 0.0) {\n+            throw new ConfigurationException(\"The rebalance tolerance percentage cannot be negative.\");\n+        }\n+        // Validate that the maximum load to shed during a rebalance is not negative.\n+        if (getRebalanceMaxShed().getNumTopics() < 0L) {\n+            throw new ConfigurationException(\"The maximum load to shed during a rebalance cannot be negative.\");\n+        }\n         // add other checks here\n     }\n "},{"sha":"2d9aba23e71a2ac9166f3706681d8f4961c64356","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","status":"modified","additions":58,"deletions":10,"changes":68,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -20,25 +20,25 @@\n import java.net.UnknownHostException;\n import java.util.ArrayList;\n import java.util.Collections;\n-import java.util.HashSet;\n-import java.util.Set;\n+import java.util.List;\n import java.util.concurrent.ScheduledExecutorService;\n import java.util.concurrent.TimeUnit;\n \n+import org.apache.hedwig.exceptions.PubSubException;\n+import org.apache.hedwig.server.common.ServerConfiguration;\n+import org.apache.hedwig.server.common.TopicOpQueuer;\n+import org.apache.hedwig.util.Callback;\n+import org.apache.hedwig.util.CallbackUtils;\n+import org.apache.hedwig.util.HedwigSocketAddress;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n-import com.google.protobuf.ByteString;\n import com.google.common.cache.Cache;\n import com.google.common.cache.CacheBuilder;\n import com.google.common.cache.RemovalListener;\n import com.google.common.cache.RemovalNotification;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TopicOpQueuer;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.CallbackUtils;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n+import com.google.common.collect.Lists;\n+import com.google.protobuf.ByteString;\n \n public abstract class AbstractTopicManager implements TopicManager {\n \n@@ -204,15 +204,17 @@ public void run() {\n             public void operationFailed(final Object ctx, final PubSubException exception) {\n                 // TODO: optimization: we can release this as soon as we experience the first error.\n                 Callback<Void> cb = new Callback<Void>() {\n+                    @Override\n                     public void operationFinished(Object _ctx, Void _resultOfOperation) {\n                         originalCallback.operationFailed(ctx, exception);\n                     }\n+                    @Override\n                     public void operationFailed(Object _ctx, PubSubException _exception) {\n                         logger.error(\"Exception releasing topic\", _exception);\n                         originalCallback.operationFailed(ctx, exception);\n                     }\n                 };\n-                \n+\n                 realReleaseTopic(topic, cb, originalContext);\n             }\n         };\n@@ -241,6 +243,52 @@ public final void releaseTopic(ByteString topic, Callback<Void> cb, Object ctx)\n         queuer.pushAndMaybeRun(topic, new ReleaseOp(topic, cb, ctx));\n     }\n \n+    @Override\n+    public final void releaseTopics(int numTopics, final Callback<Long> callback, final Object ctx) {\n+        // This is a best effort function. We sacrifice accuracy to not hold a lock on the topics set.\n+        List<ByteString> topicList = getTopicList();\n+        // Make sure we release only as many topics as we own.\n+        final long numTopicsToRelease = Math.min(topicList.size(), numTopics);\n+        // Shuffle the list of topics we own, so that we release a random subset.\n+        Collections.shuffle(topicList);\n+        Callback<Void> mcb = CallbackUtils.multiCallback((int)numTopicsToRelease, new Callback<Void>() {\n+            @Override\n+            public void operationFinished(Object ctx, Void ignoreVal) {\n+                callback.operationFinished(ctx, numTopicsToRelease);\n+            }\n+\n+            @Override\n+            public void operationFailed(Object ctx, PubSubException e) {\n+                long notReleased = 0;\n+                if (e instanceof PubSubException.CompositeException) {\n+                    notReleased = ((PubSubException.CompositeException)e).getExceptions().size();\n+                }\n+                callback.operationFinished(ctx, numTopicsToRelease - notReleased);\n+            }\n+        }, ctx);\n+\n+        // Try to release \"numTopicsToRelease\" topics. It's okay if we're not\n+        // able to release some topics. We signal that we tried by invoking the callback's\n+        // operationFinished() with the actual number of topics released.\n+        logger.info(\"This hub is releasing {} topics\", numTopicsToRelease);\n+        long releaseCount = 0;\n+        for (ByteString topic : topicList) {\n+            if (++releaseCount > numTopicsToRelease) {\n+                break;\n+            }\n+            releaseTopic(topic, mcb, ctx);\n+        }\n+    }\n+\n+    @Override\n+    public List<ByteString> getTopicList() {\n+        List<ByteString> topicList;\n+        synchronized (this.topics) {\n+            topicList = Lists.newArrayList(this.topics.asMap().keySet());\n+        }\n+        return topicList;\n+    }\n+\n     /**\n      * This method should \"return\" the owner of the topic if one has been chosen\n      * already. If there is no pre-chosen owner, either this hub or some other"},{"sha":"2f76020408120c289d8d3c7821e6a2acebbd6f2c","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","status":"modified","additions":8,"deletions":1,"changes":9,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -38,6 +38,8 @@\n     public static final HubLoad MIN_LOAD = new HubLoad(0);\n \n     public static class InvalidHubLoadException extends Exception {\n+        private static final long serialVersionUID = 5870487176956413387L;\n+\n         public InvalidHubLoadException(String msg) {\n             super(msg);\n         }\n@@ -48,7 +50,7 @@ public InvalidHubLoadException(String msg, Throwable t) {\n     }\n \n     // how many topics that a hub server serves\n-    long numTopics; \n+    long numTopics;\n \n     public HubLoad(long num) {\n         this.numTopics = num;\n@@ -58,11 +60,16 @@ public HubLoad(HubLoadData data) {\n         this.numTopics = data.getNumTopics();\n     }\n \n+    // TODO: Make this threadsafe (BOOKKEEPER-379)\n     public HubLoad setNumTopics(long numTopics) {\n         this.numTopics = numTopics;\n         return this;\n     }\n \n+    public long getNumTopics() {\n+        return this.numTopics;\n+    }\n+\n     public HubLoadData toHubLoadData() {\n         return HubLoadData.newBuilder().setNumTopics(numTopics).build();\n     }"},{"sha":"12524c924e2cda88f8a8280419681e0ef3bc8340","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","status":"modified","additions":16,"deletions":0,"changes":16,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -105,4 +105,20 @@\n      *          Callback context.\n      */\n     public void chooseLeastLoadedHub(Callback<HubInfo> callback, Object ctx);\n+\n+    /**\n+     * Try to rebalance the load within the cluster. This function will get\n+     * the {@link HubLoad} from all available hubs within the cluster, and then\n+     * shed additional load.\n+     *\n+     * @param tolerancePercentage\n+     *          the percentage of load above average that is permissible.\n+     * @param maxLoadToShed\n+     *          the maximum amount of load to shed per call.\n+     * @param callback\n+     *          Callback indicating whether we reduced load or not.\n+     * @param ctx\n+     */\n+    public void rebalanceCluster(double tolerancePercentage, HubLoad maxLoadToShed,\n+                                 Callback<Boolean> callback, Object ctx);\n }"},{"sha":"98b491b603272e7321d9eb3509783ef728f230b7","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","status":"modified","additions":7,"deletions":2,"changes":9,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -60,14 +60,14 @@\n     // all of the Ops put into the queuer will fail automatically.\n     protected volatile boolean isSuspended = false;\n \n-    public MMTopicManager(ServerConfiguration cfg, ZooKeeper zk, \n+    public MMTopicManager(ServerConfiguration cfg, ZooKeeper zk,\n                           MetadataManagerFactory mmFactory,\n                           ScheduledExecutorService scheduler)\n             throws UnknownHostException, PubSubException {\n         super(cfg, scheduler);\n         // initialize topic ownership manager\n         this.mm = mmFactory.newTopicOwnershipManager();\n-        this.hubManager = new ZkHubServerManager(cfg, zk, addr);\n+        this.hubManager = new ZkHubServerManager(cfg, zk, addr, this);\n \n         final SynchronousQueue<Either<HubInfo, PubSubException>> queue =\n             new SynchronousQueue<Either<HubInfo, PubSubException>>();\n@@ -289,6 +289,11 @@ public void operationFailed(Object ctx, PubSubException exception) {\n     @Override\n     protected void postReleaseCleanup(final ByteString topic,\n                                       final Callback<Void> cb, final Object ctx) {\n+\n+        // Reduce load. We've removed the topic from our topic set, so do this as well.\n+        // When we reclaim the topic, we will increment the load again.\n+        hubManager.uploadSelfLoadData(myHubLoad.setNumTopics(topics.size()));\n+\n         mm.readOwnerInfo(topic, new Callback<Versioned<HubInfo>>() {\n             @Override\n             public void operationFinished(Object ctx, Versioned<HubInfo> owner) {"},{"sha":"2a0dcc04b09f8694c86063b6427650ab72c8519c","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","status":"added","additions":151,"deletions":0,"changes":151,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hedwig.server.topics;\n+\n+import java.util.List;\n+import java.util.Map;\n+\n+import org.apache.hedwig.exceptions.PubSubException;\n+import org.apache.hedwig.util.Callback;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.google.protobuf.ByteString;\n+\n+/**\n+ * Shed load by releasing topics.\n+ */\n+public class TopicBasedLoadShedder {\n+    private static final Logger logger = LoggerFactory.getLogger(TopicBasedLoadShedder.class);\n+    private final double tolerancePercentage;\n+    private final long maxLoadToShed;\n+    private final TopicManager tm;\n+    private final List<ByteString> topicList;\n+\n+    /**\n+     * @param tm The topic manager used to handle load shedding\n+     * @param tolerancePercentage The tolerance percentage for shedding load\n+     * @param maxLoadToShed The maximum amoung of load to shed in one call.\n+     */\n+    public TopicBasedLoadShedder(TopicManager tm, double tolerancePercentage,\n+                                 HubLoad maxLoadToShed) {\n+        // Make sure that all functions in this class have a consistent view\n+        // of the load. So, we use the same topic list throughout.\n+        this(tm, tm.getTopicList(), tolerancePercentage, maxLoadToShed);\n+    }\n+\n+    /**\n+     * This is public because it makes testing easier.\n+     * @param tm The topic manager used to handle load shedding\n+     * @param topicList The topic list representing topics owned by this hub.\n+     * @param tolerancePercentage The tolerance percentage for shedding load\n+     * @param maxLoadToShed The maximum amoung of load to shed in one call.\n+     */\n+    TopicBasedLoadShedder(TopicManager tm, List<ByteString> topicList,\n+                          double tolerancePercentage,\n+                          HubLoad maxLoadToShed) {\n+        this.tolerancePercentage = tolerancePercentage;\n+        this.maxLoadToShed = maxLoadToShed.getNumTopics();\n+        this.tm = tm;\n+        this.topicList = topicList;\n+    }\n+\n+    /**\n+     * Reduce the load on the current hub so that it reaches the target load.\n+     * We reduce load by releasing topics using the {@link TopicManager} passed\n+     * to the constructor. We use {@link TopicManager#releaseTopics(int, org.apache.hedwig.util.Callback, Object)}\n+     * to actually release topics.\n+     *\n+     * @param targetLoad\n+     * @param callback\n+     *              a Callback<Long> that indicates how many topics we tried to release.\n+     * @param ctx\n+     */\n+    public void reduceLoadTo(HubLoad targetLoad, final Callback<Long> callback, final Object ctx) {\n+        int targetTopics = (int)targetLoad.toHubLoadData().getNumTopics();\n+        int numTopicsToRelease = topicList.size() - targetTopics;\n+\n+        // The number of topics we own is less than the target topic size. We don't release\n+        // any topics in this case.\n+        if (numTopicsToRelease <= 0) {\n+            callback.operationFinished(ctx, 0L);\n+            return;\n+        }\n+        // Call releaseTopics() on the topic manager to do this. We let the manager handle the release\n+        // policy.\n+        tm.releaseTopics(numTopicsToRelease, callback, ctx);\n+    }\n+\n+    /**\n+     * Calculate the average number of topics on the currently active hubs and release topics\n+     * if required.\n+     * We shed topics if we currently hold topics greater than average + average * tolerancePercentage/100.0\n+     * We shed a maximum of maxLoadToShed topics\n+     * We also hold on to at least one topic.\n+     * @param loadMap\n+     * @param callback\n+     *          A return value of true means we tried to rebalance. False means that there was\n+     *          no need to rebalance.\n+     * @param ctx\n+     */\n+    public void shedLoad(final Map<HubInfo, HubLoad> loadMap, final Callback<Boolean> callback,\n+                         final Object ctx) {\n+\n+        long totalTopics = 0L;\n+        long myTopics = topicList.size();\n+        for (Map.Entry<HubInfo, HubLoad> entry : loadMap.entrySet()) {\n+            if (null == entry.getKey() || null == entry.getValue()) {\n+                continue;\n+            }\n+            totalTopics += entry.getValue().toHubLoadData().getNumTopics();\n+        }\n+\n+        double averageTopics = (double)totalTopics/loadMap.size();\n+        logger.info(\"Total topics in the cluster : {}. Average : {}.\", totalTopics, averageTopics);\n+\n+        // Handle the case when averageTopics == 0. We hold on to at least 1 topic.\n+        long permissibleTopics =\n+            Math.max(1L, (long) Math.ceil(averageTopics + averageTopics * tolerancePercentage / 100.0));\n+        logger.info(\"Permissible topics : {}. Number of topics this hub holds : {}.\", permissibleTopics, myTopics);\n+        if (myTopics <= permissibleTopics) {\n+            // My owned topics are less than those permitted by the current tolerance level. No need to release\n+            // any topics.\n+            callback.operationFinished(ctx, false);\n+            return;\n+        }\n+\n+        // The number of topics I own is more than what I should be holding. We shall now attempt to shed some load.\n+        // We shed at most maxLoadToShed number of topics. We also hold on to at least 1 topic.\n+        long targetNumTopics = Math.max(1L, Math.max((long)Math.ceil(averageTopics), myTopics - maxLoadToShed));\n+\n+        // Reduce the load on the current hub to the target load we calculated above.\n+        logger.info(\"Reducing load on this hub to {} topics.\", targetNumTopics);\n+        reduceLoadTo(new HubLoad(targetNumTopics), new Callback<Long>() {\n+            @Override\n+            public void operationFinished(Object ctx, Long numReleased) {\n+                logger.info(\"Released {} topics to shed load.\", numReleased);\n+                callback.operationFinished(ctx, true);\n+            }\n+\n+            @Override\n+            public void operationFailed(Object ctx, PubSubException e) {\n+                callback.operationFailed(ctx, e);\n+            }\n+        }, ctx);\n+    }\n+}"},{"sha":"4ed2e59e04214200ab330ac40a6bb0323ac63782","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","status":"modified","additions":19,"deletions":0,"changes":19,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -23,6 +23,8 @@\n import org.apache.hedwig.util.Callback;\n import org.apache.hedwig.util.HedwigSocketAddress;\n \n+import java.util.List;\n+\n /**\n  * An implementor of this interface is basically responsible for ensuring that\n  * there is at most a single host responsible for a given topic at a given time.\n@@ -80,6 +82,23 @@ public void getOwner(ByteString topic, boolean shouldClaim,\n      */\n     public void releaseTopic(ByteString topic, Callback<Void> cb, Object ctx);\n \n+    /**\n+     * Release numTopics topics. If you hold fewer, release all.\n+     * @param numTopics\n+     *          Number of topics to release.\n+     * @param callback\n+     *          The callback should be invoked with the number of topics the hub\n+     *          released successfully.\n+     * @param ctx\n+     */\n+    public void releaseTopics(int numTopics, Callback<Long> callback, Object ctx);\n+\n+    /**\n+     * Get the list of topics this hub believes it is responsible for.\n+     * @return\n+     */\n+    public List<ByteString> getTopicList();\n+\n     /**\n      * Stop topic manager\n      */"},{"sha":"9651058394eae394c3c7b1f5c62f96f1a3f3d8a4","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","status":"modified","additions":170,"deletions":8,"changes":178,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -17,11 +17,16 @@\n  */\n package org.apache.hedwig.server.topics;\n \n+import static com.google.common.base.Charsets.UTF_8;\n+\n import java.io.IOException;\n+import java.util.HashMap;\n import java.util.List;\n+import java.util.Map;\n import java.util.Random;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n \n import org.apache.hedwig.exceptions.PubSubException;\n import org.apache.hedwig.server.common.ServerConfiguration;\n@@ -38,7 +43,6 @@\n import org.apache.zookeeper.ZooDefs.Ids;\n import org.apache.zookeeper.ZooKeeper;\n import org.apache.zookeeper.data.Stat;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -54,13 +58,15 @@\n     private final ServerConfiguration conf;\n     private final ZooKeeper zk;\n     private final HedwigSocketAddress addr;\n+    private final TopicManager tm;\n     private final String ephemeralNodePath;\n     private final String hubNodesPath;\n \n     // hub info structure represent itself\n     protected HubInfo myHubInfo;\n     protected volatile boolean isSuspended = false;\n     protected ManagerListener listener = null;\n+    protected final ScheduledExecutorService executor;\n \n     // upload hub server load to zookeeper\n     StatCallback loadReportingStatCallback = new StatCallback() {\n@@ -100,25 +106,90 @@ public void process(WatchedEvent event) {\n             if (event.getState().equals(Watcher.Event.KeeperState.Expired)) {\n                 logger.error(\"ZK client connection to the ZK server has expired.!\");\n                 if (null != listener) {\n+                    // Shutdown our executor NOW!\n+                    executor.shutdownNow();\n                     listener.onShutdown();\n                 }\n             }\n         }\n     }\n \n+    class RebalanceRunnable implements Runnable {\n+        private final double tolerancePercentage;\n+        private final HubLoad maxLoadToShed;\n+        private final long delaySeconds;\n+\n+        public RebalanceRunnable(double tolerancePercentage,\n+                                 HubLoad maxLoadToShed,\n+                                 long delaySeconds) {\n+            this.tolerancePercentage = tolerancePercentage;\n+            this.maxLoadToShed = maxLoadToShed;\n+            this.delaySeconds = delaySeconds;\n+        }\n+\n+        @Override\n+        public void run() {\n+            // If we are in suspended state, don't attempt a rebalance.\n+            if (isSuspended) {\n+                executor.schedule(this, delaySeconds, TimeUnit.SECONDS);\n+                return;\n+            }\n+            // We should attempt a rebalance. We reschedule the job at the tail so that\n+            // two rebalances don't happen simultaneously.\n+            rebalanceCluster(tolerancePercentage, maxLoadToShed, new Callback<Boolean>() {\n+                private void reschedule(Runnable task) {\n+                    executor.schedule(task, delaySeconds, TimeUnit.SECONDS);\n+                }\n+\n+                @Override\n+                public void operationFinished(Object ctx, Boolean didRebalance) {\n+                    if (didRebalance == true) {\n+                        logger.info(\"The attempt to rebalance the cluster was successful\");\n+                    } else {\n+                        logger.info(\"There was no need to rebalance.\");\n+                    }\n+                    // Our original runnable was passed as the context.\n+                    reschedule((Runnable)ctx);\n+                }\n+\n+                @Override\n+                public void operationFailed(Object ctx, PubSubException e) {\n+                    logger.error(\"The attempt to rebalance the cluster did not succeed.\", e);\n+                    // Reschedule the job\n+                    reschedule((Runnable)ctx);\n+                }\n+            }, this);\n+        }\n+\n+        public void start() {\n+            // Initiate only if delaySeconds > 0\n+            if (delaySeconds > 0) {\n+                logger.info(\"Starting the rebalancer thread with tolerance={}, maxLoadToShed={} and delay={}\",\n+                    new Object[] { tolerancePercentage, maxLoadToShed.getNumTopics(), delaySeconds });\n+                executor.schedule(this, delaySeconds, TimeUnit.SECONDS);\n+            }\n+        }\n+    }\n+\n     public ZkHubServerManager(ServerConfiguration conf,\n                               ZooKeeper zk,\n-                              HedwigSocketAddress addr) {\n+                              HedwigSocketAddress addr,\n+                              TopicManager tm) {\n         this.conf = conf;\n         this.zk = zk;\n         this.addr = addr;\n-\n+        this.tm = tm;\n         // znode path to store all available hub servers\n         this.hubNodesPath = this.conf.getZkHostsPrefix(new StringBuilder()).toString();\n         // the node's ephemeral node path\n         this.ephemeralNodePath = getHubZkNodePath(addr);\n+        this.executor = Executors.newSingleThreadScheduledExecutor();\n         // register available hub servers list watcher\n         zk.register(new ZkHubsWatcher());\n+\n+        // Start the rebalancer here.\n+        new RebalanceRunnable(conf.getRebalanceTolerance(), conf.getRebalanceMaxShed(),\n+                              conf.getRebalanceInterval()).start();\n     }\n \n     @Override\n@@ -157,7 +228,7 @@ public void safeProcessResult(int rc, String path, Object ctx, Stat stat) {\n                                 return;\n                             } else {\n                                 callback.operationFailed(ctx,\n-                                    new PubSubException.ServiceDownException(\n+                                        new PubSubException.ServiceDownException(\n                                         \"I can't state my hub node after I created it : \"\n                                         + ephemeralNodePath));\n                                 return;\n@@ -167,7 +238,7 @@ public void safeProcessResult(int rc, String path, Object ctx, Stat stat) {\n                     return;\n                 }\n                 if (rc != Code.NODEEXISTS.intValue()) {\n-                    KeeperException ke = ZkUtils .logErrorAndCreateZKException(\n+                    KeeperException ke = ZkUtils.logErrorAndCreateZKException(\n                             \"Could not create ephemeral node to register hub\", ephemeralNodePath, rc);\n                     callback.operationFailed(ctx, new PubSubException.ServiceDownException(ke));\n                     return;\n@@ -283,7 +354,7 @@ public void safeProcessResult(int rc, String path, Object ctx,\n \n                     if (numResponses == children.size()) {\n                         if (leastLoaded == null) {\n-                            callback.operationFailed(ctx, \n+                            callback.operationFailed(ctx,\n                                 new PubSubException.ServiceDownException(\"No hub available\"));\n                             return;\n                         }\n@@ -305,4 +376,95 @@ public void safeProcessResult(int rc, String path, Object ctx,\n                        dataCallback, child);\n         }\n     }\n+\n+    /**\n+     * Get a map of all currently active hubs with their advertised load.\n+     * @param callback\n+     * @param originalCtx\n+     */\n+    private void getActiveHubsInfoWithLoad(final Callback<Map<HubInfo, HubLoad>> callback,\n+                                           final Object originalCtx) {\n+        // Get the list of children and then for each child, get the data. All asynchronously.\n+        zk.getChildren(hubNodesPath, false, new SafeAsyncZKCallback.ChildrenCallback() {\n+            @Override\n+            public void safeProcessResult(int rc, String path, Object ctx, final List<String> children) {\n+                if (rc != Code.OK.intValue()) {\n+                    KeeperException e = ZkUtils.logErrorAndCreateZKException(\n+                            \"Could not get children for given path\", path, rc);\n+                    callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n+                    return;\n+                }\n+\n+                // The data callback for every child node\n+                SafeAsyncZKCallback.DataCallback dataCallback = new SafeAsyncZKCallback.DataCallback() {\n+                    Map<HubInfo, HubLoad> loadMap = new HashMap<HubInfo, HubLoad>();\n+                    int numResponse = 0;\n+                    @Override\n+                    public void safeProcessResult(int rc, String path, Object dataCtx,\n+                                                  byte[] data, Stat stat) {\n+                        synchronized (this) {\n+                            if (rc == Code.OK.intValue()) {\n+                                // Put this load in the map. dataCtx is actually the child string which is the\n+                                // IP:PORT:SSL representation of the hub.\n+                                try {\n+                                    HubInfo hubInfo =\n+                                        new HubInfo(new HedwigSocketAddress((String)dataCtx), stat.getCzxid());\n+                                    HubLoad hubLoad = HubLoad.parse(new String(data, UTF_8));\n+                                    this.loadMap.put(hubInfo, hubLoad);\n+                                } catch (HubLoad.InvalidHubLoadException e) {\n+                                    logger.warn(\"Corrupt data found for a hub. Ignoring.\");\n+                                }\n+                            }\n+                            numResponse++;\n+                            if (numResponse == children.size()) {\n+                                // We got less number of valid responses than the hubs we saw previously.\n+                                // Signal an error.\n+                                if (loadMap.size() != numResponse) {\n+                                    callback.operationFailed(originalCtx,\n+                                        new PubSubException.UnexpectedConditionException(\n+                                           \"Fewer OK responses than the number of active hubs seen previously.\"));\n+                                    return;\n+                                }\n+                                // We've seen all responses. All OK.\n+                                callback.operationFinished(originalCtx, loadMap);\n+                            }\n+                        }\n+                    }\n+                };\n+\n+                for (String child : children) {\n+                    String znode = conf.getZkHostsPrefix(new StringBuilder()).append(\"/\").append(child).toString();\n+                    zk.getData(znode, false, dataCallback, child);\n+                }\n+            }\n+        }, originalCtx);\n+    }\n+\n+    @Override\n+    public void rebalanceCluster(final double tolerancePercentage, final HubLoad maxLoadToShed,\n+                                 final Callback<Boolean> callback, final Object ctx) {\n+        // Get the load on all active hubs and then shed load if required.\n+        getActiveHubsInfoWithLoad(new Callback<Map<HubInfo, HubLoad>>() {\n+            @Override\n+            public void operationFinished(Object ctx, Map<HubInfo, HubLoad> loadMap) {\n+                if (null == tm) {\n+                    // No topic manager, so no load to shed.\n+                    callback.operationFinished(ctx, false);\n+                    return;\n+                }\n+                TopicBasedLoadShedder tbls = new TopicBasedLoadShedder(tm,\n+                        tolerancePercentage, maxLoadToShed);\n+                tbls.shedLoad(loadMap, callback, ctx);\n+            }\n+\n+            @Override\n+            public void operationFailed(Object ctx, PubSubException e) {\n+                // Rebalance failed. Log this and signal failure on the callback.\n+                logger.error(\"Failed to get active hubs. Cannot attempt a rebalance.\");\n+                callback.operationFailed(ctx, e);\n+            }\n+        }, ctx);\n+    }\n+\n+\n }"},{"sha":"12744fdd9a462fd243bac16638863d3dfe457540","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","status":"modified","additions":5,"deletions":1,"changes":6,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -77,7 +77,7 @@ public ZkTopicManager(final ZooKeeper zk, final ServerConfiguration cfg, Schedul\n \n         super(cfg, scheduler);\n         this.zk = zk;\n-        this.hubManager = new ZkHubServerManager(cfg, zk, addr);\n+        this.hubManager = new ZkHubServerManager(cfg, zk, addr, this);\n \n         myHubLoad = new HubLoad(topics.size());\n         this.hubManager.registerListener(new HubServerManager.ManagerListener() {\n@@ -275,6 +275,10 @@ public void safeProcessResult(int rc, String path, Object ctx, String name) {\n     @Override\n     protected void postReleaseCleanup(final ByteString topic, final Callback<Void> cb, Object ctx) {\n \n+        // Reduce load. We've removed the topic from our topic set, so do this as well.\n+        // When we reclaim the topic, we will increment the load again.\n+        hubManager.uploadSelfLoadData(myHubLoad.setNumTopics(topics.size()));\n+\n         zk.getData(hubPath(topic), false, new SafeAsyncZKCallback.DataCallback() {\n             @Override\n             public void safeProcessResult(int rc, String path, Object ctx, byte[] data, Stat stat) {"},{"sha":"a54d0d45629c505f84563d516638689e9f997dee","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","status":"added","additions":194,"deletions":0,"changes":194,"blob_url":"https://github.com/apache/bookkeeper/blob/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","raw_url":"https://github.com/apache/bookkeeper/raw/2d427e8d4b2c1d889ab5586e28e198c140a10489/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java?ref=2d427e8d4b2c1d889ab5586e28e198c140a10489","patch":"@@ -0,0 +1,194 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.hedwig.server.topics;\n+\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.SynchronousQueue;\n+\n+import junit.framework.Assert;\n+\n+import org.apache.hedwig.exceptions.PubSubException;\n+import org.apache.hedwig.util.Callback;\n+import org.apache.hedwig.util.ConcurrencyUtils;\n+import org.apache.hedwig.util.HedwigSocketAddress;\n+import org.junit.Test;\n+\n+import com.google.protobuf.ByteString;\n+\n+public class TestTopicBasedLoadShedder {\n+\n+    final protected SynchronousQueue<Boolean> statusQueue = new SynchronousQueue<Boolean>();\n+    private int myTopics = 10;\n+    private int numHubs = 10;\n+    private List<ByteString> mockTopicList;\n+    private final HubLoad infiniteMaxLoad = new HubLoad(10000000);\n+    Map<HubInfo, HubLoad> mockLoadMap = new HashMap<HubInfo, HubLoad>();\n+\n+    class MockTopicBasedLoadShedder extends TopicBasedLoadShedder {\n+        // This is set by the reduceLoadTo function.\n+        public HubLoad targetLoad;\n+        public MockTopicBasedLoadShedder(TopicManager tm, List<ByteString> topicList,\n+                                         Double tolerancePercentage, HubLoad maxLoadToShed) {\n+            super(tm, topicList, tolerancePercentage, maxLoadToShed);\n+        }\n+        @Override\n+        public void reduceLoadTo(HubLoad targetLoad, final Callback<Long> callback, final Object ctx) {\n+            this.targetLoad = targetLoad;\n+            // Indicates that we released these many topics.\n+            callback.operationFinished(ctx, targetLoad.toHubLoadData().getNumTopics());\n+        }\n+    }\n+    public Callback<Boolean> getShedLoadCallback(final MockTopicBasedLoadShedder ls, final HubLoad expected,\n+                                                 final Boolean shouldRelease, final Boolean shouldFail) {\n+        return new Callback<Boolean>() {\n+            @Override\n+            public void operationFinished(Object o, Boolean aBoolean) {\n+                Boolean status = false;\n+                status = (aBoolean == shouldRelease);\n+                if (shouldRelease) {\n+                    status &= (ls.targetLoad != null);\n+                    status &= (expected.numTopics == ls.targetLoad.numTopics);\n+                }\n+                final Boolean statusToPut = status;\n+                new Thread(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        ConcurrencyUtils.put(statusQueue, statusToPut);\n+                    }\n+                }).start();\n+            }\n+\n+            @Override\n+            public void operationFailed(Object o, PubSubException e) {\n+                new Thread(new Runnable() {\n+                    @Override\n+                    public void run() {\n+                        ConcurrencyUtils.put(statusQueue, shouldFail);\n+                    }\n+                }).start();\n+            }\n+        };\n+    }\n+\n+    private List<ByteString> getMockTopicList(int numTopics) {\n+        List<ByteString> topics = new ArrayList<ByteString>();\n+        for (int i = 0; i < numTopics; i++) {\n+            topics.add(ByteString.copyFromUtf8(\"MyTopic_\" + i));\n+        }\n+        return topics;\n+    }\n+\n+    private HubInfo getHubInfo(int hubNum) {\n+        return new HubInfo(new HedwigSocketAddress(\"myhub.testdomain.foo\"+hubNum+\":4080:4080\"), 0);\n+    }\n+\n+    private synchronized void initialize(int myTopics, int numHubs, int[] otherHubsLoad) {\n+        if (null != otherHubsLoad) {\n+            Assert.assertTrue(otherHubsLoad.length == numHubs - 1);\n+        }\n+        this.myTopics = myTopics;\n+        mockTopicList = getMockTopicList(this.myTopics);\n+        this.numHubs = numHubs;\n+        this.mockLoadMap.clear();\n+        this.mockLoadMap.put(getHubInfo(0), new HubLoad(this.myTopics));\n+        for (int i = 1; i < this.numHubs; i++) {\n+            this.mockLoadMap.put(getHubInfo(i), new HubLoad(otherHubsLoad[i-1]));\n+        }\n+    }\n+\n+    private int[] getEqualLoadDistributionArray(int n, int load) {\n+        if (n == 0) {\n+            return null;\n+        }\n+        int[] retLoad = new int[n];\n+        Arrays.fill(retLoad, load);\n+        return retLoad;\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized  void testAllHubsSameTopics() throws Exception {\n+        // All hubs have the same number of topics. We should not release any topics even with a\n+        // tolerance of 0.0.\n+        initialize(10, 10, getEqualLoadDistributionArray(9, 10));\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, null, false, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized void testOneHubUnequalTopics() throws Exception {\n+        // The hub has 20 topics while the average is 11. Should reduce the load to 11.\n+        initialize(20, 10, getEqualLoadDistributionArray(9, 10));\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, new HubLoad(11), true, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized void testOneHubUnequalTopicsWithTolerance() throws Exception {\n+        // The hub has 20 topics and average is 11. Should still release as tolerance level of 50.0 is\n+        // breached. Should get down to average.\n+        initialize(20, 10, getEqualLoadDistributionArray(9, 10));\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 50.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, new HubLoad(11), true, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+\n+        // A tolerance level of 100.0 should result in the hub not releasing topics.\n+        tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 100.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, null, false, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized void testMaxLoadShed() throws Exception {\n+        // The hub should not shed more than maxLoadShed topics.\n+        initialize(20, 10, getEqualLoadDistributionArray(9, 10));\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, new HubLoad(5));\n+        // Our load should reduce to 15.\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, new HubLoad(15), true, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+\n+        // We should reduce to 11 even when maxLoadShed and average result in the same\n+        // values\n+        tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, new HubLoad(9));\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, new HubLoad(11), true, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized void testSingleHubLoadShed() throws Exception {\n+        // If this is the only hub in the cluster, it should not release any topics.\n+        initialize(20, 1, null);\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, null, false, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+\n+    @Test(timeout = 60000)\n+    public synchronized void testUnderloadedClusterLoadShed() throws Exception {\n+        // Hold on to at least one topic while shedding load (if cluster is underloaded)\n+        initialize(5, 10, getEqualLoadDistributionArray(9, 0));\n+        MockTopicBasedLoadShedder tbls = new MockTopicBasedLoadShedder(null, mockTopicList, 0.0, infiniteMaxLoad);\n+        tbls.shedLoad(mockLoadMap, getShedLoadCallback(tbls, new HubLoad(1), true, false), null);\n+        Assert.assertTrue(statusQueue.take());\n+    }\n+}"}]}

