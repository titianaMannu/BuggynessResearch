{"sha":"694568b0ff0d048c284c8d5db0c9455d30dfa3ce","node_id":"MDY6Q29tbWl0MTU3NTk1Njo2OTQ1NjhiMGZmMGQwNDhjMjg0YzhkNWRiMGM5NDU1ZDMwZGZhM2Nl","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-01-22T13:35:03Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2014-01-22T13:35:03Z"},"message":"BOOKKEEPER-643: Improve concurrency of entry logger (sijie & Aniruddha via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1560348 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"66fb4b29882c7294e181f79fd3bd92fb2eac2ff2","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/66fb4b29882c7294e181f79fd3bd92fb2eac2ff2"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/694568b0ff0d048c284c8d5db0c9455d30dfa3ce","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/694568b0ff0d048c284c8d5db0c9455d30dfa3ce","html_url":"https://github.com/apache/bookkeeper/commit/694568b0ff0d048c284c8d5db0c9455d30dfa3ce","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"7b44d9552d8b854160278582db3f5ca07882358a","url":"https://api.github.com/repos/apache/bookkeeper/commits/7b44d9552d8b854160278582db3f5ca07882358a","html_url":"https://github.com/apache/bookkeeper/commit/7b44d9552d8b854160278582db3f5ca07882358a"}],"stats":{"total":682,"additions":528,"deletions":154},"files":[{"sha":"cd6ce6755a4206eb98593b5c53d26b8a1f3b84af","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -148,6 +148,8 @@ Trunk (unreleased changes)\n \n         BOOKKEEPER-720: CheckpointSource.MIN#compareTo does exactly the opposite of what it should (ivank via sijie)\n \n+        BOOKKEEPER-643: Improve concurrency of entry logger (sijie & Aniruddha via ivank)\n+\n       hedwig-server:\n \n         BOOKKEEPER-601: readahead cache size isn't updated correctly (sijie via fpj)"},{"sha":"cb7d914d7cf68307307641b13b226e1e125f2893","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","status":"modified","additions":69,"deletions":77,"changes":146,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -24,49 +24,48 @@\n import java.io.IOException;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n+import org.apache.bookkeeper.util.ZeroBuffer;\n+import java.util.concurrent.atomic.AtomicLong;\n \n /**\n  * Provides a buffering layer in front of a FileChannel.\n  */\n-public class BufferedChannel {\n+public class BufferedChannel extends BufferedReadChannel {\n+    // The capacity of the write buffer.\n+    protected final int writeCapacity;\n+    // The position of the file channel's write pointer.\n+    protected AtomicLong writeBufferStartPosition = new AtomicLong(0);\n+    // The buffer used to write operations.\n+    protected final ByteBuffer writeBuffer;\n+    // The absolute position of the next write operation.\n+    protected volatile long position;\n \n-    static final byte zeroPage[] = new byte[64 * 1024];\n-\n-    ByteBuffer writeBuffer;\n-    ByteBuffer readBuffer;\n-    private FileChannel bc;\n-    long position;\n-    int capacity;\n-    long readBufferStartPosition;\n-    long writeBufferStartPosition;\n     // make constructor to be public for unit test\n-    public BufferedChannel(FileChannel bc, int capacity) throws IOException {\n-        this.bc = bc;\n-        this.capacity = capacity;\n-        position = bc.position();\n-        writeBufferStartPosition = position;\n+    public BufferedChannel(FileChannel fc, int capacity) throws IOException {\n+        // Use the same capacity for read and write buffers.\n+        this(fc, capacity, capacity);\n     }\n \n-    /**\n-     * @return file channel\n-     */\n-    FileChannel getFileChannel() {\n-        return this.bc;\n+    public BufferedChannel(FileChannel fc, int writeCapacity, int readCapacity) throws IOException {\n+        super(fc, readCapacity);\n+        // Set the read buffer's limit to readCapacity.\n+        this.readBuffer.limit(readCapacity);\n+        this.writeCapacity = writeCapacity;\n+        this.position = fc.position();\n+        this.writeBufferStartPosition.set(position);\n+        this.writeBuffer = ByteBuffer.allocateDirect(writeCapacity);\n     }\n \n-    /*    public void close() throws IOException {\n-            bc.close();\n-        }\n-    */\n-//    public boolean isOpen() {\n-//        return bc.isOpen();\n-//    }\n-\n-    synchronized public int write(ByteBuffer src) throws IOException {\n+    /**\n+     * Write all the data in src to the {@link FileChannel}. Note that this function can\n+     * buffer or re-order writes based on the implementation. These writes will be flushed\n+     * to the disk only when flush() is invoked.\n+     *\n+     * @param src The source ByteBuffer which contains the data to be written.\n+     * @throws IOException if a write operation fails.\n+     */\n+    synchronized public void write(ByteBuffer src) throws IOException {\n         int copied = 0;\n-        if (writeBuffer == null) {\n-            writeBuffer = ByteBuffer.allocateDirect(capacity);\n-        }\n         while(src.remaining() > 0) {\n             int truncated = 0;\n             if (writeBuffer.remaining() < src.remaining()) {\n@@ -76,32 +75,31 @@ synchronized public int write(ByteBuffer src) throws IOException {\n             copied += src.remaining();\n             writeBuffer.put(src);\n             src.limit(src.limit()+truncated);\n+            // if we have run out of buffer space, we should flush to the file\n             if (writeBuffer.remaining() == 0) {\n-                writeBuffer.flip();\n-                bc.write(writeBuffer);\n-                writeBuffer.clear();\n-                writeBufferStartPosition = bc.position();\n+                flushInternal();\n             }\n         }\n         position += copied;\n-        return copied;\n     }\n \n+    /**\n+     * Get the position where the next write operation will begin writing from.\n+     * @return\n+     */\n     public long position() {\n         return position;\n     }\n \n     /**\n-     * Retrieve the current size of the underlying FileChannel\n-     *\n-     * @return FileChannel size measured in bytes\n-     *\n-     * @throws IOException if some I/O error occurs reading the FileChannel\n+     * Get the position of the file channel's write pointer.\n+     * @return\n      */\n-    public long size() throws IOException {\n-        return bc.size();\n+    public long getFileChannelPosition() {\n+        return writeBufferStartPosition.get();\n     }\n \n+\n     /**\n      * Write any data in the buffer to the file. If sync is set to true, force a sync operation so that\n      * data is persisted to the disk.\n@@ -123,90 +121,84 @@ public void flush(boolean shouldForceWrite) throws IOException {\n      * @throws IOException if the write fails.\n      */\n     private void flushInternal() throws IOException {\n-        if (writeBuffer == null) {\n-            return;\n-        }\n         writeBuffer.flip();\n         do {\n-            bc.write(writeBuffer);\n+            fileChannel.write(writeBuffer);\n         } while (writeBuffer.hasRemaining());\n         writeBuffer.clear();\n-        writeBufferStartPosition = bc.position();\n+        writeBufferStartPosition.set(fileChannel.position());\n     }\n \n     public long forceWrite(boolean forceMetadata) throws IOException {\n         // This is the point up to which we had flushed to the file system page cache\n         // before issuing this force write hence is guaranteed to be made durable by\n         // the force write, any flush that happens after this may or may\n         // not be flushed\n-        long positionForceWrite;\n-        synchronized (this) {\n-            positionForceWrite = writeBufferStartPosition;\n-        }\n-        bc.force(forceMetadata);\n+        long positionForceWrite = writeBufferStartPosition.get();\n+        fileChannel.force(forceMetadata);\n         return positionForceWrite;\n     }\n \n-    /*public Channel getInternalChannel() {\n-        return bc;\n-    }*/\n-    synchronized public int read(ByteBuffer buff, long pos) throws IOException {\n-        if (readBuffer == null) {\n-            readBuffer = ByteBuffer.allocateDirect(capacity);\n-            readBufferStartPosition = Long.MIN_VALUE;\n-        }\n+    @Override\n+    synchronized public int read(ByteBuffer dest, long pos) throws IOException {\n         long prevPos = pos;\n-        while(buff.remaining() > 0) {\n+        while(dest.remaining() > 0) {\n             // check if it is in the write buffer\n-            if (writeBuffer != null && writeBufferStartPosition <= pos) {\n-                long positionInBuffer = pos - writeBufferStartPosition;\n+            if (writeBuffer != null && writeBufferStartPosition.get() <= pos) {\n+                long positionInBuffer = pos - writeBufferStartPosition.get();\n                 long bytesToCopy = writeBuffer.position()-positionInBuffer;\n-                if (bytesToCopy > buff.remaining()) {\n-                    bytesToCopy = buff.remaining();\n+                if (bytesToCopy > dest.remaining()) {\n+                    bytesToCopy = dest.remaining();\n                 }\n                 if (bytesToCopy == 0) {\n                     throw new IOException(\"Read past EOF\");\n                 }\n                 ByteBuffer src = writeBuffer.duplicate();\n                 src.position((int) positionInBuffer);\n                 src.limit((int) (positionInBuffer+bytesToCopy));\n-                buff.put(src);\n+                dest.put(src);\n                 pos+= bytesToCopy;\n-            } else if (writeBuffer == null && writeBufferStartPosition <= pos) {\n+            } else if (writeBuffer == null && writeBufferStartPosition.get() <= pos) {\n                 // here we reach the end\n                 break;\n                 // first check if there is anything we can grab from the readBuffer\n             } else if (readBufferStartPosition <= pos && pos < readBufferStartPosition+readBuffer.capacity()) {\n                 long positionInBuffer = pos - readBufferStartPosition;\n                 long bytesToCopy = readBuffer.capacity()-positionInBuffer;\n-                if (bytesToCopy > buff.remaining()) {\n-                    bytesToCopy = buff.remaining();\n+                if (bytesToCopy > dest.remaining()) {\n+                    bytesToCopy = dest.remaining();\n                 }\n                 ByteBuffer src = readBuffer.duplicate();\n                 src.position((int) positionInBuffer);\n                 src.limit((int) (positionInBuffer+bytesToCopy));\n-                buff.put(src);\n+                dest.put(src);\n                 pos += bytesToCopy;\n                 // let's read it\n             } else {\n                 readBufferStartPosition = pos;\n                 readBuffer.clear();\n                 // make sure that we don't overlap with the write buffer\n-                if (readBufferStartPosition + readBuffer.capacity() >= writeBufferStartPosition) {\n-                    readBufferStartPosition = writeBufferStartPosition - readBuffer.capacity();\n+                if (readBufferStartPosition + readBuffer.capacity() >= writeBufferStartPosition.get()) {\n+                    readBufferStartPosition = writeBufferStartPosition.get() - readBuffer.capacity();\n                     if (readBufferStartPosition < 0) {\n-                        readBuffer.put(zeroPage, 0, (int) -readBufferStartPosition);\n+                        ZeroBuffer.put(readBuffer, (int)-readBufferStartPosition);\n                     }\n                 }\n                 while(readBuffer.remaining() > 0) {\n-                    if (bc.read(readBuffer, readBufferStartPosition+readBuffer.position()) <= 0) {\n+                    if (fileChannel.read(readBuffer, readBufferStartPosition+readBuffer.position()) <= 0) {\n                         throw new IOException(\"Short read\");\n                     }\n                 }\n-                readBuffer.put(zeroPage, 0, readBuffer.remaining());\n+                ZeroBuffer.put(readBuffer);\n                 readBuffer.clear();\n             }\n         }\n         return (int)(pos - prevPos);\n     }\n+\n+    @Override\n+    synchronized public void clear() {\n+        super.clear();\n+        writeBuffer.clear();\n+    }\n }"},{"sha":"782a39849758871512cabd9c57aba9096c2aad98","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannelBase.java","status":"added","additions":55,"deletions":0,"changes":55,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannelBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannelBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannelBase.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -0,0 +1,55 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.io.IOException;\n+import java.nio.channels.FileChannel;\n+\n+public abstract class BufferedChannelBase {\n+    protected final FileChannel fileChannel;\n+\n+    protected BufferedChannelBase(FileChannel fc) {\n+        this.fileChannel = fc;\n+    }\n+\n+    protected FileChannel validateAndGetFileChannel() throws IOException {\n+        // Even if we have BufferedChannelBase objects in the cache, higher layers should\n+        // guarantee that once a log file has been closed and possibly deleted during garbage\n+        // collection, attempts will not be made to read from it\n+        if (!fileChannel.isOpen()) {\n+            throw new IOException(\"Attempting to access a file channel that has already been closed\");\n+        }\n+        return fileChannel;\n+    }\n+\n+    /**\n+     * Get the current size of the underlying FileChannel.\n+     * @return\n+     */\n+    public long size() throws IOException {\n+        return validateAndGetFileChannel().size();\n+    }\n+\n+    /**\n+     * Get the {@link FileChannel} that this BufferedChannel wraps around.\n+     * @return\n+     */\n+    public FileChannel getFileChannel() {\n+        return fileChannel;\n+    }\n+}"},{"sha":"0114043d47e9ce1f642e43606eb3e9f0c8646fee","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedReadChannel.java","status":"added","additions":103,"deletions":0,"changes":103,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedReadChannel.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedReadChannel.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedReadChannel.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -0,0 +1,103 @@\n+/*\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.bookkeeper.bookie;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.FileChannel;\n+\n+/**\n+ * A Buffered channel without a write buffer. Only reads are buffered.\n+ */\n+public class BufferedReadChannel extends BufferedChannelBase {\n+    private static Logger LOG = LoggerFactory.getLogger(BufferedReadChannel.class);\n+    // The capacity of the read buffer.\n+    protected final int readCapacity;\n+    // The buffer for read operations.\n+    protected ByteBuffer readBuffer;\n+    // The starting position of the data currently in the read buffer.\n+    protected long readBufferStartPosition = Long.MIN_VALUE;\n+\n+    long invocationCount = 0;\n+    long cacheHitCount = 0;\n+\n+    public BufferedReadChannel(FileChannel fileChannel, int readCapacity) throws IOException {\n+        super(fileChannel);\n+        this.readCapacity = readCapacity;\n+        this.readBuffer = ByteBuffer.allocateDirect(readCapacity);\n+        this.readBuffer.limit(0);\n+    }\n+\n+    /**\n+     * Read as many bytes into dest as dest.capacity() starting at position pos in the\n+     * FileChannel. This function can read from the buffer or the file channel\n+     * depending on the implementation..\n+     * @param dest\n+     * @param pos\n+     * @return The total number of bytes read. -1 if the given position is greater than or equal to the file's current size.\n+     * @throws IOException if I/O error occurs\n+     */\n+    synchronized public int read(ByteBuffer dest, long pos) throws IOException {\n+        invocationCount++;\n+        long currentPosition = pos;\n+        long eof = validateAndGetFileChannel().size();\n+        // return -1 if the given position is greater than or equal to the file's current size.\n+        if (pos >= eof) {\n+            return -1;\n+        }\n+        while (dest.remaining() > 0) {\n+            // Check if the data is in the buffer, if so, copy it.\n+            if (readBufferStartPosition <= currentPosition && currentPosition < readBufferStartPosition + readBuffer.limit()) {\n+                long posInBuffer = currentPosition - readBufferStartPosition;\n+                long bytesToCopy = Math.min(dest.remaining(), readBuffer.limit() - posInBuffer);\n+                ByteBuffer rbDup = readBuffer.duplicate();\n+                rbDup.position((int)posInBuffer);\n+                rbDup.limit((int)(posInBuffer + bytesToCopy));\n+                dest.put(rbDup);\n+                currentPosition += bytesToCopy;\n+                cacheHitCount++;\n+            } else if (currentPosition >= eof) {\n+                // here we reached eof.\n+                break;\n+            } else {\n+                // We don't have it in the buffer, so put necessary data in the buffer\n+                readBuffer.clear();\n+                readBufferStartPosition = currentPosition;\n+                int readBytes = 0;\n+                if ((readBytes = validateAndGetFileChannel().read(readBuffer, currentPosition)) <= 0) {\n+                    throw new IOException(\"Reading from filechannel returned a non-positive value. Short read.\");\n+                }\n+                readBuffer.limit(readBytes);\n+            }\n+        }\n+        return (int)(currentPosition - pos);\n+    }\n+\n+    synchronized public void clear() {\n+        readBuffer.clear();\n+        readBuffer.limit(0);\n+    }\n+\n+}"},{"sha":"bd959c46e1300f9703393de9669385ed176981f9","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","status":"modified","additions":273,"deletions":77,"changes":350,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -40,8 +40,16 @@\n import java.util.Collections;\n import java.util.LinkedList;\n import java.util.List;\n-import java.util.Map.Entry;\n+import java.util.Map;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CancellationException;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+\n import java.util.concurrent.CopyOnWriteArrayList;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n@@ -51,6 +59,8 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+import com.google.common.collect.MapMaker;\n+\n /**\n  * This class manages the writing of the bookkeeper entries. All the new\n  * entries are written to a common log. The LedgerCache will have pointers\n@@ -61,19 +71,32 @@\n public class EntryLogger {\n     private static final Logger LOG = LoggerFactory.getLogger(EntryLogger.class);\n \n+    private static class BufferedLogChannel extends BufferedChannel {\n+        final private long logId;\n+        public BufferedLogChannel(FileChannel fc, int writeCapacity,\n+                                  int readCapacity, long logId) throws IOException {\n+            super(fc, writeCapacity, readCapacity);\n+            this.logId = logId;\n+        }\n+        public long getLogId() {\n+            return logId;\n+        }\n+    }\n+\n     volatile File currentDir;\n     private final LedgerDirsManager ledgerDirsManager;\n     private final AtomicBoolean shouldCreateNewEntryLog = new AtomicBoolean(false);\n \n-    private long logId;\n     private volatile long leastUnflushedLogId;\n \n     /**\n      * The maximum size of a entry logger file.\n      */\n     final long logSizeLimit;\n-    private List<BufferedChannel> logChannelsToFlush;\n-    private volatile BufferedChannel logChannel;\n+    private List<BufferedLogChannel> logChannelsToFlush;\n+    private volatile BufferedLogChannel logChannel;\n+    private final EntryLoggerAllocator entryLoggerAllocator;\n+    private final boolean entryLogPreAllocationEnabled;\n     private final CopyOnWriteArrayList<EntryLogListener> listeners\n         = new CopyOnWriteArrayList<EntryLogListener>();\n \n@@ -83,10 +106,12 @@\n      */\n     final static int LOGFILE_HEADER_SIZE = 1024;\n     final ByteBuffer LOGFILE_HEADER = ByteBuffer.allocate(LOGFILE_HEADER_SIZE);\n+    final static long INVALID_LID = -1L;\n \n     final static int MIN_SANE_ENTRY_SIZE = 8 + 8;\n     final static long MB = 1024 * 1024;\n \n+    final ServerConfiguration conf;\n     /**\n      * Scan entries in a entry log file.\n      */\n@@ -143,6 +168,7 @@ public EntryLogger(ServerConfiguration conf,\n         }\n         // log size limit\n         this.logSizeLimit = conf.getEntryLogSizeLimit();\n+        this.entryLogPreAllocationEnabled = conf.isEntryLogFilePreAllocationEnabled();\n \n         // Initialize the entry log header buffer. This cannot be a static object\n         // since in our unit tests, we run multiple Bookies and thus EntryLoggers\n@@ -152,7 +178,7 @@ public EntryLogger(ServerConfiguration conf,\n         LOGFILE_HEADER.put(\"BKLO\".getBytes(UTF_8));\n \n         // Find the largest logId\n-        logId = -1;\n+        long logId = INVALID_LID;\n         for (File dir : ledgerDirsManager.getAllLedgerDirs()) {\n             if (!dir.exists()) {\n                 throw new FileNotFoundException(\n@@ -164,6 +190,8 @@ public EntryLogger(ServerConfiguration conf,\n             }\n         }\n         this.leastUnflushedLogId = logId + 1;\n+        this.entryLoggerAllocator = new EntryLoggerAllocator(logId);\n+        this.conf = conf;\n         initialize();\n     }\n \n@@ -174,9 +202,86 @@ void addListener(EntryLogListener listener) {\n     }\n \n     /**\n-     * Maps entry log files to open channels.\n+     * If the log id of current writable channel is the same as entryLogId and the position\n+     * we want to read might end up reading from a position in the write buffer of the\n+     * buffered channel, route this read to the current logChannel. Else,\n+     * read from the BufferedReadChannel that is provided.\n+     * @param entryLogId\n+     * @param channel\n+     * @param buff remaining() on this bytebuffer tells us the last position that we\n+     *             expect to read.\n+     * @param pos The starting position from where we want to read.\n+     * @return\n      */\n-    private ConcurrentHashMap<Long, BufferedChannel> channels = new ConcurrentHashMap<Long, BufferedChannel>();\n+    private int readFromLogChannel(long entryLogId, BufferedReadChannel channel, ByteBuffer buff, long pos)\n+            throws IOException {\n+        BufferedLogChannel bc = logChannel;\n+        if (null != bc) {\n+            if (entryLogId == bc.getLogId()) {\n+                synchronized (bc) {\n+                    if (pos + buff.remaining() >= bc.getFileChannelPosition()) {\n+                        return bc.read(buff, pos);\n+                    }\n+                }\n+            }\n+        }\n+        return channel.read(buff, pos);\n+    }\n+\n+    /**\n+     * A thread-local variable that wraps a mapping of log ids to bufferedchannels\n+     * These channels should be used only for reading. logChannel is the one\n+     * that is used for writes.\n+     */\n+    private final ThreadLocal<Map<Long, BufferedReadChannel>> logid2Channel\n+            = new ThreadLocal<Map<Long, BufferedReadChannel>>() {\n+        @Override\n+        public Map<Long, BufferedReadChannel> initialValue() {\n+            // Since this is thread local there only one modifier\n+            // We dont really need the concurrency, but we need to use\n+            // the weak values. Therefore using the concurrency level of 1\n+            return new MapMaker().concurrencyLevel(1)\n+                .weakValues()\n+                .makeMap();\n+        }\n+    };\n+\n+    /**\n+     * Each thread local buffered read channel can share the same file handle because reads are not relative\n+     * and don't cause a change in the channel's position. We use this map to store the file channels. Each\n+     * file channel is mapped to a log id which represents an open log file.\n+     */\n+    private final ConcurrentMap<Long, FileChannel> logid2FileChannel\n+            = new ConcurrentHashMap<Long, FileChannel>();\n+\n+    /**\n+     * Put the logId, bc pair in the map responsible for the current thread.\n+     * @param logId\n+     * @param bc\n+     */\n+    public BufferedReadChannel putInReadChannels(long logId, BufferedReadChannel bc) {\n+        Map<Long, BufferedReadChannel> threadMap = logid2Channel.get();\n+        return threadMap.put(logId, bc);\n+    }\n+\n+    /**\n+     * Remove all entries for this log file in each thread's cache.\n+     * @param logId\n+     */\n+    public void removeFromChannelsAndClose(long logId) {\n+        FileChannel fileChannel = logid2FileChannel.remove(logId);\n+        if (null != fileChannel) {\n+            try {\n+                fileChannel.close();\n+            } catch (IOException e) {\n+                LOG.warn(\"Exception while closing channel for log file:\" + logId);\n+            }\n+        }\n+    }\n+\n+    public BufferedReadChannel getFromChannels(long logId) {\n+        return logid2Channel.get().get(logId);\n+    }\n \n     /**\n      * Get the least unflushed log id. Garbage collector thread should not process\n@@ -189,7 +294,7 @@ synchronized long getLeastUnflushedLogId() {\n     }\n \n     synchronized long getCurrentLogId() {\n-        return logId;\n+        return logChannel.getLogId();\n     }\n \n     protected void initialize() throws IOException {\n@@ -259,38 +364,108 @@ synchronized void rollLog() throws IOException {\n     void createNewLog() throws IOException {\n         if (null != logChannel) {\n             if (null == logChannelsToFlush) {\n-                logChannelsToFlush = new LinkedList<BufferedChannel>();\n+                logChannelsToFlush = new LinkedList<BufferedLogChannel>();\n             }\n             // flush the internal buffer back to filesystem but not sync disk\n             // so the readers could access the data from filesystem.\n             logChannel.flush(false);\n             logChannelsToFlush.add(logChannel);\n+            LOG.info(\"Flushing entry logger {} back to filesystem, pending for syncing entry loggers : {}.\",\n+                    logChannel.getLogId(), logChannelsToFlush);\n             for (EntryLogListener listener : listeners) {\n                 listener.onRotateEntryLog();\n             }\n         }\n-        String logFileName = null;\n-        do {\n-            logFileName = Long.toHexString(++logId) + \".log\";\n-            for (File dir : ledgerDirsManager.getAllLedgerDirs()) {\n-                File newLogFile = new File(dir, logFileName);\n-                if (newLogFile.exists()) {\n-                    LOG.warn(\"Found existed entry log \" + newLogFile\n-                             + \" when trying to create it as a new log.\");\n-                    logFileName = null;\n-                    break;\n+        logChannel = entryLoggerAllocator.createNewLog();\n+    }\n+\n+    /**\n+     * An allocator pre-allocates entry log files.\n+     */\n+    class EntryLoggerAllocator {\n+\n+        long preallocatedLogId;\n+        Future<BufferedLogChannel> preallocation = null;\n+        ExecutorService allocatorExecutor;\n+\n+        EntryLoggerAllocator(long logId) {\n+            preallocatedLogId = logId;\n+            allocatorExecutor = Executors.newSingleThreadExecutor();\n+        }\n+\n+        synchronized BufferedLogChannel createNewLog() throws IOException {\n+            BufferedLogChannel bc;\n+            if (!entryLogPreAllocationEnabled || null == preallocation) {\n+                // initialization time to create a new log\n+                bc = allocateNewLog();\n+            } else {\n+                // has a preallocated entry log\n+                try {\n+                    bc = preallocation.get();\n+                } catch (ExecutionException ee) {\n+                    if (ee.getCause() instanceof IOException) {\n+                        throw (IOException) (ee.getCause());\n+                    } else {\n+                        throw new IOException(\"Error to execute entry log allocation.\", ee);\n+                    }\n+                } catch (CancellationException ce) {\n+                    throw new IOException(\"Task to allocate a new entry log is cancelled.\", ce);\n+                } catch (InterruptedException ie) {\n+                    throw new IOException(\"Intrrupted when waiting a new entry log to be allocated.\", ie);\n                 }\n+                preallocation = allocatorExecutor.submit(new Callable<BufferedLogChannel>() {\n+                    @Override\n+                    public BufferedLogChannel call() throws IOException {\n+                        return allocateNewLog();\n+                    }\n+                });\n             }\n-        } while (logFileName == null);\n+            LOG.info(\"Created new entry logger {}.\", bc.getLogId());\n+            return bc;\n+        }\n+\n+        /**\n+         * Allocate a new log file.\n+         */\n+        BufferedLogChannel allocateNewLog() throws IOException {\n+            List<File> list = ledgerDirsManager.getWritableLedgerDirs();\n+            Collections.shuffle(list);\n+            // It would better not to overwrite existing entry log files\n+            File newLogFile = null;\n+            do {\n+                String logFileName = Long.toHexString(++preallocatedLogId) + \".log\";\n+                for (File dir : list) {\n+                    newLogFile = new File(dir, logFileName);\n+                    currentDir = dir;\n+                    if (newLogFile.exists()) {\n+                        LOG.warn(\"Found existed entry log \" + newLogFile\n+                               + \" when trying to create it as a new log.\");\n+                        newLogFile = null;\n+                        break;\n+                    }\n+                }\n+            } while (newLogFile == null);\n \n-        // Update last log id first\n-        currentDir = ledgerDirsManager.pickRandomWritableDir();\n-        setLastLogId(currentDir, logId);\n+            FileChannel channel = new RandomAccessFile(newLogFile, \"rw\").getChannel();\n+            BufferedLogChannel logChannel = new BufferedLogChannel(channel,\n+                    conf.getWriteBufferBytes(), conf.getReadBufferBytes(), preallocatedLogId);\n+            logChannel.write((ByteBuffer) LOGFILE_HEADER.clear());\n \n-        File newLogFile = new File(currentDir, logFileName);\n-        logChannel = new BufferedChannel(new RandomAccessFile(newLogFile, \"rw\").getChannel(), 64*1024);\n-        logChannel.write((ByteBuffer) LOGFILE_HEADER.clear());\n-        channels.put(logId, logChannel);\n+            for (File f : list) {\n+                setLastLogId(f, preallocatedLogId);\n+            }\n+            LOG.info(\"Preallocated entry logger {}.\", preallocatedLogId);\n+            return logChannel;\n+        }\n+\n+        /**\n+         * Stop the allocator.\n+         */\n+        void stop() {\n+            // wait until the preallocation finished.\n+            allocatorExecutor.shutdown();\n+            LOG.info(\"Stopped entry logger preallocator.\");\n+        }\n     }\n \n     /**\n@@ -300,15 +475,7 @@ void createNewLog() throws IOException {\n      *          Entry Log File Id\n      */\n     protected boolean removeEntryLog(long entryLogId) {\n-        BufferedChannel bc = channels.remove(entryLogId);\n-        if (null != bc) {\n-            // close its underlying file channel, so it could be deleted really\n-            try {\n-                bc.getFileChannel().close();\n-            } catch (IOException ie) {\n-                LOG.warn(\"Exception while closing garbage collected entryLog file : \", ie);\n-            }\n-        }\n+        removeFromChannelsAndClose(entryLogId);\n         File entryLogFile;\n         try {\n             entryLogFile = findFile(entryLogId);\n@@ -337,6 +504,7 @@ private void setLastLogId(File dir, long logId) throws IOException {\n             try {\n                 bw.close();\n             } catch (IOException e) {\n+                LOG.error(\"Could not close lastId file in {}\", dir.getPath());\n             }\n         }\n     }\n@@ -365,7 +533,7 @@ public boolean accept(File file) {\n         }\n         // no log file found in this directory\n         if (0 == logs.size()) {\n-            return -1;\n+            return INVALID_LID;\n         }\n         // order the collections\n         Collections.sort(logs);\n@@ -380,16 +548,16 @@ private long readLastLogId(File f) {\n         try {\n             fis = new FileInputStream(new File(f, \"lastId\"));\n         } catch (FileNotFoundException e) {\n-            return -1;\n+            return INVALID_LID;\n         }\n         BufferedReader br = new BufferedReader(new InputStreamReader(fis, UTF_8));\n         try {\n             String lastIdString = br.readLine();\n             return Long.parseLong(lastIdString, 16);\n         } catch (IOException e) {\n-            return -1;\n+            return INVALID_LID;\n         } catch(NumberFormatException e) {\n-            return -1;\n+            return INVALID_LID;\n         } finally {\n             try {\n                 br.close();\n@@ -407,21 +575,28 @@ void checkpoint() throws IOException {\n     }\n \n     void flushRotatedLogs() throws IOException {\n-        List<BufferedChannel> tmpChannels = null;\n-        long newUnflushedLogId;\n+        List<BufferedLogChannel> channels = null;\n+        long flushedLogId = INVALID_LID;\n         synchronized (this) {\n-            tmpChannels = logChannelsToFlush;\n+            channels = logChannelsToFlush;\n             logChannelsToFlush = null;\n-            newUnflushedLogId = logId;\n         }\n-        if (null == tmpChannels) {\n+        if (null == channels) {\n             return;\n         }\n-        for (BufferedChannel channel : tmpChannels) {\n+        for (BufferedLogChannel channel : channels) {\n             channel.flush(true);\n+            // since this channel is only used for writing, after flushing the channel,\n+            // we had to close the underlying file channel. Otherwise, we might end up\n+            // leaking fds which cause the disk spaces could not be reclaimed.\n+            closeFileChannel(channel);\n+            if (channel.getLogId() > flushedLogId) {\n+                flushedLogId = channel.getLogId();\n+            }\n+            LOG.info(\"Synced entry logger {} to disk.\", channel.getLogId());\n         }\n         // move the leastUnflushedLogId ptr\n-        leastUnflushedLogId = newUnflushedLogId;\n+        leastUnflushedLogId = flushedLogId + 1;\n     }\n \n     void flush() throws IOException {\n@@ -432,6 +607,7 @@ void flush() throws IOException {\n     synchronized void flushCurrentLog() throws IOException {\n         if (logChannel != null) {\n             logChannel.flush(true);\n+            LOG.debug(\"Flush and sync current entry logger {}.\", logChannel.getLogId());\n         }\n     }\n \n@@ -458,7 +634,7 @@ synchronized long addEntry(long ledger, ByteBuffer entry, boolean rollLog) throw\n         long pos = logChannel.position();\n         logChannel.write(entry);\n \n-        return (logId << 32L) | pos;\n+        return (logChannel.getLogId() << 32L) | pos;\n     }\n \n     static long logIdForOffset(long offset) {\n@@ -474,15 +650,15 @@ synchronized boolean reachEntryLogLimit(long size) {\n         long pos = location & 0xffffffffL;\n         ByteBuffer sizeBuff = ByteBuffer.allocate(4);\n         pos -= 4; // we want to get the ledgerId and length to check\n-        BufferedChannel fc;\n+        BufferedReadChannel fc;\n         try {\n             fc = getChannelForLogId(entryLogId);\n         } catch (FileNotFoundException e) {\n             FileNotFoundException newe = new FileNotFoundException(e.getMessage() + \" for \" + ledgerId + \" with location \" + location);\n             newe.setStackTrace(e.getStackTrace());\n             throw newe;\n         }\n-        if (fc.read(sizeBuff, pos) != sizeBuff.capacity()) {\n+        if (readFromLogChannel(entryLogId, fc, sizeBuff, pos) != sizeBuff.capacity()) {\n             throw new Bookie.NoEntryException(\"Short read from entrylog \" + entryLogId,\n                                               ledgerId, entryId);\n         }\n@@ -500,7 +676,7 @@ synchronized boolean reachEntryLogLimit(long size) {\n         }\n         byte data[] = new byte[entrySize];\n         ByteBuffer buff = ByteBuffer.wrap(data);\n-        int rc = fc.read(buff, pos);\n+        int rc = readFromLogChannel(entryLogId, fc, buff, pos);\n         if ( rc != data.length) {\n             // Note that throwing NoEntryException here instead of IOException is not\n             // without risk. If all bookies in a quorum throw this same exception\n@@ -526,27 +702,25 @@ synchronized boolean reachEntryLogLimit(long size) {\n         return data;\n     }\n \n-    private BufferedChannel getChannelForLogId(long entryLogId) throws IOException {\n-        BufferedChannel fc = channels.get(entryLogId);\n+    private BufferedReadChannel getChannelForLogId(long entryLogId) throws IOException {\n+        BufferedReadChannel fc = getFromChannels(entryLogId);\n         if (fc != null) {\n             return fc;\n         }\n         File file = findFile(entryLogId);\n         // get channel is used to open an existing entry log file\n         // it would be better to open using read mode\n         FileChannel newFc = new RandomAccessFile(file, \"r\").getChannel();\n-        // If the file already exists before creating a BufferedChannel layer above it,\n-        // set the FileChannel's position to the end so the write buffer knows where to start.\n-        newFc.position(newFc.size());\n-        fc = new BufferedChannel(newFc, 8192);\n-\n-        BufferedChannel oldfc = channels.putIfAbsent(entryLogId, fc);\n-        if (oldfc != null) {\n+        FileChannel oldFc = logid2FileChannel.putIfAbsent(entryLogId, newFc);\n+        if (null != oldFc) {\n             newFc.close();\n-            return oldfc;\n-        } else {\n-            return fc;\n+            newFc = oldFc;\n         }\n+        // We set the position of the write buffer of this buffered channel to Long.MAX_VALUE\n+        // so that there are no overlaps with the write buffer while reading\n+        fc = new BufferedReadChannel(newFc, conf.getReadBufferBytes());\n+        putInReadChannels(entryLogId, fc);\n+        return fc;\n     }\n \n     /**\n@@ -584,7 +758,7 @@ private File findFile(long logId) throws FileNotFoundException {\n     protected void scanEntryLog(long entryLogId, EntryLogScanner scanner) throws IOException {\n         ByteBuffer sizeBuff = ByteBuffer.allocate(4);\n         ByteBuffer lidBuff = ByteBuffer.allocate(8);\n-        BufferedChannel bc;\n+        BufferedReadChannel bc;\n         // Get the BufferedChannel for the current entry log file\n         try {\n             bc = getChannelForLogId(entryLogId);\n@@ -601,7 +775,7 @@ protected void scanEntryLog(long entryLogId, EntryLogScanner scanner) throws IOE\n             if (pos >= bc.size()) {\n                 break;\n             }\n-            if (bc.read(sizeBuff, pos) != sizeBuff.capacity()) {\n+            if (readFromLogChannel(entryLogId, bc, sizeBuff, pos) != sizeBuff.capacity()) {\n                 throw new IOException(\"Short read for entry size from entrylog \" + entryLogId);\n             }\n             long offset = pos;\n@@ -614,7 +788,7 @@ protected void scanEntryLog(long entryLogId, EntryLogScanner scanner) throws IOE\n             }\n             sizeBuff.clear();\n             // try to read ledger id first\n-            if (bc.read(lidBuff, pos) != lidBuff.capacity()) {\n+            if (readFromLogChannel(entryLogId, bc, lidBuff, pos) != lidBuff.capacity()) {\n                 throw new IOException(\"Short read for ledger id from entrylog \" + entryLogId);\n             }\n             lidBuff.flip();\n@@ -628,7 +802,7 @@ protected void scanEntryLog(long entryLogId, EntryLogScanner scanner) throws IOE\n             // read the entry\n             byte data[] = new byte[entrySize];\n             ByteBuffer buff = ByteBuffer.wrap(data);\n-            int rc = bc.read(buff, pos);\n+            int rc = readFromLogChannel(entryLogId, bc, buff, pos);\n             if (rc != data.length) {\n                 throw new IOException(\"Short read for ledger entry from entryLog \" + entryLogId\n                                     + \"@\" + pos + \"(\" + rc + \"!=\" + data.length + \")\");\n@@ -649,22 +823,44 @@ public void shutdown() {\n         LOG.info(\"Stopping EntryLogger\");\n         try {\n             flush();\n-            for (Entry<Long, BufferedChannel> channelEntry : channels\n-                    .entrySet()) {\n-                channelEntry.getValue().getFileChannel().close();\n+            for (FileChannel fc : logid2FileChannel.values()) {\n+                fc.close();\n             }\n+            // clear the mapping, so we don't need to go through the channels again in finally block in normal case.\n+            logid2FileChannel.clear();\n+            // close current writing log file\n+            closeFileChannel(logChannel);\n+            logChannel = null;\n         } catch (IOException ie) {\n             // we have no idea how to avoid io exception during shutting down, so just ignore it\n             LOG.error(\"Error flush entry log during shutting down, which may cause entry log corrupted.\", ie);\n         } finally {\n-            for (Entry<Long, BufferedChannel> channelEntry : channels\n-                    .entrySet()) {\n-                FileChannel fileChannel = channelEntry.getValue()\n-                        .getFileChannel();\n-                if (fileChannel.isOpen()) {\n-                    IOUtils.close(LOG, fileChannel);\n-                }\n+            for (FileChannel fc : logid2FileChannel.values()) {\n+                IOUtils.close(LOG, fc);\n             }\n+            forceCloseFileChannel(logChannel);\n+        }\n+        // shutdown the pre-allocation thread\n+        entryLoggerAllocator.stop();\n+    }\n+\n+    private static void closeFileChannel(BufferedChannelBase channel) throws IOException {\n+        if (null == channel) {\n+            return;\n+        }\n+        FileChannel fileChannel = channel.getFileChannel();\n+        if (null != fileChannel) {\n+            fileChannel.close();\n+        }\n+    }\n+\n+    private static void forceCloseFileChannel(BufferedChannelBase channel) {\n+        if (null == channel) {\n+            return;\n+        }\n+        FileChannel fileChannel = channel.getFileChannel();\n+        if (null != fileChannel) {\n+            IOUtils.close(LOG, fileChannel);\n         }\n     }\n "},{"sha":"ed830ca244845a9ce180be594f8f7744e96bb0d0","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","status":"modified","additions":22,"deletions":0,"changes":22,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -32,6 +32,7 @@\n public class ServerConfiguration extends AbstractConfiguration {\n     // Entry Log Parameters\n     protected final static String ENTRY_LOG_SIZE_LIMIT = \"logSizeLimit\";\n+    protected final static String ENTRY_LOG_FILE_PREALLOCATION_ENABLED = \"entryLogFilePreallocationEnabled\";\n     protected final static String MINOR_COMPACTION_INTERVAL = \"minorCompactionInterval\";\n     protected final static String MINOR_COMPACTION_THRESHOLD = \"minorCompactionThreshold\";\n     protected final static String MAJOR_COMPACTION_INTERVAL = \"majorCompactionInterval\";\n@@ -131,6 +132,27 @@ public ServerConfiguration setEntryLogSizeLimit(long logSizeLimit) {\n         return this;\n     }\n \n+    /**\n+     * Is entry log file preallocation enabled.\n+     *\n+     * @return whether entry log file preallocation is enabled or not.\n+     */\n+    public boolean isEntryLogFilePreAllocationEnabled() {\n+        return this.getBoolean(ENTRY_LOG_FILE_PREALLOCATION_ENABLED, true);\n+    }\n+\n+    /**\n+     * Enable/disable entry log file preallocation.\n+     *\n+     * @param enabled\n+     *          enable/disable entry log file preallocation.\n+     * @return server configuration object.\n+     */\n+    public ServerConfiguration setEntryLogFilePreAllocationEnabled(boolean enabled) {\n+        this.setProperty(ENTRY_LOG_FILE_PREALLOCATION_ENABLED, enabled);\n+        return this;\n+    }\n+\n     /**\n      * Get Garbage collection wait time\n      *"},{"sha":"929f332ea1e2f4a798dfa97e12385403ce526e9b","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -95,11 +95,13 @@ public CompactionTest() {\n     public void setUp() throws Exception {\n         // Set up the configuration properties needed.\n         baseConf.setEntryLogSizeLimit(numEntries * ENTRY_SIZE);\n+        // Disable skip list for compaction\n         baseConf.setGcWaitTime(gcWaitTime);\n         baseConf.setMinorCompactionThreshold(minorCompactionThreshold);\n         baseConf.setMajorCompactionThreshold(majorCompactionThreshold);\n         baseConf.setMinorCompactionInterval(minorCompactionInterval);\n         baseConf.setMajorCompactionInterval(majorCompactionInterval);\n+        baseConf.setEntryLogFilePreAllocationEnabled(false);\n \n         super.setUp();\n     }"},{"sha":"c9a11d165d9671c6197e1cbe9435709e9d32effd","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -57,6 +57,7 @@ public void setUp() throws Exception {\n         // Set up the configuration properties needed.\n         baseConf.setEntryLogSizeLimit(2 * 1024 * 1024L);\n         baseConf.setGcWaitTime(1000);\n+        baseConf.setEntryLogFilePreAllocationEnabled(false);\n         super.setUp();\n     }\n "},{"sha":"604ead70b72c59bc023952201e7495e3df176f44","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/test/ReadOnlyBookieTest.java","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/apache/bookkeeper/blob/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/ReadOnlyBookieTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/694568b0ff0d048c284c8d5db0c9455d30dfa3ce/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/ReadOnlyBookieTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/ReadOnlyBookieTest.java?ref=694568b0ff0d048c284c8d5db0c9455d30dfa3ce","patch":"@@ -39,6 +39,7 @@\n \n     public ReadOnlyBookieTest() {\n         super(2);\n+        baseConf.setEntryLogFilePreAllocationEnabled(false);\n     }\n \n     /**"}]}

