{"sha":"7f67e765c73890a2f838ec8f5d43b814ce42c84b","node_id":"MDY6Q29tbWl0MTU3NTk1Njo3ZjY3ZTc2NWM3Mzg5MGEyZjgzOGVjOGY1ZDQzYjgxNGNlNDJjODRi","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2012-12-04T17:54:23Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2012-12-04T17:54:23Z"},"message":"BOOKKEEPER-461: Delivery throughput degrades when there are lots of publishers w/ high traffic. (sijie via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1417066 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"08a4d586263414f2caa722c01b0b13f7f63ffb6d","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/08a4d586263414f2caa722c01b0b13f7f63ffb6d"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/7f67e765c73890a2f838ec8f5d43b814ce42c84b","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/7f67e765c73890a2f838ec8f5d43b814ce42c84b","html_url":"https://github.com/apache/bookkeeper/commit/7f67e765c73890a2f838ec8f5d43b814ce42c84b","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/7f67e765c73890a2f838ec8f5d43b814ce42c84b/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"6030beaba9e770db9b856b8de1b06dab843b2ccc","url":"https://api.github.com/repos/apache/bookkeeper/commits/6030beaba9e770db9b856b8de1b06dab843b2ccc","html_url":"https://github.com/apache/bookkeeper/commit/6030beaba9e770db9b856b8de1b06dab843b2ccc"}],"stats":{"total":198,"additions":145,"deletions":53},"files":[{"sha":"4f674efa79f353e896b31d6d7026cdd1628194d3","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/7f67e765c73890a2f838ec8f5d43b814ce42c84b/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/7f67e765c73890a2f838ec8f5d43b814ce42c84b/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=7f67e765c73890a2f838ec8f5d43b814ce42c84b","patch":"@@ -168,6 +168,8 @@ Trunk (unreleased changes)\n \n         BOOKKEEPER-442: Failed to deliver messages due to inconsistency between SubscriptionState and LedgerRanges. (jiannan via ivank)\n \n+        BOOKKEEPER-461: Delivery throughput degrades when there are lots of publishers w/ high traffic. (sijie via ivank)\n+\n     IMPROVEMENTS:\n \n       BOOKKEEPER-467: Allocate ports for testing dynamically (ivank)"},{"sha":"b56397d9fc4c18f9cf6a5a4194d8a1e163890733","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","status":"modified","additions":10,"deletions":0,"changes":10,"blob_url":"https://github.com/apache/bookkeeper/blob/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java?ref=7f67e765c73890a2f838ec8f5d43b814ce42c84b","patch":"@@ -66,6 +66,7 @@\n     protected final static String RETRY_REMOTE_SUBSCRIBE_THREAD_RUN_INTERVAL = \"retry_remote_subscribe_thread_run_interval\";\n     protected final static String DEFAULT_MESSAGE_WINDOW_SIZE =\n         \"default_message_window_size\";\n+    protected final static String NUM_READAHEAD_CACHE_THREADS = \"num_readahead_cache_threads\";\n \n     protected final static String MAX_ENTRIES_PER_LEDGER = \"max_entries_per_ledger\";\n \n@@ -379,6 +380,15 @@ public void validate() throws ConfigurationException {\n         // add other checks here\n     }\n \n+    /**\n+     * Get number of read ahead cache threads.\n+     *\n+     * @return number of read ahead cache threads.\n+     */\n+    public int getNumReadAheadCacheThreads() {\n+        return conf.getInt(NUM_READAHEAD_CACHE_THREADS, Runtime.getRuntime().availableProcessors());\n+    }\n+\n     /**\n      * Whether enable metadata manager based topic manager.\n      *"},{"sha":"5c2e3b6c752e25d265c6c644e0ff5142a89e45ed","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","status":"modified","additions":120,"deletions":47,"changes":167,"blob_url":"https://github.com/apache/bookkeeper/blob/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","raw_url":"https://github.com/apache/bookkeeper/raw/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java?ref=7f67e765c73890a2f838ec8f5d43b814ce42c84b","patch":"@@ -28,8 +28,12 @@\n import java.util.SortedSet;\n import java.util.TreeMap;\n import java.util.TreeSet;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.RejectedExecutionException;\n+import java.util.concurrent.atomic.AtomicLong;\n \n import org.apache.hedwig.protocol.PubSubProtocol;\n import org.slf4j.Logger;\n@@ -38,6 +42,8 @@\n import com.google.protobuf.ByteString;\n \n import org.apache.bookkeeper.util.MathUtils;\n+import org.apache.bookkeeper.util.OrderedSafeExecutor;\n+import org.apache.bookkeeper.util.SafeRunnable;\n import org.apache.hedwig.exceptions.PubSubException;\n import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n import org.apache.hedwig.protocol.PubSubProtocol.Message;\n@@ -68,7 +74,8 @@\n     /**\n      * The structure for the cache\n      */\n-    protected Map<CacheKey, CacheValue> cache = new HashMap<CacheKey, CacheValue>();\n+    protected ConcurrentMap<CacheKey, CacheValue> cache =\n+        new ConcurrentHashMap<CacheKey, CacheValue>();\n \n     /**\n      * To simplify synchronization, the cache will be maintained by a single\n@@ -87,13 +94,14 @@\n      * We also want to track the entries in seq-id order so that we can clean up\n      * entries after the last subscriber\n      */\n-    protected Map<ByteString, SortedSet<Long>> orderedIndexOnSeqId = new HashMap<ByteString, SortedSet<Long>>();\n+    protected Map<ByteString, SortedSet<Long>> orderedIndexOnSeqId =\n+        new HashMap<ByteString, SortedSet<Long>>();\n \n     /**\n      * We maintain an estimate of the current size of the cache, so that we know\n      * when to evict entries.\n      */\n-    protected long presentCacheSize = 0;\n+    protected AtomicLong presentCacheSize = new AtomicLong(0);\n \n     /**\n      * One instance of a callback that we will pass to the underlying\n@@ -111,7 +119,10 @@\n     protected Thread cacheThread;\n     // Boolean indicating if this thread should continue running. This is used\n     // when we want to stop the thread during a PubSubServer shutdown.\n-    protected boolean keepRunning = true;\n+    protected volatile boolean keepRunning = true;\n+\n+    protected final OrderedSafeExecutor cacheWorkers;\n+    protected final long maxCacheSize;\n \n     // JMX Beans\n     ReadAheadCacheBean jmxCacheBean = null;\n@@ -125,6 +136,8 @@ public ReadAheadCache(PersistenceManagerWithRangeScan realPersistenceManager, Se\n         this.realPersistenceManager = realPersistenceManager;\n         this.cfg = cfg;\n         cacheThread = new Thread(this, \"CacheThread\");\n+        cacheWorkers = new OrderedSafeExecutor(cfg.getNumReadAheadCacheThreads());\n+        maxCacheSize = cfg.getMaximumCacheSize();\n     }\n \n     public ReadAheadCache start() {\n@@ -205,11 +218,28 @@ public void operationFinished(Object ctx, PubSubProtocol.MessageSeqId resultOfOp\n             // cache\n             CacheKey cacheKey = new CacheKey(originalRequest.getTopic(), resultOfOperation.getLocalComponent());\n \n-            enqueueWithoutFailure(new ScanResponse(cacheKey, messageWithLocalSeqId));\n+            enqueueWithoutFailureByTopic(cacheKey.getTopic(),\n+                    new ScanResponse(cacheKey, messageWithLocalSeqId));\n         }\n \n     }\n \n+    protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest obj) {\n+        if (!keepRunning) {\n+            return;\n+        }\n+        try {\n+            cacheWorkers.submitOrdered(topic, new SafeRunnable() {\n+                @Override\n+                public void safeRun() {\n+                    obj.performRequest();\n+                }\n+            });\n+        } catch (RejectedExecutionException ree) {\n+            logger.error(\"Failed to submit cache request for topic \" + topic.toStringUtf8() + \" : \", ree);\n+        }\n+    }\n+\n     /**\n      * Too complicated to deal with enqueue failures from the context of our\n      * callbacks. Its just simpler to quit and restart afresh. Moreover, this\n@@ -234,7 +264,8 @@ protected void enqueueWithoutFailure(CacheRequest obj) {\n      */\n     public void scanSingleMessage(ScanRequest request) {\n         // Let the scan requests be serialized through the queue\n-        enqueueWithoutFailure(new ScanRequestWrapper(request));\n+        enqueueWithoutFailureByTopic(request.getTopic(),\n+                new ScanRequestWrapper(request));\n     }\n \n     /**\n@@ -358,7 +389,10 @@ protected RangeScanRequest doReadAheadStartingFrom(ByteString topic, long seqId,\n                 break;\n             }\n             CacheValue cacheValue = new CacheValue();\n-            cache.put(cacheKey, cacheValue);\n+            if (null != cache.putIfAbsent(cacheKey, cacheValue)) {\n+                logger.warn(\"It is unexpected that more than one threads are adding message to cache key {}\"\n+                            +\" at the same time.\", cacheKey);\n+            }\n \n             logger.debug(\"Adding cache stub for: {}\", cacheKey);\n             installedStubs.add(cacheKey);\n@@ -405,7 +439,7 @@ public void messageScanned(Object ctx, Message message) {\n             // Any message we read is potentially useful for us, so lets first\n             // enqueue it\n             CacheKey cacheKey = new CacheKey(topic, message.getMsgId().getLocalComponent());\n-            enqueueWithoutFailure(new ScanResponse(cacheKey, message));\n+            enqueueWithoutFailureByTopic(topic, new ScanResponse(cacheKey, message));\n \n             // Now lets see if this message is the one we were expecting\n             CacheKey expectedKey = installedStubs.peek();\n@@ -453,7 +487,8 @@ public void scanFinished(Object ctx, ReasonForFinish reason) {\n         private void enqueueDeleteOfRemainingStubs(Exception reason) {\n             CacheKey installedStub;\n             while ((installedStub = installedStubs.poll()) != null) {\n-                enqueueWithoutFailure(new ExceptionOnCacheKey(installedStub, reason));\n+                enqueueWithoutFailureByTopic(installedStub.getTopic(),\n+                        new ExceptionOnCacheKey(installedStub, reason));\n             }\n         }\n     }\n@@ -482,57 +517,87 @@ private void enqueueDeleteOfRemainingStubs(Exception reason) {\n      * @param cacheKey\n      * @param message\n      */\n-    protected void addMessageToCache(CacheKey cacheKey, Message message, long currTime) {\n+    protected void addMessageToCache(final CacheKey cacheKey,\n+                                     final Message message, final long currTime) {\n         logger.debug(\"Adding msg {} to readahead cache\", cacheKey);\n \n         CacheValue cacheValue;\n \n         if ((cacheValue = cache.get(cacheKey)) == null) {\n             cacheValue = new CacheValue();\n-            cache.put(cacheKey, cacheValue);\n+            CacheValue oldValue = cache.putIfAbsent(cacheKey, cacheValue);\n+            if (null != oldValue) {\n+                logger.warn(\"Weird! Should not have two threads adding message to cache key {} at the same time.\",\n+                            cacheKey);\n+                cacheValue = oldValue;\n+            }\n         }\n \n         // update the cache size\n-        presentCacheSize += message.getBody().size();\n+        final long newCacheSize = presentCacheSize.addAndGet(message.getBody().size());\n \n-        // maintain the time index of addition\n-        MapMethods.addToMultiMap(timeIndexOfAddition, currTime, cacheKey, HashSetCacheKeyFactory.instance);\n-\n-        // maintain the index of seq-id\n-        MapMethods.addToMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(), cacheKey.getSeqId(),\n-                                 TreeSetLongFactory.instance);\n-\n-        // finally add the message to the cache\n-        cacheValue.setMessageAndInvokeCallbacks(message, currTime);\n+        synchronized (cacheValue) {\n+            // finally add the message to the cache\n+            cacheValue.setMessageAndInvokeCallbacks(message, currTime);\n+        }\n \n         // if overgrown, collect old entries\n-        collectOldCacheEntries();\n+        enqueueWithoutFailure(new CacheRequest() {\n+            @Override\n+            public void performRequest() {\n+                // maintain the index of seq-id\n+                MapMethods.addToMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n+                                         cacheKey.getSeqId(), TreeSetLongFactory.instance);\n+\n+                // maintain the time index of addition\n+                MapMethods.addToMultiMap(timeIndexOfAddition, currTime,\n+                                         cacheKey, HashSetCacheKeyFactory.instance);\n+                // update time index\n+                if (newCacheSize > maxCacheSize) {\n+                    collectOldCacheEntries();\n+                }\n+            }\n+        });\n     }\n \n-    protected void removeMessageFromCache(CacheKey cacheKey, Exception exception, boolean maintainTimeIndex,\n-                                          boolean maintainSeqIdIndex) {\n+    protected void removeMessageFromCache(final CacheKey cacheKey, Exception exception,\n+                                          final boolean maintainTimeIndex,\n+                                          final boolean maintainSeqIdIndex) {\n         CacheValue cacheValue = cache.remove(cacheKey);\n \n         if (cacheValue == null) {\n             return;\n         }\n \n-        if (cacheValue.isStub()) {\n-            cacheValue.setErrorAndInvokeCallbacks(exception);\n-            // Stubs are not present in the indexes, so dont need to maintain\n-            // indexes here\n-            return;\n-        }\n-\n-        presentCacheSize -= cacheValue.getMessage().getBody().size();\n+        long timeOfAddition = 0;\n+        synchronized (cacheValue) {\n+            if (cacheValue.isStub()) {\n+                cacheValue.setErrorAndInvokeCallbacks(exception);\n+                // Stubs are not present in the indexes, so don't need to maintain\n+                // indexes here\n+                return;\n+            }\n \n-        // maintain the 2 indexes\n-        // TODO: can we maintain these lazily?\n-        if (maintainSeqIdIndex) {\n-            MapMethods.removeFromMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(), cacheKey.getSeqId());\n+            presentCacheSize.addAndGet(0 - cacheValue.getMessage().getBody().size());\n+            timeOfAddition = cacheValue.getTimeOfAddition();\n         }\n-        if (maintainTimeIndex) {\n-            MapMethods.removeFromMultiMap(timeIndexOfAddition, cacheValue.getTimeOfAddition(), cacheKey);\n+\n+        // maintain the 2 indexes lazily\n+        if (maintainSeqIdIndex || maintainTimeIndex) {\n+            final long additionTime = timeOfAddition;\n+            enqueueWithoutFailure(new CacheRequest() {\n+                @Override\n+                public void performRequest() {\n+                    if (maintainSeqIdIndex) {\n+                        MapMethods.removeFromMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n+                                                      cacheKey.getSeqId());\n+                    }\n+                    if (maintainTimeIndex) {\n+                        MapMethods.removeFromMultiMap(timeIndexOfAddition, additionTime,\n+                                                      cacheKey);\n+                    }\n+                }\n+            });\n         }\n     }\n \n@@ -541,17 +606,16 @@ protected void removeMessageFromCache(CacheKey cacheKey, Exception exception, bo\n      * oldest to newest.\n      */\n     protected void collectOldCacheEntries() {\n-        long maxCacheSize = cfg.getMaximumCacheSize();\n-\n-        while (presentCacheSize > maxCacheSize && !timeIndexOfAddition.isEmpty()) {\n+        while (presentCacheSize.get() > cfg.getMaximumCacheSize () &&\n+               !timeIndexOfAddition.isEmpty()) {\n             Long earliestTime = timeIndexOfAddition.firstKey();\n             Set<CacheKey> oldCacheEntries = timeIndexOfAddition.get(earliestTime);\n \n             // Note: only concrete cache entries, and not stubs are in the time\n             // index. Hence there can be no callbacks pending on these cache\n             // entries. Hence safe to remove them directly.\n             for (Iterator<CacheKey> iter = oldCacheEntries.iterator(); iter.hasNext();) {\n-                CacheKey cacheKey = iter.next();\n+                final CacheKey cacheKey = iter.next();\n \n                 logger.debug(\"Removing {} from cache because it's the oldest.\", cacheKey);\n                 removeMessageFromCache(cacheKey, readAheadExceptionInstance, //\n@@ -562,7 +626,6 @@ protected void collectOldCacheEntries() {\n             }\n \n             timeIndexOfAddition.remove(earliestTime);\n-\n         }\n     }\n \n@@ -691,11 +754,20 @@ public void performRequest() {\n \n             // Read ahead must have installed at least a stub for us, so this\n             // can't be null\n-            CacheValue cacheValue = cache.get(new CacheKey(request.getTopic(), request.getStartSeqId()));\n+            CacheKey cacheKey = new CacheKey(request.getTopic(), request.getStartSeqId());\n+            CacheValue cacheValue = cache.get(cacheKey);\n+            if (null == cacheValue) {\n+                logger.error(\"Cache key {} is removed after installing stub when scanning.\", cacheKey);\n+                // reissue the request \n+                scanSingleMessage(request);\n+                return;\n+            }\n \n-            // Add our callback to the stub. If the cache value was already a\n-            // concrete message, the callback will be called right away\n-            cacheValue.addCallback(request.getCallback(), request.getCtx());\n+            synchronized (cacheValue) {\n+                // Add our callback to the stub. If the cache value was already a\n+                // concrete message, the callback will be called right away\n+                cacheValue.addCallback(request.getCallback(), request.getCtx());\n+            }\n \n             if (readAheadRequest != null) {\n                 realPersistenceManager.scanMessages(readAheadRequest);\n@@ -709,6 +781,7 @@ public void performRequest() {\n         // thread.\n         public void performRequest() {\n             keepRunning = false;\n+            cacheWorkers.shutdown();\n         }\n     }\n "},{"sha":"b228c1dd5d68b96a8fd2ebc114fdd64f9de78896","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java?ref=7f67e765c73890a2f838ec8f5d43b814ce42c84b","patch":"@@ -48,7 +48,7 @@ public long getMaxCacheSize() {\n \n     @Override\n     public long getPresentCacheSize() {\n-        return cache.presentCacheSize;\n+        return cache.presentCacheSize.get();\n     }\n \n     @Override"},{"sha":"36b80eaabd9f24db47e4d7fe2e87a6495a169ef7","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","status":"modified","additions":12,"deletions":5,"changes":17,"blob_url":"https://github.com/apache/bookkeeper/blob/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/7f67e765c73890a2f838ec8f5d43b814ce42c84b/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java?ref=7f67e765c73890a2f838ec8f5d43b814ce42c84b","patch":"@@ -27,6 +27,7 @@\n import org.junit.Test;\n \n import com.google.protobuf.ByteString;\n+import org.apache.bookkeeper.util.MathUtils;\n import org.apache.hedwig.HelperMethods;\n import org.apache.hedwig.StubCallback;\n import org.apache.hedwig.StubScanCallback;\n@@ -53,6 +54,12 @@ protected void enqueueWithoutFailure(CacheRequest obj) {\n             // make it perform in the same thread\n             obj.performRequest();\n         }\n+\n+        @Override\n+        protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest obj) {\n+            // make it perform in the same thread\n+            obj.performRequest();\n+        }\n     }\n \n     class MyServerConfiguration extends ServerConfiguration {\n@@ -145,7 +152,7 @@ public void testDeliveredUntil() throws Exception {\n         for (Message m : messages) {\n             persistMessage(m);\n         }\n-        assertEquals((long) NUM_MESSAGES * MSG_SIZE, cacheBasedPersistenceManager.presentCacheSize);\n+        assertEquals((long) NUM_MESSAGES * MSG_SIZE, cacheBasedPersistenceManager.presentCacheSize.get());\n         long middle = messages.size() / 2;\n         cacheBasedPersistenceManager.deliveredUntil(topic, middle);\n \n@@ -162,7 +169,7 @@ public void testDeliveredUntil() throws Exception {\n         assertTrue(cacheBasedPersistenceManager.cache.isEmpty());\n         assertTrue(cacheBasedPersistenceManager.timeIndexOfAddition.isEmpty());\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.isEmpty());\n-        assertTrue(0 == cacheBasedPersistenceManager.presentCacheSize);\n+        assertTrue(0 == cacheBasedPersistenceManager.presentCacheSize.get());\n \n     }\n \n@@ -231,9 +238,9 @@ public void testDoReadAheadStartingFrom() throws Exception {\n     @Test\n     public void testAddMessageToCache() {\n         CacheKey key = new CacheKey(topic, 1);\n-        cacheBasedPersistenceManager.addMessageToCache(key, messages.get(0), System.currentTimeMillis());\n+        cacheBasedPersistenceManager.addMessageToCache(key, messages.get(0), MathUtils.now());\n         assertEquals(1, cacheBasedPersistenceManager.cache.size());\n-        assertEquals(MSG_SIZE, cacheBasedPersistenceManager.presentCacheSize);\n+        assertEquals(MSG_SIZE, cacheBasedPersistenceManager.presentCacheSize.get());\n         assertEquals(1, cacheBasedPersistenceManager.orderedIndexOnSeqId.get(topic).size());\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.get(topic).contains(1L));\n \n@@ -244,7 +251,7 @@ public void testAddMessageToCache() {\n     @Test\n     public void testRemoveMessageFromCache() {\n         CacheKey key = new CacheKey(topic, 1);\n-        cacheBasedPersistenceManager.addMessageToCache(key, messages.get(0), System.currentTimeMillis());\n+        cacheBasedPersistenceManager.addMessageToCache(key, messages.get(0), MathUtils.now());\n         cacheBasedPersistenceManager.removeMessageFromCache(key, new Exception(), true, true);\n         assertTrue(cacheBasedPersistenceManager.cache.isEmpty());\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.isEmpty());"}]}

