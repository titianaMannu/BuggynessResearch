{"sha":"924fb834de0ae926ea075385c47dd29f8dd804a3","node_id":"MDY6Q29tbWl0MTU3NTk1Njo5MjRmYjgzNGRlMGFlOTI2ZWEwNzUzODVjNDdkZDI5ZjhkZDgwNGEz","commit":{"author":{"name":"Benjamin Reed","email":"breed@apache.org","date":"2011-11-28T22:01:53Z"},"committer":{"name":"Benjamin Reed","email":"breed@apache.org","date":"2011-11-28T22:01:53Z"},"message":"BOOKKEEPER-53: race condition of outstandingMsgSet@SubscribeResponseHandler\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1207648 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"e5d72020b773d7e0543d59237dc2a61834de25e0","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/e5d72020b773d7e0543d59237dc2a61834de25e0"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/924fb834de0ae926ea075385c47dd29f8dd804a3","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/924fb834de0ae926ea075385c47dd29f8dd804a3","html_url":"https://github.com/apache/bookkeeper/commit/924fb834de0ae926ea075385c47dd29f8dd804a3","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/924fb834de0ae926ea075385c47dd29f8dd804a3/comments","author":{"login":"breed","id":143779,"node_id":"MDQ6VXNlcjE0Mzc3OQ==","avatar_url":"https://avatars.githubusercontent.com/u/143779?v=4","gravatar_id":"","url":"https://api.github.com/users/breed","html_url":"https://github.com/breed","followers_url":"https://api.github.com/users/breed/followers","following_url":"https://api.github.com/users/breed/following{/other_user}","gists_url":"https://api.github.com/users/breed/gists{/gist_id}","starred_url":"https://api.github.com/users/breed/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/breed/subscriptions","organizations_url":"https://api.github.com/users/breed/orgs","repos_url":"https://api.github.com/users/breed/repos","events_url":"https://api.github.com/users/breed/events{/privacy}","received_events_url":"https://api.github.com/users/breed/received_events","type":"User","site_admin":false},"committer":{"login":"breed","id":143779,"node_id":"MDQ6VXNlcjE0Mzc3OQ==","avatar_url":"https://avatars.githubusercontent.com/u/143779?v=4","gravatar_id":"","url":"https://api.github.com/users/breed","html_url":"https://github.com/breed","followers_url":"https://api.github.com/users/breed/followers","following_url":"https://api.github.com/users/breed/following{/other_user}","gists_url":"https://api.github.com/users/breed/gists{/gist_id}","starred_url":"https://api.github.com/users/breed/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/breed/subscriptions","organizations_url":"https://api.github.com/users/breed/orgs","repos_url":"https://api.github.com/users/breed/repos","events_url":"https://api.github.com/users/breed/events{/privacy}","received_events_url":"https://api.github.com/users/breed/received_events","type":"User","site_admin":false},"parents":[{"sha":"3af9f38fc3b53c40751904972384ecb9a4e9fb44","url":"https://api.github.com/repos/apache/bookkeeper/commits/3af9f38fc3b53c40751904972384ecb9a4e9fb44","html_url":"https://github.com/apache/bookkeeper/commit/3af9f38fc3b53c40751904972384ecb9a4e9fb44"}],"stats":{"total":21,"additions":13,"deletions":8},"files":[{"sha":"4181dff92813962e38f64a92022b2ff3086c12b3","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/924fb834de0ae926ea075385c47dd29f8dd804a3/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/924fb834de0ae926ea075385c47dd29f8dd804a3/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=924fb834de0ae926ea075385c47dd29f8dd804a3","patch":"@@ -114,6 +114,8 @@ BUGFIXES:\n \n   BOOKKEEPER-117: Support multi threads in hedwig cpp client to leverage multi-core hardware (Sijie Guo via ivank)\n \n+  BOOKKEEPER-53: race condition of outstandingMsgSet@SubscribeResponseHandler (fpj via breed)\n+\n IMPROVEMENTS:\n \n  BOOKKEEPER-28: Create useful startup scripts for bookkeeper and hedwig (ivank)"},{"sha":"c17ffcbb18d58adca15c4e13182056f1813ca8ea","filename":"hedwig-client/src/main/java/org/apache/hedwig/client/handlers/SubscribeResponseHandler.java","status":"modified","additions":11,"deletions":8,"changes":19,"blob_url":"https://github.com/apache/bookkeeper/blob/924fb834de0ae926ea075385c47dd29f8dd804a3/hedwig-client/src/main/java/org/apache/hedwig/client/handlers/SubscribeResponseHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/924fb834de0ae926ea075385c47dd29f8dd804a3/hedwig-client/src/main/java/org/apache/hedwig/client/handlers/SubscribeResponseHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/client/handlers/SubscribeResponseHandler.java?ref=924fb834de0ae926ea075385c47dd29f8dd804a3","patch":"@@ -17,7 +17,8 @@\n  */\n package org.apache.hedwig.client.handlers;\n \n-import java.util.HashSet;\n+import java.util.Collections;\n+import java.util.concurrent.ConcurrentHashMap;\n import java.util.LinkedList;\n import java.util.Queue;\n import java.util.Set;\n@@ -112,18 +113,20 @@ public void handleSubscribeResponse(PubSubResponse response, PubSubData pubSubDa\n             // this only on a successful ack response from the server.\n             TopicSubscriber topicSubscriber = new TopicSubscriber(pubSubData.topic, pubSubData.subscriberId);\n             responseHandler.getSubscriber().setChannelForTopic(topicSubscriber, channel);\n-            // Lazily create the Set to keep track of outstanding Messages\n-            // to be consumed by the client app. At this stage, delivery for\n-            // that topic hasn't started yet so creation of this Set should\n-            // be thread safe. We'll create the Set with an initial capacity\n-            // equal to the configured parameter for the maximum number of\n+            // Lazily create the Set (from a concurrent hashmap) to keep track\n+            // of outstanding Messages to be consumed by the client app. At this\n+            // stage, delivery for that topic hasn't started yet so creation of \n+            // this Set should be thread safe. We'll create the Set with an initial\n+            // capacity equal to the configured parameter for the maximum number of\n             // outstanding messages to allow. The load factor will be set to\n             // 1.0f which means we'll only rehash and allocate more space if\n             // we ever exceed the initial capacity. That should be okay\n             // because when that happens, things are slow already and piling\n             // up on the client app side to consume messages.\n-            outstandingMsgSet = new HashSet<Message>(\n-                responseHandler.getConfiguration().getMaximumOutstandingMessages(), 1.0f);\n+            \n+            outstandingMsgSet = Collections.newSetFromMap(new ConcurrentHashMap<Message,Boolean>(\n+                responseHandler.getConfiguration().getMaximumOutstandingMessages(), 1.0f));\n+            \n             // Response was success so invoke the callback's operationFinished\n             // method.\n             pubSubData.callback.operationFinished(pubSubData.context, null);"}]}

