{"sha":"9a8d62b1d1231f2fe6feca7e0c407a426a1278d5","node_id":"MDY6Q29tbWl0MTU3NTk1Njo5YThkNjJiMWQxMjMxZjJmZTZmZWNhN2UwYzQwN2E0MjZhMTI3OGQ1","commit":{"author":{"name":"Robin Dhamankar","email":"robindh@apache.org","date":"2016-03-16T03:43:54Z"},"committer":{"name":"Sijie Guo","email":"sijie@apache.org","date":"2016-03-16T03:43:54Z"},"message":"BOOKKEEPER-769: Remove the Hedwig Code\n\n- Remove code directories for Hedwig code\n- Remove code directories under compat\n- Remove Hedwig related documentation\n- Remove references to Hedwig code in pom files\n\n* There is an unrelated findbugs violation in BookieWatcher which is not related to this change\n* There were flaky tests that failed locally but passed when I reran them\n\nAuthor: Robin Dhamankar <robindh@Robins-MacBook-Air.local>\n\nReviewers: Sijie Guo <sijie@apache.org>\n\nCloses #27 from robindh/RemoveHedwig","tree":{"sha":"02ef5a2fa0c8090e5e410f5804a51ce5a0cf7ff0","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/02ef5a2fa0c8090e5e410f5804a51ce5a0cf7ff0"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5","html_url":"https://github.com/apache/bookkeeper/commit/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5/comments","author":null,"committer":{"login":"sijie","id":1217863,"node_id":"MDQ6VXNlcjEyMTc4NjM=","avatar_url":"https://avatars.githubusercontent.com/u/1217863?v=4","gravatar_id":"","url":"https://api.github.com/users/sijie","html_url":"https://github.com/sijie","followers_url":"https://api.github.com/users/sijie/followers","following_url":"https://api.github.com/users/sijie/following{/other_user}","gists_url":"https://api.github.com/users/sijie/gists{/gist_id}","starred_url":"https://api.github.com/users/sijie/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/sijie/subscriptions","organizations_url":"https://api.github.com/users/sijie/orgs","repos_url":"https://api.github.com/users/sijie/repos","events_url":"https://api.github.com/users/sijie/events{/privacy}","received_events_url":"https://api.github.com/users/sijie/received_events","type":"User","site_admin":false},"parents":[{"sha":"410ff7263a477d4b75a43d006adde3549225a4b9","url":"https://api.github.com/repos/apache/bookkeeper/commits/410ff7263a477d4b75a43d006adde3549225a4b9","html_url":"https://github.com/apache/bookkeeper/commit/410ff7263a477d4b75a43d006adde3549225a4b9"}],"stats":{"total":104540,"additions":11,"deletions":104529},"files":[{"sha":"7bab01b6c4f51401d37b1b541b1e19b596794f54","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/FileUtils.java","status":"removed","additions":0,"deletions":98,"changes":98,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/FileUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/FileUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/FileUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,98 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class FileUtils {\n-\n-    static DirDeleterThred dirDeleterThread;\n-    static final Logger log = LoggerFactory.getLogger(FileUtils.class);\n-\n-    static {\n-        dirDeleterThread = new DirDeleterThred();\n-        Runtime.getRuntime().addShutdownHook(dirDeleterThread);\n-    }\n-\n-    public static File createTempDirectory(String prefix) throws IOException {\n-        return createTempDirectory(prefix, null);\n-    }\n-\n-    public static File createTempDirectory(String prefix, String suffix) throws IOException {\n-        File tempDir = File.createTempFile(prefix, suffix);\n-        if (!tempDir.delete()) {\n-            throw new IOException(\"Could not delete temp file: \" + tempDir.getAbsolutePath());\n-        }\n-\n-        if (!tempDir.mkdir()) {\n-            throw new IOException(\"Could not create temp directory: \" + tempDir.getAbsolutePath());\n-        }\n-\n-        dirDeleterThread.addDirToDelete(tempDir);\n-        return tempDir;\n-\n-    }\n-\n-    static class DirDeleterThred extends Thread {\n-        List<File> dirsToDelete = new LinkedList<File>();\n-\n-        public synchronized void addDirToDelete(File dir) {\n-            dirsToDelete.add(dir);\n-        }\n-\n-        @Override\n-        public void run() {\n-            synchronized (this) {\n-                for (File dir : dirsToDelete) {\n-                    deleteDirectory(dir);\n-                }\n-            }\n-        }\n-\n-        protected void deleteDirectory(File dir) {\n-            if (dir.isFile()) {\n-                if (!dir.delete()) {\n-                    log.error(\"Could not delete \" + dir.getAbsolutePath());\n-                }\n-                return;\n-            }\n-\n-            File[] files = dir.listFiles();\n-            if (files == null) {\n-                return;\n-            }\n-\n-            for (File f : files) {\n-                deleteDirectory(f);\n-            }\n-\n-            if (!dir.delete()) {\n-                log.error(\"Could not delete directory: \" + dir.getAbsolutePath());\n-            }\n-\n-        }\n-\n-    }\n-\n-}"},{"sha":"8bfdadaa97d0d22154906af16a9aefa47b375530","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/HedwigSocketAddress.java","status":"removed","additions":0,"deletions":143,"changes":143,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/HedwigSocketAddress.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/HedwigSocketAddress.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/HedwigSocketAddress.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,143 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.net.InetSocketAddress;\n-\n-/**\n- * This is a data wrapper class that is basically an InetSocketAddress with one\n- * extra piece of information for the SSL port (optional). This is used by\n- * Hedwig so we can encapsulate both regular and SSL port information in one\n- * data structure. Hedwig hub servers can be configured to listen on the\n- * standard regular port and additionally on an optional SSL port. The String\n- * representation of a HedwigSocketAddress is: <hostname>:<port>:<SSL\n- * port(optional)>\n- */\n-public class HedwigSocketAddress {\n-\n-    // Member fields that make up this class.\n-    private final String hostname;\n-    private final int port;\n-    private final int sslPort;\n-\n-    private final InetSocketAddress socketAddress;\n-    private final InetSocketAddress sslSocketAddress;\n-\n-    // Constants used by this class.\n-    public static final String COLON = \":\";\n-    private static final int NO_SSL_PORT = -1;\n-\n-    // Constructor that takes in both a regular and SSL port.\n-    public HedwigSocketAddress(String hostname, int port, int sslPort) {\n-        this.hostname = hostname;\n-        this.port = port;\n-        this.sslPort = sslPort;\n-        socketAddress = new InetSocketAddress(hostname, port);\n-        if (sslPort != NO_SSL_PORT)\n-            sslSocketAddress = new InetSocketAddress(hostname, sslPort);\n-        else\n-            sslSocketAddress = null;\n-    }\n-\n-    // Constructor that only takes in a regular port.\n-    public HedwigSocketAddress(String hostname, int port) {\n-        this(hostname, port, NO_SSL_PORT);\n-    }\n-\n-    // Constructor from a String \"serialized\" version of this class.\n-    public HedwigSocketAddress(String addr) {\n-        String[] parts = addr.split(COLON);\n-        this.hostname = parts[0];\n-        this.port = Integer.parseInt(parts[1]);\n-        if (parts.length > 2)\n-            this.sslPort = Integer.parseInt(parts[2]);\n-        else\n-            this.sslPort = NO_SSL_PORT;\n-        socketAddress = new InetSocketAddress(hostname, port);\n-        if (sslPort != NO_SSL_PORT)\n-            sslSocketAddress = new InetSocketAddress(hostname, sslPort);\n-        else\n-            sslSocketAddress = null;\n-    }\n-\n-    // Public getters\n-    public String getHostname() {\n-        return hostname;\n-    }\n-\n-    public int getPort() {\n-        return port;\n-    }\n-\n-    public int getSSLPort() {\n-        return sslPort;\n-    }\n-\n-    // Method to return an InetSocketAddress for the regular port.\n-    public InetSocketAddress getSocketAddress() {\n-        return socketAddress;\n-    }\n-\n-    // Method to return an InetSocketAddress for the SSL port.\n-    // Note that if no SSL port (or an invalid value) was passed\n-    // during object creation, this call will throw an IllegalArgumentException\n-    // (runtime exception).\n-    public InetSocketAddress getSSLSocketAddress() {\n-        return sslSocketAddress;\n-    }\n-\n-    // Method to determine if this object instance is SSL enabled or not\n-    // (contains a valid SSL port).\n-    public boolean isSSLEnabled() {\n-        return sslPort != NO_SSL_PORT;\n-    }\n-\n-    // Return the String \"serialized\" version of this object.\n-    @Override\n-    public String toString() {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(hostname).append(COLON).append(port).append(COLON).append(sslPort);\n-        return sb.toString();\n-    }\n-\n-    // Implement an equals method comparing two HedwigSocketAddress objects.\n-    @Override\n-    public boolean equals(Object obj) {\n-        if (!(obj instanceof HedwigSocketAddress))\n-            return false;\n-        HedwigSocketAddress that = (HedwigSocketAddress) obj;\n-        return (this.hostname.equals(that.hostname) && (this.port == that.port) && (this.sslPort == that.sslPort));\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return (this.hostname + this.port + this.sslPort).hashCode();\n-    }\n-\n-    // Static helper method to return the string representation for an\n-    // InetSocketAddress. The HedwigClient can only operate in SSL or non-SSL\n-    // mode. So the server hosts it connects to will just be an\n-    // InetSocketAddress instead of a HedwigSocketAddress. This utility method\n-    // can be used so we can store these server hosts as strings (ByteStrings)\n-    // in various places (e.g. list of server hosts we've connected to\n-    // or wrote to unsuccessfully).\n-    public static String sockAddrStr(InetSocketAddress addr) {\n-        return addr.getAddress().getHostAddress() + \":\" + addr.getPort();\n-    }\n-\n-}"},{"sha":"6a347823f2c73f85c4efce37ca48864c434fbf17","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/Option.java","status":"removed","additions":0,"deletions":43,"changes":43,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/Option.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/Option.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/Option.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,43 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-public class Option<T> {\n-\n-    private T x;\n-\n-    public static <T> Option<T> of(T x) {\n-        return new Option<T>(x);\n-    }\n-\n-    public static <T> Option<T> of() {\n-        return new Option<T>();\n-    }\n-\n-    public Option() {\n-    }\n-\n-    public Option(T x) {\n-        this.x = x;\n-    }\n-\n-    public T get() {\n-        return x;\n-    }\n-\n-}"},{"sha":"f0582b5e0210c4a05ee4c6ec65dc6c33d8377cd0","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/Pair.java","status":"removed","additions":0,"deletions":42,"changes":42,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/Pair.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/Pair.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/Pair.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,42 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-public class Pair<T, U> {\n-\n-    private T x;\n-    private U y;\n-\n-    public Pair(T x, U y) {\n-        this.x = x;\n-        this.y = y;\n-    }\n-\n-    public static <T, U> Pair<T, U> of(T x, U y) {\n-        return new Pair<T, U>(x, y);\n-    }\n-\n-    public T first() {\n-        return x;\n-    }\n-\n-    public U second() {\n-        return y;\n-    }\n-\n-}"},{"sha":"269286caf9057204a4f9431843461812e60cbb8d","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/PathUtils.java","status":"removed","additions":0,"deletions":56,"changes":56,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/PathUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/PathUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/PathUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,56 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.io.File;\n-import java.util.ArrayList;\n-import java.util.List;\n-\n-public class PathUtils {\n-\n-    /** Generate all prefixes for a path. \"/a/b/c\" -> [\"/a\",\"/a/b\",\"/a/b/c\"] */\n-    public static List<String> prefixes(String path) {\n-        List<String> prefixes = new ArrayList<String>();\n-        StringBuilder prefix = new StringBuilder();\n-        for (String comp : path.split(\"/+\")) {\n-            // Skip the first (empty) path component.\n-            if (!comp.equals(\"\")) {\n-                prefix.append(\"/\").append(comp);\n-                prefixes.add(prefix.toString());\n-            }\n-        }\n-        return prefixes;\n-    }\n-\n-    /** Return true iff prefix is a prefix of path. */\n-    public static boolean isPrefix(String prefix, String path) {\n-        String[] as = prefix.split(\"/+\"), bs = path.split(\"/+\");\n-        if (as.length > bs.length)\n-            return false;\n-        for (int i = 0; i < as.length; i++)\n-            if (!as[i].equals(bs[i]))\n-                return false;\n-        return true;\n-    }\n-\n-    /** Like File.getParent but always uses the / separator. */\n-    public static String parent(String path) {\n-        return new File(path).getParent().replace(\"\\\\\", \"/\");\n-    }\n-\n-}"},{"sha":"508519665fe147db074b3302c6cf45a018aa79e0","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/SubscriptionListener.java","status":"removed","additions":0,"deletions":44,"changes":44,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/SubscriptionListener.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/SubscriptionListener.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/SubscriptionListener.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,44 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-\n-/**\n- * This class is used for subscriber to listen on subscription event.\n- */\n-public interface SubscriptionListener {\n-\n-    /**\n-     * Process an event from a subscription.\n-     * <p>\n-     * NOTE: It would be better to not run blocking operations in a\n-     *       listener implementation.\n-     * </p>\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber Id\n-     * @param event\n-     *          Event tell what happened to the subscription.\n-     */\n-    public void processEvent(ByteString topic, ByteString subscriberId,\n-                             SubscriptionEvent event);\n-}"},{"sha":"b8d22dac7943dee562e9a8eb6469659dc31493e4","filename":"hedwig-client/src/main/java/org/apache/hedwig/util/VarArgs.java","status":"removed","additions":0,"deletions":26,"changes":26,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/VarArgs.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/main/java/org/apache/hedwig/util/VarArgs.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/main/java/org/apache/hedwig/util/VarArgs.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,26 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-public class VarArgs {\n-\n-    public static Object[] va(Object...args) {\n-        return args;\n-    }\n-\n-}"},{"sha":"53e99b36ecc3f815a4b8ae31d94f9e038161d203","filename":"hedwig-client/src/test/java/org/apache/hedwig/util/TestFileUtils.java","status":"removed","additions":0,"deletions":41,"changes":41,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestFileUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestFileUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/test/java/org/apache/hedwig/util/TestFileUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,41 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.io.File;\n-\n-import org.junit.Test;\n-\n-import static org.junit.Assert.*;\n-\n-public class TestFileUtils {\n-\n-    @Test(timeout=60000)\n-    public void testCreateTmpDirectory() throws Exception {\n-        String prefix = \"abc\";\n-        String suffix = \"def\";\n-        File dir = FileUtils.createTempDirectory(prefix, suffix);\n-        assertTrue(dir.isDirectory());\n-        assertTrue(dir.getName().startsWith(prefix));\n-        assertTrue(dir.getName().endsWith(suffix));\n-        FileUtils.dirDeleterThread.start();\n-        FileUtils.dirDeleterThread.join();\n-        assertFalse(dir.exists());\n-    }\n-\n-}"},{"sha":"b6bb78a5ae44b5ccadc2bf229928d6ad4fa5956b","filename":"hedwig-client/src/test/java/org/apache/hedwig/util/TestHedwigSocketAddress.java","status":"removed","additions":0,"deletions":104,"changes":104,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestHedwigSocketAddress.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestHedwigSocketAddress.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/test/java/org/apache/hedwig/util/TestHedwigSocketAddress.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,104 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.net.InetSocketAddress;\n-\n-import org.junit.Test;\n-\n-import static org.junit.Assert.*;\n-\n-public class TestHedwigSocketAddress {\n-\n-    // Common values used by tests\n-    private String hostname = \"localhost\";\n-    private int port = 4080;\n-    private int sslPort = 9876;\n-    private int invalidPort = -9999;\n-    private String COLON = \":\";\n-\n-    @Test(timeout=60000)\n-    public void testCreateWithSSLPort() throws Exception {\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname, port, sslPort);\n-        assertTrue(addr.getSocketAddress().equals(new InetSocketAddress(hostname, port)));\n-        assertTrue(addr.getSSLSocketAddress().equals(new InetSocketAddress(hostname, sslPort)));\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testCreateWithNoSSLPort() throws Exception {\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname, port);\n-        assertTrue(addr.getSocketAddress().equals(new InetSocketAddress(hostname, port)));\n-        assertTrue(addr.getSSLSocketAddress() == null);\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testCreateFromStringWithSSLPort() throws Exception {\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname+COLON+port+COLON+sslPort);\n-        assertTrue(addr.getSocketAddress().equals(new InetSocketAddress(hostname, port)));\n-        assertTrue(addr.getSSLSocketAddress().equals(new InetSocketAddress(hostname, sslPort)));\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testCreateFromStringWithNoSSLPort() throws Exception {\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname+COLON+port);\n-        assertTrue(addr.getSocketAddress().equals(new InetSocketAddress(hostname, port)));\n-        assertTrue(addr.getSSLSocketAddress() == null);\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testCreateWithInvalidRegularPort() throws Exception {\n-        boolean success = false;\n-        try {\n-            new HedwigSocketAddress(hostname+COLON+invalidPort);\n-        }\n-        catch (IllegalArgumentException e) {\n-            success = true;\n-        }\n-        assertTrue(success);\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testCreateWithInvalidSSLPort() throws Exception {\n-        boolean success = false;\n-        try {\n-            new HedwigSocketAddress(hostname, port, invalidPort);\n-        }\n-        catch (IllegalArgumentException e) {\n-            success = true;\n-        }\n-        assertTrue(success);\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testToStringConversion() throws Exception {\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname, port, sslPort);\n-        HedwigSocketAddress addr2 = new HedwigSocketAddress(addr.toString());\n-        assertTrue(addr.getSocketAddress().equals(addr2.getSocketAddress()));\n-        assertTrue(addr.getSSLSocketAddress().equals(addr2.getSSLSocketAddress()));\n-        addr.toString().equals(addr2.toString());\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testIsSSLEnabledFlag() throws Exception {\n-        HedwigSocketAddress sslAddr = new HedwigSocketAddress(hostname, port, sslPort);\n-        assertTrue(sslAddr.isSSLEnabled());\n-        HedwigSocketAddress addr = new HedwigSocketAddress(hostname, port);\n-        assertFalse(addr.isSSLEnabled());\n-    }\n-\n-}"},{"sha":"a596841eecd44f82c0b237d1b1205a06aa59d451","filename":"hedwig-client/src/test/java/org/apache/hedwig/util/TestPathUtils.java","status":"removed","additions":0,"deletions":54,"changes":54,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestPathUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-client/src/test/java/org/apache/hedwig/util/TestPathUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-client/src/test/java/org/apache/hedwig/util/TestPathUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,54 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.util;\n-\n-import java.util.Arrays;\n-\n-import org.junit.Test;\n-\n-import static org.junit.Assert.*;\n-\n-public class TestPathUtils {\n-\n-    @Test(timeout=60000)\n-    public void testPrefixes() {\n-        assertEquals(Arrays.asList(new String[] { \"/a\", \"/a/b\", \"/a/b/c\" }), PathUtils.prefixes(\"/a/b/c\"));\n-        assertEquals(Arrays.asList(new String[] { \"/a\", \"/a/b\", \"/a/b/c\" }), PathUtils.prefixes(\"///a///b///c\"));\n-\n-    }\n-\n-    @Test(timeout=60000)\n-    public void testIsPrefix() {\n-        String[] paths = new String[] { \"/\", \"/a\", \"/a/b\" };\n-        for (int i = 0; i < paths.length; i++) {\n-            for (int j = 0; j <= i; j++) {\n-                assertTrue(PathUtils.isPrefix(paths[j], paths[i]));\n-                assertTrue(PathUtils.isPrefix(paths[j], paths[i] + \"/\"));\n-                assertTrue(PathUtils.isPrefix(paths[j] + \"/\", paths[i]));\n-                assertTrue(PathUtils.isPrefix(paths[j] + \"/\", paths[i] + \"/\"));\n-            }\n-            for (int j = i + 1; j < paths.length; j++) {\n-                assertFalse(PathUtils.isPrefix(paths[j], paths[i]));\n-                assertFalse(PathUtils.isPrefix(paths[j], paths[i] + \"/\"));\n-                assertFalse(PathUtils.isPrefix(paths[j] + \"/\", paths[i]));\n-                assertFalse(PathUtils.isPrefix(paths[j] + \"/\", paths[i] + \"/\"));\n-            }\n-        }\n-    }\n-\n-}"},{"sha":"c0609ae3cab9c7cfd256ad02de363ab262674c60","filename":"hedwig-protocol/pom.xml","status":"removed","additions":0,"deletions":116,"changes":116,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/pom.xml","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/pom.xml","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/pom.xml?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,116 +0,0 @@\n-<?xml version=\"1.0\"?>\n-<!--\n-   Licensed to the Apache Software Foundation (ASF) under one or more\n-   contributor license agreements.  See the NOTICE file distributed with\n-   this work for additional information regarding copyright ownership.\n-   The ASF licenses this file to You under the Apache License, Version 2.0\n-   (the \"License\"); you may not use this file except in compliance with\n-   the License.  You may obtain a copy of the License at\n-\n-       http://www.apache.org/licenses/LICENSE-2.0\n-\n-   Unless required by applicable law or agreed to in writing, software\n-   distributed under the License is distributed on an \"AS IS\" BASIS,\n-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-   See the License for the specific language governing permissions and\n-   limitations under the License.\n--->\n-\n-<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n-  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n-  <modelVersion>4.0.0</modelVersion>\n-  <parent>\n-    <groupId>org.apache.bookkeeper</groupId>\n-    <artifactId>bookkeeper</artifactId>\n-    <version>4.4.0-SNAPSHOT</version>\n-  </parent>\n-  <artifactId>hedwig-protocol</artifactId>\n-  <packaging>jar</packaging>\n-  <name>hedwig-protocol</name>\n-  <url>http://maven.apache.org</url>\n-  <dependencies>\n-    <dependency>\n-      <groupId>com.google.protobuf</groupId>\n-      <artifactId>protobuf-java</artifactId>\n-      <version>${protobuf.version}</version>\n-      <scope>compile</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>junit</groupId>\n-      <artifactId>junit</artifactId>\n-      <version>4.8.1</version>\n-      <scope>test</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.slf4j</groupId>\n-      <artifactId>slf4j-api</artifactId>\n-      <version>1.6.4</version>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.slf4j</groupId>\n-      <artifactId>slf4j-log4j12</artifactId>\n-      <version>1.6.4</version>\n-    </dependency>\n-  </dependencies>\n-  <repositories>\n-  </repositories>\n-  <build>\n-    <defaultGoal>install</defaultGoal>\n-    <plugins>\n-      <plugin>\n-        <artifactId>maven-assembly-plugin</artifactId>\n-        <version>2.2.1</version>\n-        <configuration>\n-\t  <skipAssembly>true</skipAssembly>\n-        </configuration>\n-      </plugin>\n-      <plugin>\n-\t<groupId>org.apache.rat</groupId>\n-\t<artifactId>apache-rat-plugin</artifactId>\n-\t<version>0.7</version>\n-\t<configuration>\n-\t  <excludes>\n-\t    <!-- exclude generated file //-->\n-\t    <exclude>**/PubSubProtocol.java</exclude>\n-\t  </excludes>\n-\t</configuration>\n-      </plugin>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>findbugs-maven-plugin</artifactId>\n-        <configuration>\n-          <excludeFilterFile>${basedir}/src/main/resources/findbugsExclude.xml</excludeFilterFile>\n-        </configuration>\n-      </plugin>\n-    </plugins>\n-  </build>\n-  <profiles>\n-    <profile>\n-      <id>protobuf</id>\n-      <build>\n-        <plugins>\n-          <plugin>\n-            <artifactId>maven-antrun-plugin</artifactId>\n-            <executions>\n-              <execution>\n-                <phase>generate-sources</phase>\n-                <id>default-cli</id>\n-                <configuration>\n-                  <target>\n-                    <exec executable=\"protoc\" failonerror=\"true\">\n-                      <arg value=\"--java_out=src/main/java\" />\n-                      <arg value=\"src/main/protobuf/PubSubProtocol.proto\" />\n-                    </exec>\n-                  </target>\n-                </configuration>\n-                <goals>\n-                  <goal>run</goal>\n-                </goals>\n-              </execution>\n-            </executions>\n-          </plugin>\n-        </plugins>\n-      </build>\n-    </profile>\n-  </profiles>\n-</project>"},{"sha":"2e8dc0909ae31d579f61c57aa2b05e65ffd72d4b","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/exceptions/PubSubException.java","status":"removed","additions":0,"deletions":254,"changes":254,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/exceptions/PubSubException.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/exceptions/PubSubException.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/exceptions/PubSubException.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,254 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.exceptions;\n-\n-import java.util.Collection;\n-import java.util.Iterator;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-\n-@SuppressWarnings(\"serial\")\n-public abstract class PubSubException extends Exception {\n-    protected StatusCode code;\n-\n-    protected PubSubException(StatusCode code, String msg) {\n-        super(msg);\n-        this.code = code;\n-    }\n-\n-    protected PubSubException(StatusCode code, Throwable t) {\n-        super(t);\n-        this.code = code;\n-    }\n-\n-    protected PubSubException(StatusCode code, String msg, Throwable t) {\n-        super(msg, t);\n-        this.code = code;\n-    }\n-\n-    public static PubSubException create(StatusCode code, String msg) {\n-        if (code == StatusCode.CLIENT_ALREADY_SUBSCRIBED) {\n-            return new ClientAlreadySubscribedException(msg);\n-        } else if (code == StatusCode.CLIENT_NOT_SUBSCRIBED) {\n-            return new ClientNotSubscribedException(msg);\n-        } else if (code == StatusCode.MALFORMED_REQUEST) {\n-            return new MalformedRequestException(msg);\n-        } else if (code == StatusCode.NO_SUCH_TOPIC) {\n-            return new NoSuchTopicException(msg);\n-        } else if (code == StatusCode.NOT_RESPONSIBLE_FOR_TOPIC) {\n-            return new ServerNotResponsibleForTopicException(msg);\n-        } else if (code == StatusCode.SERVICE_DOWN) {\n-            return new ServiceDownException(msg);\n-        } else if (code == StatusCode.COULD_NOT_CONNECT) {\n-            return new CouldNotConnectException(msg);\n-        } else if (code == StatusCode.TOPIC_BUSY) {\n-            return new TopicBusyException(msg);\n-        } else if (code == StatusCode.BAD_VERSION) {\n-            return new BadVersionException(msg);\n-        } else if (code == StatusCode.NO_TOPIC_PERSISTENCE_INFO) {\n-            return new NoTopicPersistenceInfoException(msg);\n-        } else if (code == StatusCode.TOPIC_PERSISTENCE_INFO_EXISTS) {\n-            return new TopicPersistenceInfoExistsException(msg);\n-        } else if (code == StatusCode.NO_SUBSCRIPTION_STATE) {\n-            return new NoSubscriptionStateException(msg);\n-        } else if (code == StatusCode.SUBSCRIPTION_STATE_EXISTS) {\n-            return new SubscriptionStateExistsException(msg);\n-        } else if (code == StatusCode.NO_TOPIC_OWNER_INFO) {\n-            return new NoTopicOwnerInfoException(msg);\n-        } else if (code == StatusCode.TOPIC_OWNER_INFO_EXISTS) {\n-            return new TopicOwnerInfoExistsException(msg);\n-        } else if (code == StatusCode.INVALID_MESSAGE_FILTER) {\n-            return new InvalidMessageFilterException(msg);\n-        } else if (code == StatusCode.RESUBSCRIBE_EXCEPTION) {\n-            return new ResubscribeException(msg);\n-        }\n-        /*\n-         * Insert new ones here\n-         */\n-        else if (code == StatusCode.UNCERTAIN_STATE) {\n-            return new UncertainStateException(msg);\n-        }\n-        // Finally the catch all exception (for unexpected error conditions)\n-        else {\n-            return new UnexpectedConditionException(\"Unknow status code:\" + code.getNumber() + \", msg: \" + msg);\n-        }\n-    }\n-\n-    public StatusCode getCode() {\n-        return code;\n-    }\n-\n-    public static class ClientAlreadySubscribedException extends PubSubException {\n-        public ClientAlreadySubscribedException(String msg) {\n-            super(StatusCode.CLIENT_ALREADY_SUBSCRIBED, msg);\n-        }\n-    }\n-\n-    public static class ClientNotSubscribedException extends PubSubException {\n-        public ClientNotSubscribedException(String msg) {\n-            super(StatusCode.CLIENT_NOT_SUBSCRIBED, msg);\n-        }\n-    }\n-\n-    public static class ResubscribeException extends PubSubException {\n-        public ResubscribeException(String msg) {\n-            super(StatusCode.RESUBSCRIBE_EXCEPTION, msg);\n-        }\n-    }\n-\n-    public static class MalformedRequestException extends PubSubException {\n-        public MalformedRequestException(String msg) {\n-            super(StatusCode.MALFORMED_REQUEST, msg);\n-        }\n-    }\n-\n-    public static class NoSuchTopicException extends PubSubException {\n-        public NoSuchTopicException(String msg) {\n-            super(StatusCode.NO_SUCH_TOPIC, msg);\n-        }\n-    }\n-\n-    public static class ServerNotResponsibleForTopicException extends PubSubException {\n-        // Note the exception message serves as the name of the responsible host\n-        public ServerNotResponsibleForTopicException(String responsibleHost) {\n-            super(StatusCode.NOT_RESPONSIBLE_FOR_TOPIC, responsibleHost);\n-        }\n-    }\n-\n-    public static class TopicBusyException extends PubSubException {\n-        public TopicBusyException(String msg) {\n-            super(StatusCode.TOPIC_BUSY, msg);\n-        }\n-    }\n-\n-    public static class ServiceDownException extends PubSubException {\n-        public ServiceDownException(String msg) {\n-            super(StatusCode.SERVICE_DOWN, msg);\n-        }\n-\n-        public ServiceDownException(Exception e) {\n-            super(StatusCode.SERVICE_DOWN, e);\n-        }\n-\n-        public ServiceDownException(String msg, Throwable t) {\n-            super(StatusCode.SERVICE_DOWN, msg, t);\n-        }\n-    }\n-\n-    public static class CouldNotConnectException extends PubSubException {\n-        public CouldNotConnectException(String msg) {\n-            super(StatusCode.COULD_NOT_CONNECT, msg);\n-        }\n-    }\n-\n-    public static class BadVersionException extends PubSubException {\n-        public BadVersionException(String msg) {\n-            super(StatusCode.BAD_VERSION, msg);\n-        }\n-    }\n-\n-    public static class NoTopicPersistenceInfoException extends PubSubException {\n-        public NoTopicPersistenceInfoException(String msg) {\n-            super(StatusCode.NO_TOPIC_PERSISTENCE_INFO, msg);\n-        }\n-    }\n-\n-    public static class TopicPersistenceInfoExistsException extends PubSubException {\n-        public TopicPersistenceInfoExistsException(String msg) {\n-            super(StatusCode.TOPIC_PERSISTENCE_INFO_EXISTS, msg);\n-        }\n-    }\n-\n-    public static class NoSubscriptionStateException extends PubSubException {\n-        public NoSubscriptionStateException(String msg) {\n-            super(StatusCode.NO_SUBSCRIPTION_STATE, msg);\n-        }\n-    }\n-\n-    public static class SubscriptionStateExistsException extends PubSubException {\n-        public SubscriptionStateExistsException(String msg) {\n-            super(StatusCode.SUBSCRIPTION_STATE_EXISTS, msg);\n-        }\n-    }\n-\n-    public static class NoTopicOwnerInfoException extends PubSubException {\n-        public NoTopicOwnerInfoException(String msg) {\n-            super(StatusCode.NO_TOPIC_OWNER_INFO, msg);\n-        }\n-    }\n-\n-    public static class TopicOwnerInfoExistsException extends PubSubException {\n-        public TopicOwnerInfoExistsException(String msg) {\n-            super(StatusCode.TOPIC_OWNER_INFO_EXISTS, msg);\n-        }\n-    }\n-\n-    public static class InvalidMessageFilterException extends PubSubException {\n-        public InvalidMessageFilterException(String msg) {\n-            super(StatusCode.INVALID_MESSAGE_FILTER, msg);\n-        }\n-\n-        public InvalidMessageFilterException(String msg, Throwable t) {\n-            super(StatusCode.INVALID_MESSAGE_FILTER, msg, t);\n-        }\n-    }\n-\n-    public static class UncertainStateException extends PubSubException {\n-        public UncertainStateException(String msg) {\n-            super(StatusCode.UNCERTAIN_STATE, msg);\n-        }\n-    }\n-\n-    // The catch all exception (for unexpected error conditions)\n-    public static class UnexpectedConditionException extends PubSubException {\n-        public UnexpectedConditionException(String msg) {\n-            super(StatusCode.UNEXPECTED_CONDITION, msg);\n-        }\n-        public UnexpectedConditionException(String msg, Throwable t) {\n-            super(StatusCode.UNEXPECTED_CONDITION, msg, t);\n-        }\n-    }\n-\n-    // The composite exception (for concurrent operations).\n-    public static class CompositeException extends PubSubException {\n-        private final Collection<PubSubException> exceptions;\n-        public CompositeException(Collection<PubSubException> exceptions) {\n-            super(StatusCode.COMPOSITE, compositeMessage(exceptions));\n-            this.exceptions = exceptions;\n-        }\n-\n-        public Collection<PubSubException> getExceptions() {\n-            return exceptions;\n-        }\n-\n-        /** Merges the message fields of the given Exceptions into a one line string. */\n-        private static String compositeMessage(Collection<PubSubException> exceptions) {\n-            StringBuilder builder = new StringBuilder(\"Composite exception: [\");\n-            Iterator<PubSubException> iter = exceptions.iterator();\n-            if (iter.hasNext())\n-                builder.append(iter.next().getMessage());\n-            while (iter.hasNext())\n-                builder.append(\" :: \").append(iter.next().getMessage());\n-            return builder.append(\"]\").toString();\n-        }\n-    }\n-\n-    public static class ClientNotSubscribedRuntimeException extends RuntimeException {\n-    }\n-\n-}"},{"sha":"4bba8cc849c1e10354c7e022f94b23e6a2e88d4f","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/protocol/PubSubProtocol.java","status":"removed","additions":0,"deletions":16883,"changes":16883,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protocol/PubSubProtocol.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protocol/PubSubProtocol.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/protocol/PubSubProtocol.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"898e8b12f65b705a987cb75d82231d8a923b44c5","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MapUtils.java","status":"removed","additions":0,"deletions":74,"changes":74,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MapUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MapUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MapUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,74 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.protoextensions;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class MapUtils {\n-\n-    static final Logger logger = LoggerFactory.getLogger(MapUtils.class);\n-\n-    public static String toString(PubSubProtocol.Map map) {\n-        StringBuilder sb = new StringBuilder();\n-        int numEntries = map.getEntriesCount();\n-        for (int i=0; i<numEntries; i++) {\n-            PubSubProtocol.Map.Entry entry = map.getEntries(i);\n-            String key = entry.getKey();\n-            ByteString value = entry.getValue();\n-            sb.append(key).append('=').append(value.toStringUtf8());\n-            if (i != (numEntries - 1)) {\n-                sb.append(',');\n-            }\n-        }\n-        return sb.toString();\n-    }\n-\n-    public static Map<String, ByteString> buildMap(PubSubProtocol.Map protoMap) {\n-        Map<String, ByteString> javaMap = new HashMap<String, ByteString>();\n-\n-        int numEntries = protoMap.getEntriesCount();\n-        for (int i=0; i<numEntries; i++) {\n-            PubSubProtocol.Map.Entry entry = protoMap.getEntries(i);\n-            String key = entry.getKey();\n-            if (javaMap.containsKey(key)) {\n-                ByteString preValue = javaMap.get(key);\n-                logger.warn(\"Key \" + key + \" has already been defined as value : \" + preValue.toStringUtf8());\n-            } else {\n-                javaMap.put(key, entry.getValue());\n-            }\n-        }\n-        return javaMap;\n-    }\n-\n-    public static PubSubProtocol.Map.Builder buildMapBuilder(Map<String, ByteString> javaMap) {\n-        PubSubProtocol.Map.Builder mapBuilder = PubSubProtocol.Map.newBuilder();\n-\n-        for (Map.Entry<String, ByteString> entry : javaMap.entrySet()) {\n-            mapBuilder.addEntries(PubSubProtocol.Map.Entry.newBuilder().setKey(entry.getKey())\n-                                                .setValue(entry.getValue()));\n-        }\n-        return mapBuilder;\n-    }\n-}"},{"sha":"9ceec26e1cdda6b5c876d8f05e37ef52031f5a4f","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MessageIdUtils.java","status":"removed","additions":0,"deletions":153,"changes":153,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MessageIdUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MessageIdUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/MessageIdUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,153 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.protoextensions;\n-\n-import java.util.HashMap;\n-import java.util.List;\n-import java.util.Map;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.exceptions.PubSubException.UnexpectedConditionException;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.RegionSpecificSeqId;\n-\n-public class MessageIdUtils {\n-\n-    public static String msgIdToReadableString(MessageSeqId seqId) {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"local:\");\n-        sb.append(seqId.getLocalComponent());\n-\n-        String separator = \";\";\n-        for (RegionSpecificSeqId regionId : seqId.getRemoteComponentsList()) {\n-            sb.append(separator);\n-            sb.append(regionId.getRegion().toStringUtf8());\n-            sb.append(':');\n-            sb.append(regionId.getSeqId());\n-        }\n-        return sb.toString();\n-    }\n-\n-    public static Map<ByteString, RegionSpecificSeqId> inMapForm(MessageSeqId msi) {\n-        Map<ByteString, RegionSpecificSeqId> map = new HashMap<ByteString, RegionSpecificSeqId>();\n-\n-        for (RegionSpecificSeqId lmsid : msi.getRemoteComponentsList()) {\n-            map.put(lmsid.getRegion(), lmsid);\n-        }\n-\n-        return map;\n-    }\n-\n-    public static boolean areEqual(MessageSeqId m1, MessageSeqId m2) {\n-\n-        if (m1.getLocalComponent() != m2.getLocalComponent()) {\n-            return false;\n-        }\n-\n-        if (m1.getRemoteComponentsCount() != m2.getRemoteComponentsCount()) {\n-            return false;\n-        }\n-\n-        Map<ByteString, RegionSpecificSeqId> m2map = inMapForm(m2);\n-\n-        for (RegionSpecificSeqId lmsid1 : m1.getRemoteComponentsList()) {\n-            RegionSpecificSeqId lmsid2 = m2map.get(lmsid1.getRegion());\n-            if (lmsid2 == null) {\n-                return false;\n-            }\n-            if (lmsid1.getSeqId() != lmsid2.getSeqId()) {\n-                return false;\n-            }\n-        }\n-\n-        return true;\n-\n-    }\n-\n-    public static Message mergeLocalSeqId(Message.Builder messageBuilder, long localSeqId) {\n-        MessageSeqId.Builder msidBuilder = MessageSeqId.newBuilder(messageBuilder.getMsgId());\n-        msidBuilder.setLocalComponent(localSeqId);\n-        messageBuilder.setMsgId(msidBuilder);\n-        return messageBuilder.build();\n-    }\n-\n-    public static Message mergeLocalSeqId(Message orginalMessage, long localSeqId) {\n-        return mergeLocalSeqId(Message.newBuilder(orginalMessage), localSeqId);\n-    }\n-\n-    /**\n-     * Compares two seq numbers represented as lists of longs.\n-     *\n-     * @param l1\n-     * @param l2\n-     * @return 1 if the l1 is greater, 0 if they are equal, -1 if l2 is greater\n-     * @throws UnexpectedConditionException\n-     *             If the lists are of unequal length\n-     */\n-    public static int compare(List<Long> l1, List<Long> l2) throws UnexpectedConditionException {\n-        if (l1.size() != l2.size()) {\n-            throw new UnexpectedConditionException(\"Seq-ids being compared have different sizes: \" + l1.size()\n-                                                   + \" and \" + l2.size());\n-        }\n-\n-        for (int i = 0; i < l1.size(); i++) {\n-            long v1 = l1.get(i);\n-            long v2 = l2.get(i);\n-\n-            if (v1 == v2) {\n-                continue;\n-            }\n-\n-            return v1 > v2 ? 1 : -1;\n-        }\n-\n-        // All components equal\n-        return 0;\n-    }\n-\n-    /**\n-     * Returns the element-wise vector maximum of the two vectors id1 and id2,\n-     * if we imagine them to be sparse representations of vectors.\n-     */\n-    public static void takeRegionMaximum(MessageSeqId.Builder newIdBuilder, MessageSeqId id1, MessageSeqId id2) {\n-        Map<ByteString, RegionSpecificSeqId> id2Map = MessageIdUtils.inMapForm(id2);\n-\n-        for (RegionSpecificSeqId rrsid1 : id1.getRemoteComponentsList()) {\n-            ByteString region = rrsid1.getRegion();\n-\n-            RegionSpecificSeqId rssid2 = id2Map.get(region);\n-\n-            if (rssid2 == null) {\n-                newIdBuilder.addRemoteComponents(rrsid1);\n-                continue;\n-            }\n-\n-            newIdBuilder.addRemoteComponents((rrsid1.getSeqId() > rssid2.getSeqId()) ? rrsid1 : rssid2);\n-\n-            // remove from map\n-            id2Map.remove(region);\n-        }\n-\n-        // now take the remaining components in the map and add them\n-        for (RegionSpecificSeqId rssid2 : id2Map.values()) {\n-            newIdBuilder.addRemoteComponents(rssid2);\n-        }\n-\n-    }\n-}"},{"sha":"5a9cdf78f10ab893e547c206b555855d121e2e6c","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/PubSubResponseUtils.java","status":"removed","additions":0,"deletions":68,"changes":68,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/PubSubResponseUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/PubSubResponseUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/PubSubResponseUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,68 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.protoextensions;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.ProtocolVersion;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.protocol.PubSubProtocol.ResponseBody;\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEventResponse;\n-\n-public class PubSubResponseUtils {\n-\n-    /**\n-     * Change here if bumping up the version number that the server sends back\n-     */\n-    public final static ProtocolVersion serverVersion = ProtocolVersion.VERSION_ONE;\n-\n-    static PubSubResponse.Builder getBasicBuilder(StatusCode status) {\n-        return PubSubResponse.newBuilder().setProtocolVersion(serverVersion).setStatusCode(status);\n-    }\n-\n-    public static PubSubResponse getSuccessResponse(long txnId) {\n-        return getBasicBuilder(StatusCode.SUCCESS).setTxnId(txnId).build();\n-    }\n-\n-    public static PubSubResponse getSuccessResponse(long txnId, ResponseBody respBody) {\n-        return getBasicBuilder(StatusCode.SUCCESS).setTxnId(txnId)\n-               .setResponseBody(respBody).build();\n-    }\n-\n-    public static PubSubResponse getResponseForException(PubSubException e, long txnId) {\n-        return getBasicBuilder(e.getCode()).setStatusMsg(e.getMessage()).setTxnId(txnId).build();\n-    }\n-\n-    public static PubSubResponse getResponseForSubscriptionEvent(ByteString topic,\n-                                                                 ByteString subscriberId,\n-                                                                 SubscriptionEvent event) {\n-        SubscriptionEventResponse.Builder eventBuilder =\n-            SubscriptionEventResponse.newBuilder().setEvent(event);\n-        ResponseBody.Builder respBuilder =\n-            ResponseBody.newBuilder().setSubscriptionEvent(eventBuilder);\n-        PubSubResponse response = PubSubResponse.newBuilder()\n-                                  .setProtocolVersion(ProtocolVersion.VERSION_ONE)\n-                                  .setStatusCode(StatusCode.SUCCESS).setTxnId(0)\n-                                  .setTopic(topic).setSubscriberId(subscriberId)\n-                                  .setResponseBody(respBuilder).build();\n-        return response;\n-    }\n-}"},{"sha":"e195ace85d9605717798fdcc8aeddb1d3c238917","filename":"hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/SubscriptionStateUtils.java","status":"removed","additions":0,"deletions":100,"changes":100,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/SubscriptionStateUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/SubscriptionStateUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/java/org/apache/hedwig/protoextensions/SubscriptionStateUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,100 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.protoextensions;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import com.google.protobuf.ByteString;\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionState;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class SubscriptionStateUtils {\n-\n-    static final Logger logger = LoggerFactory.getLogger(SubscriptionStateUtils.class);\n-\n-    // For now, to differentiate hub subscribers from local ones, the\n-    // subscriberId will be prepended with a hard-coded prefix. Local\n-    // subscribers will validate that the subscriberId used cannot start with\n-    // this prefix. This is only used internally by the hub subscribers.\n-    public static final String HUB_SUBSCRIBER_PREFIX = \"__\";\n-\n-    public static SubscriptionData parseSubscriptionData(byte[] data)\n-    throws InvalidProtocolBufferException {\n-        try {\n-            return SubscriptionData.parseFrom(data);\n-        } catch (InvalidProtocolBufferException ex) {\n-            logger.info(\"Failed to parse data as SubscriptionData. Fall backward to parse it as SubscriptionState for backward compatability.\");\n-            // backward compability\n-            SubscriptionState state = SubscriptionState.parseFrom(data);\n-            return SubscriptionData.newBuilder().setState(state).build();\n-        }\n-    }\n-\n-    public static String toString(SubscriptionData data) {\n-        StringBuilder sb = new StringBuilder();\n-        if (data.hasState()) {\n-            sb.append(\"State : { \").append(toString(data.getState())).append(\" };\");\n-        }\n-        if (data.hasPreferences()) {\n-            sb.append(\"Preferences : { \").append(toString(data.getPreferences())).append(\" };\");\n-        }\n-        return sb.toString();\n-    }\n-\n-    public static String toString(SubscriptionState state) {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"consumeSeqId: \" + MessageIdUtils.msgIdToReadableString(state.getMsgId()));\n-        return sb.toString();\n-    }\n-\n-    public static String toString(SubscriptionPreferences preferences) {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"System Preferences : [\");\n-        if (preferences.hasMessageBound()) {\n-            sb.append(\"(messageBound=\").append(preferences.getMessageBound())\n-              .append(\")\");\n-        }\n-        sb.append(\"]\");\n-        if (preferences.hasOptions()) {\n-            sb.append(\", Customized Preferences : [\");\n-            sb.append(MapUtils.toString(preferences.getOptions()));\n-            sb.append(\"]\");\n-        }\n-        return sb.toString();\n-    }\n-\n-    public static boolean isHubSubscriber(ByteString subscriberId) {\n-        return subscriberId.toStringUtf8().startsWith(HUB_SUBSCRIBER_PREFIX);\n-    }\n-\n-    public static Map<String, ByteString> buildUserOptions(SubscriptionPreferences preferences) {\n-        if (preferences.hasOptions()) {\n-            return MapUtils.buildMap(preferences.getOptions());\n-        } else {\n-            return new HashMap<String, ByteString>();\n-        }\n-    }\n-\n-}"},{"sha":"c31f0a6986d0a7c93ceecf249f461c0d115fcd70","filename":"hedwig-protocol/src/main/protobuf/PubSubProtocol.proto","status":"removed","additions":0,"deletions":313,"changes":313,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/protobuf/PubSubProtocol.proto","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/protobuf/PubSubProtocol.proto","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/protobuf/PubSubProtocol.proto?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,313 +0,0 @@\n-/*\n- * Licensed to the Apache Software Foundation (ASF) under one or more\n- * contributor license agreements.  See the NOTICE file distributed with\n- * this work for additional information regarding copyright ownership.\n- * The ASF licenses this file to You under the Apache License, Version 2.0\n- * (the \"License\"); you may not use this file except in compliance with\n- * the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-option java_package = \"org.apache.hedwig.protocol\";\n-option optimize_for = SPEED;\n-package Hedwig; \n-\n-enum ProtocolVersion{\n-    VERSION_ONE = 1;\n-}\n-\n-// common structure to store header or properties\n-message Map {\n-    message Entry {\n-        optional string key  = 1;\n-        optional bytes value = 2;\n-    }\n-    repeated Entry entries = 1;\n-}\n-\n-// message header\n-message MessageHeader {\n-    // user customized fields used for message filter\n-    optional Map properties = 1;\n-    // following are system properties in message header\n-    optional string messageType = 2;\n-}\n-\n-/*\n- * this is the structure that will be serialized\n- */\n-message Message {\n-    required bytes body = 1;\n-    optional bytes srcRegion = 2;\n-    optional MessageSeqId msgId = 3;\n-    // message header\n-    optional MessageHeader header = 4;\n-}\n-\n-message RegionSpecificSeqId {\n-    required bytes region = 1;\n-    required uint64 seqId = 2;\n-}\n-    \n-message MessageSeqId{\n-    optional uint64 localComponent = 1;\n-    repeated RegionSpecificSeqId remoteComponents = 2;    \n-}\n-\n-enum OperationType{\n-    PUBLISH = 0;\n-    SUBSCRIBE = 1;\n-    CONSUME = 2;\n-    UNSUBSCRIBE = 3;\n-    \n-    //the following two are only used for the hedwig proxy\n-    START_DELIVERY = 4;\n-    STOP_DELIVERY = 5;\n-    // end for requests only used for hedwig proxy\n-\n-    CLOSESUBSCRIPTION = 6;\n-}\n-\n-/* A PubSubRequest is just a union of the various request types, with\n- * an enum telling us which type it is. The same can also be done through \n- * extensions. We need one request type that we will deserialize into on \n- * the server side.\n- */\n-message PubSubRequest{\n-    \n-    required ProtocolVersion protocolVersion = 1;\n-    required OperationType type = 2;\n-    repeated bytes triedServers = 3;\n-    required uint64 txnId = 4;\n-    optional bool shouldClaim = 5;\n-    required bytes topic = 6;\n-    //any authentication stuff and other general stuff here\n-    \n-    \n-    /* one entry for each type of request */\n-    optional PublishRequest publishRequest = 52; \n-    optional SubscribeRequest subscribeRequest = 53;\n-    optional ConsumeRequest consumeRequest = 54;\n-    optional UnsubscribeRequest unsubscribeRequest = 55;\n-    optional StopDeliveryRequest stopDeliveryRequest = 56;\n-    optional StartDeliveryRequest startDeliveryRequest = 57;\n-    optional CloseSubscriptionRequest closeSubscriptionRequest = 58;\n-}\n-\n-\n-\n-message PublishRequest{\n-    required Message msg = 2;\n-}\n-\n-// record all preferences for a subscription,\n-// would be serialized to be stored in meta store\n-message SubscriptionPreferences {\n-    // user customized subscription options\n-    optional Map options = 1;\n-\n-    ///\n-    /// system defined options\n-    ///\n-\n-    // message bound\n-    optional uint32 messageBound = 2;\n-    // server-side message filter\n-    optional string messageFilter = 3;\n-    // message window size, this is the maximum number of messages \n-    // which will be delivered without being consumed\n-    optional uint32 messageWindowSize = 4;\n-}\n-\n-message SubscribeRequest{\n-    required bytes subscriberId = 2;\n-\n-    enum CreateOrAttach{\n-        CREATE = 0;\n-        ATTACH = 1;\n-        CREATE_OR_ATTACH = 2;\n-    };\n-    optional CreateOrAttach createOrAttach = 3 [default = CREATE_OR_ATTACH];\n-\n-    // wait for cross-regional subscriptions to be established before returning\n-    optional bool synchronous = 4 [default = false];\n-    // @Deprecated. set message bound in SubscriptionPreferences\n-    optional uint32 messageBound = 5;\n-\n-    // subscription options\n-    optional SubscriptionPreferences preferences = 6;\n-\n-    // force attach subscription which would kill existed channel\n-    // this option doesn't need to be persisted\n-    optional bool forceAttach = 7 [default = false];\n-}\n-\n-// used in client only\n-// options are stored in SubscriptionPreferences structure\n-message SubscriptionOptions {\n-    // force attach subscription which would kill existed channel\n-    // this option doesn't need to be persisted\n-    optional bool forceAttach = 1 [default = false];\n-    optional SubscribeRequest.CreateOrAttach createOrAttach = 2 [default = CREATE_OR_ATTACH];\n-    optional uint32 messageBound = 3 [default = 0];\n-    // user customized subscription options\n-    optional Map options = 4;\n-    // server-side message filter\n-    optional string messageFilter = 5;\n-    // message window size, this is the maximum number of messages \n-    // which will be delivered without being consumed\n-    optional uint32 messageWindowSize = 6;\n-    // enable resubscribe\n-    optional bool enableResubscribe = 7 [default = true];\n-}\n-\n-message ConsumeRequest{\n-    required bytes subscriberId = 2;    \n-    required MessageSeqId msgId = 3;\n-    //the msgId is cumulative: all messages up to this id are marked as consumed\n-}\n-\n-message UnsubscribeRequest{\n-    required bytes subscriberId = 2;\n-}\n-\n-message CloseSubscriptionRequest {\n-    required bytes subscriberId = 2;\n-}\n-\n-message StopDeliveryRequest{\n-    required bytes subscriberId = 2;\n-}\n-\n-message StartDeliveryRequest{\n-    required bytes subscriberId = 2;\n-}\n-\n-// Identify an event happened for a subscription\n-enum SubscriptionEvent {\n-    // topic has changed ownership (hub server down or topic released)\n-    TOPIC_MOVED = 1;\n-    // subscription is force closed by other subscribers\n-    SUBSCRIPTION_FORCED_CLOSED = 2;\n-}\n-\n-// a response carries an event for a subscription sent to client\n-message SubscriptionEventResponse {\n-    optional SubscriptionEvent event = 1;\n-}\n-\n-message PubSubResponse{\n-    required ProtocolVersion protocolVersion = 1;\n-    required StatusCode statusCode = 2;\n-    required uint64 txnId = 3;\n-\n-    optional string statusMsg = 4;\n-    //in case of a status code of NOT_RESPONSIBLE_FOR_TOPIC, the status\n-    //message will contain the name of the host actually responsible \n-    //for the topic\n-    \n-    //the following fields are sent in delivered messages\n-    optional Message message = 5;\n-    optional bytes topic = 6;\n-    optional bytes subscriberId = 7;\n-\n-    // the following fields are sent by other requests\n-    optional ResponseBody responseBody = 8;\n-}\n-\n-message PublishResponse {\n-    // If the request was a publish request, this was the message Id of the published message.\n-    required MessageSeqId publishedMsgId = 1;\n-}\n-\n-message SubscribeResponse {\n-    optional SubscriptionPreferences preferences = 2;\n-}\n-\n-message ResponseBody {\n-    optional PublishResponse publishResponse = 1;\n-    optional SubscribeResponse subscribeResponse = 2;\n-    optional SubscriptionEventResponse subscriptionEvent = 3;\n-}\n-\n-\n-enum StatusCode{\n-    SUCCESS = 0;\n-    \n-    //client-side errors (4xx)\n-    MALFORMED_REQUEST = 401;\n-    NO_SUCH_TOPIC = 402;\n-    CLIENT_ALREADY_SUBSCRIBED = 403;\n-    CLIENT_NOT_SUBSCRIBED = 404;\n-    COULD_NOT_CONNECT = 405;\n-    TOPIC_BUSY = 406;\n-    RESUBSCRIBE_EXCEPTION = 407;\n-    \n-    //server-side errors (5xx)\n-    NOT_RESPONSIBLE_FOR_TOPIC = 501;\n-    SERVICE_DOWN = 502;\n-    UNCERTAIN_STATE = 503;\n-    INVALID_MESSAGE_FILTER = 504;\n-\n-    //server-side meta manager errors (52x)\n-    BAD_VERSION = 520;\n-    NO_TOPIC_PERSISTENCE_INFO = 521;\n-    TOPIC_PERSISTENCE_INFO_EXISTS = 522;\n-    NO_SUBSCRIPTION_STATE = 523;\n-    SUBSCRIPTION_STATE_EXISTS = 524;\n-    NO_TOPIC_OWNER_INFO = 525;\n-    TOPIC_OWNER_INFO_EXISTS = 526;\n-\n-    //For all unexpected error conditions\n-    UNEXPECTED_CONDITION = 600;\n-    \n-    COMPOSITE = 700;\n-}\n-  \n-//What follows is not the server client protocol, but server-internal structures that are serialized in ZK  \n-//They should eventually be moved into the server \n-    \n-message SubscriptionState {\n-    required MessageSeqId msgId = 1;\n-    // @Deprecated.\n-    // It is a bad idea to put fields that don't change frequently\n-    // together with fields that change frequently\n-    // so move it to subscription preferences structure\n-    optional uint32 messageBound = 2;\n-}\n-\n-message SubscriptionData {\n-    optional SubscriptionState state = 1;\n-    optional SubscriptionPreferences preferences = 2;\n-}\n-\n-message LedgerRange{\n-    required uint64 ledgerId = 1;\n-    optional MessageSeqId endSeqIdIncluded = 2;\n-    optional uint64 startSeqIdIncluded = 3;\n-}\n-\n-message LedgerRanges{\n-    repeated LedgerRange ranges = 1;\n-}\n-\n-message ManagerMeta {\n-    required string managerImpl = 2;\n-    required uint32 managerVersion = 3;\n-}\n-\n-message HubInfoData {\n-    required string hostname = 2;\n-    required uint64 czxid = 3;\n-}\n-\n-message HubLoadData {\n-    required uint64 numTopics = 2;\n-}"},{"sha":"27cd3398f4cbd7bec9dd911c92afa12ed2eee4db","filename":"hedwig-protocol/src/main/resources/findbugsExclude.xml","status":"removed","additions":0,"deletions":23,"changes":23,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/resources/findbugsExclude.xml","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-protocol/src/main/resources/findbugsExclude.xml","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-protocol/src/main/resources/findbugsExclude.xml?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,23 +0,0 @@\n-<!--\n-    Licensed to the Apache Software Foundation (ASF) under one\n-    or more contributor license agreements.  See the NOTICE file\n-    distributed with this work for additional information\n-    regarding copyright ownership.  The ASF licenses this file\n-    to you under the Apache License, Version 2.0 (the\n-    \"License\"); you may not use this file except in compliance\n-    with the License.  You may obtain a copy of the License at\n-\n-      http://www.apache.org/licenses/LICENSE-2.0\n-\n-   Unless required by applicable law or agreed to in writing, software\n-   distributed under the License is distributed on an \"AS IS\" BASIS,\n-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-   See the License for the specific language governing permissions and\n-   limitations under the License.\n-//-->\n-<FindBugsFilter>\n-  <Match>\n-    <!-- generated code, we can't be held responsible for findbugs in it //-->\n-    <Class name=\"~org\\.apache\\.hedwig\\.protocol\\.PubSubProtocol.*\" />\n-  </Match>\n-</FindBugsFilter>"},{"sha":"a2ff83b839f95130eaf3d6a57561b929c3bccd62","filename":"hedwig-server/bin/hedwig","status":"removed","additions":0,"deletions":205,"changes":205,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/bin/hedwig","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/bin/hedwig","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/bin/hedwig?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,205 +0,0 @@\n-#!/usr/bin/env bash\n-#\n-#/**\n-# * Copyright 2007 The Apache Software Foundation\n-# *\n-# * Licensed to the Apache Software Foundation (ASF) under one\n-# * or more contributor license agreements.  See the NOTICE file\n-# * distributed with this work for additional information\n-# * regarding copyright ownership.  The ASF licenses this file\n-# * to you under the Apache License, Version 2.0 (the\n-# * \"License\"); you may not use this file except in compliance\n-# * with the License.  You may obtain a copy of the License at\n-# *\n-# *     http://www.apache.org/licenses/LICENSE-2.0\n-# *\n-# * Unless required by applicable law or agreed to in writing, software\n-# * distributed under the License is distributed on an \"AS IS\" BASIS,\n-# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# * See the License for the specific language governing permissions and\n-# * limitations under the License.\n-# */\n-\n-# check if net.ipv6.bindv6only is set to 1\n-bindv6only=$(/sbin/sysctl -n net.ipv6.bindv6only 2> /dev/null)\n-if [ -n \"$bindv6only\" ] && [ \"$bindv6only\" -eq \"1\" ]\n-then\n-  echo \"Error: \\\"net.ipv6.bindv6only\\\" is set to 1 - Java networking could be broken\"\n-  echo \"For more info (the following page also applies to hedwig): http://wiki.apache.org/hadoop/HadoopIPv6\"\n-  exit 1\n-fi\n-\n-# See the following page for extensive details on setting\n-# up the JVM to accept JMX remote management:\n-# http://java.sun.com/javase/6/docs/technotes/guides/management/agent.html\n-# by default we allow local JMX connections\n-if [ \"x$JMXLOCALONLY\" = \"x\" ]\n-then\n-    JMXLOCALONLY=false\n-fi\n-\n-if [ \"x$JMXDISABLE\" = \"x\" ]\n-then\n-    echo \"JMX enabled by default\" >&2\n-    # for some reason these two options are necessary on jdk6 on Ubuntu\n-    #   accord to the docs they are not necessary, but otw jconsole cannot\n-    #   do a local attach\n-    JMX_ARGS=\"-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.local.only=$JMXLOCALONLY\"\n-else\n-    echo \"JMX disabled by user request\" >&2\n-fi\n-\n-BINDIR=`dirname \"$0\"`\n-HW_HOME=`cd $BINDIR/..;pwd`\n-\n-DEFAULT_CONF=$HW_HOME/conf/hw_server.conf\n-DEFAULT_REGION_CLIENT_CONF=$HW_HOME/conf/hw_region_client.conf\n-DEFAULT_LOG_CONF=$HW_HOME/conf/log4j.properties\n-\n-. $HW_HOME/conf/hwenv.sh\n-\n-# Check for the java to use\n-if [[ -z $JAVA_HOME ]]; then\n-    JAVA=$(which java)\n-    if [ $? = 0 ]; then\n-        echo \"JAVA_HOME not set, using java from PATH. ($JAVA)\"\n-    else\n-        echo \"Error: JAVA_HOME not set, and no java executable found in $PATH.\" 1>&2\n-        exit 1\n-    fi\n-else\n-    JAVA=$JAVA_HOME/bin/java\n-fi\n-\n-RELEASE_JAR=`ls $HW_HOME/hedwig-server-*.jar 2> /dev/null | grep -v tests | tail -1`\n-\n-if [ $? == 0 ]; then\n-    HEDWIG_JAR=$RELEASE_JAR\n-fi\n-\n-BUILT_JAR=`ls $HW_HOME/target/hedwig-server-*.jar 2> /dev/null | grep -v tests | tail -1`\n-if [ $? != 0 ] && [ ! -e \"$HEDWIG_JAR\" ]; then \n-    echo \"\\nCouldn't find hedwig jar.\";\n-    echo \"Make sure you've run 'mvn package'\\n\";\n-    exit 1;\n-elif [ -e \"$BUILT_JAR\" ]; then\n-    HEDWIG_JAR=$BUILT_JAR\n-fi\n-\n-add_maven_deps_to_classpath() {\n-    MVN=\"mvn\"\n-    if [ \"$MAVEN_HOME\" != \"\" ]; then\n-\tMVN=${MAVEN_HOME}/bin/mvn\n-    fi\n-    \n-    # Need to generate classpath from maven pom. This is costly so generate it\n-    # and cache it. Save the file into our target dir so a mvn clean will get\n-    # clean it up and force us create a new one.\n-    f=\"${HW_HOME}/target/cached_classpath.txt\"\n-    if [ ! -f \"${f}\" ]\n-    then\n-\t${MVN} -f \"${HW_HOME}/pom.xml\" dependency:build-classpath -Dmdep.outputFile=\"${f}\" &> /dev/null\n-    fi\n-    HEDWIG_CLASSPATH=${CLASSPATH}:`cat \"${f}\"`\n-}\n-\n-if [ -d \"$HW_HOME/lib\" ]; then\n-    for i in $HW_HOME/lib/*.jar; do\n-\tHEDWIG_CLASSPATH=$HEDWIG_CLASSPATH:$i\n-    done\n-else\n-    add_maven_deps_to_classpath\n-fi\n-\n-hedwig_help() {\n-    cat <<EOF\n-Usage: hedwig <command>\n-where command is one of:\n-    server           Run the hedwig server\n-    console          Run the hedwig admin console\n-    help             This help message\n-\n-or command is the full name of a class with a defined main() method.\n-\n-Environment variables:\n-   HEDWIG_SERVER_CONF           Hedwig server configuration file (default $DEFAULT_CONF)\n-   HEDWIG_REGION_CLIENT_CONF           Configuration file for the hedwig client used by the\n-                                region manager (default $DEFAULT_REGION_CLIENT_CONF)\n-   HEDWIG_CONSOLE_SERVER_CONF   Server part configuration for hedwig console,\n-                                used for metadata management (defaults to HEDWIG_SERVER_CONF)\n-   HEDWIG_CONSOLE_CLIENT_CONF   Client part configuration for hedwig console,\n-                                used for interacting with hub server.\n-   HEDWIG_LOG_CONF              Log4j configuration file (default $DEFAULT_LOG_CONF)\n-   HEDWIG_ROOT_LOGGER           Root logger for hedwig\n-   HEDWIG_LOG_DIR               Log directory to store log files for hedwig server\n-   HEDWIG_LOG_FILE              Log file name\n-   HEDWIG_EXTRA_OPTS            Extra options to be passed to the jvm\n-\n-These variable can also be set in conf/hwenv.sh\n-EOF\n-}\n-\n-# if no args specified, show usage\n-if [ $# = 0 ]; then\n-    hedwig_help;\n-    exit 1;\n-fi\n-\n-# get arguments\n-COMMAND=$1\n-shift\n-\n-if [ -z \"$HEDWIG_SERVER_CONF\" ]; then\n-    HEDWIG_SERVER_CONF=$DEFAULT_CONF;\n-fi\n-\n-if [ -z \"$HEDWIG_REGION_CLIENT_CONF\" ]; then\n-    HEDWIG_REGION_CLIENT_CONF=$DEFAULT_REGION_CLIENT_CONF;\n-fi\n-\n-if [ -z \"$HEDWIG_LOG_CONF\" ]; then\n-    HEDWIG_LOG_CONF=$DEFAULT_LOG_CONF\n-fi\n-\n-HEDWIG_CLASSPATH=\"$HEDWIG_JAR:$HEDWIG_CLASSPATH\"\n-\n-if [ \"$HEDWIG_LOG_CONF\" != \"\" ]; then\n-    HEDWIG_CLASSPATH=\"`dirname $HEDWIG_LOG_CONF`:$HEDWIG_CLASSPATH\"\n-    OPTS=\"$OPTS -Dlog4j.configuration=`basename $HEDWIG_LOG_CONF`\"\n-fi\n-OPTS=\"-cp $HEDWIG_CLASSPATH $OPTS $HEDWIG_EXTRA_OPTS\"\n-\n-# Disable ipv6 as it can cause issues\n-OPTS=\"$OPTS -Djava.net.preferIPv4Stack=true\"\n-\n-# log directory & file\n-HEDWIG_ROOT_LOGGER=${HEDWIG_ROOT_LOGGER:-\"INFO,CONSOLE\"}\n-HEDWIG_LOG_DIR=${HEDWIG_LOG_DIR:-\"$HW_HOME/logs\"}\n-HEDWIG_LOG_FILE=${HEDWIG_LOG_FILE:-\"hedwig-server.log\"}\n-\n-# Configure log configuration system properties\n-OPTS=\"$OPTS -Dhedwig.root.logger=$HEDWIG_ROOT_LOGGER\"\n-OPTS=\"$OPTS -Dhedwig.log.dir=$HEDWIG_LOG_DIR\"\n-OPTS=\"$OPTS -Dhedwig.log.file=$HEDWIG_LOG_FILE\"\n-\n-# Change to HW_HOME to support relative paths\n-cd \"$BK_HOME\"\n-if [ $COMMAND == \"server\" ]; then\n-    exec $JAVA $OPTS $JMX_ARGS org.apache.hedwig.server.netty.PubSubServer $HEDWIG_SERVER_CONF $HEDWIG_REGION_CLIENT_CONF $@\n-elif [ $COMMAND == \"console\" ]; then\n-    # hedwig console configuration server part\n-    if [ -z \"$HEDWIG_CONSOLE_SERVER_CONF\" ]; then\n-        HEDWIG_CONSOLE_SERVER_CONF=$HEDWIG_SERVER_CONF\n-    fi\n-    # hedwig console configuration client part\n-    if [ -n \"$HEDWIG_CONSOLE_CLIENT_CONF\" ]; then\n-        HEDWIG_CONSOLE_CLIENT_OPTIONS=\"-client-cfg $HEDWIG_CONSOLE_CLIENT_CONF\"\n-    fi\n-    exec $JAVA $OPTS org.apache.hedwig.admin.console.HedwigConsole -server-cfg $HEDWIG_CONSOLE_SERVER_CONF $HEDWIG_CONSOLE_CLIENT_OPTIONS $@\n-elif [ $COMMAND == \"help\" ]; then\n-    hedwig_help;\n-else\n-    exec $JAVA $OPTS $COMMAND $@\n-fi\n-\n-"},{"sha":"73eac6f8236645e72826fef21716c92c75836096","filename":"hedwig-server/bin/hedwig-daemon.sh","status":"removed","additions":0,"deletions":163,"changes":163,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/bin/hedwig-daemon.sh","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/bin/hedwig-daemon.sh","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/bin/hedwig-daemon.sh?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,163 +0,0 @@\n-#!/usr/bin/env bash\n-#\n-#/**\n-# * Licensed to the Apache Software Foundation (ASF) under one\n-# * or more contributor license agreements.  See the NOTICE file\n-# * distributed with this work for additional information\n-# * regarding copyright ownership.  The ASF licenses this file\n-# * to you under the Apache License, Version 2.0 (the\n-# * \"License\"); you may not use this file except in compliance\n-# * with the License.  You may obtain a copy of the License at\n-# *\n-# *     http://www.apache.org/licenses/LICENSE-2.0\n-# *\n-# * Unless required by applicable law or agreed to in writing, software\n-# * distributed under the License is distributed on an \"AS IS\" BASIS,\n-# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# * See the License for the specific language governing permissions and\n-# * limitations under the License.\n-# */\n-\n-usage() {\n-    cat <<EOF\n-Usage: hedwig-daemon.sh (start|stop) <command> <args...>\n-where command is one of:\n-    server           Run the hedwig server\n-EOF\n-}\n-\n-\n-BINDIR=`dirname \"$0\"`\n-HEDWIG_HOME=`cd $BINDIR/..;pwd`\n-\n-if [ -f $HEDWIG_HOME/conf/hwenv.sh ]\n-then\n- . $HEDWIG_HOME/conf/hwenv.sh\n-fi\n-\n-HEDWIG_LOG_DIR=${HEDWIG_LOG_DIR:-\"$HEDWIG_HOME/logs\"}\n-\n-HEDWIG_ROOT_LOGGER=${HEDWIG_ROOT_LOGGER:-'INFO,ROLLINGFILE'}\n-\n-HEDWIG_STOP_TIMEOUT=${HEDWIG_STOP_TIMEOUT:-30}\n-\n-HEDWIG_PID_DIR=${HEDWIG_PID_DIR:-$HEDWIG_HOME/bin}\n-\n-if [ $# -lt 2 ]\n-then\n-    echo \"Error: no enough arguments provided.\"\n-    usage\n-    exit 1\n-fi\n-\n-startStop=$1\n-shift\n-command=$1\n-shift\n-\n-case $command in\n-    (server)\n-        echo \"doing $startStop $command ...\"\n-        ;;\n-    (*)\n-        echo \"Error: unknown service name $command\"\n-        usage\n-        exit 1\n-        ;;\n-esac\n-\n-export HEDWIG_LOG_DIR=$HEDWIG_LOG_DIR\n-export HEDWIG_ROOT_LOGGER=$HEDWIG_ROOT_LOGGER\n-export HEDWIG_LOG_FILE=hedwig-$command-$HOSTNAME.log\n-\n-pid=$HEDWIG_PID_DIR/hedwig-$command.pid\n-out=$HEDWIG_LOG_DIR/hedwig-$command-$HOSTNAME.out\n-logfile=$HEDWIG_LOG_DIR/$HEDWIG_LOG_FILE\n-\n-rotate_out_log ()\n-{\n-    log=$1;\n-    num=5;\n-    if [ -n \"$2\" ]; then\n-       num=$2\n-    fi\n-    if [ -f \"$log\" ]; then # rotate logs\n-        while [ $num -gt 1 ]; do\n-            prev=`expr $num - 1`\n-            [ -f \"$log.$prev\" ] && mv \"$log.$prev\" \"$log.$num\"\n-            num=$prev\n-        done\n-        mv \"$log\" \"$log.$num\";\n-    fi\n-}\n-\n-mkdir -p \"$HEDWIG_LOG_DIR\"\n-\n-case $startStop in\n-  (start)\n-    if [ -f $pid ]; then\n-      if kill -0 `cat $pid` > /dev/null 2>&1; then\n-        echo $command running as process `cat $pid`.  Stop it first.\n-        exit 1\n-      fi\n-    fi\n-\n-    rotate_out_log $out\n-    echo starting $command, logging to $logfile\n-    hedwig=$HEDWIG_HOME/bin/hedwig\n-    nohup $hedwig $command \"$@\" > \"$out\" 2>&1 < /dev/null &\n-    echo $! > $pid\n-    sleep 1; head $out\n-    sleep 2;\n-    if ! ps -p $! > /dev/null ; then\n-      exit 1\n-    fi\n-    ;;\n-\n-  (stop)\n-    if [ -f $pid ]; then\n-      TARGET_PID=`cat $pid`\n-      if kill -0 $TARGET_PID > /dev/null 2>&1; then\n-        echo stopping $command\n-        kill $TARGET_PID\n-\n-        count=0\n-        location=$HEDWIG_LOG_DIR\n-        while ps -p $TARGET_PID > /dev/null;\n-         do\n-          echo \"Shutdown is in progress... Please wait...\"\n-          sleep 1\n-          count=`expr $count + 1`\n-         \n-          if [ \"$count\" = \"$HEDWIG_STOP_TIMEOUT\" ]; then\n-                break\n-          fi\n-         done\n-        \n-        if [ \"$count\" != \"$HEDWIG_STOP_TIMEOUT\" ]; then\n-                 echo \"Shutdown completed.\"\n-                exit 0\n-        fi\n-                 \n-        if kill -0 $TARGET_PID > /dev/null 2>&1; then\n-              fileName=$location/$command.out\n-              $JAVA_HOME/bin/jstack $TARGET_PID > $fileName\n-              echo Thread dumps are taken for analysis at $fileName\n-              echo forcefully stopping $command\n-              kill -9 $TARGET_PID >/dev/null 2>&1\n-              echo Successfully stopped the process\n-        fi\n-      else\n-        echo no $command to stop\n-      fi\n-      rm $pid\n-    else\n-      echo no $command to stop\n-    fi\n-    ;;\n-\n-  (*)\n-    usage\n-    exit 1\n-    ;;\n-esac"},{"sha":"9a5592ee56bb294bc1f3dfd7c4a1c7ad7a4e3e24","filename":"hedwig-server/conf/hw_region_client.conf","status":"removed","additions":0,"deletions":42,"changes":42,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hw_region_client.conf","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hw_region_client.conf","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/conf/hw_region_client.conf?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,42 +0,0 @@\n-#   Licensed to the Apache Software Foundation (ASF) under one or more\n-#   contributor license agreements.  See the NOTICE file distributed with\n-#   this work for additional information regarding copyright ownership.\n-#   The ASF licenses this file to You under the Apache License, Version 2.0\n-#   (the \"License\"); you may not use this file except in compliance with\n-#   the License.  You may obtain a copy of the License at\n-#\n-#       http://www.apache.org/licenses/LICENSE-2.0\n-#\n-#   Unless required by applicable law or agreed to in writing, software\n-#   distributed under the License is distributed on an \"AS IS\" BASIS,\n-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-#   See the License for the specific language governing permissions and\n-#   limitations under the License.\n-\n-# This is the configuration file for the hedwig client used by the region manager\n-\n-# This parameter is a boolean flag indicating if communication with the\n-# server should be done via SSL for encryption. The Hedwig server hubs also\n-# need to be SSL enabled for this to work.\n-# ssl_enabled=false\n-\n-# The maximum message size in bytes\n-# max_message_size=2097152\n-\n-# The maximum number of redirects we permit before signalling an error\n-# max_server_redirects=2\n-\n-# A flag indicating whether the client library should automatically send\n-# consume messages to the server\n-# auto_send_consume_message_enabled=true\n-\n-# The number of messages we buffer before sending a consume message\n-# to the server\n-# consumed_messages_buffer_size=5\n-\n-# Support for client side throttling.\n-# max_outstanding_messages=10\n-\n-# The timeout in milliseconds before we error out any existing\n-# requests\n-# server_ack_response_timeout=30000"},{"sha":"2ca2d5462a9dbdcaaf4b0bfaa4f63f5709256cdd","filename":"hedwig-server/conf/hw_server.conf","status":"removed","additions":0,"deletions":168,"changes":168,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hw_server.conf","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hw_server.conf","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/conf/hw_server.conf?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,168 +0,0 @@\n-#   Licensed to the Apache Software Foundation (ASF) under one or more\n-#   contributor license agreements.  See the NOTICE file distributed with\n-#   this work for additional information regarding copyright ownership.\n-#   The ASF licenses this file to You under the Apache License, Version 2.0\n-#   (the \"License\"); you may not use this file except in compliance with\n-#   the License.  You may obtain a copy of the License at\n-#\n-#       http://www.apache.org/licenses/LICENSE-2.0\n-#\n-#   Unless required by applicable law or agreed to in writing, software\n-#   distributed under the License is distributed on an \"AS IS\" BASIS,\n-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-#   See the License for the specific language governing permissions and\n-#   limitations under the License.\n-\n-################################\n-# ZooKeeper Settings\n-################################\n-\n-# The ZooKeeper server host(s) for the Hedwig Server to use.\n-zk_host=localhost:2181\n-\n-# The number of milliseconds of each tick in ZooKeeper.\n-zk_timeout=2000\n-\n-################################\n-# Hub Server Settings\n-################################\n-\n-# Is the hub server running in standalone mode?\n-# Default is false.\n-standalone=false\n-\n-# The port at which the clients will connect.\n-server_port=4080\n-\n-# The SSL port at which the clients will connect (only if SSL is enabled).\n-ssl_server_port=9876\n-\n-# Flag indicating if the server should also operate in SSL mode.\n-ssl_enabled=false\n-\n-# Name of the SSL certificate if available as a resource.\n-# The certificate should be in pkcs12 format.\n-# cert_name=\n-\n-# Path to the SSL certificate if available as a file.\n-# The certificate should be in pkcs12 format.\n-# cert_path=\n-\n-# Password used for pkcs12 certificate.\n-# password=\n-\n-#######################################\n-# Publish and subscription parameters\n-#######################################\n-# Max Message Size that a hub server could accept\n-# max_message_size=1258291 \n-\n-# Message Sequence Interval to update subscription state to metadata store.\n-# Default is 50.\n-# consume_interval=50\n-\n-# Time interval (in seconds) to release topic ownership. If the time interval\n-# is less than zero, the ownership will never be released automatically.\n-# Default is 0.\n-# retention_secs=0\n-\n-# Time interval (in milliseconds) to run messages consumed timer task to\n-# delete those consumed ledgers in BookKeeper.\n-# messages_consumed_thread_run_interval=60000\n-\n-# Default maximum number of messages which can be delivered to a subscriber\n-# without being consumed. We pause messages delivery to a subscriber when\n-# reaching the window size. Default is 0, which means we never pause messages\n-# delivery even a subscriber consumes nothing and it doesn't set any subscriber\n-# specified message window size.\n-# default_message_window_size=0\n-\n-# The maximum number of entries stored in a ledger. When the number of entries\n-# reaches this threshold, hub server will open a new ledger to write. Default is 0.\n-# If it was set to 0, hub server will keep using same ledger to write entries unless\n-# the topic ownership changed.\n-# max_entries_per_ledger=0\n-\n-################################\n-# Region Related Settings\n-################################\n-\n-# Region name that the hub server belongs to.\n-# region=standalone\n-\n-# Regions list of a Hedwig instance.\n-# The expected format for the regions parameter is Hostname:Port:SSLPort\n-# with spaces in between each of regions.\n-# regions=\n-\n-# Enabled ssl connections between regions or not.\n-# (@Deprecated here. It is recommended to set in conf/hw_region_client.conf)\n-# Default is false.\n-# inter_region_ssl_enabled=false\n-\n-# Time interval (in milliseconds) to run thread to retry those failed\n-# remote subscriptions in asynchronous mode. Default is 120000.\n-# retry_remote_subscribe_thread_run_interval=120000\n-\n-################################\n-# ReadAhead Settings\n-################################\n-\n-# Enable read ahead cache or not. If disabled, read requests\n-# would access BookKeeper directly.\n-# Default is true.\n-# readahead_enabled=true\n-\n-# Number of entries to read ahead. Default value is 10.\n-# readahead_count=10\n-\n-# Max size of entries to read ahead. Default value is 4M.\n-# readahead_size=4194304\n-\n-# Max memory used for ReadAhead Cache.\n-# Default value is minimum value of 2G or half of JVM max memory.\n-# cache_size=\n-\n-# The backoff time (in milliseconds) to retry scans after failures.\n-# Default value is 1000.\n-# scan_backoff_ms=1000\n-\n-# Sets the number of threads to be used for the read-ahead mechanism.\n-# Default is the number of cores as returned with a call to \n-# <code>Runtime.getRuntime().availableProcessors()</code>.\n-# num_readahead_cache_threads=\n-\n-# Set TTL for cache entries. Each time adding new entry into the cache,\n-# those expired cache entries would be discarded. If the value is set\n-# to zero or less than zero, cache entry will not be evicted until the\n-# cache is fullfilled or the messages are already consumed. By default\n-# the value is zero.\n-# cache_entry_ttl=\n-\n-################################\n-# Metadata Settings\n-################################\n-\n-# zookeeper prefix to store metadata if using zookeeper as metadata store.\n-# Default value is \"/hedwig\".\n-# zk_prefix=/hedwig\n-\n-# Enable metadata manager based topic manager. Default is false.\n-# metadata_manager_based_topic_manager_enabled=false\n-\n-# Class name of metadata manager factory used to store metadata.\n-# Default is null.\n-# metadata_manager_factory_class=\n-\n-################################\n-# BookKeeper Settings\n-################################\n-\n-# Ensemble size of a ledger in BookKeeper. Default is 3.\n-# bk_ensemble_size=3\n-\n-# Write quorum size for a ledger in BookKeeper. Default is 2.\n-# bk_write_quorum_size=2\n-\n-# Ack quorum size for a ledger in BookKeeper. Default is 2.\n-# bk_ack_quorum_size=2"},{"sha":"8d379b6a11d5ba580f21e7a73fa7d0c54ae5d36a","filename":"hedwig-server/conf/hwenv.sh","status":"removed","additions":0,"deletions":56,"changes":56,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hwenv.sh","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/hwenv.sh","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/conf/hwenv.sh?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,56 +0,0 @@\n-#!/bin/sh\n-#\n-#/**\n-# * Copyright 2007 The Apache Software Foundation\n-# *\n-# * Licensed to the Apache Software Foundation (ASF) under one\n-# * or more contributor license agreements.  See the NOTICE file\n-# * distributed with this work for additional information\n-# * regarding copyright ownership.  The ASF licenses this file\n-# * to you under the Apache License, Version 2.0 (the\n-# * \"License\"); you may not use this file except in compliance\n-# * with the License.  You may obtain a copy of the License at\n-# *\n-# *     http://www.apache.org/licenses/LICENSE-2.0\n-# *\n-# * Unless required by applicable law or agreed to in writing, software\n-# * distributed under the License is distributed on an \"AS IS\" BASIS,\n-# * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# * See the License for the specific language governing permissions and\n-# * limitations under the License.\n-# */\n-\n-# Set JAVA_HOME here to override the environment setting\n-# JAVA_HOME=\n-\n-# default settings for starting hedwig\n-# HEDWIG_SERVER_CONF=\n-\n-# default settings for the region manager's hedwig client\n-# HEDWIG_REGION_CLIENT_CONF=\n-\n-# default settings for the region manager's hedwig client\n-# HEDWIG_CLIENT_CONF=\n-\n-# Server part configuration for hedwig console,\n-# used for metadata management\n-# HEDWIG_CONSOLE_SERVER_CONF=\n-\n-# Client part configuration for hedwig console,\n-# used for interacting with hub server.\n-# HEDWIG_CONSOLE_CLIENT_CONF=\n-\n-# Log4j configuration file\n-# HEDWIG_LOG_CONF=\n-\n-# Logs location\n-# HEDWIG_LOG_DIR=\n-\n-# Extra options to be passed to the jvm\n-# HEDWIG_EXTRA_OPTS=\n-\n-#Folder where the hedwig server PID file should be stored\n-#HEDWIG_PID_DIR=\n-\n-#Wait time before forcefully kill the hedwig server instance, if the stop is not successful\n-#HEDWIG_STOP_TIMEOUT="},{"sha":"c0f1c49f1c4dca8270bd3cf9e686c1a3c6cf627c","filename":"hedwig-server/conf/log4j.properties","status":"removed","additions":0,"deletions":78,"changes":78,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/log4j.properties","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/conf/log4j.properties","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/conf/log4j.properties?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,78 +0,0 @@\n-#\n-#\n-# Licensed to the Apache Software Foundation (ASF) under one\n-# or more contributor license agreements.  See the NOTICE file\n-# distributed with this work for additional information\n-# regarding copyright ownership.  The ASF licenses this file\n-# to you under the Apache License, Version 2.0 (the\n-# \"License\"); you may not use this file except in compliance\n-# with the License.  You may obtain a copy of the License at\n-#\n-#   http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing,\n-# software distributed under the License is distributed on an\n-# \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n-# KIND, either express or implied.  See the License for the\n-# specific language governing permissions and limitations\n-# under the License.\n-#\n-#\n-\n-#\n-# Hedwig Logging Configuration\n-#\n-\n-# Format is \"<default threshold> (, <appender>)+\n-\n-# DEFAULT: console appender only\n-# Define some default values that can be overridden by system properties\n-hedwig.root.logger=WARN,CONSOLE\n-hedwig.log.dir=.\n-hedwig.log.file=hedwig-server.log\n-hedwig.trace.file=hedwig-trace.log\n-\n-log4j.rootLogger=${hedwig.root.logger}\n-\n-# Example with rolling log file\n-#log4j.rootLogger=DEBUG, CONSOLE, ROLLINGFILE\n-\n-# Example with rolling log file and tracing\n-#log4j.rootLogger=TRACE, CONSOLE, ROLLINGFILE, TRACEFILE\n-\n-#\n-# Log INFO level and above messages to the console\n-#\n-log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppender\n-log4j.appender.CONSOLE.Threshold=INFO\n-log4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayout\n-log4j.appender.CONSOLE.layout.ConversionPattern=%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n\n-\n-#\n-# Add ROLLINGFILE to rootLogger to get log file output\n-#    Log DEBUG level and above messages to a log file\n-log4j.appender.ROLLINGFILE=org.apache.log4j.DailyRollingFileAppender\n-log4j.appender.ROLLINGFILE.Threshold=INFO\n-log4j.appender.ROLLINGFILE.File=${hedwig.log.dir}/${hedwig.log.file}\n-log4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayout\n-log4j.appender.ROLLINGFILE.layout.ConversionPattern=%d{ISO8601} - %-5p - [%t:%C{1}@%L] - %m%n\n-\n-# Max log file size of 10MB\n-#log4j.appender.ROLLINGFILE.MaxFileSize=10MB\n-# uncomment the next line to limit number of backup files\n-#log4j.appender.ROLLINGFILE.MaxBackupIndex=10\n-\n-log4j.appender.ROLLINGFILE.layout=org.apache.log4j.PatternLayout\n-log4j.appender.ROLLINGFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L] - %m%n\n-\n-\n-#\n-# Add TRACEFILE to rootLogger to get log file output\n-#    Log DEBUG level and above messages to a log file\n-log4j.appender.TRACEFILE=org.apache.log4j.FileAppender\n-log4j.appender.TRACEFILE.Threshold=TRACE\n-log4j.appender.TRACEFILE.File=${hedwig.log.dir}/${hedwig.trace.file}\n-\n-log4j.appender.TRACEFILE.layout=org.apache.log4j.PatternLayout\n-### Notice we are including log4j's NDC here (%x)\n-log4j.appender.TRACEFILE.layout.ConversionPattern=%d{ISO8601} - %-5p [%t:%C{1}@%L][%x] - %m%n"},{"sha":"b460f25c85000ad5db53118175f5a56be1c630ea","filename":"hedwig-server/pom.xml","status":"removed","additions":0,"deletions":294,"changes":294,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/pom.xml","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/pom.xml","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/pom.xml?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,294 +0,0 @@\n-<?xml version=\"1.0\"?>\n-<!--\n-   Licensed to the Apache Software Foundation (ASF) under one or more\n-   contributor license agreements.  See the NOTICE file distributed with\n-   this work for additional information regarding copyright ownership.\n-   The ASF licenses this file to You under the Apache License, Version 2.0\n-   (the \"License\"); you may not use this file except in compliance with\n-   the License.  You may obtain a copy of the License at\n-\n-       http://www.apache.org/licenses/LICENSE-2.0\n-\n-   Unless required by applicable law or agreed to in writing, software\n-   distributed under the License is distributed on an \"AS IS\" BASIS,\n-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-   See the License for the specific language governing permissions and\n-   limitations under the License.\n--->\n-\n-<project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n-  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n-  <modelVersion>4.0.0</modelVersion>\n-  <parent>\n-    <groupId>org.apache.bookkeeper</groupId>\n-    <artifactId>bookkeeper</artifactId>\n-    <version>4.4.0-SNAPSHOT</version>\n-  </parent>\n-  <properties>\n-      <mainclass>org.apache.hedwig.server.netty.PubSubServer</mainclass>\n-      <project.libdir>${basedir}/lib</project.libdir>\n-  </properties>\n-  <artifactId>hedwig-server</artifactId>\n-  <packaging>jar</packaging>\n-  <name>hedwig-server</name>\n-  <url>http://maven.apache.org</url>\n-  <dependencies>\n-    <dependency>\n-      <groupId>junit</groupId>\n-      <artifactId>junit</artifactId>\n-      <version>4.8.1</version>\n-      <scope>test</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.slf4j</groupId>\n-      <artifactId>slf4j-api</artifactId>\n-      <version>1.6.4</version>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.slf4j</groupId>\n-      <artifactId>slf4j-log4j12</artifactId>\n-      <version>1.6.4</version>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>hedwig-client</artifactId>\n-      <version>${project.parent.version}</version>\n-      <scope>compile</scope>\n-      <type>jar</type>\n-    </dependency>\n-    <dependency>\n-        <groupId>org.apache.derby</groupId>\n-        <artifactId>derby</artifactId>\n-        <version>10.8.2.2</version>\n-        <scope>runtime</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.zookeeper</groupId>\n-      <artifactId>zookeeper</artifactId>\n-      <version>${zookeeper.version}</version>\n-      <scope>compile</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.zookeeper</groupId>\n-      <artifactId>zookeeper</artifactId>\n-      <version>${zookeeper.version}</version>\n-      <type>test-jar</type>\n-      <scope>test</scope>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>bookkeeper-server</artifactId>\n-      <version>${project.parent.version}</version>\n-      <scope>compile</scope>\n-      <type>jar</type>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>bookkeeper-server</artifactId>\n-      <version>${project.parent.version}</version>\n-      <scope>test</scope>\n-      <type>test-jar</type>\n-    </dependency>\n-    <!--\n-        Annoying dependency we need to include because\n-        zookeeper uses log4j and so we transatively do, but\n-        log4j has some dependencies which aren't in the \n-        default maven repositories\n-    //-->\n-    <dependency>\n-      <groupId>log4j</groupId>\n-      <artifactId>log4j</artifactId>\n-      <version>1.2.15</version>\n-      <exclusions>\n-        <exclusion>\n-          <groupId>javax.mail</groupId>\n-          <artifactId>mail</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>javax.jms</groupId>\n-          <artifactId>jms</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>com.sun.jdmk</groupId>\n-          <artifactId>jmxtools</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>com.sun.jmx</groupId>\n-          <artifactId>jmxri</artifactId>\n-        </exclusion>\n-      </exclusions>\n-    </dependency>\n-    <dependency>\n-      <groupId>jline</groupId>\n-      <artifactId>jline</artifactId>\n-      <version>0.9.94</version>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>hedwig-server-compat420</artifactId>\n-      <version>4.2.0</version>\n-      <scope>test</scope>\n-      <exclusions>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>bookkeeper-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-protocol</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-client</artifactId>\n-        </exclusion>\n-      </exclusions>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>hedwig-server-compat410</artifactId>\n-      <version>4.1.0</version>\n-      <scope>test</scope>\n-      <exclusions>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>bookkeeper-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-protocol</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-client</artifactId>\n-        </exclusion>\n-      </exclusions>\n-    </dependency>\n-    <dependency>\n-      <groupId>org.apache.bookkeeper</groupId>\n-      <artifactId>hedwig-server-compat400</artifactId>\n-      <version>4.0.0</version>\n-      <scope>test</scope>\n-      <exclusions>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>bookkeeper-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-server</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-protocol</artifactId>\n-        </exclusion>\n-        <exclusion>\n-          <groupId>org.apache.bookkeeper</groupId>\n-          <artifactId>hedwig-client</artifactId>\n-        </exclusion>\n-      </exclusions>\n-    </dependency>\n-  </dependencies>\n-  <build>\n-    <plugins>\n-      <plugin>\n-        <groupId>org.apache.maven.plugins</groupId>\n-        <artifactId>maven-jar-plugin</artifactId>\n-        <executions>\n-          <execution>\n-            <phase>package</phase>\n-            <goals>\n-              <goal>test-jar</goal>\n-            </goals>\n-          </execution>\n-        </executions>\n-      </plugin>\n-      <plugin>\n-        <groupId>org.apache.rat</groupId>\n-        <artifactId>apache-rat-plugin</artifactId>\n-        <version>0.7</version>\n-        <configuration>\n-          <excludes>\n-            <exclude>**/p12.pass</exclude>\n-          </excludes>\n-        </configuration>\n-      </plugin>\n-      <plugin>\n-        <artifactId>maven-assembly-plugin</artifactId>\n-        <version>2.2.1</version>\n-        <configuration>\n-          <descriptors>\n-            <descriptor>../src/assemble/bin.xml</descriptor>\n-          </descriptors>\n-        </configuration>\n-      </plugin>\n-      <plugin>\n-        <groupId>org.codehaus.mojo</groupId>\n-        <artifactId>findbugs-maven-plugin</artifactId>\n-        <configuration>\n-          <excludeFilterFile>${basedir}/src/main/resources/findbugsExclude.xml</excludeFilterFile>\n-        </configuration>\n-      </plugin>\n-      <plugin>\n-        <artifactId>maven-antrun-plugin</artifactId>\n-        <executions>\n-          <execution>\n-            <id>createbuilddir</id>\n-            <phase>generate-test-resources</phase>\n-            <configuration>\n-              <target>\n-                <mkdir dir=\"target/zk_clientbase_build\" />\n-              </target>\n-            </configuration>\n-            <goals>\n-              <goal>run</goal>\n-            </goals>\n-          </execution>\n-        </executions>\n-      </plugin>\n-      <plugin>\n-        <artifactId>maven-dependency-plugin</artifactId>\n-        <executions>\n-          <execution>\n-            <phase>package</phase>\n-            <goals>\n-              <goal>copy-dependencies</goal>\n-            </goals>\n-            <configuration>\n-              <outputDirectory>${project.libdir}</outputDirectory>\n-            </configuration>\n-          </execution>\n-        </executions>\n-      </plugin>\n-      <plugin>\n-        <groupId>org.apache.maven.plugins</groupId>\n-        <artifactId>maven-surefire-plugin</artifactId>\n-        <configuration>\n-          <systemPropertyVariables>\n-            <derby.stream.error.file>target/derby.log</derby.stream.error.file>\n-            <build.test.dir>target/zk_clientbase_build</build.test.dir>\n-          </systemPropertyVariables>\n-        </configuration>\n-      </plugin>\n-      <plugin>\n-        <artifactId>maven-clean-plugin</artifactId>\n-        <version>2.5</version>\n-\t<configuration>\n-\t  <filesets>\n-            <fileset>\n-              <directory>${project.libdir}</directory>\n-              <followSymlinks>false</followSymlinks>\n-            </fileset>\n-\t  </filesets>\n-\t</configuration>\n-      </plugin>\n-    </plugins>\n-  </build>\n-</project>"},{"sha":"ec38fc24025f67737c232b1dff6a3cc0affeea87","filename":"hedwig-server/src/main/java/org/apache/hedwig/admin/HedwigAdmin.java","status":"removed","additions":0,"deletions":547,"changes":547,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/HedwigAdmin.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/HedwigAdmin.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/admin/HedwigAdmin.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,547 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.admin;\n-\n-import java.util.Arrays;\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.bookkeeper.conf.ClientConfiguration;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.BookKeeper.DigestType;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRange;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.meta.MetadataManagerFactory;\n-import org.apache.hedwig.server.meta.FactoryLayout;\n-import org.apache.hedwig.server.meta.SubscriptionDataManager;\n-import org.apache.hedwig.server.meta.TopicOwnershipManager;\n-import org.apache.hedwig.server.meta.TopicPersistenceManager;\n-import org.apache.hedwig.server.topics.HubInfo;\n-import org.apache.hedwig.server.topics.HubLoad;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.data.Stat;\n-\n-import com.google.protobuf.ByteString;\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-/**\n- * Hedwig Admin\n- */\n-public class HedwigAdmin {\n-    private static final Logger LOG = LoggerFactory.getLogger(HedwigAdmin.class);\n-\n-    // NOTE: now it is fixed passwd used in hedwig\n-    static byte[] passwd = \"sillysecret\".getBytes(UTF_8);\n-\n-    protected final ZooKeeper zk;\n-    protected final BookKeeper bk;\n-    protected final MetadataManagerFactory mmFactory;\n-    protected final SubscriptionDataManager sdm;\n-    protected final TopicOwnershipManager tom;\n-    protected final TopicPersistenceManager tpm;\n-\n-    // hub configurations\n-    protected final ServerConfiguration serverConf;\n-    // bookkeeper configurations\n-    protected final ClientConfiguration bkClientConf;\n-\n-    protected final CountDownLatch zkReadyLatch = new CountDownLatch(1);\n-\n-    // Empty watcher\n-    private class MyWatcher implements Watcher {\n-        public void process(WatchedEvent event) {\n-            if (Event.KeeperState.SyncConnected.equals(event.getState())) {\n-                zkReadyLatch.countDown();\n-            }\n-        }\n-    }\n-\n-    static class SyncObj<T> {\n-        boolean finished = false;\n-        boolean success = false;\n-        T value = null;\n-        PubSubException exception = null;\n-\n-        synchronized void success(T v) {\n-            finished = true;\n-            success = true;\n-            value = v;\n-            notify();\n-        }\n-\n-        synchronized void fail(PubSubException pse) {\n-            finished = true;\n-            success = false;\n-            exception = pse;\n-            notify();\n-        }\n-\n-        synchronized void block() {\n-            try {\n-                while (!finished) {\n-                    wait();\n-                }\n-            } catch (InterruptedException ie) {\n-            }\n-        }\n-\n-        synchronized boolean isSuccess() {\n-            return success;\n-        }\n-    }\n-\n-    /**\n-     * Stats of a hub\n-     */\n-    public static class HubStats {\n-        HubInfo hubInfo;\n-        HubLoad hubLoad;\n-\n-        public HubStats(HubInfo info, HubLoad load) {\n-            this.hubInfo = info;\n-            this.hubLoad = load;\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder sb = new StringBuilder();\n-            sb.append(\"info : [\").append(hubInfo.toString().trim().replaceAll(\"\\n\", \", \"))\n-              .append(\"], load : [\").append(hubLoad.toString().trim().replaceAll(\"\\n\", \", \"))\n-              .append(\"]\");\n-            return sb.toString();\n-        }\n-    }\n-\n-    /**\n-     * Hedwig Admin Constructor\n-     *\n-     * @param bkConf\n-     *          BookKeeper Client Configuration.\n-     * @param hubConf\n-     *          Hub Server Configuration.\n-     * @throws Exception\n-     */\n-    public HedwigAdmin(ClientConfiguration bkConf, ServerConfiguration hubConf) throws Exception {\n-        this.serverConf = hubConf;\n-        this.bkClientConf = bkConf;\n-\n-        // connect to zookeeper\n-        zk = new ZooKeeper(hubConf.getZkHost(), hubConf.getZkTimeout(), new MyWatcher());\n-        LOG.debug(\"Connecting to zookeeper {}, timeout = {}\",\n-                hubConf.getZkHost(), hubConf.getZkTimeout());\n-        // wait until connection is ready\n-        if (!zkReadyLatch.await(hubConf.getZkTimeout() * 2, TimeUnit.MILLISECONDS)) {\n-            throw new Exception(\"Count not establish connection with ZooKeeper after \" + hubConf.getZkTimeout() * 2 + \" ms.\");\n-        }\n-\n-        // construct the metadata manager factory\n-        mmFactory = MetadataManagerFactory.newMetadataManagerFactory(hubConf, zk);\n-        tpm = mmFactory.newTopicPersistenceManager();\n-        tom = mmFactory.newTopicOwnershipManager();\n-        sdm = mmFactory.newSubscriptionDataManager();\n-\n-        // connect to bookkeeper\n-        bk = new BookKeeper(bkClientConf, zk);\n-        LOG.debug(\"Connecting to bookkeeper\");\n-    }\n-\n-    /**\n-     * Close the hedwig admin.\n-     *\n-     * @throws Exception\n-     */\n-    public void close() throws Exception {\n-        tpm.close();\n-        tom.close();\n-        sdm.close();\n-        mmFactory.shutdown();\n-        bk.close();\n-        zk.close();\n-    }\n-\n-    /**\n-     * Return zookeeper handle used in hedwig admin.\n-     *\n-     * @return zookeeper handle\n-     */\n-    public ZooKeeper getZkHandle() {\n-        return zk;\n-    }\n-\n-    /**\n-     * Return bookkeeper handle used in hedwig admin.\n-     *\n-     * @return bookkeeper handle\n-     */\n-    public BookKeeper getBkHandle() {\n-        return bk;\n-    }\n-\n-    /**\n-     * Return hub server configuration used in hedwig admin\n-     *\n-     * @return hub server configuration\n-     */\n-    public ServerConfiguration getHubServerConf() {\n-        return serverConf;\n-    }\n-\n-    /**\n-     * Return metadata manager factory.\n-     *\n-     * @return metadata manager factory instance.\n-     */\n-    public MetadataManagerFactory getMetadataManagerFactory() {\n-        return mmFactory;\n-    }\n-\n-    /**\n-     * Return bookeeper passwd used in hedwig admin\n-     *\n-     * @return bookeeper passwd\n-     */\n-    public byte[] getBkPasswd() {\n-        return Arrays.copyOf(passwd, passwd.length);\n-    }\n-\n-    /**\n-     * Return digest type used in hedwig admin\n-     *\n-     * @return bookeeper digest type\n-     */\n-    public DigestType getBkDigestType() {\n-        return DigestType.CRC32;\n-    }\n-\n-    /**\n-     * Dose topic exist?\n-     *\n-     * @param topic\n-     *            Topic name\n-     * @return whether topic exists or not?\n-     * @throws Exception\n-     */\n-    public boolean hasTopic(ByteString topic) throws Exception {\n-        // current persistence info is bound with a topic, so if there is persistence info\n-        // there is topic.\n-        final SyncObj<Boolean> syncObj = new SyncObj<Boolean>();\n-        tpm.readTopicPersistenceInfo(topic, new Callback<Versioned<LedgerRanges>>() {\n-            @Override\n-            public void operationFinished(Object ctx, Versioned<LedgerRanges> result) {\n-                if (null == result) {\n-                    syncObj.success(false);\n-                } else {\n-                    syncObj.success(true);\n-                }\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                syncObj.fail(pse);\n-            }\n-        }, syncObj);\n-\n-        syncObj.block();\n-\n-        if (!syncObj.isSuccess()) {\n-            throw syncObj.exception;\n-        }\n-\n-        return syncObj.value;\n-    }\n-\n-    /**\n-     * Get available hubs.\n-     *\n-     * @return available hubs and their loads\n-     * @throws Exception\n-     */\n-    public Map<HedwigSocketAddress, HubStats> getAvailableHubs() throws Exception {\n-        String zkHubsPath = serverConf.getZkHostsPrefix(new StringBuilder()).toString();\n-        Map<HedwigSocketAddress, HubStats> hubs =\n-            new HashMap<HedwigSocketAddress, HubStats>();\n-        List<String> hosts = zk.getChildren(zkHubsPath, false);\n-        for (String host : hosts) {\n-            String zkHubPath = serverConf.getZkHostsPrefix(new StringBuilder())\n-                                         .append(\"/\").append(host).toString();\n-            HedwigSocketAddress addr = new HedwigSocketAddress(host);\n-            try {\n-                Stat stat = new Stat();\n-                byte[] data = zk.getData(zkHubPath, false, stat);\n-                if (data == null) {\n-                    continue;\n-                }\n-                HubLoad load = HubLoad.parse(new String(data, UTF_8));\n-                HubInfo info = new HubInfo(addr, stat.getCzxid());\n-                hubs.put(addr, new HubStats(info, load));\n-            } catch (KeeperException ke) {\n-                LOG.warn(\"Couldn't read hub data from ZooKeeper\", ke);\n-            } catch (InterruptedException ie) {\n-                LOG.warn(\"Interrupted during read\", ie);\n-            }\n-        }\n-        return hubs;\n-    }\n-\n-    /**\n-     * Get list of topics\n-     *\n-     * @return list of topics\n-     * @throws Exception\n-     */\n-    public Iterator<ByteString> getTopics() throws Exception {\n-        return mmFactory.getTopics();\n-    }\n-\n-    /**\n-     * Return the topic owner of a topic\n-     *\n-     * @param topic\n-     *            Topic name\n-     * @return the address of the owner of a topic\n-     * @throws Exception\n-     */\n-    public HubInfo getTopicOwner(ByteString topic) throws Exception {\n-        final SyncObj<HubInfo> syncObj = new SyncObj<HubInfo>();\n-        tom.readOwnerInfo(topic, new Callback<Versioned<HubInfo>>() {\n-            @Override\n-            public void operationFinished(Object ctx, Versioned<HubInfo> result) {\n-                if (null == result) {\n-                    syncObj.success(null);\n-                } else {\n-                    syncObj.success(result.getValue());\n-                }\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                syncObj.fail(pse);\n-            }\n-        }, syncObj);\n-\n-        syncObj.block();\n-\n-        if (!syncObj.isSuccess()) {\n-            throw syncObj.exception;\n-        }\n-\n-        return syncObj.value;\n-    }\n-\n-    private static LedgerRange buildLedgerRange(long ledgerId, long startOfLedger, MessageSeqId endOfLedger) {\n-        LedgerRange.Builder builder =\n-            LedgerRange.newBuilder().setLedgerId(ledgerId).setStartSeqIdIncluded(startOfLedger)\n-                       .setEndSeqIdIncluded(endOfLedger);\n-        return builder.build();\n-    }\n-\n-    /**\n-     * Return the ledger range forming the topic\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @return ledger ranges forming the topic\n-     * @throws Exception\n-     */\n-    public List<LedgerRange> getTopicLedgers(ByteString topic) throws Exception {\n-        final SyncObj<LedgerRanges> syncObj = new SyncObj<LedgerRanges>();\n-        tpm.readTopicPersistenceInfo(topic, new Callback<Versioned<LedgerRanges>>() {\n-            @Override\n-            public void operationFinished(Object ctx, Versioned<LedgerRanges> result) {\n-                if (null == result) {\n-                    syncObj.success(null);\n-                } else {\n-                    syncObj.success(result.getValue());\n-                }\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                syncObj.fail(pse);\n-            }\n-        }, syncObj);\n-\n-        syncObj.block();\n-\n-        if (!syncObj.isSuccess()) {\n-            throw syncObj.exception;\n-        }\n-\n-        LedgerRanges ranges = syncObj.value;\n-        if (null == ranges) {\n-            return null;\n-        }\n-        List<LedgerRange> results = new ArrayList<LedgerRange>();\n-        List<LedgerRange> lrs = ranges.getRangesList();\n-        long startSeqId = 1L;\n-        if (!lrs.isEmpty()) {\n-            LedgerRange range = lrs.get(0);\n-            if (!range.hasStartSeqIdIncluded() && range.hasEndSeqIdIncluded()) {\n-                long ledgerId = range.getLedgerId();\n-                try {\n-                    LedgerHandle lh = bk.openLedgerNoRecovery(ledgerId, DigestType.CRC32, passwd);\n-                    long numEntries = lh.readLastConfirmed() + 1;\n-                    long endOfLedger = range.getEndSeqIdIncluded().getLocalComponent();\n-                    startSeqId = endOfLedger - numEntries + 1;\n-                } catch (BKException.BKNoSuchLedgerExistsException be) {\n-                    // ignore it\n-                }\n-            }\n-        }\n-        Iterator<LedgerRange> lrIter = lrs.iterator();\n-        while (lrIter.hasNext()) {\n-            LedgerRange range = lrIter.next();\n-            if (range.hasEndSeqIdIncluded()) {\n-                long endOfLedger = range.getEndSeqIdIncluded().getLocalComponent();\n-                if (range.hasStartSeqIdIncluded()) {\n-                    startSeqId = range.getStartSeqIdIncluded();\n-                } else {\n-                    range = buildLedgerRange(range.getLedgerId(), startSeqId, range.getEndSeqIdIncluded());\n-                }\n-                results.add(range);\n-                if (startSeqId < endOfLedger + 1) {\n-                    startSeqId = endOfLedger + 1;\n-                }\n-                continue;\n-            }\n-            if (lrIter.hasNext()) {\n-                throw new IllegalStateException(\"Ledger \" + range.getLedgerId() + \" for topic \" + topic.toString()\n-                                                + \" is not the last one but still does not have an end seq-id\");\n-            }\n-\n-            if (range.hasStartSeqIdIncluded()) {\n-                startSeqId = range.getStartSeqIdIncluded();\n-            }\n-\n-            LedgerHandle lh = bk.openLedgerNoRecovery(range.getLedgerId(), DigestType.CRC32, passwd);\n-            long endOfLedger = startSeqId + lh.readLastConfirmed();\n-            MessageSeqId endSeqId = MessageSeqId.newBuilder().setLocalComponent(endOfLedger).build();\n-            results.add(buildLedgerRange(range.getLedgerId(), startSeqId, endSeqId));\n-        }\n-        return results;\n-    }\n-\n-    /**\n-     * Return subscriptions of a topic\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @return subscriptions of a topic\n-     * @throws Exception\n-     */\n-    public Map<ByteString, SubscriptionData> getTopicSubscriptions(ByteString topic)\n-        throws Exception {\n-\n-        final SyncObj<Map<ByteString, SubscriptionData>> syncObj =\n-            new SyncObj<Map<ByteString, SubscriptionData>>();\n-        sdm.readSubscriptions(topic, new Callback<Map<ByteString, Versioned<SubscriptionData>>>() {\n-            @Override\n-            public void operationFinished(Object ctx, Map<ByteString, Versioned<SubscriptionData>> result) {\n-                // It was just used to console tool to print some information, so don't need to return version for it\n-                // just keep the getTopicSubscriptions interface as before\n-                Map<ByteString, SubscriptionData> subs = new ConcurrentHashMap<ByteString, SubscriptionData>();\n-                for (Map.Entry<ByteString, Versioned<SubscriptionData>> subEntry : result.entrySet()) {\n-                    subs.put(subEntry.getKey(), subEntry.getValue().getValue());\n-                }\n-                syncObj.success(subs);\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                syncObj.fail(pse);\n-            }\n-        }, syncObj);\n-\n-        syncObj.block();\n-\n-        if (!syncObj.isSuccess()) {\n-            throw syncObj.exception;\n-        }\n-\n-        return syncObj.value;\n-    }\n-\n-    /**\n-     * Return subscription state of a subscriber of topic\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param subscriber\n-     *          Subscriber name\n-     * @return subscription state\n-     * @throws Exception\n-     */\n-    public SubscriptionData getSubscription(ByteString topic, ByteString subscriber) throws Exception {\n-        final SyncObj<SubscriptionData> syncObj = new SyncObj<SubscriptionData>();\n-        sdm.readSubscriptionData(topic, subscriber, new Callback<Versioned<SubscriptionData>>() {\n-            @Override\n-            public void operationFinished(Object ctx, Versioned<SubscriptionData> result) {\n-                if (null == result) {\n-                    syncObj.success(null);\n-                } else {\n-                    syncObj.success(result.getValue());\n-                }\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                syncObj.fail(pse);\n-            }\n-        }, syncObj);\n-\n-        syncObj.block();\n-\n-        if (!syncObj.isSuccess()) {\n-            throw syncObj.exception;\n-        }\n-\n-        return syncObj.value;\n-    }\n-\n-    /**\n-     * Format metadata for Hedwig.\n-     */\n-    public void format() throws Exception {\n-        // format metadata first\n-        mmFactory.format(serverConf, zk);\n-        LOG.info(\"Formatted Hedwig metadata successfully.\");\n-        // remove metadata layout\n-        FactoryLayout.deleteLayout(zk, serverConf);\n-        LOG.info(\"Removed old factory layout.\");\n-        // create new metadata manager factory and write new metadata layout\n-        MetadataManagerFactory.createMetadataManagerFactory(serverConf, zk,\n-            serverConf.getMetadataManagerFactoryClass());\n-        LOG.info(\"Created new factory layout.\");\n-    }\n-}"},{"sha":"407769bdd71d2ce5114b555416306fe8d7df56d8","filename":"hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigCommands.java","status":"removed","additions":0,"deletions":437,"changes":437,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigCommands.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigCommands.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigCommands.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,437 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.admin.console;\n-\n-import java.util.Map;\n-import java.util.List;\n-import java.util.LinkedList;\n-import java.util.LinkedHashMap;\n-\n-/**\n- * List all the available commands\n- */\n-public final class HedwigCommands {\n-\n-    static final String[] EMPTY_ARRAY = new String[0];\n-\n-    //\n-    // List all commands used to play with hedwig\n-    //\n-\n-    /* PUB : publish a message to hedwig */\n-    static final String PUB = \"pub\";\n-    static final String PUB_DESC = \"Publish a message to a topic in Hedwig\";\n-    static final String[] PUB_USAGE = new String[] {\n-        \"usage: pub {topic} {message}\",\n-        \"\",\n-        \"  {topic}   : topic name.\",\n-        \"              any printable string without spaces.\",\n-        \"  {message} : message body.\",\n-        \"              remaining arguments are used as message body to publish.\",\n-    };\n-\n-    /* SUB : subscriber a topic in hedwig for a specified subscriber */\n-    static final String SUB = \"sub\";\n-    static final String SUB_DESC = \"Subscribe a topic for a specified subscriber\";\n-    static final String[] SUB_USAGE = new String[] {\n-        \"usage: sub {topic} {subscriber} [mode]\",\n-        \"\",\n-        \"  {topic}      : topic name.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {subscriber} : subscriber id.\",\n-        \"                 any printable string without spaces.\",\n-        \"  [mode]       : mode to create subscription.\",\n-        \"  [receive]    : bool. whether to start delivery to receive messages.\",\n-        \"\",\n-        \"  available modes: (default value is 1)\",\n-        \"    0 = CREATE: create subscription.\",\n-        \"                if the subscription is exsited, it will fail.\",\n-        \"    1 = ATTACH: attach to exsited subscription.\",\n-        \"                if the subscription is not existed, it will faile.\",\n-        \"    2 = CREATE_OR_ATTACH:\",\n-        \"                attach to subscription, if not existed create one.\"\n-    };\n-\n-    /* CLOSESUB : close the subscription of a subscriber for a topic */\n-    static final String CLOSESUB = \"closesub\";\n-    static final String CLOSESUB_DESC = \"Close subscription of a subscriber to a specified topic\";\n-    static final String[] CLOSESUB_USAGE = new String[] {\n-        \"usage: closesub {topic} {subscriber}\",\n-        \"\",\n-        \"  {topic}      : topic name.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {subscriber} : subscriber id.\",\n-        \"                 any printable string without spaces.\",\n-        \"\",\n-        \" NOTE: this command just cleanup subscription states on client side.\",\n-        \"       You can try UNSUB to clean subscription states on server side.\",\n-    };\n-\n-    /* UNSUB: unsubscribe of a subscriber to a topic */\n-    static final String UNSUB = \"unsub\";\n-    static final String UNSUB_DESC = \"Unsubscribe a topic for a subscriber\";\n-    static final String[] UNSUB_USAGE = new String[] {\n-        \"usage: unsub {topic} {subscriber}\",\n-        \"\",\n-        \"  {topic}      : topic name.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {subscriber} : subscriber id.\",\n-        \"                 any printable string without spaces.\",\n-        \"\",\n-        \" NOTE: this command will cleanup subscription states on server side.\",\n-        \"       You can try CLOSESUB to just clean subscription states on client side.\",\n-    };\n-\n-    static final String RMSUB = \"rmsub\";\n-    static final String RMSUB_DESC = \"Remove subscriptions for topics\";\n-    static final String[] RMSUB_USAGE = new String[] {\n-        \"usage: rmsub {topic_prefix} {start_topic} {end_topic} {subscriber_prefix} {start_sub} {end_sub}\",\n-        \"\",\n-        \"  {topic_prefix}       : topic prefix.\",\n-        \"  {start_topic}        : start topic id.\",\n-        \"  {end_topic}          : end topic id.\",\n-        \"  {subscriber_prefix}  : subscriber prefix.\",\n-        \"  {start_sub}          : start subscriber id.\",\n-        \"  {end_sub}            : end subscriber id.\",\n-    };\n-\n-    /* CONSUME: move consume ptr of a subscription with specified steps */\n-    static final String CONSUME = \"consume\";\n-    static final String CONSUME_DESC = \"Move consume ptr of a subscription with sepcified steps\";\n-    static final String[] CONSUME_USAGE = new String[] {\n-        \"usage: consume {topic} {subscriber} {nmsgs}\",\n-        \"\",\n-        \"  {topic}      : topic name.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {subscriber} : subscriber id.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {nmsgs}      : how many messages to move consume ptr.\",\n-        \"\",\n-        \"  Example:\",\n-        \"  suppose, from zk we know subscriber B consumed topic T to message 10\",\n-        \"  [hedwig: (standalone) 1] consume T B 2\",\n-        \"  after executed above command, a consume(10+2) request will be sent to hedwig.\",\n-        \"\",\n-        \"  NOTE:\",\n-        \"  since Hedwig updates subscription consume ptr lazily, so you need to know that\",\n-        \"    1) the consumption ptr read from zookeeper may be stable; \",\n-        \"    2) after sent the consume request, hedwig may just move ptr in its memory and lazily update it to zookeeper. you may not see the ptr changed when DESCRIBE the topic.\",\n-    };\n-\n-    /* CONSUMETO: move consume ptr of a subscription to a specified pos */\n-    static final String CONSUMETO = \"consumeto\";\n-    static final String CONSUMETO_DESC = \"Move consume ptr of a subscription to a specified message id\";\n-    static final String[] CONSUMETO_USAGE = new String[] {\n-        \"usage: consumeto {topic} {subscriber} {msg_id}\",\n-        \"\",\n-        \"  {topic}      : topic name.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {subscriber} : subscriber id.\",\n-        \"                 any printable string without spaces.\",\n-        \"  {msg_id}     : message id that consume ptr will be moved to.\",\n-        \"                 if the message id is less than current consume ptr,\",\n-        \"                 hedwig will do nothing.\",\n-        \"\",\n-        \"  Example:\",\n-        \"  suppose, from zk we know subscriber B consumed topic T to message 10\",\n-        \"  [hedwig: (standalone) 1] consumeto T B 12\",\n-        \"  after executed above command, a consume(12) request will be sent to hedwig.\",\n-        \"\",\n-        \"  NOTE:\",\n-        \"  since Hedwig updates subscription consume ptr lazily, so you need to know that\",\n-        \"    1) the consumption ptr read from zookeeper may be stable; \",\n-        \"    2) after sent the consume request, hedwig may just move ptr in its memory and lazily update it to zookeeper. you may not see the ptr changed when DESCRIBE the topic.\",\n-    };\n-\n-    /* PUBSUB: a healthy checking command to ensure cluster is running */\n-    static final String PUBSUB = \"pubsub\";\n-    static final String PUBSUB_DESC = \"A healthy checking command to ensure hedwig is in running state\";\n-    static final String[] PUBSUB_USAGE = new String[] {\n-        \"usage: pubsub {topic} {subscriber} {timeout_secs} {message}\",\n-        \"\",\n-        \"  {topic}        : topic name.\",\n-        \"                   any printable string without spaces.\",\n-        \"  {subscriber}   : subscriber id.\",\n-        \"                   any printable string without spaces.\",\n-        \"  {timeout_secs} : how long will the subscriber wait for published message.\",\n-        \"  {message}      : message body.\",\n-        \"                   remaining arguments are used as message body to publish.\",\n-        \"\",\n-        \"  Example:\",\n-        \"  [hedwig: (standalone) 1] pubsub TOPIC SUBID 10 TEST_MESSAGS\",\n-        \"\",\n-        \"  1) hw will subscribe topic TOPIC as subscriber SUBID;\",\n-        \"  2) subscriber SUBID will wait a message until 10 seconds;\",\n-        \"  3) hw publishes TEST_MESSAGES to topic TOPIC;\",\n-        \"  4) if subscriber recevied message in 10 secs, it checked that whether the message is published message.\",\n-        \"     if true, it will return SUCCESS, otherwise return FAILED.\",\n-    };\n-\n-    //\n-    // List all commands used to admin hedwig\n-    //\n-\n-    /* SHOW: list all available hub servers or topics */\n-    static final String SHOW = \"show\";\n-    static final String SHOW_DESC = \"list all available hub servers or topics\";\n-    static final String[] SHOW_USAGE = new String[] {\n-        \"usage: show [topics | hubs]\",\n-        \"\",\n-        \"  show topics :\",\n-        \"    listing all available topics in hedwig.\",\n-        \"\",\n-        \"  show hubs :\",\n-        \"    listing all available hubs in hedwig.\",\n-        \"\",\n-        \"  NOTES:\",\n-        \"  'show topics' will not works when there are millions of topics in hedwig, since we have packetLen limitation fetching data from zookeeper.\",\n-    };\n-\n-    static final String SHOW_TOPICS = \"topics\";\n-    static final String SHOW_HUBS   = \"hubs\";\n-\n-    /* DESCRIBE: show the metadata of a topic */\n-    static final String DESCRIBE = \"describe\";\n-    static final String DESCRIBE_DESC = \"show metadata of a topic, including topic owner, persistence info, subscriptions info\";\n-    static final String[] DESCRIBE_USAGE = new String[] {\n-        \"usage: describe topic {topic}\",\n-        \"\",\n-        \"  {topic} : topic name.\",\n-        \"            any printable string without spaces.\",\n-        \"\",\n-        \"  Example: describe topic ttttt\",\n-        \"\",\n-        \"  Output:\",\n-        \"  ===== Topic Information : ttttt =====\",\n-        \"\",\n-        \"  Owner : 98.137.99.27:9875:9876\",\n-        \"\",\n-        \"  >>> Persistence Info <<<\",\n-        \"  Ledger 54729 [ 1 ~ 59 ]\",\n-        \"  Ledger 54731 [ 60 ~ 60 ]\",\n-        \"  Ledger 54733 [ 61 ~ 61 ]\",\n-        \"\",\n-        \"  >>> Subscription Info <<<\",\n-        \"  Subscriber mysub : consumeSeqId: local:50\",\n-    };\n-\n-    static final String DESCRIBE_TOPIC = \"topic\";\n-\n-    /* READTOPIC: read messages of a specified topic */\n-    static final String READTOPIC = \"readtopic\";\n-    static final String READTOPIC_DESC = \"read messages of a specified topic\";\n-    static final String[] READTOPIC_USAGE = new String[] {\n-        \"usage: readtopic {topic} [start_msg_id]\",\n-        \"\",\n-        \"  {topic}        : topic name.\",\n-        \"                   any printable string without spaces.\",\n-        \"  [start_msg_id] : message id that start to read from.\",\n-        \"\",\n-        \"  no start_msg_id provided:\",\n-        \"    it will start from least_consumed_message_id + 1.\",\n-        \"    least_consume_message_id is computed from all its subscribers.\",\n-        \"\",\n-        \"  start_msg_id provided:\",\n-        \"    it will start from MAX(start_msg_id, least_consumed_message_id).\",\n-        \"\",\n-        \"  MESSAGE FORMAT:\",\n-        \"\",\n-        \"  ---------- MSGID=LOCAL(51) ----------\",\n-        \"  MsgId:     LOCAL(51)\",\n-        \"  SrcRegion: standalone\",\n-        \"  Message:\",\n-        \"\",\n-        \"  hello\",\n-    };\n-\n-    /* FORMAT: format metadata for Hedwig */\n-    static final String FORMAT = \"format\";\n-    static final String FORMAT_DESC = \"format metadata for Hedwig\";\n-    static final String[] FORMAT_USAGE = new String[] {\n-        \"usage: format [-force]\",\n-        \"\",\n-        \"  [-force] : Format metadata for Hedwig w/o confirmation.\",\n-    };\n-\n-\n-    //\n-    // List other useful commands\n-    //\n-\n-    /* SET: set whether printing zk watches or not */\n-    static final String SET = \"set\";\n-    static final String SET_DESC = \"set whether printing zk watches or not\";\n-    static final String[] SET_USAGE = EMPTY_ARRAY;\n-\n-    /* HISTORY: list history commands */\n-    static final String HISTORY = \"history\";\n-    static final String HISTORY_DESC = \"list history commands\";\n-    static final String[] HISTORY_USAGE = EMPTY_ARRAY;\n-\n-    /* REDO: redo previous command */\n-    static final String REDO = \"redo\";\n-    static final String REDO_DESC = \"redo history command\";\n-    static final String[] REDO_USAGE = new String[] {\n-        \"usage: redo [{cmdno} | !]\",\n-        \"\",\n-        \"  {cmdno} : history command no.\",\n-        \"  !       : last command.\",\n-    };\n-\n-    /* HELP: print usage information of a specified command */\n-    static final String HELP = \"help\";\n-    static final String HELP_DESC = \"print usage information of a specified command\";\n-    static final String[] HELP_USAGE = new String[] {\n-        \"usage: help {command}\",\n-        \"\",\n-        \"  {command} : command name\",\n-    };\n-\n-    static final String QUIT = \"quit\";\n-    static final String QUIT_DESC = \"exit console\";\n-    static final String[] QUIT_USAGE = EMPTY_ARRAY;\n-\n-    static final String EXIT = \"exit\";\n-    static final String EXIT_DESC = QUIT_DESC;\n-    static final String[] EXIT_USAGE = EMPTY_ARRAY;\n-\n-    public static enum COMMAND {\n-\n-        CMD_PUB (PUB, PUB_DESC, PUB_USAGE),\n-        CMD_SUB (SUB, SUB_DESC, SUB_USAGE),\n-        CMD_CLOSESUB (CLOSESUB, CLOSESUB_DESC, CLOSESUB_USAGE),\n-        CMD_UNSUB (UNSUB, UNSUB_DESC, UNSUB_USAGE),\n-        CMD_RMSUB (RMSUB, RMSUB_DESC, RMSUB_USAGE),\n-        CMD_CONSUME (CONSUME, CONSUME_DESC, CONSUME_USAGE),\n-        CMD_CONSUMETO (CONSUMETO, CONSUMETO_DESC, CONSUMETO_USAGE),\n-        CMD_PUBSUB (PUBSUB, PUBSUB_DESC, PUBSUB_USAGE),\n-        CMD_SHOW (SHOW, SHOW_DESC, SHOW_USAGE),\n-        CMD_DESCRIBE (DESCRIBE, DESCRIBE_DESC, DESCRIBE_USAGE),\n-        CMD_READTOPIC (READTOPIC, READTOPIC_DESC, READTOPIC_USAGE),\n-        CMD_FORMAT (FORMAT, FORMAT_DESC, FORMAT_USAGE),\n-        CMD_SET (SET, SET_DESC, SET_USAGE),\n-        CMD_HISTORY (HISTORY, HISTORY_DESC, HISTORY_USAGE),\n-        CMD_REDO (REDO, REDO_DESC, REDO_USAGE),\n-        CMD_HELP (HELP, HELP_DESC, HELP_USAGE),\n-        CMD_QUIT (QUIT, QUIT_DESC, QUIT_USAGE),\n-        CMD_EXIT (EXIT, EXIT_DESC, EXIT_USAGE),\n-        // sub commands\n-        CMD_SHOW_TOPICS (SHOW_TOPICS, \"\", EMPTY_ARRAY),\n-        CMD_SHOW_HUBS (SHOW_HUBS, \"\", EMPTY_ARRAY),\n-        CMD_DESCRIBE_TOPIC (DESCRIBE_TOPIC, \"\", EMPTY_ARRAY);\n-\n-        COMMAND(String name, String desc, String[] usage) {\n-            this.name = name;\n-            this.desc = desc;\n-            this.usage = usage;\n-            this.subCmds = new LinkedHashMap<String, COMMAND>();\n-        }\n-\n-        public String getName() { return name; }\n-\n-        public String getDescription() { return desc; }\n-\n-        public Map<String, COMMAND> getSubCommands() { return subCmds; }\n-\n-        public void addSubCommand(COMMAND c) {\n-            this.subCmds.put(c.name, c);\n-        };\n-\n-        public void printUsage() {\n-            System.err.println(name + \": \" + desc);\n-            for(String line : usage) {\n-                System.err.println(line);\n-            }\n-            System.err.println();\n-        }\n-\n-        protected String name;\n-        protected String desc;\n-        protected String[] usage;\n-        protected Map<String, COMMAND> subCmds;\n-    }\n-\n-    static Map<String, COMMAND> commands = null;\n-\n-    private static void addCommand(COMMAND c) {\n-        commands.put(c.getName(), c);\n-    }\n-\n-    static synchronized void init() {\n-        if (commands != null) {\n-            return;\n-        }\n-        commands = new LinkedHashMap<String, COMMAND>();\n-\n-        addCommand(COMMAND.CMD_PUB);\n-        addCommand(COMMAND.CMD_SUB);\n-        addCommand(COMMAND.CMD_CLOSESUB);\n-        addCommand(COMMAND.CMD_UNSUB);\n-        addCommand(COMMAND.CMD_RMSUB);\n-        addCommand(COMMAND.CMD_CONSUME);\n-        addCommand(COMMAND.CMD_CONSUMETO);\n-        addCommand(COMMAND.CMD_PUBSUB);\n-\n-        // show\n-        COMMAND.CMD_SHOW.addSubCommand(COMMAND.CMD_SHOW_TOPICS);\n-        COMMAND.CMD_SHOW.addSubCommand(COMMAND.CMD_SHOW_HUBS);\n-        addCommand(COMMAND.CMD_SHOW);\n-\n-        // describe\n-        COMMAND.CMD_DESCRIBE.addSubCommand(COMMAND.CMD_DESCRIBE_TOPIC);\n-        addCommand(COMMAND.CMD_DESCRIBE);\n-\n-        addCommand(COMMAND.CMD_READTOPIC);\n-        addCommand(COMMAND.CMD_FORMAT);\n-        addCommand(COMMAND.CMD_SET);\n-        addCommand(COMMAND.CMD_HISTORY);\n-        addCommand(COMMAND.CMD_REDO);\n-        addCommand(COMMAND.CMD_HELP);\n-        addCommand(COMMAND.CMD_QUIT);\n-        addCommand(COMMAND.CMD_EXIT);\n-    }\n-\n-    public static Map<String, COMMAND> getHedwigCommands() {\n-        return commands;\n-    }\n-\n-    /**\n-     * Find candidate commands by the specified token list\n-     *\n-     * @param token token list\n-     *\n-     * @return list of candidate commands\n-     */\n-    public static List<String> findCandidateCommands(String[] tokens) {\n-        List<String> cmds = new LinkedList<String>();\n-\n-        Map<String, COMMAND> cmdMap = commands;\n-        for (int i=0; i<(tokens.length - 1); i++) {\n-            COMMAND c = cmdMap.get(tokens[i]);\n-            // no commands\n-            if (c == null || c.getSubCommands().size() <= 0) {\n-                return cmds;\n-            } else {\n-                cmdMap = c.getSubCommands();\n-            }\n-        }\n-        cmds.addAll(cmdMap.keySet());\n-        return cmds;\n-    }\n-}"},{"sha":"3a5ef5a5bd4920eebb34e5fbbf8297519a3cdf82","filename":"hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigConsole.java","status":"removed","additions":0,"deletions":1038,"changes":1038,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigConsole.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigConsole.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/admin/console/HedwigConsole.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,1038 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.admin.console;\n-\n-import jline.ConsoleReader;\n-import jline.History;\n-import jline.Terminal;\n-\n-import java.io.BufferedReader;\n-import java.io.File;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n-import java.util.ArrayList;\n-import java.util.Arrays;\n-import java.util.HashMap;\n-import java.util.Iterator;\n-import java.util.LinkedHashMap;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.NoSuchElementException;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.apache.hedwig.admin.HedwigAdmin;\n-import org.apache.hedwig.client.api.MessageHandler;\n-import org.apache.hedwig.client.api.Publisher;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.client.conf.ClientConfiguration;\n-import org.apache.hedwig.client.HedwigClient;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRange;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest.CreateOrAttach;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionOptions;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.topics.HubInfo;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-import org.apache.hedwig.util.SubscriptionListener;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.protobuf.ByteString;\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-import static org.apache.hedwig.admin.console.HedwigCommands.*;\n-import static org.apache.hedwig.admin.console.HedwigCommands.COMMAND.*;\n-\n-/**\n- * Console Client to Hedwig\n- */\n-public class HedwigConsole {\n-    private static final Logger LOG = LoggerFactory.getLogger(HedwigConsole.class);\n-    // NOTE: now it is fixed passwd in bookkeeper\n-    static byte[] passwd = \"sillysecret\".getBytes(UTF_8);\n-\n-    // history file name\n-    static final String HW_HISTORY_FILE = \".hw_history\";\n-\n-    static final char[] CONTINUE_OR_QUIT = new char[] { 'Q', 'q', '\\n' };\n-\n-    protected MyCommandOptions cl = new MyCommandOptions();\n-    protected HashMap<Integer, String> history = new LinkedHashMap<Integer, String>();\n-    protected int commandCount = 0;\n-    protected boolean printWatches = true;\n-    protected Map<String, MyCommand> myCommands;\n-\n-    protected boolean inConsole = true;\n-    protected ConsoleReader console = null;\n-\n-    protected HedwigAdmin admin;\n-    protected HedwigClient hubClient;\n-    protected Publisher publisher;\n-    protected Subscriber subscriber;\n-    protected ConsoleMessageHandler consoleHandler =\n-            new ConsoleMessageHandler();\n-    protected Terminal terminal;\n-\n-    protected String myRegion;\n-\n-    interface MyCommand {\n-        boolean runCmd(String[] args) throws Exception;\n-    }\n-\n-    static class HelpCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            boolean printUsage = true;\n-            if (args.length >= 2) {\n-                String command = args[1];\n-                COMMAND c = getHedwigCommands().get(command);\n-                if (c != null) {\n-                    c.printUsage();\n-                    printUsage = false;\n-                }\n-            }\n-            if (printUsage) {\n-                usage();\n-            }\n-            return true;\n-        }\n-    }\n-\n-    class ExitCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            printMessage(\"Quitting ...\");\n-            hubClient.close();\n-            admin.close();\n-            Runtime.getRuntime().exit(0);\n-            return true;\n-        }\n-    }\n-\n-    class RedoCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 2) {\n-                return false;\n-            }\n-\n-            int index;\n-            if (\"!\".equals(args[1])) {\n-                index = commandCount - 1;\n-            } else {\n-                index = Integer.decode(args[1]);\n-                if (commandCount <= index) {\n-                    System.err.println(\"Command index out of range\");\n-                    return false;\n-                }\n-            }\n-            cl.parseCommand(history.get(index));\n-            if (cl.getCommand().equals(\"redo\")) {\n-                System.err.println(\"No redoing redos\");\n-                return false;\n-            }\n-            history.put(commandCount, history.get(index));\n-            processCmd(cl);\n-            return true;\n-        }\n-        \n-    }\n-\n-    class HistoryCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            for (int i=commandCount - 10; i<=commandCount; ++i) {\n-                if (i < 0) {\n-                    continue;\n-                }\n-                System.out.println(i + \" - \" + history.get(i));\n-            }\n-            return true;\n-        }\n-        \n-    }\n-\n-    class SetCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 3 || !\"printwatches\".equals(args[1])) {\n-                return false;\n-            } else if (args.length == 2) {\n-                System.out.println(\"printwatches is \" + (printWatches ? \"on\" : \"off\"));\n-            } else {\n-                printWatches = args[2].equals(\"on\");\n-            }\n-            return true;\n-        }\n-        \n-    }\n-\n-    class PubCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 3) {\n-                return false;\n-            }\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-\n-            StringBuilder sb = new StringBuilder();\n-            for (int i=2; i<args.length; i++) {\n-                sb.append(args[i]);\n-                if (i != args.length - 1) {\n-                    sb.append(' ');\n-                }\n-            }\n-            ByteString msgBody = ByteString.copyFromUtf8(sb.toString());\n-            Message msg = Message.newBuilder().setBody(msgBody).build();\n-            try {\n-                publisher.publish(topic, msg);\n-                System.out.println(\"PUB DONE\");\n-            } catch (Exception e) {\n-                System.err.println(\"PUB FAILED\");\n-                e.printStackTrace();\n-            }\n-            return true;\n-        }\n-        \n-    }\n-\n-    static class ConsoleMessageHandler implements MessageHandler {\n-\n-        @Override\n-        public void deliver(ByteString topic, ByteString subscriberId,\n-                Message msg, Callback<Void> callback, Object context) {\n-            System.out.println(\"Received message from topic \" + topic.toStringUtf8() + \n-                    \" for subscriber \" + subscriberId.toStringUtf8() + \" : \"\n-                    + msg.getBody().toStringUtf8());\n-            callback.operationFinished(context, null);\n-        }\n-        \n-    }\n-\n-    static class ConsoleSubscriptionListener implements SubscriptionListener {\n-\n-        @Override\n-        public void processEvent(ByteString t, ByteString s, SubscriptionEvent event) {\n-            System.out.println(\"Subscription Channel for (topic:\" + t.toStringUtf8() + \", subscriber:\"\n-                                + s.toStringUtf8() + \") received event : \" + event);\n-        }\n-    }\n-\n-    class SubCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            CreateOrAttach mode;\n-            boolean receive = true;\n-            if (args.length < 3) {\n-                return false;\n-            } else if (args.length == 3) {\n-                mode = CreateOrAttach.ATTACH;\n-                receive = true;\n-            } else {\n-                try {\n-                    mode = CreateOrAttach.valueOf(Integer.parseInt(args[3]));\n-                } catch (Exception e) {\n-                    System.err.println(\"Unknow mode : \" + args[3]);\n-                    return false;\n-                }\n-                if (args.length >= 5) {\n-                    try {\n-                        receive = Boolean.parseBoolean(args[4]);\n-                    } catch (Exception e) {\n-                        receive = false;\n-                    }\n-                }\n-            }\n-            if (mode == null) {\n-                System.err.println(\"Unknow mode : \" + args[3]);\n-                return false;\n-            }\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            ByteString subId = ByteString.copyFromUtf8(args[2]);\n-            try {\n-                SubscriptionOptions options =\n-                    SubscriptionOptions.newBuilder().setCreateOrAttach(mode)\n-                                       .setForceAttach(false).build();\n-                subscriber.subscribe(topic, subId, options);\n-                if (receive) {\n-                    subscriber.startDelivery(topic, subId, consoleHandler);\n-                    System.out.println(\"SUB DONE AND RECEIVE\");\n-                } else {\n-                    System.out.println(\"SUB DONE BUT NOT RECEIVE\");\n-                }\n-            } catch (Exception e) {\n-                System.err.println(\"SUB FAILED\");\n-                e.printStackTrace();\n-            }\n-            return true;\n-        }\n-    }\n-\n-    class UnsubCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 3) {\n-                return false;\n-            }\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            ByteString subId = ByteString.copyFromUtf8(args[2]);\n-            try {\n-                subscriber.stopDelivery(topic, subId);\n-                subscriber.unsubscribe(topic, subId);\n-                System.out.println(\"UNSUB DONE\");\n-            } catch (Exception e) {\n-                System.err.println(\"UNSUB FAILED\");\n-                e.printStackTrace();\n-            }\n-            return true;\n-        }\n-        \n-    }\n-\n-    class RmsubCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 7) {\n-                return false;\n-            }\n-            String topicPrefix = args[1];\n-            int startTopic = Integer.parseInt(args[2]);\n-            int endTopic = Integer.parseInt(args[3]);\n-            String subPrefix = args[4];\n-            int startSub = Integer.parseInt(args[5]);\n-            int endSub = Integer.parseInt(args[6]);\n-            if (startTopic > endTopic || endSub < startSub) {\n-                return false;\n-            }\n-            for (int i=startTopic; i<=endTopic; i++) {\n-                ByteString topic = ByteString.copyFromUtf8(topicPrefix + i);\n-                try {\n-                    for (int j=startSub; j<=endSub; j++) {\n-                        ByteString sub = ByteString.copyFromUtf8(subPrefix + j);\n-                        SubscriptionOptions opts = SubscriptionOptions.newBuilder()\n-                            .setCreateOrAttach(CreateOrAttach.CREATE_OR_ATTACH).build();\n-                        subscriber.subscribe(topic, sub, opts);\n-                        subscriber.unsubscribe(topic, sub);\n-                    }\n-                    System.out.println(\"RMSUB \" + topic.toStringUtf8() + \" DONE\");\n-                } catch (Exception e) {\n-                    System.err.println(\"RMSUB \" + topic.toStringUtf8() + \" FAILED\");\n-                    e.printStackTrace();\n-                }\n-            }\n-            return true;\n-        }\n-\n-    }\n-    \n-    class CloseSubscriptionCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 3) {\n-                return false;\n-            }\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            ByteString sudId = ByteString.copyFromUtf8(args[2]);\n-            \n-            try {\n-                subscriber.stopDelivery(topic, sudId);\n-                subscriber.closeSubscription(topic, sudId);\n-            } catch (Exception e) {\n-                System.err.println(\"CLOSESUB FAILED\");\n-            }\n-            return true;\n-        }\n-        \n-    }\n-    \n-    class ConsumeToCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 4) {\n-                return false;\n-            }\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            ByteString subId = ByteString.copyFromUtf8(args[2]);\n-            long msgId = Long.parseLong(args[3]);\n-            MessageSeqId consumeId = MessageSeqId.newBuilder().setLocalComponent(msgId).build();\n-            try {\n-                subscriber.consume(topic, subId, consumeId);\n-            } catch (Exception e) {\n-                System.err.println(\"CONSUMETO FAILED\");\n-            }\n-            return true;\n-        }\n-        \n-    }\n-    \n-    class ConsumeCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 4) {\n-                return false;\n-            }\n-            long lastConsumedId = 0;\n-            SubscriptionData subData = admin.getSubscription(ByteString.copyFromUtf8(args[1]),\n-                                                             ByteString.copyFromUtf8(args[2]));\n-            if (null == subData) {\n-                System.err.println(\"Failed to read subscription for topic: \" + args[1]\n-                                 + \" subscriber: \" + args[2]);\n-                return true;\n-            }\n-            lastConsumedId = subData.getState().getMsgId().getLocalComponent();\n-            long numMessagesToConsume = Long.parseLong(args[3]);\n-            long idToConsumed = lastConsumedId + numMessagesToConsume;\n-            System.out.println(\"Try to move subscriber(\" + args[2] + \") consume ptr of topic(\" + args[1]\n-                             + \") from \" + lastConsumedId + \" to \" + idToConsumed);\n-            MessageSeqId consumeId = MessageSeqId.newBuilder().setLocalComponent(idToConsumed).build();\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            ByteString subId = ByteString.copyFromUtf8(args[2]);\n-            try {\n-                subscriber.consume(topic, subId, consumeId);\n-            } catch (Exception e) {\n-                System.err.println(\"CONSUME FAILED\");\n-            }\n-            return true;\n-        }\n-        \n-    }\n-\n-    class PubSubCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 5) {\n-                return false;\n-            }\n-            final long startTime = MathUtils.now();\n-\n-            final ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            final ByteString subId = ByteString.copyFromUtf8(args[2] + \"-\" + startTime);\n-            int timeoutSecs = 60;\n-            try {\n-                timeoutSecs = Integer.parseInt(args[3]);\n-            } catch (NumberFormatException nfe) {\n-            }\n-\n-            StringBuilder sb = new StringBuilder();\n-            for (int i=4; i<args.length; i++) {\n-                sb.append(args[i]);\n-                if (i != args.length - 1) {\n-                    sb.append(' ');\n-                }\n-            }\n-            // append a timestamp tag\n-            ByteString msgBody = ByteString.copyFromUtf8(sb.toString() + \"-\" + startTime);\n-            final Message msg = Message.newBuilder().setBody(msgBody).build();\n-\n-            boolean subscribed = false;\n-            boolean success = false;\n-            final CountDownLatch isDone = new CountDownLatch(1);\n-            long elapsedTime = 0L;\n-\n-            System.out.println(\"Starting PUBSUB test ...\");\n-            try {\n-                // sub the topic\n-                SubscriptionOptions opts = SubscriptionOptions.newBuilder()\n-                    .setCreateOrAttach(CreateOrAttach.CREATE_OR_ATTACH).build();\n-                subscriber.subscribe(topic, subId, opts);\n-                subscribed = true;\n-\n-                System.out.println(\"Sub topic \" + topic.toStringUtf8() + \", subscriber id \" + subId.toStringUtf8());\n-\n-                \n-\n-                // pub topic\n-                publisher.publish(topic, msg);\n-                System.out.println(\"Pub topic \" + topic.toStringUtf8() + \" : \" + msg.getBody().toStringUtf8());\n-\n-                // ensure subscriber first, publish next, then we start delivery to receive message\n-                // if start delivery first before publish, isDone may notify before wait\n-                subscriber.startDelivery(topic, subId, new MessageHandler() {\n-\n-                    @Override\n-                    public void deliver(ByteString thisTopic, ByteString subscriberId,\n-                            Message message, Callback<Void> callback, Object context) {\n-                        if (thisTopic.equals(topic) && subscriberId.equals(subId) &&\n-                            msg.getBody().equals(message.getBody())) {\n-                            System.out.println(\"Received message : \" + message.getBody().toStringUtf8());\n-                            isDone.countDown();\n-                        }\n-                        callback.operationFinished(context, null);\n-                    }\n-\n-                });\n-\n-                // wait for the message\n-                success = isDone.await(timeoutSecs, TimeUnit.SECONDS);\n-                elapsedTime = MathUtils.now() - startTime;\n-            } finally {\n-                try {\n-                    if (subscribed) {\n-                        subscriber.stopDelivery(topic, subId);\n-                        subscriber.unsubscribe(topic, subId);\n-                    }\n-                } finally {\n-                    if (success) {\n-                        System.out.println(\"PUBSUB SUCCESS. TIME: \" + elapsedTime + \" MS\");\n-                    } else {\n-                        System.out.println(\"PUBSUB FAILED. \");\n-                    }\n-                    return success;\n-                }\n-            }\n-        }\n-\n-    }\n-    \n-    class ReadTopicCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 2) {\n-                return false;\n-            }\n-            ReadTopic rt;\n-            ByteString topic = ByteString.copyFromUtf8(args[1]);\n-            if (args.length == 2) {\n-                rt = new ReadTopic(admin, topic, inConsole);\n-            } else {\n-                rt = new ReadTopic(admin, topic, Long.parseLong(args[2]), inConsole);\n-            }\n-            rt.readTopic();\n-            return true;\n-        }\n-        \n-    }\n-\n-    class ShowCmd implements MyCommand {\n-\n-        static final int MAX_TOPICS_PER_SHOW = 100;\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 2) {\n-                return false;\n-            }\n-            String errorMsg = null;\n-            try {\n-                if (HedwigCommands.SHOW_HUBS.equals(args[1])) {\n-                    errorMsg = \"Unable to fetch the list of hub servers\";\n-                    showHubs();\n-                } else if (HedwigCommands.SHOW_TOPICS.equals(args[1])) {\n-                    errorMsg = \"Unable to fetch the list of topics\";\n-                    showTopics();\n-                } else {\n-                    System.err.println(\"ERROR: Unknown show command '\" + args[1] + \"'\");\n-                    return false;\n-                }\n-            } catch (Exception e) {\n-                if (null != errorMsg) {\n-                    System.err.println(errorMsg);\n-                }\n-                e.printStackTrace();\n-            }\n-            return true;\n-        }\n-\n-        protected void showHubs() throws Exception {\n-            Map<HedwigSocketAddress, HedwigAdmin.HubStats> hubs = admin.getAvailableHubs();\n-            System.out.println(\"Available Hub Servers:\");\n-            for (Map.Entry<HedwigSocketAddress, HedwigAdmin.HubStats> entry : hubs.entrySet()) {\n-                System.out.println(\"\\t\" + entry.getKey() + \" :\\t\" + entry.getValue());\n-            }\n-        }\n-\n-        protected void showTopics() throws Exception {\n-            List<String> topics = new ArrayList<String>();\n-            Iterator<ByteString> iter = admin.getTopics();\n-\n-            System.out.println(\"Topic List:\");\n-            boolean stop = false;\n-            while (iter.hasNext()) {\n-                if (topics.size() >= MAX_TOPICS_PER_SHOW) {\n-                    System.out.println(topics);\n-                    topics.clear();\n-                    stop = !continueOrQuit();\n-                    if (stop) {\n-                        break;\n-                    }\n-                }\n-                ByteString t = iter.next();\n-                topics.add(t.toStringUtf8());\n-            }\n-            if (!stop) {\n-                System.out.println(topics);\n-            }\n-        }\n-\n-        \n-        \n-    }\n-\n-    class DescribeCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            if (args.length < 3) {\n-                return false;\n-            }\n-            if (HedwigCommands.DESCRIBE_TOPIC.equals(args[1])) {\n-                return describeTopic(args[2]);\n-            } else {\n-                return false;\n-            }\n-        }\n-\n-        protected boolean describeTopic(String topic) throws Exception {\n-            ByteString btopic = ByteString.copyFromUtf8(topic);\n-            HubInfo owner = admin.getTopicOwner(btopic);\n-            List<LedgerRange> ranges = admin.getTopicLedgers(btopic);\n-            Map<ByteString, SubscriptionData> states = admin.getTopicSubscriptions(btopic);\n-\n-            System.out.println(\"===== Topic Information : \" + topic + \" =====\");\n-            System.out.println();\n-            System.out.println(\"Owner : \" + (owner == null ? \"NULL\" :\n-                               owner.toString().trim().replaceAll(\"\\n\", \", \")));\n-            System.out.println();\n-\n-            // print ledgers\n-            printTopicLedgers(ranges);\n-            // print subscriptions\n-            printTopicSubscriptions(states);\n-\n-            return true;\n-        }\n-\n-        private void printTopicLedgers(List<LedgerRange> ranges) {\n-            System.out.println(\">>> Persistence Info <<<\");\n-            if (null == ranges) {\n-                System.out.println(\"N/A\");\n-                return;\n-            }\n-            if (ranges.isEmpty()) {\n-                System.out.println(\"No Ledger used.\");\n-                return;\n-            }\n-            for (LedgerRange range : ranges) {\n-                System.out.println(\"Ledger \" + range.getLedgerId() + \" [ \"\n-                                   + range.getStartSeqIdIncluded() + \" ~ \"\n-                                   + range.getEndSeqIdIncluded().getLocalComponent() + \" ]\");\n-            }\n-            System.out.println();\n-        }\n-\n-        private void printTopicSubscriptions(Map<ByteString, SubscriptionData> states) {\n-            System.out.println(\">>> Subscription Info <<<\");\n-            if (0 == states.size()) {\n-                System.out.println(\"No subscriber.\");\n-                return;\n-            }\n-            for (Map.Entry<ByteString, SubscriptionData> entry : states.entrySet()) {\n-                System.out.println(\"Subscriber \" + entry.getKey().toStringUtf8() + \" : \"\n-                                 + SubscriptionStateUtils.toString(entry.getValue()));\n-            }\n-            System.out.println();\n-        }\n-\n-    }\n-\n-    class FormatCmd implements MyCommand {\n-\n-        @Override\n-        public boolean runCmd(String[] args) throws Exception {\n-            boolean force = false;\n-            if (args.length >= 2 && \"-force\".equals(args[1])) {\n-                force = true;\n-            }\n-            boolean doFormat = true;\n-            System.out.println(\"You ask to format hedwig metadata stored in \"\n-                               + admin.getMetadataManagerFactory().getClass().getName() + \".\");\n-            if (!force) {\n-                doFormat = continueOrQuit();\n-            }\n-            if (doFormat) {\n-                admin.format();\n-                System.out.println(\"Formatted hedwig metadata successfully.\");\n-            } else {\n-                System.out.println(\"Given up formatting hedwig metadata.\");\n-            }\n-            return true;\n-        }\n-\n-    }\n-\n-    protected Map<String, MyCommand> buildMyCommands() {\n-        Map<String, MyCommand> cmds =\n-                new HashMap<String, MyCommand>();\n-\n-        ExitCmd exitCmd = new ExitCmd();\n-        cmds.put(EXIT, exitCmd);\n-        cmds.put(QUIT, exitCmd);\n-        cmds.put(HELP, new HelpCmd());\n-        cmds.put(HISTORY, new HistoryCmd());\n-        cmds.put(REDO, new RedoCmd());\n-        cmds.put(SET, new SetCmd());\n-        cmds.put(PUB, new PubCmd());\n-        cmds.put(SUB, new SubCmd());\n-        cmds.put(PUBSUB, new PubSubCmd());\n-        cmds.put(CLOSESUB, new CloseSubscriptionCmd());\n-        cmds.put(UNSUB, new UnsubCmd());\n-        cmds.put(RMSUB, new RmsubCmd());\n-        cmds.put(CONSUME, new ConsumeCmd());\n-        cmds.put(CONSUMETO, new ConsumeToCmd());\n-        cmds.put(SHOW, new ShowCmd());\n-        cmds.put(DESCRIBE, new DescribeCmd());\n-        cmds.put(READTOPIC, new ReadTopicCmd());\n-        cmds.put(FORMAT, new FormatCmd());\n-\n-        return cmds;\n-    }\n-\n-    static void usage() {\n-        System.err.println(\"HedwigConsole [options] [command] [args]\");\n-        System.err.println();\n-        System.err.println(\"Avaiable commands:\");\n-        for (String cmd : getHedwigCommands().keySet()) {\n-            System.err.println(\"\\t\" + cmd);\n-        }\n-        System.err.println();\n-    }\n-\n-    /**\n-     * A storage class for both command line options and shell commands.\n-     */\n-    static private class MyCommandOptions {\n-\n-        private Map<String,String> options = new HashMap<String,String>();\n-        private List<String> cmdArgs = null;\n-        private String command = null;\n-\n-        public MyCommandOptions() {\n-        }\n-\n-        public String getOption(String opt) {\n-            return options.get(opt);\n-        }\n-\n-        public String getCommand( ) {\n-            return command;\n-        }\n-\n-        public String getCmdArgument( int index ) {\n-            return cmdArgs.get(index);\n-        }\n-\n-        public int getNumArguments( ) {\n-            return cmdArgs.size();\n-        }\n-\n-        public String[] getArgArray() {\n-            return cmdArgs.toArray(new String[0]);\n-        }\n-\n-        /**\n-         * Parses a command line that may contain one or more flags\n-         * before an optional command string\n-         * @param args command line arguments\n-         * @return true if parsing succeeded, false otherwise.\n-         */\n-        public boolean parseOptions(String[] args) {\n-            List<String> argList = Arrays.asList(args);\n-            Iterator<String> it = argList.iterator();\n-\n-            while (it.hasNext()) {\n-                String opt = it.next();\n-                if (!opt.startsWith(\"-\")) {\n-                    command = opt;\n-                    cmdArgs = new ArrayList<String>( );\n-                    cmdArgs.add( command );\n-                    while (it.hasNext()) {\n-                        cmdArgs.add(it.next());\n-                    }\n-                    return true;\n-                } else {\n-                    try {\n-                        options.put(opt.substring(1), it.next());\n-                    } catch (NoSuchElementException e) {\n-                        System.err.println(\"Error: no argument found for option \"\n-                                + opt);\n-                        return false;\n-                    }\n-                }\n-            }\n-            return true;\n-        }\n-\n-        /**\n-         * Breaks a string into command + arguments.\n-         * @param cmdstring string of form \"cmd arg1 arg2..etc\"\n-         * @return true if parsing succeeded.\n-         */\n-        public boolean parseCommand( String cmdstring ) {\n-            String[] args = cmdstring.split(\" \");\n-            if (args.length == 0){\n-                return false;\n-            }\n-            command = args[0];\n-            cmdArgs = Arrays.asList(args);\n-            return true;\n-        }\n-    }\n-\n-    private class MyWatcher implements Watcher {\n-        public void process(WatchedEvent event) {\n-            if (getPrintWatches()) {\n-                printMessage(\"WATCHER::\");\n-                printMessage(event.toString());\n-            }\n-        }\n-    }\n-\n-    public void printMessage(String msg) {\n-        if (inConsole) {\n-            System.out.println(\"\\n\"+msg);\n-        }\n-    }\n-\n-    /**\n-     * Hedwig Console\n-     *\n-     * @param args arguments\n-     * @throws IOException\n-     * @throws InterruptedException \n-     */\n-    public HedwigConsole(String[] args) throws IOException, InterruptedException {\n-        // Setup Terminal\n-        terminal = Terminal.setupTerminal();\n-        HedwigCommands.init();\n-        cl.parseOptions(args);\n-\n-        if (cl.getCommand() == null) {\n-            inConsole = true;\n-        } else {\n-            inConsole = false;\n-        }\n-\n-        org.apache.bookkeeper.conf.ClientConfiguration bkClientConf =\n-            new org.apache.bookkeeper.conf.ClientConfiguration();\n-        ServerConfiguration hubServerConf = new ServerConfiguration();\n-        String serverCfgFile = cl.getOption(\"server-cfg\");\n-        if (serverCfgFile != null) {\n-            try {\n-                hubServerConf.loadConf(new File(serverCfgFile).toURI().toURL());\n-            } catch (ConfigurationException e) {\n-                throw new IOException(e);\n-            }\n-            try {\n-                bkClientConf.loadConf(new File(serverCfgFile).toURI().toURL());\n-            } catch (ConfigurationException e) {\n-                throw new IOException(e);\n-            }\n-        }\n-\n-        ClientConfiguration hubClientCfg = new ClientConfiguration();\n-        String clientCfgFile = cl.getOption(\"client-cfg\");\n-        if (clientCfgFile != null) {\n-            try {\n-                hubClientCfg.loadConf(new File(clientCfgFile).toURI().toURL());\n-            } catch (ConfigurationException e) {\n-                throw new IOException(e);\n-            }\n-        }\n-\n-        printMessage(\"Connecting to zookeeper/bookkeeper using HedwigAdmin\");\n-        try {\n-            admin = new HedwigAdmin(bkClientConf, hubServerConf);\n-            admin.getZkHandle().register(new MyWatcher());\n-        } catch (Exception e) {\n-            throw new IOException(e);\n-        }\n-        \n-        printMessage(\"Connecting to default hub server \" + hubClientCfg.getDefaultServerHost());\n-        hubClient = new HedwigClient(hubClientCfg);\n-        publisher = hubClient.getPublisher();\n-        subscriber = hubClient.getSubscriber();\n-        subscriber.addSubscriptionListener(new ConsoleSubscriptionListener());\n-        \n-        // other parameters\n-        myRegion = hubServerConf.getMyRegion();\n-    }\n-\n-    public boolean getPrintWatches() {\n-        return printWatches;\n-    }\n-\n-    protected String getPrompt() {\n-        StringBuilder sb = new StringBuilder();\n-        sb.append(\"[hedwig: (\").append(myRegion).append(\") \").append(commandCount).append(\"] \");\n-        return sb.toString();\n-    }\n-\n-    protected boolean continueOrQuit() throws IOException {\n-        System.out.println(\"Press <Return> to continue, or Q to cancel ...\");\n-        int ch;\n-        if (null != console) {\n-            ch = console.readCharacter(CONTINUE_OR_QUIT);\n-        } else {\n-            do {\n-                ch = terminal.readCharacter(System.in);\n-            } while (ch != 'q' && ch != 'Q' && ch != '\\n');\n-        }\n-        if (ch == 'q' ||\n-            ch == 'Q') {\n-            return false;\n-        }\n-        return true;\n-    }\n-\n-    protected void addToHistory(int i, String cmd) {\n-        history.put(i, cmd);\n-    }\n-\n-    public void executeLine(String line) {\n-        if (!line.equals(\"\")) {\n-            cl.parseCommand(line);\n-            addToHistory(commandCount, line);\n-            processCmd(cl);\n-            commandCount++;\n-        }\n-    }\n-\n-    protected boolean processCmd(MyCommandOptions co) {\n-        String[] args = co.getArgArray();\n-        String cmd = co.getCommand();\n-        if (args.length < 1) {\n-            usage();\n-            return false;\n-        }\n-        if (!getHedwigCommands().containsKey(cmd)) {\n-            usage();\n-            return false;\n-        }\n-\n-        LOG.debug(\"Processing {}\", cmd);\n-\n-        MyCommand myCommand = myCommands.get(cmd);\n-        if (myCommand == null) {\n-            System.err.println(\"No Command Processor found for command \" + cmd);\n-            usage();\n-            return false;\n-        }\n-\n-        long startTime = MathUtils.now();\n-        boolean success = false;\n-        try {\n-            success = myCommand.runCmd(args);\n-        } catch (Exception e) {\n-            e.printStackTrace();\n-            success = false;\n-        }\n-        long elapsedTime = MathUtils.now() - startTime;\n-        if (inConsole) {\n-            if (success) {\n-                System.out.println(\"Finished \" + ((double)elapsedTime / 1000) + \" s.\");\n-            } else {\n-                COMMAND c = getHedwigCommands().get(cmd);\n-                if (c != null) {\n-                    c.printUsage();\n-                }\n-            }\n-        }\n-        return success;\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    void run() throws IOException {\n-        inConsole = true;\n-        myCommands = buildMyCommands();\n-        if (cl.getCommand() == null) {\n-            System.out.println(\"Welcome to Hedwig!\");\n-            System.out.println(\"JLine support is enabled\");\n-\n-            console = new ConsoleReader();\n-            JLineHedwigCompletor completor = new JLineHedwigCompletor(admin);\n-            console.addCompletor(completor);\n-\n-            // load history file\n-            History history = new History();\n-            File file = new File(System.getProperty(\"hw.history\",\n-                                 new File(System.getProperty(\"user.home\"), HW_HISTORY_FILE).toString()));\n-            if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"History file is \" + file.toString());\n-            }\n-            history.setHistoryFile(file);\n-            // set history to console reader\n-            console.setHistory(history);\n-            // load history from history file\n-            history.moveToFirstEntry();\n-\n-            while (history.next()) {\n-                String entry = history.current();\n-                if (!entry.equals(\"\")) {\n-                    addToHistory(commandCount, entry);\n-                }\n-                commandCount++;\n-            }\n-            System.out.println(\"JLine history support is enabled\");\n-\n-            String line;\n-            while ((line = console.readLine(getPrompt())) != null) {\n-                executeLine(line);\n-                history.addToHistory(line);\n-            }\n-        }\n-\n-        inConsole = false;\n-        processCmd(cl);\n-        try {\n-            myCommands.get(EXIT).runCmd(new String[0]);\n-        } catch (Exception e) {\n-        }\n-    }\n-\n-    public static void main(String[] args) throws IOException, InterruptedException {\n-        HedwigConsole console = new HedwigConsole(args);\n-        console.run();\n-    }\n-}"},{"sha":"cdc0c339a1917f6da3212bd40f2ead3161e8cce2","filename":"hedwig-server/src/main/java/org/apache/hedwig/admin/console/JLineHedwigCompletor.java","status":"removed","additions":0,"deletions":104,"changes":104,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/JLineHedwigCompletor.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/JLineHedwigCompletor.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/admin/console/JLineHedwigCompletor.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,104 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.admin.console;\n-\n-import java.util.Iterator;\n-import java.util.List;\n-\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.hedwig.admin.HedwigAdmin;\n-\n-import com.google.protobuf.ByteString;\n-\n-import jline.Completor;\n-\n-import static org.apache.hedwig.admin.console.HedwigCommands.*;\n-\n-/**\n- * A jline completor for hedwig console\n- */\n-public class JLineHedwigCompletor implements Completor {\n-    // for topic completion\n-    static final int MAX_TOPICS_TO_SEARCH = 1000;\n-\n-    private HedwigAdmin admin;\n-\n-    public JLineHedwigCompletor(HedwigAdmin admin) {\n-        this.admin = admin;\n-    }\n-\n-    @Override\n-    public int complete(String buffer, int cursor, List candidates) {\n-        // Guarantee that the final token is the one we're expanding\n-        buffer = buffer.substring(0,cursor);\n-        String[] tokens = buffer.split(\" \");\n-        if (buffer.endsWith(\" \")) {\n-            String[] newTokens = new String[tokens.length + 1];\n-            System.arraycopy(tokens, 0, newTokens, 0, tokens.length);\n-            newTokens[newTokens.length - 1] = \"\";\n-            tokens = newTokens;\n-        }\n-        \n-        if (tokens.length > 2 &&\n-            DESCRIBE.equalsIgnoreCase(tokens[0]) &&\n-            DESCRIBE_TOPIC.equalsIgnoreCase(tokens[1])) {\n-            return completeTopic(buffer, tokens[2], candidates);\n-        } else if (tokens.length > 1 &&\n-                   (SUB.equalsIgnoreCase(tokens[0]) ||\n-                    PUB.equalsIgnoreCase(tokens[0]) ||\n-                    CLOSESUB.equalsIgnoreCase(tokens[0]) ||\n-                    CONSUME.equalsIgnoreCase(tokens[0]) ||\n-                    CONSUMETO.equalsIgnoreCase(tokens[0]) ||\n-                    READTOPIC.equalsIgnoreCase(tokens[0]))) {\n-            return completeTopic(buffer, tokens[1], candidates);\n-        }\n-        List cmds = HedwigCommands.findCandidateCommands(tokens);\n-        return completeCommand(buffer, tokens[tokens.length - 1], cmds, candidates);\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    private int completeCommand(String buffer, String token,\n-            List commands, List candidates) {\n-        for (Object cmdo : commands) {\n-            assert (cmdo instanceof String);\n-            if (((String)cmdo).startsWith(token)) {\n-                candidates.add(cmdo);\n-            }\n-        }\n-        return buffer.lastIndexOf(\" \") + 1;\n-    }\n-\n-    @SuppressWarnings(\"unchecked\")\n-    private int completeTopic(String buffer, String token, List candidates) {\n-        try {\n-            Iterator<ByteString> children = admin.getTopics();\n-            int i = 0;\n-            while (children.hasNext() && i <= MAX_TOPICS_TO_SEARCH) {\n-                String child = children.next().toStringUtf8();\n-                if (child.startsWith(token)) {\n-                    candidates.add(child);\n-                }\n-                ++i;\n-            }\n-        } catch (Exception e) {\n-            return buffer.length();\n-        }\n-        return candidates.size() == 0 ? buffer.length() : buffer.lastIndexOf(\" \") + 1;\n-    }\n-}"},{"sha":"edad190bd2860efa94e89f0b740255d28d9ec191","filename":"hedwig-server/src/main/java/org/apache/hedwig/admin/console/ReadTopic.java","status":"removed","additions":0,"deletions":332,"changes":332,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/ReadTopic.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/admin/console/ReadTopic.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/admin/console/ReadTopic.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,332 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.admin.console;\n-\n-import java.io.BufferedReader;\n-import java.io.IOException;\n-import java.io.InputStreamReader;\n-import java.util.ArrayList;\n-import java.util.Enumeration;\n-import java.util.Iterator;\n-import java.util.List;\n-import java.util.Map;\n-\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.BookKeeper.DigestType;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.hedwig.admin.HedwigAdmin;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRange;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.RegionSpecificSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.data.Stat;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-import com.google.protobuf.ByteString;\n-import com.google.protobuf.InvalidProtocolBufferException;\n-\n-/**\n- * A tool to read topic messages.\n- *\n- * This tool :\n- * 1) read persistence info from zookeeper: ledger ranges\n- * 2) read subscription infor from zookeeper: we can know the least message id (ledger id) \n- * 3) use bk client to read message starting from least message id\n- */\n-public class ReadTopic {\n-    \n-    final HedwigAdmin admin;\n-    final ByteString topic;\n-    long startSeqId;\n-    long leastConsumedSeqId = Long.MAX_VALUE;\n-    final boolean inConsole;\n-\n-    static final int RC_OK = 0;\n-    static final int RC_ERROR = -1;\n-    static final int RC_NOTOPIC = -2;\n-    static final int RC_NOLEDGERS = -3;\n-    static final int RC_NOSUBSCRIBERS = -4;\n-    \n-    static final int NUM_MESSAGES_TO_PRINT = 15;\n-\n-    List<LedgerRange> ledgers = new ArrayList<LedgerRange>();\n-    \n-    /**\n-     * Constructor\n-     */\n-    public ReadTopic(HedwigAdmin admin, ByteString topic, boolean inConsole) {\n-        this(admin, topic, 1, inConsole);\n-    }\n-\n-    /**\n-     * Constructor\n-     */\n-    public ReadTopic(HedwigAdmin admin, ByteString topic, long msgSeqId, boolean inConsole) {\n-        this.admin = admin;\n-        this.topic = topic;\n-        this.startSeqId = msgSeqId;\n-        this.inConsole = inConsole;\n-    }\n-    \n-    /**\n-     * Check whether the topic existed or not\n-     *\n-     * @return RC_OK if topic is existed; RC_NOTOPIC if not.\n-     * @throws Exception\n-     */\n-    protected int checkTopic() throws Exception {\n-        return admin.hasTopic(topic) ? RC_OK : RC_NOTOPIC;\n-    }\n-    \n-    /**\n-     * Get the ledgers used by this topic to store messages\n-     *\n-     * @return RC_OK if topic has messages; RC_NOLEDGERS if not.\n-     * @throws Exception\n-     */\n-    protected int getTopicLedgers() throws Exception {\n-        List<LedgerRange> ranges = admin.getTopicLedgers(topic); \n-        if (null == ranges || ranges.isEmpty()) {\n-            return RC_NOLEDGERS;\n-        }\n-        ledgers.addAll(ranges);\n-        return RC_OK;\n-    }\n-    \n-    protected int getLeastSubscription() throws Exception {\n-        Map<ByteString, SubscriptionData> states = admin.getTopicSubscriptions(topic); \n-        if (states.isEmpty()) {\n-            return RC_NOSUBSCRIBERS;\n-        }\n-        for (Map.Entry<ByteString, SubscriptionData> entry : states.entrySet()) {\n-            SubscriptionData state = entry.getValue();\n-            long localMsgId = state.getState().getMsgId().getLocalComponent();\n-            if (localMsgId < leastConsumedSeqId) {\n-                leastConsumedSeqId = localMsgId;\n-            }\n-        }\n-        if (leastConsumedSeqId == Long.MAX_VALUE) {\n-            leastConsumedSeqId = 0;\n-        }\n-        return RC_OK;\n-    }\n-    \n-    public void readTopic() {\n-        try {\n-            int rc = _readTopic();\n-            switch (rc) {\n-            case RC_NOTOPIC:\n-                System.err.println(\"No topic \" + topic + \" found.\");\n-                break;\n-            case RC_NOLEDGERS:\n-                System.err.println(\"No message is published to topic \" + topic);\n-                break;\n-            default:\n-                break;\n-            }\n-        } catch (Exception e) {\n-            System.err.println(\"ERROR: read messages of topic \" + topic + \" failed.\");\n-            e.printStackTrace();\n-        }\n-    }\n-    \n-    protected int _readTopic() throws Exception {\n-        int rc;\n-        // check topic\n-        rc = checkTopic();\n-        if (RC_OK != rc) {\n-            return rc;\n-        }\n-        // get topic ledgers\n-        rc = getTopicLedgers();\n-        if (RC_OK != rc) {\n-            return rc;\n-        }\n-        // get topic subscription to find the least one\n-        rc = getLeastSubscription();\n-        if (RC_NOSUBSCRIBERS == rc) {\n-            startSeqId = 1;\n-        } else if (RC_OK == rc) {\n-            if (leastConsumedSeqId > startSeqId) {\n-                startSeqId = leastConsumedSeqId + 1;\n-            }\n-        } else {\n-            return rc;\n-        }\n-\n-        for (LedgerRange range : ledgers) {\n-            long endSeqId = range.getEndSeqIdIncluded().getLocalComponent();\n-            if (endSeqId < startSeqId) {\n-                continue;\n-            }\n-            boolean toContinue = readLedger(range);\n-            startSeqId = endSeqId + 1;\n-            if (!toContinue) {\n-                break;\n-            }\n-        }\n-        \n-        return RC_OK;\n-    }\n-    \n-    /**\n-     * Read a specific ledger\n-     *\n-     * @param ledger in memory ledger range\n-     * @param endSeqId end seq id\n-     * @return true if continue, otherwise false\n-     * @throws BKException\n-     * @throws IOException\n-     * @throws InterruptedException\n-     */\n-    protected boolean readLedger(LedgerRange ledger)\n-    throws BKException, IOException, InterruptedException {\n-        long tEndSeqId = ledger.getEndSeqIdIncluded().getLocalComponent();\n-\n-        if (tEndSeqId < this.startSeqId) {\n-            return true;\n-        }\n-        // Open Ledger Handle\n-        long ledgerId = ledger.getLedgerId();\n-        System.out.println(\"\\n>>>>> \" + ledger + \" <<<<<\\n\");\n-        LedgerHandle lh = null;\n-        try {\n-            lh = admin.getBkHandle().openLedgerNoRecovery(ledgerId, admin.getBkDigestType(), admin.getBkPasswd());\n-        } catch (BKException e) {\n-            System.err.println(\"ERROR: No ledger \" + ledgerId + \" found. maybe garbage collected due to the messages are consumed.\");\n-        }\n-        if (null == lh) {\n-            return true;\n-        }\n-        long expectedEntryId = startSeqId - ledger.getStartSeqIdIncluded();\n-        \n-        long correctedEndSeqId = tEndSeqId;\n-        try {\n-            while (startSeqId <= tEndSeqId) {\n-                correctedEndSeqId = Math.min(startSeqId + NUM_MESSAGES_TO_PRINT - 1, tEndSeqId);\n-                \n-                try {\n-                    Enumeration<LedgerEntry> seq =\n-                        lh.readEntries(startSeqId - ledger.getStartSeqIdIncluded(),\n-                                       correctedEndSeqId - ledger.getStartSeqIdIncluded());\n-                    LedgerEntry entry = null;\n-                    while (seq.hasMoreElements()) {\n-                        entry = seq.nextElement();\n-                        Message message;\n-                        try {\n-                            message = Message.parseFrom(entry.getEntryInputStream());\n-                        } catch (IOException e) {\n-                            System.out.println(\"WARN: Unreadable message found\\n\");\n-                            expectedEntryId++;\n-                            continue;\n-                        }\n-                        if (expectedEntryId != entry.getEntryId()\n-                            || (message.getMsgId().getLocalComponent() - ledger.getStartSeqIdIncluded()) != expectedEntryId) {\n-                            throw new IOException(\"ERROR: Message ids are out of order : expected entry id \" + expectedEntryId\n-                                                + \", current entry id \" + entry.getEntryId() + \", msg seq id \" + message.getMsgId().getLocalComponent());\n-                        }\n-                        expectedEntryId++;\n-                        formatMessage(message);\n-\n-                    }\n-                    startSeqId = correctedEndSeqId + 1;\n-                    if (inConsole) {\n-                        if (!pressKeyToContinue()) {\n-                            return false;\n-                        }\n-                    }\n-                } catch (BKException.BKReadException be) {\n-                    throw be;\n-                }\n-            }\n-        } catch (BKException bke) {\n-            if (tEndSeqId != Long.MAX_VALUE) {\n-                System.err.println(\"ERROR: ledger \" + ledgerId + \" may be corrupted, since read messages [\"\n-                                 + startSeqId + \" ~ \" + correctedEndSeqId + \" ] failed :\");\n-                throw bke;\n-            }\n-        }\n-        System.out.println(\"\\n\");\n-        return true;\n-    }\n-    \n-    protected void formatMessage(Message message) {\n-        // print msg id\n-        String msgId;\n-        if (!message.hasMsgId()) {\n-            msgId = \"N/A\";\n-        } else {\n-            MessageSeqId seqId = message.getMsgId();\n-            StringBuilder idBuilder = new StringBuilder();\n-            if (seqId.hasLocalComponent()) {\n-                idBuilder.append(\"LOCAL(\").append(seqId.getLocalComponent()).append(\")\");\n-            } else {\n-                List<RegionSpecificSeqId> remoteIds = seqId.getRemoteComponentsList();\n-                int i = 0, numRegions = remoteIds.size();\n-                idBuilder.append(\"REMOTE(\");\n-                for (RegionSpecificSeqId rssid : remoteIds) {\n-                    idBuilder.append(rssid.getRegion().toStringUtf8());\n-                    idBuilder.append(\"[\");\n-                    idBuilder.append(rssid.getSeqId());\n-                    idBuilder.append(\"]\");\n-                    ++i;\n-                    if (i < numRegions) {\n-                        idBuilder.append(\",\");\n-                    }\n-                }\n-                idBuilder.append(\")\");\n-            }\n-            msgId = idBuilder.toString();\n-        }\n-        System.out.println(\"---------- MSGID=\" + msgId + \" ----------\");\n-        System.out.println(\"MsgId:     \" + msgId);\n-        // print source region\n-        if (message.hasSrcRegion()) {\n-            System.out.println(\"SrcRegion: \" + message.getSrcRegion().toStringUtf8());\n-        } else {\n-            System.out.println(\"SrcRegion: N/A\");\n-        }\n-        // print message body\n-        System.out.println(\"Message:\");\n-        System.out.println();\n-        if (message.hasBody()) {\n-            System.out.println(message.getBody().toStringUtf8());\n-        } else {\n-            System.out.println(\"N/A\");\n-        }\n-        System.out.println();\n-    }\n-    \n-    boolean pressKeyToContinue() throws IOException {\n-        System.out.println(\"Press Y to continue...\");\n-        BufferedReader stdin = new BufferedReader(new InputStreamReader(System.in, UTF_8));\n-        int ch = stdin.read();\n-        if (ch == 'y' ||\n-            ch == 'Y') {\n-            return true;\n-        }\n-        return false;\n-    }\n-}"},{"sha":"6ac6879fdc9efe0917da6cbee9cd2850d267222c","filename":"hedwig-server/src/main/java/org/apache/hedwig/data/MessageFormatter.java","status":"removed","additions":0,"deletions":123,"changes":123,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/data/MessageFormatter.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/data/MessageFormatter.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/data/MessageFormatter.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,123 +0,0 @@\n-/*\n- *\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- *\n- */\n-\n-package org.apache.hedwig.data;\n-\n-import java.io.IOException;\n-import java.util.List;\n-\n-import org.apache.bookkeeper.util.EntryFormatter;\n-import org.apache.commons.configuration.Configuration;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.RegionSpecificSeqId;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * Format a pub sub message into a readable format.\n- */\n-public class MessageFormatter extends EntryFormatter {\n-    private static final Logger logger = LoggerFactory.getLogger(MessageFormatter.class);\n-\n-    static final String MESSAGE_PAYLOAD_FORMATTER_CLASS = \"message_payload_formatter_class\";\n-\n-    EntryFormatter dataFormatter = EntryFormatter.STRING_FORMATTER;\n-\n-    @Override\n-    public void setConf(Configuration conf) {\n-        super.setConf(conf);\n-        dataFormatter = EntryFormatter.newEntryFormatter(conf, MESSAGE_PAYLOAD_FORMATTER_CLASS);\n-    }\n-\n-    @Override\n-    public void formatEntry(java.io.InputStream input) {\n-        Message message;\n-        try {\n-            message = Message.parseFrom(input);\n-        } catch (IOException e) {\n-            System.out.println(\"WARN: Unreadable message found\\n\");\n-            EntryFormatter.STRING_FORMATTER.formatEntry(input);\n-            return;\n-        }\n-        formatMessage(message);\n-    }\n-\n-    @Override\n-    public void formatEntry(byte[] data) {\n-        Message message;\n-        try {\n-            message = Message.parseFrom(data);\n-        } catch (IOException e) {\n-            System.out.println(\"WARN: Unreadable message found\\n\");\n-            EntryFormatter.STRING_FORMATTER.formatEntry(data);\n-            return;\n-        }\n-        formatMessage(message);\n-    }\n-\n-    void formatMessage(Message message) {\n-        // print msg id\n-        String msgId;\n-        if (!message.hasMsgId()) {\n-            msgId = \"N/A\";\n-        } else {\n-            MessageSeqId seqId = message.getMsgId();\n-            StringBuilder idBuilder = new StringBuilder();\n-            if (seqId.hasLocalComponent()) {\n-                idBuilder.append(\"LOCAL(\").append(seqId.getLocalComponent()).append(\")\");\n-            } else {\n-                List<RegionSpecificSeqId> remoteIds = seqId.getRemoteComponentsList();\n-                int i = 0, numRegions = remoteIds.size();\n-                idBuilder.append(\"REMOTE(\");\n-                for (RegionSpecificSeqId rssid : remoteIds) {\n-                    idBuilder.append(rssid.getRegion().toStringUtf8());\n-                    idBuilder.append(\"[\");\n-                    idBuilder.append(rssid.getSeqId());\n-                    idBuilder.append(\"]\");\n-                    ++i;\n-                    if (i < numRegions) {\n-                        idBuilder.append(\",\");\n-                    }\n-                }\n-                idBuilder.append(\")\");\n-            }\n-            msgId = idBuilder.toString();\n-        }\n-        System.out.println(\"****** MSGID=\" + msgId + \" ******\");\n-        System.out.println(\"MessageId:      \" + msgId);\n-        // print source region\n-        if (message.hasSrcRegion()) {\n-            System.out.println(\"SrcRegion:      \" + message.getSrcRegion().toStringUtf8());\n-        } else {\n-            System.out.println(\"SrcRegion:      N/A\");\n-        }\n-        // print message body\n-        if (message.hasBody()) {\n-            System.out.println(\"Body:\");\n-            dataFormatter.formatEntry(message.getBody().toByteArray());\n-        } else {\n-            System.out.println(\"Body:           N/A\");\n-        }\n-        System.out.println();\n-    }\n-}"},{"sha":"21687eb6924d232a8f998b94089a0ec5c1a8d681","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/AbstractBenchmark.java","status":"removed","additions":0,"deletions":106,"changes":106,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/AbstractBenchmark.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/AbstractBenchmark.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/AbstractBenchmark.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,106 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.benchmark;\n-\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.Semaphore;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicLong;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.hedwig.util.ConcurrencyUtils;\n-\n-public abstract class AbstractBenchmark {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(AbstractBenchmark.class);\n-\n-    AtomicLong totalLatency = new AtomicLong();\n-    LinkedBlockingQueue<Boolean> doneSignalQueue = new LinkedBlockingQueue<Boolean>();\n-\n-    abstract void doOps(int numOps) throws Exception;\n-    abstract void tearDown() throws Exception;\n-\n-    protected class AbstractCallback {\n-        AtomicInteger numDone = new AtomicInteger(0);\n-        Semaphore outstanding;\n-        int numOps;\n-        boolean logging;\n-\n-        public AbstractCallback(Semaphore outstanding, int numOps) {\n-            this.outstanding = outstanding;\n-            this.numOps = numOps;\n-            logging = Boolean.getBoolean(\"progress\");\n-        }\n-\n-        public void handle(boolean success, Object ctx) {\n-            outstanding.release();\n-\n-            if (!success) {\n-                ConcurrencyUtils.put(doneSignalQueue, false);\n-                return;\n-            }\n-\n-            totalLatency.addAndGet(MathUtils.now() - (Long)ctx);\n-            int numDoneInt = numDone.incrementAndGet();\n-\n-            if (logging && numDoneInt % 10000 == 0) {\n-                logger.info(\"Finished \" + numDoneInt + \" ops\");\n-            }\n-\n-            if (numOps == numDoneInt) {\n-                ConcurrencyUtils.put(doneSignalQueue, true);\n-            }\n-        }\n-    }\n-\n-    public void runPhase(String phase, int numOps) throws Exception {\n-        long startTime = MathUtils.now();\n-\n-        doOps(numOps);\n-\n-        if (!doneSignalQueue.take()) {\n-            logger.error(\"One or more operations failed in phase: \" + phase);\n-            throw new RuntimeException();\n-        } else {\n-            logger.info(\"Phase: \" + phase + \" Avg latency : \" + totalLatency.get() / numOps + \", tput = \" + (numOps * 1000/ (MathUtils.now() - startTime)));\n-        }\n-    }\n-\n-\n-\n-\n-\n-    public void run() throws Exception {\n-\n-        int numWarmup = Integer.getInteger(\"nWarmup\", 50000);\n-        runPhase(\"warmup\", numWarmup);\n-\n-        logger.info(\"Sleeping for 10 seconds\");\n-        Thread.sleep(10000);\n-        //reset latency\n-        totalLatency.set(0);\n-\n-        int numOps = Integer.getInteger(\"nOps\", 400000);\n-        runPhase(\"real\", numOps);\n-\n-        tearDown();\n-    }\n-}"},{"sha":"d58883d9ef849c7715280718e312a62ae1acab49","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookieBenchmark.java","status":"removed","additions":0,"deletions":107,"changes":107,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookieBenchmark.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookieBenchmark.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookieBenchmark.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,107 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.benchmark;\n-\n-import java.nio.ByteBuffer;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.Semaphore;\n-import org.apache.bookkeeper.conf.ClientConfiguration;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.net.BookieSocketAddress;\n-import org.apache.bookkeeper.proto.BookieClient;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks.WriteCallback;\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.bookkeeper.util.OrderedSafeExecutor;\n-import org.jboss.netty.buffer.ChannelBuffer;\n-import org.jboss.netty.buffer.ChannelBuffers;\n-import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n-import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory;\n-\n-public class BookieBenchmark extends AbstractBenchmark {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(BookkeeperBenchmark.class);\n-\n-    BookieClient bkc;\n-    BookieSocketAddress addr;\n-    ClientSocketChannelFactory channelFactory;\n-    OrderedSafeExecutor executor = OrderedSafeExecutor.newBuilder()\n-            .name(\"BookieBenchmarkScheduler\")\n-            .numThreads(1)\n-            .build();\n-\n-    public BookieBenchmark(String bookieHostPort)  throws Exception {\n-        channelFactory = new NioClientSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool());\n-        bkc = new BookieClient(new ClientConfiguration(), channelFactory, executor);\n-        String[] hostPort = bookieHostPort.split(\":\");\n-        addr = new BookieSocketAddress(hostPort[0], Integer.parseInt(hostPort[1]));\n-    }\n-\n-\n-    @Override\n-    void doOps(final int numOps) throws Exception {\n-        int numOutstanding = Integer.getInteger(\"nPars\",1000);\n-        final Semaphore outstanding = new Semaphore(numOutstanding);\n-\n-\n-        WriteCallback callback = new WriteCallback() {\n-            AbstractCallback handler = new AbstractCallback(outstanding, numOps);\n-\n-            @Override\n-            public void writeComplete(int rc, long ledgerId, long entryId,\n-            BookieSocketAddress addr, Object ctx) {\n-                handler.handle(rc == BKException.Code.OK, ctx);\n-            }\n-        };\n-\n-        byte[] passwd = new byte[20];\n-        int size = Integer.getInteger(\"size\", 1024);\n-        byte[] data = new byte[size];\n-\n-        for (int i=0; i<numOps; i++) {\n-            outstanding.acquire();\n-\n-            ByteBuffer buffer = ByteBuffer.allocate(44);\n-            long ledgerId = 1000;\n-            buffer.putLong(ledgerId);\n-            buffer.putLong(i);\n-            buffer.putLong(0);\n-            buffer.put(passwd);\n-            buffer.rewind();\n-            ChannelBuffer toSend = ChannelBuffers.wrappedBuffer(ChannelBuffers.wrappedBuffer(buffer.slice()), ChannelBuffers.wrappedBuffer(data));\n-            bkc.addEntry(addr, ledgerId, passwd, i, toSend, callback, MathUtils.now(), 0);\n-        }\n-\n-    }\n-\n-    @Override\n-    public void tearDown() {\n-        bkc.close();\n-        channelFactory.releaseExternalResources();\n-        executor.shutdown();\n-    }\n-\n-\n-    public static void main(String[] args) throws Exception {\n-        BookieBenchmark benchmark = new BookieBenchmark(args[0]);\n-        benchmark.run();\n-    }\n-\n-\n-}"},{"sha":"1b6a4a3239dcfdcc1979add1d4ef4e9e0e5c9ae3","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookkeeperBenchmark.java","status":"removed","additions":0,"deletions":94,"changes":94,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookkeeperBenchmark.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookkeeperBenchmark.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/BookkeeperBenchmark.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,94 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.benchmark;\n-\n-import java.util.Random;\n-import java.util.concurrent.Semaphore;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.client.AsyncCallback.AddCallback;\n-import org.apache.bookkeeper.client.BookKeeper.DigestType;\n-import org.apache.bookkeeper.util.MathUtils;\n-import static com.google.common.base.Charsets.UTF_8;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class BookkeeperBenchmark extends AbstractBenchmark {\n-\n-    static final Logger logger = LoggerFactory.getLogger(BookkeeperBenchmark.class);\n-\n-    BookKeeper bk;\n-    LedgerHandle[] lh;\n-\n-    public BookkeeperBenchmark(String zkHostPort) throws Exception {\n-        bk = new BookKeeper(zkHostPort);\n-        int numLedgers = Integer.getInteger(\"nLedgers\",5);\n-        lh = new LedgerHandle[numLedgers];\n-        int quorumSize = Integer.getInteger(\"quorum\", 2);\n-        int ensembleSize = Integer.getInteger(\"ensemble\", 4);\n-        DigestType digestType = DigestType.valueOf(System.getProperty(\"digestType\", \"CRC32\"));\n-        for (int i=0; i< numLedgers; i++) {\n-            lh[i] = bk.createLedger(ensembleSize, quorumSize, digestType, \"blah\".getBytes(UTF_8));\n-        }\n-\n-    }\n-\n-\n-    @Override\n-    void doOps(final int numOps) throws Exception {\n-        int size = Integer.getInteger(\"size\", 1024);\n-        byte[] msg = new byte[size];\n-\n-        int numOutstanding = Integer.getInteger(\"nPars\",1000);\n-        final Semaphore outstanding = new Semaphore(numOutstanding);\n-\n-        AddCallback callback = new AddCallback() {\n-            AbstractCallback handler = new AbstractCallback(outstanding, numOps);\n-\n-\n-            @Override\n-            public void addComplete(int rc, LedgerHandle lh, long entryId, Object ctx) {\n-                handler.handle(rc == BKException.Code.OK, ctx);\n-            }\n-\n-        };\n-\n-\n-\n-        Random rand = new Random();\n-\n-        for (int i=0; i<numOps; i++) {\n-            outstanding.acquire();\n-            lh[rand.nextInt(lh.length)].asyncAddEntry(msg, callback, MathUtils.now());\n-        }\n-\n-\n-    }\n-\n-    @Override\n-    public void tearDown() throws Exception {\n-        bk.close();\n-    }\n-\n-\n-    public static void main(String[] args) throws Exception {\n-        BookkeeperBenchmark benchmark = new BookkeeperBenchmark(args[0]);\n-        benchmark.run();\n-    }\n-}"},{"sha":"ba818340b082d2055ef6bb4c298ddf6af20c2a4e","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/FakeBookie.java","status":"removed","additions":0,"deletions":101,"changes":101,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/FakeBookie.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/FakeBookie.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/benchmark/FakeBookie.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,101 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.benchmark;\n-\n-import java.net.InetSocketAddress;\n-import java.util.concurrent.Executors;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.bootstrap.ServerBootstrap;\n-import org.jboss.netty.buffer.ChannelBuffer;\n-import org.jboss.netty.channel.ChannelHandlerContext;\n-import org.jboss.netty.channel.ChannelPipeline;\n-import org.jboss.netty.channel.ChannelHandler.Sharable;\n-import org.jboss.netty.channel.ChannelPipelineFactory;\n-import org.jboss.netty.channel.Channels;\n-import org.jboss.netty.channel.MessageEvent;\n-import org.jboss.netty.channel.SimpleChannelHandler;\n-import org.jboss.netty.channel.socket.ServerSocketChannelFactory;\n-import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory;\n-import org.jboss.netty.handler.codec.frame.LengthFieldBasedFrameDecoder;\n-import org.jboss.netty.handler.codec.frame.LengthFieldPrepender;\n-import org.jboss.netty.logging.InternalLoggerFactory;\n-import org.jboss.netty.logging.Log4JLoggerFactory;\n-\n-@Sharable\n-public class FakeBookie extends SimpleChannelHandler implements\n-    ChannelPipelineFactory {\n-    private static final Logger logger = LoggerFactory.getLogger(FakeBookie.class);\n-    ServerSocketChannelFactory serverChannelFactory = new NioServerSocketChannelFactory(\n-        Executors.newCachedThreadPool(), Executors.newCachedThreadPool());\n-\n-    public FakeBookie(int port) {\n-        InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory());\n-        ServerBootstrap bootstrap = new ServerBootstrap(serverChannelFactory);\n-\n-        bootstrap.setPipelineFactory(this);\n-        bootstrap.setOption(\"child.tcpNoDelay\", true);\n-        bootstrap.setOption(\"child.keepAlive\", true);\n-        bootstrap.setOption(\"reuseAddress\", true);\n-\n-        logger.info(\"Going into receive loop\");\n-        // Bind and start to accept incoming connections.\n-        bootstrap.bind(new InetSocketAddress(port));\n-    }\n-\n-    @Override\n-    public ChannelPipeline getPipeline() throws Exception {\n-        ChannelPipeline pipeline = Channels.pipeline();\n-        pipeline.addLast(\"lengthbaseddecoder\",\n-                         new LengthFieldBasedFrameDecoder(1024 * 1024, 0, 4, 0, 4));\n-        pipeline.addLast(\"lengthprepender\", new LengthFieldPrepender(4));\n-        pipeline.addLast(\"main\", this);\n-        return pipeline;\n-    }\n-\n-    @Override\n-    public void messageReceived(ChannelHandlerContext ctx, MessageEvent e)\n-            throws Exception {\n-        if (!(e.getMessage() instanceof ChannelBuffer)) {\n-            ctx.sendUpstream(e);\n-            return;\n-        }\n-\n-        ChannelBuffer buffer = (ChannelBuffer) e.getMessage();\n-\n-        int type = buffer.readInt();\n-        buffer.readerIndex(24);\n-        long ledgerId = buffer.readLong();\n-        long entryId = buffer.readLong();\n-\n-        ChannelBuffer outBuf = ctx.getChannel().getConfig().getBufferFactory()\n-                               .getBuffer(24);\n-        outBuf.writeInt(type);\n-        outBuf.writeInt(0); // rc\n-        outBuf.writeLong(ledgerId);\n-        outBuf.writeLong(entryId);\n-        e.getChannel().write(outBuf);\n-\n-    }\n-\n-\n-    public static void main(String args[]) {\n-        new FakeBookie(Integer.parseInt(args[0]));\n-    }\n-}"},{"sha":"2611bc0ffe85ca3ea7ae6e7993f576b2f2f835ed","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/ByteStringInterner.java","status":"removed","additions":0,"deletions":38,"changes":38,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/ByteStringInterner.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/ByteStringInterner.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/ByteStringInterner.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,38 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.common;\n-\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-\n-import com.google.protobuf.ByteString;\n-\n-public class ByteStringInterner {\n-    // TODO: how to release references when strings are no longer used. weak\n-    // references?\n-\n-    private static final ConcurrentMap<ByteString, ByteString> map = new ConcurrentHashMap<ByteString, ByteString>();\n-\n-    public static ByteString intern(ByteString in) {\n-        ByteString presentValueInMap = map.putIfAbsent(in, in);\n-        if (presentValueInMap != null) {\n-            return presentValueInMap;\n-        }\n-        return in;\n-    }\n-}"},{"sha":"237c7dec646a12202b15e56607836f4fce82acab","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","status":"removed","additions":0,"deletions":666,"changes":666,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,666 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.common;\n-\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.InputStream;\n-import java.net.InetAddress;\n-import java.net.URL;\n-import java.net.UnknownHostException;\n-import java.util.Arrays;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-import org.apache.bookkeeper.util.ReflectionUtils;\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.apache.commons.lang.StringUtils;\n-import org.apache.hedwig.conf.AbstractConfiguration;\n-import org.apache.hedwig.server.meta.MetadataManagerFactory;\n-import org.apache.hedwig.server.topics.HubLoad;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-\n-import com.google.protobuf.ByteString;\n-\n-public class ServerConfiguration extends AbstractConfiguration {\n-    public final static String REGION = \"region\";\n-    protected final static String MAX_MESSAGE_SIZE = \"max_message_size\";\n-    protected final static String READAHEAD_COUNT = \"readahead_count\";\n-    protected final static String READAHEAD_SIZE = \"readahead_size\";\n-    protected final static String CACHE_SIZE = \"cache_size\";\n-    protected final static String CACHE_ENTRY_TTL = \"cache_entry_ttl\";\n-    protected final static String SCAN_BACKOFF_MSEC = \"scan_backoff_ms\";\n-    protected final static String SERVER_PORT = \"server_port\";\n-    protected final static String SSL_SERVER_PORT = \"ssl_server_port\";\n-    protected final static String ZK_PREFIX = \"zk_prefix\";\n-    protected final static String ZK_HOST = \"zk_host\";\n-    protected final static String ZK_TIMEOUT = \"zk_timeout\";\n-    protected final static String READAHEAD_ENABLED = \"readahead_enabled\";\n-    protected final static String STANDALONE = \"standalone\";\n-    protected final static String REGIONS = \"regions\";\n-    protected final static String CERT_NAME = \"cert_name\";\n-    protected final static String CERT_PATH = \"cert_path\";\n-    protected final static String PASSWORD = \"password\";\n-    protected final static String SSL_ENABLED = \"ssl_enabled\";\n-    protected final static String CONSUME_INTERVAL = \"consume_interval\";\n-    protected final static String INIT_NUM_TOPICS = \"init_num_topics\";\n-    protected final static String MAX_NUM_TOPICS = \"max_num_topics\";\n-    protected final static String RETENTION_SECS = \"retention_secs\";\n-    protected final static String RETENTION_SECS_AFTER_ACCESS = \"retention_secs_after_access\";\n-    protected final static String INTER_REGION_SSL_ENABLED = \"inter_region_ssl_enabled\";\n-    protected final static String MESSAGES_CONSUMED_THREAD_RUN_INTERVAL = \"messages_consumed_thread_run_interval\";\n-    protected final static String BK_ENSEMBLE_SIZE = \"bk_ensemble_size\";\n-    @Deprecated\n-    protected final static String BK_QUORUM_SIZE = \"bk_quorum_size\";\n-    protected final static String BK_WRITE_QUORUM_SIZE = \"bk_write_quorum_size\";\n-    protected final static String BK_ACK_QUORUM_SIZE = \"bk_ack_quorum_size\";\n-    protected final static String RETRY_REMOTE_SUBSCRIBE_THREAD_RUN_INTERVAL = \"retry_remote_subscribe_thread_run_interval\";\n-    protected final static String DEFAULT_MESSAGE_WINDOW_SIZE =\n-        \"default_message_window_size\";\n-    protected final static String NUM_READAHEAD_CACHE_THREADS = \"num_readahead_cache_threads\";\n-    protected final static String NUM_DELIVERY_THREADS = \"num_delivery_threads\";\n-\n-    protected final static String MAX_ENTRIES_PER_LEDGER = \"max_entries_per_ledger\";\n-    protected final static String REBALANCE_TOLERANCE_PERCENTAGE = \"rebalance_tolerance\";\n-    protected final static String REBALANCE_MAX_SHED = \"rebalance_max_shed\";\n-    protected final static String REBALANCE_INTERVAL_SEC = \"rebalance_interval_sec\";\n-\n-    // manager related settings\n-    protected final static String METADATA_MANAGER_BASED_TOPIC_MANAGER_ENABLED = \"metadata_manager_based_topic_manager_enabled\";\n-    protected final static String METADATA_MANAGER_FACTORY_CLASS = \"metadata_manager_factory_class\";\n-\n-    // metastore settings, only being used when METADATA_MANAGER_FACTORY_CLASS is MsMetadataManagerFactory\n-    protected final static String METASTORE_IMPL_CLASS = \"metastore_impl_class\";\n-    protected final static String METASTORE_MAX_ENTRIES_PER_SCAN = \"metastoreMaxEntriesPerScan\";\n-\n-    private static ClassLoader defaultLoader;\n-    static {\n-        defaultLoader = Thread.currentThread().getContextClassLoader();\n-        if (null == defaultLoader) {\n-            defaultLoader = ServerConfiguration.class.getClassLoader();\n-        }\n-    }\n-\n-    // these are the derived attributes\n-    protected ByteString myRegionByteString = null;\n-    protected HedwigSocketAddress myServerAddress = null;\n-    protected List<String> regionList = null;\n-\n-    // Although this method is not currently used, currently maintaining it like\n-    // this so that we can support on-the-fly changes in configuration\n-    protected void refreshDerivedAttributes() {\n-        refreshMyRegionByteString();\n-        refreshMyServerAddress();\n-        refreshRegionList();\n-    }\n-\n-    @Override\n-    public void loadConf(URL confURL) throws ConfigurationException {\n-        super.loadConf(confURL);\n-        refreshDerivedAttributes();\n-    }\n-\n-    public int getMaximumMessageSize() {\n-        return conf.getInt(MAX_MESSAGE_SIZE, 1258291); /* 1.2M */\n-    }\n-\n-    public String getMyRegion() {\n-        return conf.getString(REGION, \"standalone\");\n-    }\n-\n-    protected void refreshMyRegionByteString() {\n-        myRegionByteString = ByteString.copyFromUtf8(getMyRegion());\n-    }\n-\n-    protected void refreshMyServerAddress() {\n-        try {\n-            // Use the raw IP address as the hostname\n-            myServerAddress = new HedwigSocketAddress(InetAddress.getLocalHost().getHostAddress(), getServerPort(),\n-                    getSSLServerPort());\n-        } catch (UnknownHostException e) {\n-            throw new RuntimeException(e);\n-        }\n-    }\n-\n-    // The expected format for the regions parameter is Hostname:Port:SSLPort\n-    // with spaces in between each of the regions.\n-    protected void refreshRegionList() {\n-        String regions = conf.getString(REGIONS, \"\");\n-        if (regions.isEmpty()) {\n-            regionList = new LinkedList<String>();\n-        } else {\n-            regionList = Arrays.asList(regions.split(\" \"));\n-        }\n-    }\n-\n-    public ByteString getMyRegionByteString() {\n-        if (myRegionByteString == null) {\n-            refreshMyRegionByteString();\n-        }\n-        return myRegionByteString;\n-    }\n-\n-    /**\n-     * Maximum number of messages to read ahead. Default is 10.\n-     *\n-     * @return int\n-     */\n-    public int getReadAheadCount() {\n-        return conf.getInt(READAHEAD_COUNT, 10);\n-    }\n-\n-    /**\n-     * Maximum number of bytes to read ahead. Default is 4MB.\n-     *\n-     * @return long\n-     */\n-    public long getReadAheadSizeBytes() {\n-        return conf.getLong(READAHEAD_SIZE, 4 * 1024 * 1024); // 4M\n-    }\n-\n-    /**\n-     * Maximum cache size. By default is the smallest of 2G or\n-     * half the heap size.\n-     *\n-     * @return long\n-     */\n-    public long getMaximumCacheSize() {\n-        // 2G or half of the maximum amount of memory the JVM uses\n-        return conf.getLong(CACHE_SIZE, Math.min(2 * 1024L * 1024L * 1024L, Runtime.getRuntime().maxMemory() / 2));\n-    }\n-\n-    /**\n-     * Cache Entry TTL. By default is 0, cache entry will not be evicted\n-     * until the cache is fullfilled or the messages are already consumed.\n-     * The TTL is only checked when trying adding a new entry into the cache.\n-     *\n-     * @return cache entry ttl.\n-     */\n-    public long getCacheEntryTTL() {\n-        return conf.getLong(CACHE_ENTRY_TTL, 0L);\n-    }\n-\n-    /**\n-     * After a scan of a log fails, how long before we retry (in msec)\n-     *\n-     * @return long\n-     */\n-    public long getScanBackoffPeriodMs() {\n-        return conf.getLong(SCAN_BACKOFF_MSEC, 1000);\n-    }\n-\n-    /**\n-     * Returns server port.\n-     *\n-     * @return int\n-     */\n-    public int getServerPort() {\n-        return conf.getInt(SERVER_PORT, 4080);\n-    }\n-\n-    /**\n-     * Returns SSL server port.\n-     *\n-     * @return int\n-     */\n-    public int getSSLServerPort() {\n-        return conf.getInt(SSL_SERVER_PORT, 9876);\n-    }\n-\n-    /**\n-     * Returns ZooKeeper path prefix.\n-     *\n-     * @return string\n-     */\n-    public String getZkPrefix() {\n-        return conf.getString(ZK_PREFIX, \"/hedwig\");\n-    }\n-\n-    public StringBuilder getZkRegionPrefix(StringBuilder sb) {\n-        return sb.append(getZkPrefix()).append(\"/\").append(getMyRegion());\n-    }\n-\n-    /**\n-     * Get znode path to store manager layouts.\n-     *\n-     * @param sb\n-     *          StringBuilder to store znode path to store manager layouts.\n-     * @return znode path to store manager layouts.\n-     */\n-    public StringBuilder getZkManagersPrefix(StringBuilder sb) {\n-        return getZkRegionPrefix(sb).append(\"/managers\");\n-    }\n-\n-    public StringBuilder getZkTopicsPrefix(StringBuilder sb) {\n-        return getZkRegionPrefix(sb).append(\"/topics\");\n-    }\n-\n-    public StringBuilder getZkTopicPath(StringBuilder sb, ByteString topic) {\n-        return getZkTopicsPrefix(sb).append(\"/\").append(topic.toStringUtf8());\n-    }\n-\n-    public StringBuilder getZkHostsPrefix(StringBuilder sb) {\n-        return getZkRegionPrefix(sb).append(\"/hosts\");\n-    }\n-\n-    public HedwigSocketAddress getServerAddr() {\n-        if (myServerAddress == null) {\n-            refreshMyServerAddress();\n-        }\n-        return myServerAddress;\n-    }\n-\n-    /**\n-     * Return ZooKeeper list of servers. Default is localhost.\n-     *\n-     * @return String\n-     */\n-    public String getZkHost() {\n-        List servers = conf.getList(ZK_HOST, null);\n-        if (null == servers || 0 == servers.size()) {\n-            return \"localhost\";\n-        }\n-        return StringUtils.join(servers, \",\");\n-    }\n-\n-    /**\n-     * Return ZooKeeper session timeout. Default is 2s.\n-     *\n-     * @return int\n-     */\n-    public int getZkTimeout() {\n-        return conf.getInt(ZK_TIMEOUT, 2000);\n-    }\n-\n-    /**\n-     * Returns true if read-ahead enabled. Default is true.\n-     *\n-     * @return boolean\n-     */\n-    public boolean getReadAheadEnabled() {\n-        return conf.getBoolean(READAHEAD_ENABLED, true)\n-            || conf.getBoolean(\"readhead_enabled\");\n-        // the key was misspelt in a previous version, so compensate here\n-    }\n-\n-    /**\n-     * Returns true if standalone. Default is false.\n-     *\n-     * @return boolean\n-     */\n-    public boolean isStandalone() {\n-        return conf.getBoolean(STANDALONE, false);\n-    }\n-\n-    /**\n-     * Returns list of regions.\n-     *\n-     * @return List<String>\n-     */\n-    public List<String> getRegions() {\n-        if (regionList == null) {\n-            refreshRegionList();\n-        }\n-        return regionList;\n-    }\n-\n-    /**\n-     *  Returns the name of the SSL certificate if available as a resource.\n-     *\n-     * @return String\n-     */\n-    public String getCertName() {\n-        return conf.getString(CERT_NAME, \"\");\n-    }\n-\n-    /**\n-     * This is the path to the SSL certificate if it is available as a file.\n-     *\n-     * @return String\n-     */\n-    public String getCertPath() {\n-        return conf.getString(CERT_PATH, \"\");\n-    }\n-\n-    // This method return the SSL certificate as an InputStream based on if it\n-    // is configured to be available as a resource or as a file. If nothing is\n-    // configured correctly, then a ConfigurationException will be thrown as\n-    // we do not know how to obtain the SSL certificate stream.\n-    public InputStream getCertStream() throws FileNotFoundException, ConfigurationException {\n-        String certName = getCertName();\n-        String certPath = getCertPath();\n-        if (certName != null && !certName.isEmpty()) {\n-            return getClass().getResourceAsStream(certName);\n-        } else if (certPath != null && !certPath.isEmpty()) {\n-            return new FileInputStream(certPath);\n-        } else\n-            throw new ConfigurationException(\"SSL Certificate configuration does not have resource name or path set!\");\n-    }\n-\n-    /**\n-     * Returns the password used for BookKeeper ledgers. Default\n-     * is the empty string.\n-     *\n-     * @return\n-     */\n-    public String getPassword() {\n-        return conf.getString(PASSWORD, \"\");\n-    }\n-\n-    /**\n-     * Returns true if SSL is enabled. Default is false.\n-     *\n-     * @return boolean\n-     */\n-    public boolean isSSLEnabled() {\n-        return conf.getBoolean(SSL_ENABLED, false);\n-    }\n-\n-    /**\n-     * Gets the number of messages consumed before persisting\n-     * information about consumed messages. A value greater than\n-     * one avoids persisting information about consumed messages\n-     * upon every consumed message. Default is 50.\n-     *\n-     * @return int\n-     */\n-    public int getConsumeInterval() {\n-        return conf.getInt(CONSUME_INTERVAL, 50);\n-    }\n-\n-    /**\n-     * Returns the interval to release a topic. If this\n-     * parameter is greater than zero, then schedule a\n-     * task to release an owned topic. Default is 0 (never released).\n-     *\n-     * @return int\n-     */\n-    public int getRetentionSecs() {\n-        return conf.getInt(RETENTION_SECS, 0);\n-    }\n-\n-    /**\n-     * Specifies that the topic should be automatically released\n-     * once a fixed duration after the topic is owned, a message is\n-     * published, or a message is delivered.\n-     *\n-     * @return the length of time after an entry is last accessed that\n-     *         it should be automatically removed.\n-     */\n-    public int getRetentionSecsAfterAccess() {\n-        return conf.getInt(RETENTION_SECS_AFTER_ACCESS, 0);\n-    }\n-\n-    /**\n-     * Max number of topics for a hub server to serve.\n-     *\n-     * @return max number of topics for a hub server to serve.\n-     */\n-    public int getMaxNumTopics() {\n-        return conf.getInt(MAX_NUM_TOPICS, Integer.MAX_VALUE);\n-    }\n-\n-    /**\n-     * Minimum size of internal structure to store topics.\n-     *\n-     * @return init number of topics for a hub server.\n-     */\n-    public int getInitNumTopics() {\n-        return conf.getInt(INIT_NUM_TOPICS, 128);\n-    }\n-\n-    /**\n-     * True if SSL is enabled across regions.\n-     *\n-     * @return boolean\n-     */\n-    public boolean isInterRegionSSLEnabled() {\n-        return conf.getBoolean(INTER_REGION_SSL_ENABLED, false);\n-    }\n-\n-    /**\n-     * This parameter is used to determine how often we run the\n-     * SubscriptionManager's Messages Consumed timer task thread\n-     * (in milliseconds).\n-     *\n-     * @return int\n-     */\n-    public int getMessagesConsumedThreadRunInterval() {\n-        return conf.getInt(MESSAGES_CONSUMED_THREAD_RUN_INTERVAL, 60000);\n-    }\n-\n-    /**\n-     * This parameter is used to determine how often we run a thread\n-     * to retry those failed remote subscriptions in asynchronous mode\n-     * (in milliseconds).\n-     *\n-     * @return int\n-     */\n-    public int getRetryRemoteSubscribeThreadRunInterval() {\n-        return conf.getInt(RETRY_REMOTE_SUBSCRIBE_THREAD_RUN_INTERVAL, 120000);\n-    }\n-\n-    /**\n-     * This parameter is for setting the default maximum number of messages which\n-     * can be delivered to a subscriber without being consumed.\n-     * we pause messages delivery to a subscriber when reaching the window size\n-     *\n-     * @return int\n-     */\n-    public int getDefaultMessageWindowSize() {\n-        return conf.getInt(DEFAULT_MESSAGE_WINDOW_SIZE, 0);\n-    }\n-\n-    /**\n-     * This parameter is used when Bookkeeper is the persistence\n-     * store and indicates what the ensemble size is (i.e. how\n-     * many bookie servers to stripe the ledger entries across).\n-     *\n-     * @return int\n-     */\n-    public int getBkEnsembleSize() {\n-        return conf.getInt(BK_ENSEMBLE_SIZE, 3);\n-    }\n-\n-\n-    /**\n-     * This parameter is used when Bookkeeper is the persistence store\n-     * and indicates what the quorum size is (i.e. how many redundant\n-     * copies of each ledger entry is written).\n-     *\n-     * @return int\n-     * @deprecated please use #getBkWriteQuorumSize() and #getBkAckQuorumSize()\n-     */\n-    @Deprecated\n-    protected int getBkQuorumSize() {\n-        return conf.getInt(BK_QUORUM_SIZE, 2);\n-    }\n-\n-    /**\n-     * Get the write quorum size for BookKeeper client, which is used to\n-     * indicate how many redundant copies of each ledger entry is written.\n-     *\n-     * @return write quorum size for BookKeeper client.\n-     */\n-    public int getBkWriteQuorumSize() {\n-        if (conf.containsKey(BK_WRITE_QUORUM_SIZE)) {\n-            return conf.getInt(BK_WRITE_QUORUM_SIZE, 2);\n-        } else {\n-            return getBkQuorumSize();\n-        }\n-    }\n-\n-    /**\n-     * Get the ack quorum size for BookKeeper client.\n-     *\n-     * @return ack quorum size for BookKeeper client.\n-     */\n-    public int getBkAckQuorumSize() {\n-        if (conf.containsKey(BK_ACK_QUORUM_SIZE)) {\n-            return conf.getInt(BK_ACK_QUORUM_SIZE, 2);\n-        } else {\n-            return getBkQuorumSize();\n-        }\n-    }\n-\n-    /**\n-     * This parameter is used when BookKeeper is the persistence storage,\n-     * and indicates when the number of entries stored in a ledger reach\n-     * the threshold, hub server will open a new ledger to write.\n-     *\n-     * @return max entries per ledger\n-     */\n-    public long getMaxEntriesPerLedger() {\n-        return conf.getLong(MAX_ENTRIES_PER_LEDGER, 0L);\n-    }\n-\n-    /**\n-     * Get the tolerance percentage for the rebalancer. The rebalancer will not\n-     * shed load if it's current load is less than average + average*tolerancePercentage/100.0\n-     *\n-     * @return the tolerance percentage for the rebalancer.\n-     */\n-    public double getRebalanceTolerance() {\n-        return conf.getDouble(REBALANCE_TOLERANCE_PERCENTAGE, 10.0);\n-    }\n-\n-    /**\n-     * Get the maximum load the rebalancer can shed at once. Default is 50.\n-     * @return\n-     */\n-    public HubLoad getRebalanceMaxShed() {\n-        return new HubLoad(conf.getLong(REBALANCE_MAX_SHED, 50));\n-    }\n-\n-    /**\n-     * Get the interval(in seconds) between rebalancing attempts. The default is\n-     * 5 minutes.\n-     * @return\n-     */\n-    public long getRebalanceInterval() {\n-        return conf.getLong(REBALANCE_INTERVAL_SEC, 300);\n-    }\n-\n-    /*\n-     * Is this a valid configuration that we can run with? This code might grow\n-     * over time.\n-     */\n-    public void validate() throws ConfigurationException {\n-        if (!getZkPrefix().startsWith(\"/\")) {\n-            throw new ConfigurationException(ZK_PREFIX + \" must start with a /\");\n-        }\n-        // Validate that if Regions exist and inter-region communication is SSL\n-        // enabled, that the Regions correspond to valid HedwigSocketAddresses,\n-        // namely that SSL ports are present.\n-        if (isInterRegionSSLEnabled() && getRegions().size() > 0) {\n-            for (String hubString : getRegions()) {\n-                HedwigSocketAddress hub = new HedwigSocketAddress(hubString);\n-                if (hub.getSSLSocketAddress() == null)\n-                    throw new ConfigurationException(\"Region defined does not have required SSL port: \" + hubString);\n-            }\n-        }\n-        // Validate that the Bookkeeper ensemble size >= quorum size.\n-        if (getBkEnsembleSize() < getBkWriteQuorumSize()) {\n-            throw new ConfigurationException(\"BK ensemble size (\" + getBkEnsembleSize()\n-                                             + \") is less than the write quorum size (\" + getBkWriteQuorumSize() + \")\");\n-        }\n-\n-        if (getBkWriteQuorumSize() < getBkAckQuorumSize()) {\n-            throw new ConfigurationException(\"BK write quorum size (\" + getBkWriteQuorumSize()\n-                                             + \") is less than the ack quorum size (\" + getBkAckQuorumSize() + \")\");\n-        }\n-        // Validate that the rebalance tolerance percentage is not negative.\n-        if (getRebalanceTolerance() < 0.0) {\n-            throw new ConfigurationException(\"The rebalance tolerance percentage cannot be negative.\");\n-        }\n-        // Validate that the maximum load to shed during a rebalance is not negative.\n-        if (getRebalanceMaxShed().getNumTopics() < 0L) {\n-            throw new ConfigurationException(\"The maximum load to shed during a rebalance cannot be negative.\");\n-        }\n-        // add other checks here\n-    }\n-\n-    /**\n-     * Get number of read ahead cache threads.\n-     *\n-     * @return number of read ahead cache threads.\n-     */\n-    public int getNumReadAheadCacheThreads() {\n-        return conf.getInt(NUM_READAHEAD_CACHE_THREADS, Runtime.getRuntime().availableProcessors());\n-    }\n-\n-    /**\n-     * Get number of delivery threads\n-     *\n-     * @return number of delivery threads.\n-     */\n-    public int getNumDeliveryThreads() {\n-        return conf.getInt(NUM_DELIVERY_THREADS, Runtime.getRuntime().availableProcessors());\n-    }\n-\n-    /**\n-     * Whether enable metadata manager based topic manager.\n-     *\n-     * @return true if enabled metadata manager based topic manager.\n-     */\n-    public boolean isMetadataManagerBasedTopicManagerEnabled() {\n-        return conf.getBoolean(METADATA_MANAGER_BASED_TOPIC_MANAGER_ENABLED, false);\n-    }\n-\n-    /**\n-     * Get metadata manager factory class.\n-     *\n-     * @return manager class\n-     */\n-    public Class<? extends MetadataManagerFactory> getMetadataManagerFactoryClass()\n-    throws ConfigurationException {\n-        return ReflectionUtils.getClass(conf, METADATA_MANAGER_FACTORY_CLASS,\n-                                        null, MetadataManagerFactory.class,\n-                                        defaultLoader);\n-    }\n-\n-    /**\n-     * Set metadata manager factory class name\n-     *\n-     * @param managerClsName\n-     *          Manager Class Name\n-     * @return server configuration\n-     */\n-    public ServerConfiguration setMetadataManagerFactoryName(String managerClsName) {\n-        conf.setProperty(METADATA_MANAGER_FACTORY_CLASS, managerClsName);\n-        return this;\n-    }\n-\n-    /**\n-     * Get metastore implementation class.\n-     *\n-     * @return metastore implementation class name.\n-     */\n-    public String getMetastoreImplClass() {\n-        return conf.getString(METASTORE_IMPL_CLASS);\n-    }\n-\n-    /**\n-     * Get max entries per scan in metastore.\n-     *\n-     * @return max entries per scan in metastore.\n-     */\n-    public int getMetastoreMaxEntriesPerScan() {\n-        return conf.getInt(METASTORE_MAX_ENTRIES_PER_SCAN, 50);\n-    }\n-}"},{"sha":"fd8234fed9eb166d2412afd6fc4ddebbaf8c0d3b","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/TerminateJVMExceptionHandler.java","status":"removed","additions":0,"deletions":32,"changes":32,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/TerminateJVMExceptionHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/TerminateJVMExceptionHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/TerminateJVMExceptionHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,32 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.common;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class TerminateJVMExceptionHandler implements Thread.UncaughtExceptionHandler {\n-    private static Logger logger = LoggerFactory.getLogger(TerminateJVMExceptionHandler.class);\n-\n-    @Override\n-    public void uncaughtException(Thread t, Throwable e) {\n-        logger.error(\"Uncaught exception in thread \" + t.getName(), e);\n-        Runtime.getRuntime().exit(1);\n-    }\n-\n-}"},{"sha":"3c4a56286f76bdc08602177c004da5de5f4ed990","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/TopicOpQueuer.java","status":"removed","additions":0,"deletions":111,"changes":111,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/TopicOpQueuer.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/TopicOpQueuer.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/TopicOpQueuer.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,111 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.common;\n-\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.Queue;\n-import java.util.concurrent.ScheduledExecutorService;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.util.Callback;\n-\n-public class TopicOpQueuer {\n-    /**\n-     * Map from topic to the queue of operations for that topic.\n-     */\n-    protected HashMap<ByteString, Queue<Runnable>> topic2ops = new HashMap<ByteString, Queue<Runnable>>();\n-\n-    protected final ScheduledExecutorService scheduler;\n-\n-    public TopicOpQueuer(ScheduledExecutorService scheduler) {\n-        this.scheduler = scheduler;\n-    }\n-\n-    public interface Op extends Runnable {\n-    }\n-\n-    public abstract class AsynchronousOp<T> implements Op {\n-        final public ByteString topic;\n-        final public Callback<T> cb;\n-        final public Object ctx;\n-\n-        public AsynchronousOp(final ByteString topic, final Callback<T> cb, Object ctx) {\n-            this.topic = topic;\n-            this.cb = new Callback<T>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    cb.operationFailed(ctx, exception);\n-                    popAndRunNext(topic);\n-                }\n-\n-                @Override\n-                public void operationFinished(Object ctx, T resultOfOperation) {\n-                    cb.operationFinished(ctx, resultOfOperation);\n-                    popAndRunNext(topic);\n-                }\n-            };\n-            this.ctx = ctx;\n-        }\n-    }\n-\n-    public abstract class SynchronousOp implements Op {\n-        final public ByteString topic;\n-\n-        public SynchronousOp(ByteString topic) {\n-            this.topic = topic;\n-        }\n-\n-        @Override\n-        public final void run() {\n-            runInternal();\n-            popAndRunNext(topic);\n-        }\n-\n-        protected abstract void runInternal();\n-\n-    }\n-\n-    protected synchronized void popAndRunNext(ByteString topic) {\n-        Queue<Runnable> ops = topic2ops.get(topic);\n-        if (!ops.isEmpty())\n-            ops.remove();\n-        if (!ops.isEmpty())\n-            scheduler.submit(ops.peek());\n-    }\n-\n-    public void pushAndMaybeRun(ByteString topic, Op op) {\n-        int size;\n-        synchronized (this) {\n-            Queue<Runnable> ops = topic2ops.get(topic);\n-            if (ops == null) {\n-                ops = new LinkedList<Runnable>();\n-                topic2ops.put(topic, ops);\n-            }\n-            ops.add(op);\n-            size = ops.size();\n-        }\n-        if (size == 1)\n-            op.run();\n-    }\n-\n-    public Runnable peek(ByteString topic) {\n-        return topic2ops.get(topic).peek();\n-    }\n-}"},{"sha":"364ffdc766ed00abde16c049e35613ac7c48c1da","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/UnexpectedError.java","status":"removed","additions":0,"deletions":35,"changes":35,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/UnexpectedError.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/common/UnexpectedError.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/UnexpectedError.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,35 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.common;\n-\n-public class UnexpectedError extends Error {\n-\n-    /**\n-     *\n-     */\n-    private static final long serialVersionUID = 1L;\n-\n-    public UnexpectedError(String msg) {\n-        super(msg);\n-    }\n-\n-    public UnexpectedError(Throwable cause) {\n-        super(cause);\n-    }\n-\n-}"},{"sha":"e7dc1fa0b70e19536aaaef8d23d4b6e64e77295e","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/delivery/ChannelEndPoint.java","status":"removed","additions":0,"deletions":90,"changes":90,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/ChannelEndPoint.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/ChannelEndPoint.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/ChannelEndPoint.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,90 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.delivery;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFuture;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.server.common.UnexpectedError;\n-\n-public class ChannelEndPoint implements DeliveryEndPoint, ChannelFutureListener {\n-\n-    Channel channel;\n-\n-    public Channel getChannel() {\n-        return channel;\n-    }\n-\n-    Map<ChannelFuture, DeliveryCallback> callbacks = new HashMap<ChannelFuture, DeliveryCallback>();\n-\n-    public ChannelEndPoint(Channel channel) {\n-        this.channel = channel;\n-    }\n-\n-    public void close() {\n-        channel.close();\n-    }\n-\n-    public void send(PubSubResponse response, DeliveryCallback callback) {\n-        ChannelFuture future = channel.write(response);\n-        callbacks.put(future, callback);\n-        future.addListener(this);\n-    }\n-\n-    public void operationComplete(ChannelFuture future) throws Exception {\n-        DeliveryCallback callback = callbacks.get(future);\n-        callbacks.remove(future);\n-\n-        if (callback == null) {\n-            throw new UnexpectedError(\"Could not locate callback for channel future\");\n-        }\n-\n-        if (future.isSuccess()) {\n-            callback.sendingFinished();\n-        } else {\n-            // treat all channel errors as permanent\n-            callback.permanentErrorOnSend();\n-        }\n-\n-    }\n-\n-    @Override\n-    public boolean equals(Object obj) {\n-        if (obj instanceof ChannelEndPoint) {\n-            ChannelEndPoint channelEndPoint = (ChannelEndPoint) obj;\n-            return channel.equals(channelEndPoint.channel);\n-        } else {\n-            return false;\n-        }\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return channel.hashCode();\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return channel.toString();\n-    }\n-}"},{"sha":"9ee63f154f94cef14e71a6fb400ac7d6b4d3bcce","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryCallback.java","status":"removed","additions":0,"deletions":27,"changes":27,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,27 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.delivery;\n-\n-public interface DeliveryCallback {\n-\n-    public void sendingFinished();\n-\n-    public void transientErrorOnSend();\n-\n-    public void permanentErrorOnSend();\n-}"},{"sha":"077480122194b7e28d326084585d890a69f77a4a","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryEndPoint.java","status":"removed","additions":0,"deletions":28,"changes":28,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryEndPoint.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryEndPoint.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryEndPoint.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,28 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.delivery;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-\n-public interface DeliveryEndPoint {\n-\n-    public void send(PubSubResponse response, DeliveryCallback callback);\n-\n-    public void close();\n-\n-}"},{"sha":"af3d15061eb7cb3b77281688888449505b410ae2","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryManager.java","status":"removed","additions":0,"deletions":92,"changes":92,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/DeliveryManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,92 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.delivery;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.filter.ServerMessageFilter;\n-import org.apache.hedwig.util.Callback;\n-\n-public interface DeliveryManager {\n-    public void start();\n-\n-    /**\n-     * Start serving a given subscription.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber Id\n-     * @param preferences\n-     *          Subscription Preferences\n-     * @param seqIdToStartFrom\n-     *          Message sequence id starting delivery from.\n-     * @param endPoint\n-     *          End point to deliver messages to.\n-     * @param filter\n-     *          Message filter used to filter messages before delivery.\n-     * @param callback\n-     *          Callback instance.\n-     * @param ctx\n-     *          Callback context.\n-     */\n-    public void startServingSubscription(ByteString topic, ByteString subscriberId,\n-                                         SubscriptionPreferences preferences,\n-                                         MessageSeqId seqIdToStartFrom,\n-                                         DeliveryEndPoint endPoint,\n-                                         ServerMessageFilter filter,\n-                                         Callback<Void> callback, Object ctx);\n-\n-    /**\n-     * Stop serving a given subscription.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber Id\n-     * @param event\n-     *          Subscription event indicating the reason to stop the subscriber.\n-     * @param callback\n-     *          Callback instance.\n-     * @param ctx\n-     *          Callback context.\n-     */\n-    public void stopServingSubscriber(ByteString topic, ByteString subscriberId,\n-                                      SubscriptionEvent event,\n-                                      Callback<Void> callback, Object ctx);\n-\n-    /**\n-     * Tell the delivery manager where that a subscriber has consumed\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber Id\n-     * @param consumedSeqId\n-     *          Max consumed seq id.\n-     */\n-    public void messageConsumed(ByteString topic, ByteString subscriberId,\n-                                MessageSeqId consumedSeqId);\n-\n-    /**\n-     * Stop delivery manager\n-     */\n-    public void stop();\n-}"},{"sha":"0480b222f91d847c60fff839e1469c9ffd222c0a","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/delivery/FIFODeliveryManager.java","status":"removed","additions":0,"deletions":978,"changes":978,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/FIFODeliveryManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/FIFODeliveryManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/delivery/FIFODeliveryManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,978 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.delivery;\n-\n-import static org.apache.hedwig.util.VarArgs.va;\n-\n-import java.util.Comparator;\n-import java.util.HashSet;\n-import java.util.Queue;\n-import java.util.Set;\n-import java.util.SortedMap;\n-import java.util.TreeMap;\n-import java.util.concurrent.BlockingQueue;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-import java.util.concurrent.PriorityBlockingQueue;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.TimeUnit;\n-import java.util.concurrent.locks.ReentrantReadWriteLock;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.filter.ServerMessageFilter;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.ProtocolVersion;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.UnexpectedError;\n-import org.apache.hedwig.server.handlers.SubscriptionChannelManager.SubChannelDisconnectedListener;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.persistence.CancelScanRequest;\n-import org.apache.hedwig.server.persistence.Factory;\n-import org.apache.hedwig.server.persistence.MapMethods;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.persistence.ReadAheadCache;\n-import org.apache.hedwig.server.persistence.ScanCallback;\n-import org.apache.hedwig.server.persistence.ScanRequest;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class FIFODeliveryManager implements DeliveryManager, SubChannelDisconnectedListener {\n-\n-    protected static final Logger logger = LoggerFactory.getLogger(FIFODeliveryManager.class);\n-\n-    private static Callback<Void> NOP_CALLBACK = new Callback<Void>() {\n-        @Override\n-        public void operationFinished(Object ctx, Void result) {\n-        }\n-        @Override\n-        public void operationFailed(Object ctx, PubSubException exception) {\n-        }\n-    };\n-\n-    protected interface DeliveryManagerRequest {\n-        public void performRequest();\n-    }\n-\n-    /**\n-     * Stores a mapping from topic to the delivery pointers on the topic. The\n-     * delivery pointers are stored in a sorted map from seq-id to the set of\n-     * subscribers at that seq-id\n-     */\n-    ConcurrentMap<ByteString, SortedMap<Long, Set<ActiveSubscriberState>>> perTopicDeliveryPtrs;\n-\n-    /**\n-     * Mapping from delivery end point to the subscriber state that we are\n-     * serving at that end point. This prevents us e.g., from serving two\n-     * subscriptions to the same endpoint\n-     */\n-    ConcurrentMap<TopicSubscriber, ActiveSubscriberState> subscriberStates;\n-\n-    private final ReadAheadCache cache;\n-    private final PersistenceManager persistenceMgr;\n-    private TopicManager tm;\n-    private ServerConfiguration cfg;\n-\n-    private final int numDeliveryWorkers;\n-    private final DeliveryWorker[] deliveryWorkers;\n-\n-    private class DeliveryWorker implements Runnable {\n-\n-        BlockingQueue<DeliveryManagerRequest> requestQueue =\n-            new LinkedBlockingQueue<DeliveryManagerRequest>();;\n-\n-        /**\n-         * The queue of all subscriptions that are facing a transient error either\n-         * in scanning from the persistence manager, or in sending to the consumer\n-         */\n-        Queue<ActiveSubscriberState> retryQueue =\n-            new PriorityBlockingQueue<ActiveSubscriberState>(32, new Comparator<ActiveSubscriberState>() {\n-                @Override\n-                public int compare(ActiveSubscriberState as1, ActiveSubscriberState as2) {\n-                    long s = as1.lastScanErrorTime - as2.lastScanErrorTime;\n-                    return s > 0 ? 1 : (s < 0 ? -1 : 0);\n-                }\n-            });\n-\n-        // Boolean indicating if this thread should continue running. This is used\n-        // when we want to stop the thread during a PubSubServer shutdown.\n-        protected volatile boolean keepRunning = true;\n-        private final Thread workerThread;\n-        private final int idx;\n-\n-        private final Object suspensionLock = new Object();\n-        private boolean suspended = false;\n-\n-        DeliveryWorker(int index) {\n-            this.idx = index;\n-            workerThread = new Thread(this, \"DeliveryManagerThread-\" + index);\n-        }\n-\n-        void start() {\n-            workerThread.start();\n-        }\n-\n-        /**\n-         * Stop method which will enqueue a ShutdownDeliveryManagerRequest.\n-         */\n-        void stop() {\n-            enqueueWithoutFailure(new ShutdownDeliveryManagerRequest());\n-        }\n-\n-        /**\n-         * Stop FIFO delivery worker from processing requests. (for testing)\n-         */\n-        void suspendProcessing() {\n-            synchronized(suspensionLock) {\n-                suspended = true;\n-            }\n-        }\n-\n-        /**\n-         * Resume FIFO delivery worker. (for testing)\n-         */\n-        void resumeProcessing() {\n-            synchronized(suspensionLock) {\n-                suspended = false;\n-                suspensionLock.notify();\n-            }\n-        }\n-\n-        @Override\n-        public void run() {\n-            while (keepRunning) {\n-                DeliveryManagerRequest request = null;\n-\n-                try {\n-                    // We use a timeout of 1 second, so that we can wake up once in\n-                    // a while to check if there is something in the retry queue.\n-                    request = requestQueue.poll(1, TimeUnit.SECONDS);\n-                    synchronized(suspensionLock) {\n-                        while (suspended) {\n-                            suspensionLock.wait();\n-                        }\n-                    }\n-                } catch (InterruptedException e) {\n-                    Thread.currentThread().interrupt();\n-                }\n-\n-                // First retry any subscriptions that had failed and need a retry\n-                retryErroredSubscribers();\n-\n-                if (request == null) {\n-                    continue;\n-                }\n-\n-                request.performRequest();\n-\n-            }\n-        }\n-\n-        protected void enqueueWithoutFailure(DeliveryManagerRequest request) {\n-            if (!requestQueue.offer(request)) {\n-                throw new UnexpectedError(\"Could not enqueue object: \" + request\n-                    + \" to request queue for delivery worker .\" + idx);\n-            }\n-        }\n-\n-        public void retryErroredSubscriberAfterDelay(ActiveSubscriberState subscriber) {\n-            subscriber.setLastScanErrorTime(MathUtils.now());\n-\n-            if (!retryQueue.offer(subscriber)) {\n-                throw new UnexpectedError(\"Could not enqueue to retry queue for delivery worker \" + idx);\n-            }\n-        }\n-\n-        public void clearRetryDelayForSubscriber(ActiveSubscriberState subscriber) {\n-            subscriber.clearLastScanErrorTime();\n-            if (!retryQueue.offer(subscriber)) {\n-                throw new UnexpectedError(\"Could not enqueue to delivery manager retry queue\");\n-            }\n-            // no request in request queue now\n-            // issue a empty delivery request to not waiting for polling requests queue\n-            if (requestQueue.isEmpty()) {\n-                enqueueWithoutFailure(new DeliveryManagerRequest() {\n-                        @Override\n-                        public void performRequest() {\n-                        // do nothing\n-                        }\n-                        });\n-            }\n-        }\n-\n-        protected void retryErroredSubscribers() {\n-            long lastInterestingFailureTime = MathUtils.now() - cfg.getScanBackoffPeriodMs();\n-            ActiveSubscriberState subscriber;\n-\n-            while ((subscriber = retryQueue.peek()) != null) {\n-                if (subscriber.getLastScanErrorTime() > lastInterestingFailureTime) {\n-                    // Not enough time has elapsed yet, will retry later\n-                    // Since the queue is fifo, no need to check later items\n-                    return;\n-                }\n-\n-                // retry now\n-                subscriber.deliverNextMessage();\n-                retryQueue.poll();\n-            }\n-        }\n-\n-        protected class ShutdownDeliveryManagerRequest implements DeliveryManagerRequest {\n-            // This is a simple type of Request we will enqueue when the\n-            // PubSubServer is shut down and we want to stop the DeliveryManager\n-            // thread.\n-            @Override\n-            public void performRequest() {\n-                keepRunning = false;\n-            }\n-        }\n-\n-    }\n-\n-\n-\n-    public FIFODeliveryManager(TopicManager tm, PersistenceManager persistenceMgr,\n-                               ServerConfiguration cfg) {\n-        this.tm = tm;\n-        this.persistenceMgr = persistenceMgr;\n-        if (persistenceMgr instanceof ReadAheadCache) {\n-            this.cache = (ReadAheadCache) persistenceMgr;\n-        } else {\n-            this.cache = null;\n-        }\n-        perTopicDeliveryPtrs =\n-            new ConcurrentHashMap<ByteString, SortedMap<Long, Set<ActiveSubscriberState>>>();\n-        subscriberStates =\n-            new ConcurrentHashMap<TopicSubscriber, ActiveSubscriberState>();\n-        this.cfg = cfg;\n-        // initialize the delivery workers\n-        this.numDeliveryWorkers = cfg.getNumDeliveryThreads();\n-        this.deliveryWorkers = new DeliveryWorker[numDeliveryWorkers];\n-        for (int i=0; i<numDeliveryWorkers; i++) {\n-            deliveryWorkers[i] = new DeliveryWorker(i);\n-        }\n-    }\n-\n-    @Override\n-    public void start() {\n-        for (int i=0; i<numDeliveryWorkers; i++) {\n-            deliveryWorkers[i].start();\n-        }\n-    }\n-\n-    /**\n-     * Stop FIFO delivery manager from processing requests. (for testing)\n-     */\n-    @VisibleForTesting\n-    public void suspendProcessing() {\n-        for (int i=0; i<numDeliveryWorkers; i++) {\n-            deliveryWorkers[i].suspendProcessing();\n-        }\n-    }\n-\n-    /**\n-     * Resume FIFO delivery manager. (for testing)\n-     */\n-    @VisibleForTesting\n-    public void resumeProcessing() {\n-        for (int i=0; i<numDeliveryWorkers; i++) {\n-            deliveryWorkers[i].resumeProcessing();\n-        }\n-    }\n-\n-    /**\n-     * Stop the FIFO delivery manager.\n-     */\n-    @Override\n-    public void stop() {\n-        for (int i=0; i<numDeliveryWorkers; i++) {\n-            deliveryWorkers[i].stop();\n-        }\n-    }\n-\n-    private DeliveryWorker getDeliveryWorker(ByteString topic) {\n-        return deliveryWorkers[MathUtils.signSafeMod(topic.hashCode(), numDeliveryWorkers)];\n-    }\n-\n-    /**\n-     * ===================================================================== Our\n-     * usual enqueue function, stop if error because of unbounded queue, should\n-     * never happen\n-     *\n-     */\n-    protected void enqueueWithoutFailure(ByteString topic, DeliveryManagerRequest request) {\n-        getDeliveryWorker(topic).enqueueWithoutFailure(request);\n-    }\n-\n-    /**\n-     * Tells the delivery manager to start sending out messages for a particular\n-     * subscription\n-     *\n-     * @param topic\n-     * @param subscriberId\n-     * @param seqIdToStartFrom\n-     *            Message sequence-id from where delivery should be started\n-     * @param endPoint\n-     *            The delivery end point to which send messages to\n-     * @param filter\n-     *            Only messages passing this filter should be sent to this\n-     *            subscriber\n-     * @param callback\n-     *            Callback instance\n-     * @param ctx\n-     *            Callback context\n-     */\n-    @Override\n-    public void startServingSubscription(ByteString topic, ByteString subscriberId,\n-                                         SubscriptionPreferences preferences,\n-                                         MessageSeqId seqIdToStartFrom,\n-                                         DeliveryEndPoint endPoint, ServerMessageFilter filter,\n-                                         Callback<Void> callback, Object ctx) {\n-        ActiveSubscriberState subscriber =\n-            new ActiveSubscriberState(topic, subscriberId,\n-                                      preferences,\n-                                      seqIdToStartFrom.getLocalComponent() - 1,\n-                                      endPoint, filter, callback, ctx);\n-\n-        enqueueWithoutFailure(topic, subscriber);\n-    }\n-\n-    public void stopServingSubscriber(ByteString topic, ByteString subscriberId,\n-                                      SubscriptionEvent event,\n-                                      Callback<Void> cb, Object ctx) {\n-        enqueueWithoutFailure(topic, new StopServingSubscriber(topic, subscriberId, event, cb, ctx));\n-    }\n-\n-    /**\n-     * Instructs the delivery manager to backoff on the given subscriber and\n-     * retry sending after some time\n-     *\n-     * @param subscriber\n-     */\n-    public void retryErroredSubscriberAfterDelay(ActiveSubscriberState subscriber) {\n-        getDeliveryWorker(subscriber.getTopic()).retryErroredSubscriberAfterDelay(subscriber);\n-    }\n-\n-    public void clearRetryDelayForSubscriber(ActiveSubscriberState subscriber) {\n-        getDeliveryWorker(subscriber.getTopic()).clearRetryDelayForSubscriber(subscriber);\n-    }\n-\n-    // TODO: for now, I don't move messageConsumed request to delivery manager thread,\n-    //       which is supposed to be fixed in {@link https://issues.apache.org/jira/browse/BOOKKEEPER-503}\n-    @Override\n-    public void messageConsumed(ByteString topic, ByteString subscriberId,\n-                                MessageSeqId consumedSeqId) {\n-        ActiveSubscriberState subState =\n-            subscriberStates.get(new TopicSubscriber(topic, subscriberId));\n-        if (null == subState) {\n-            return;\n-        }\n-        subState.messageConsumed(consumedSeqId.getLocalComponent());\n-    }\n-\n-    /**\n-     * Instructs the delivery manager to move the delivery pointer for a given\n-     * subscriber\n-     *\n-     * @param subscriber\n-     * @param prevSeqId\n-     * @param newSeqId\n-     */\n-    public void moveDeliveryPtrForward(ActiveSubscriberState subscriber, long prevSeqId, long newSeqId) {\n-        enqueueWithoutFailure(subscriber.getTopic(),\n-            new DeliveryPtrMove(subscriber, prevSeqId, newSeqId));\n-    }\n-\n-    protected void removeDeliveryPtr(ActiveSubscriberState subscriber, Long seqId, boolean isAbsenceOk,\n-                                     boolean pruneTopic) {\n-\n-        assert seqId != null;\n-\n-        // remove this subscriber from the delivery pointers data structure\n-        ByteString topic = subscriber.getTopic();\n-        SortedMap<Long, Set<ActiveSubscriberState>> deliveryPtrs = perTopicDeliveryPtrs.get(topic);\n-\n-        if (deliveryPtrs == null && !isAbsenceOk) {\n-            throw new UnexpectedError(\"No delivery pointers found while disconnecting \" + \"channel for topic:\" + topic);\n-        }\n-\n-        if(null == deliveryPtrs) {\n-            return;\n-        }\n-\n-        if (!MapMethods.removeFromMultiMap(deliveryPtrs, seqId, subscriber) && !isAbsenceOk) {\n-\n-            throw new UnexpectedError(\"Could not find subscriber:\" + subscriber + \" at the expected delivery pointer\");\n-        }\n-\n-        if (pruneTopic && deliveryPtrs.isEmpty()) {\n-            perTopicDeliveryPtrs.remove(topic);\n-        }\n-\n-    }\n-\n-    protected long getMinimumSeqId(ByteString topic) {\n-        SortedMap<Long, Set<ActiveSubscriberState>> deliveryPtrs = perTopicDeliveryPtrs.get(topic);\n-\n-        if (deliveryPtrs == null || deliveryPtrs.isEmpty()) {\n-            return Long.MAX_VALUE - 1;\n-        }\n-        return deliveryPtrs.firstKey();\n-    }\n-\n-    protected void addDeliveryPtr(ActiveSubscriberState subscriber, Long seqId) {\n-\n-        // If this topic doesn't exist in the per-topic delivery pointers table,\n-        // create an entry for it\n-        SortedMap<Long, Set<ActiveSubscriberState>> deliveryPtrs = MapMethods.getAfterInsertingIfAbsent(\n-                    perTopicDeliveryPtrs, subscriber.getTopic(), TreeMapLongToSetSubscriberFactory.instance);\n-\n-        MapMethods.addToMultiMap(deliveryPtrs, seqId, subscriber, HashMapSubscriberFactory.instance);\n-    }\n-\n-    public class ActiveSubscriberState\n-        implements ScanCallback, DeliveryCallback, DeliveryManagerRequest, CancelScanRequest {\n-\n-        static final int UNLIMITED = 0;\n-\n-        ByteString topic;\n-        ByteString subscriberId;\n-        long lastLocalSeqIdDelivered;\n-        boolean connected = true;\n-        ReentrantReadWriteLock connectedLock = new ReentrantReadWriteLock();\n-        DeliveryEndPoint deliveryEndPoint;\n-        long lastScanErrorTime = -1;\n-        long localSeqIdDeliveringNow;\n-        long lastSeqIdCommunicatedExternally;\n-        long lastSeqIdConsumedUtil;\n-        boolean isThrottled = false;\n-        final int messageWindowSize;\n-        ServerMessageFilter filter;\n-        Callback<Void> cb;\n-        Object ctx;\n-\n-        // track the outstanding scan request\n-        // so we could cancel it\n-        ScanRequest outstandingScanRequest;\n-\n-        final static int SEQ_ID_SLACK = 10;\n-\n-        public ActiveSubscriberState(ByteString topic, ByteString subscriberId,\n-                                     SubscriptionPreferences preferences,\n-                                     long lastLocalSeqIdDelivered,\n-                                     DeliveryEndPoint deliveryEndPoint,\n-                                     ServerMessageFilter filter,\n-                                     Callback<Void> cb, Object ctx) {\n-            this.topic = topic;\n-            this.subscriberId = subscriberId;\n-            this.lastLocalSeqIdDelivered = lastLocalSeqIdDelivered;\n-            this.lastSeqIdConsumedUtil = lastLocalSeqIdDelivered;\n-            this.deliveryEndPoint = deliveryEndPoint;\n-            this.filter = filter;\n-            if (preferences.hasMessageWindowSize()) {\n-                messageWindowSize = preferences.getMessageWindowSize();\n-            } else {\n-                if (FIFODeliveryManager.this.cfg.getDefaultMessageWindowSize() > 0) {\n-                    messageWindowSize =\n-                        FIFODeliveryManager.this.cfg.getDefaultMessageWindowSize();\n-                } else {\n-                    messageWindowSize = UNLIMITED;\n-                }\n-            }\n-            this.cb = cb;\n-            this.ctx = ctx;\n-        }\n-\n-        public void setNotConnected(SubscriptionEvent event) {\n-            this.connectedLock.writeLock().lock();\n-            try {\n-                // have closed it.\n-                if (!connected) {\n-                    return;\n-                }\n-                this.connected = false;\n-                // put itself in ReadAhead queue to cancel outstanding scan request\n-                // if outstanding scan request callback before cancel op executed,\n-                // nothing it would cancel.\n-                if (null != cache && null != outstandingScanRequest) {\n-                    cache.cancelScanRequest(topic, this);\n-                }\n-            } finally {\n-                this.connectedLock.writeLock().unlock();\n-            }\n-\n-            if (null != event &&\n-                (SubscriptionEvent.TOPIC_MOVED == event ||\n-                 SubscriptionEvent.SUBSCRIPTION_FORCED_CLOSED == event)) {\n-                // we should not close the channel now after enabling multiplexing\n-                PubSubResponse response = PubSubResponseUtils.getResponseForSubscriptionEvent(\n-                    topic, subscriberId, event\n-                );\n-                deliveryEndPoint.send(response, new DeliveryCallback() {\n-                    @Override\n-                    public void sendingFinished() {\n-                        // do nothing now\n-                    }\n-                    @Override\n-                    public void transientErrorOnSend() {\n-                        // do nothing now\n-                    }\n-                    @Override\n-                    public void permanentErrorOnSend() {\n-                        // if channel is broken, close the channel\n-                        deliveryEndPoint.close();\n-                    }\n-                });\n-            }\n-            // uninitialize filter\n-            this.filter.uninitialize();\n-        }\n-\n-        public ByteString getTopic() {\n-            return topic;\n-        }\n-\n-        public synchronized long getLastScanErrorTime() {\n-            return lastScanErrorTime;\n-        }\n-\n-        public synchronized void setLastScanErrorTime(long lastScanErrorTime) {\n-            this.lastScanErrorTime = lastScanErrorTime;\n-        }\n-\n-        /**\n-         * Clear the last scan error time so it could be retry immediately.\n-         */\n-        protected synchronized void clearLastScanErrorTime() {\n-            this.lastScanErrorTime = -1;\n-        }\n-\n-        protected boolean isConnected() {\n-            connectedLock.readLock().lock();\n-            try {\n-                return connected;\n-            } finally {\n-                connectedLock.readLock().unlock();\n-            }\n-        }\n-\n-        protected synchronized void messageConsumed(long newSeqIdConsumed) {\n-            if (newSeqIdConsumed <= lastSeqIdConsumedUtil) {\n-                return;\n-            }\n-            if (logger.isDebugEnabled()) {\n-                logger.debug(\"Subscriber ({}) moved consumed ptr from {} to {}.\",\n-                             va(this, lastSeqIdConsumedUtil, newSeqIdConsumed));\n-            }\n-            lastSeqIdConsumedUtil = newSeqIdConsumed;\n-            // after updated seq id check whether it still exceed msg limitation\n-            if (msgLimitExceeded()) {\n-                return;\n-            }\n-            if (isThrottled) {\n-                isThrottled = false;\n-                logger.info(\"Try to wake up subscriber ({}) to deliver messages again : last delivered {}, last consumed {}.\",\n-                            va(this, lastLocalSeqIdDelivered, lastSeqIdConsumedUtil));\n-\n-                enqueueWithoutFailure(topic, new DeliveryManagerRequest() {\n-                    @Override\n-                    public void performRequest() {\n-                        // enqueue\n-                        clearRetryDelayForSubscriber(ActiveSubscriberState.this);\n-                    }\n-                });\n-            }\n-        }\n-\n-        protected boolean msgLimitExceeded() {\n-            if (messageWindowSize == UNLIMITED) {\n-                return false;\n-            }\n-            if (lastLocalSeqIdDelivered - lastSeqIdConsumedUtil >= messageWindowSize) {\n-                return true;\n-            }\n-            return false;\n-        }\n-\n-        public void deliverNextMessage() {\n-            connectedLock.readLock().lock();\n-            try {\n-                doDeliverNextMessage();\n-            } finally {\n-                connectedLock.readLock().unlock();\n-            }\n-        }\n-\n-        private void doDeliverNextMessage() {\n-            if (!connected) {\n-                return;\n-            }\n-\n-            synchronized (this) {\n-                // check whether we have delivered enough messages without receiving their consumes\n-                if (msgLimitExceeded()) {\n-                    logger.info(\"Subscriber ({}) is throttled : last delivered {}, last consumed {}.\",\n-                                va(this, lastLocalSeqIdDelivered, lastSeqIdConsumedUtil));\n-                    isThrottled = true;\n-                    // do nothing, since the delivery process would be throttled.\n-                    // After message consumed, it would be added back to retry queue.\n-                    return;\n-                }\n-\n-                localSeqIdDeliveringNow = persistenceMgr.getSeqIdAfterSkipping(topic, lastLocalSeqIdDelivered, 1);\n-\n-                outstandingScanRequest = new ScanRequest(topic, localSeqIdDeliveringNow,\n-                        /* callback= */this, /* ctx= */null);\n-            }\n-\n-            persistenceMgr.scanSingleMessage(outstandingScanRequest);\n-        }\n-\n-        /**\n-         * ===============================================================\n-         * {@link CancelScanRequest} methods\n-         *\n-         * This method runs ins same threads with ScanCallback. When it runs,\n-         * it checked whether it is outstanding scan request. if there is one,\n-         * cancel it.\n-         */\n-        @Override\n-        public ScanRequest getScanRequest() {\n-            // no race between cancel request and scan callback\n-            // the only race is between stopServing and deliverNextMessage\n-            // deliverNextMessage would be executed in netty callback which is in netty thread\n-            // stopServing is run in delivery thread. if stopServing runs before deliverNextMessage\n-            // deliverNextMessage would have chance to put a stub in ReadAheadCache\n-            // then we don't have any chance to cancel it.\n-            // use connectedLock to avoid such race.\n-            return outstandingScanRequest;\n-        }\n-\n-        private boolean checkConnected() {\n-            connectedLock.readLock().lock();\n-            try {\n-                // message scanned means the outstanding request is executed\n-                outstandingScanRequest = null;\n-                return connected;\n-            } finally {\n-                connectedLock.readLock().unlock();\n-            }\n-        }\n-\n-        /**\n-         * ===============================================================\n-         * {@link ScanCallback} methods\n-         */\n-\n-        public void messageScanned(Object ctx, Message message) {\n-            if (!checkConnected()) {\n-                return;\n-            }\n-\n-            // only increment topic access times when tried to deliver a message\n-            // for those subscribers just waiting for a published for a long time\n-            // we don't increment topic access times, so the topic would be evicted\n-            // in future.\n-            tm.incrementTopicAccessTimes(topic);\n-\n-            if (!filter.testMessage(message)) {\n-                // for filtered out messages, we don't deliver the message to client, so we would not\n-                // receive its consume request which moves the <i>lastSeqIdConsumedUtil</i> pointer.\n-                // we move the <i>lastSeqIdConsumedUtil</i> here for filtered out messages, which would\n-                // avoid a subscriber being throttled due to the message gap introduced by filtering.\n-                //\n-                // it is OK to move <i>lastSeqIdConsumedUtil</i> here, since this pointer is subscriber's\n-                // delivery state which to trottling deliver. changing <i>lastSeqIdConsumedUtil</i> would\n-                // not affect the subscriber's consume pointer in zookeeper which is managed in subscription\n-                // manager.\n-                //\n-                // And marking message consumed before calling sending finished, would avoid the subscriber\n-                // being throttled first and released from throttled state laster.\n-                messageConsumed(message.getMsgId().getLocalComponent());\n-                sendingFinished();\n-                return;\n-            }\n-\n-            /**\n-             * The method below will invoke our sendingFinished() method when\n-             * done\n-             */\n-            PubSubResponse response = PubSubResponse.newBuilder()\n-                                      .setProtocolVersion(ProtocolVersion.VERSION_ONE)\n-                                      .setStatusCode(StatusCode.SUCCESS).setTxnId(0)\n-                                      .setMessage(message).setTopic(topic)\n-                                      .setSubscriberId(subscriberId).build();\n-\n-            deliveryEndPoint.send(response, //\n-                                  // callback =\n-                                  this);\n-\n-        }\n-\n-        @Override\n-        public void scanFailed(Object ctx, Exception exception) {\n-            if (!checkConnected()) {\n-                return;\n-            }\n-\n-            // wait for some time and then retry\n-            retryErroredSubscriberAfterDelay(this);\n-        }\n-\n-        @Override\n-        public void scanFinished(Object ctx, ReasonForFinish reason) {\n-            checkConnected();\n-        }\n-\n-        /**\n-         * ===============================================================\n-         * {@link DeliveryCallback} methods\n-         */\n-        @Override\n-        public void sendingFinished() {\n-            if (!isConnected()) {\n-                return;\n-            }\n-\n-            synchronized (this) {\n-                lastLocalSeqIdDelivered = localSeqIdDeliveringNow;\n-\n-                if (lastLocalSeqIdDelivered > lastSeqIdCommunicatedExternally + SEQ_ID_SLACK) {\n-                    // Note: The order of the next 2 statements is important. We should\n-                    // submit a request to change our delivery pointer only *after* we\n-                    // have actually changed it. Otherwise, there is a race condition\n-                    // with removal of this channel, w.r.t, maintaining the deliveryPtrs\n-                    // tree map.\n-                    long prevId = lastSeqIdCommunicatedExternally;\n-                    lastSeqIdCommunicatedExternally = lastLocalSeqIdDelivered;\n-                    moveDeliveryPtrForward(this, prevId, lastLocalSeqIdDelivered);\n-                }\n-            }\n-            // increment deliveried message\n-            ServerStats.getInstance().incrementMessagesDelivered();\n-            deliverNextMessage();\n-        }\n-\n-        public synchronized long getLastSeqIdCommunicatedExternally() {\n-            return lastSeqIdCommunicatedExternally;\n-        }\n-\n-\n-        @Override\n-        public void permanentErrorOnSend() {\n-            // the underlying channel is broken, the channel will\n-            // be closed in UmbrellaHandler when exception happened.\n-            // so we don't need to close the channel again\n-            stopServingSubscriber(topic, subscriberId, null,\n-                                  NOP_CALLBACK, null);\n-        }\n-\n-        @Override\n-        public void transientErrorOnSend() {\n-            retryErroredSubscriberAfterDelay(this);\n-        }\n-\n-        /**\n-         * ===============================================================\n-         * {@link DeliveryManagerRequest} methods\n-         */\n-        @Override\n-        public void performRequest() {\n-            // Put this subscriber in the channel to subscriber mapping\n-            ActiveSubscriberState prevSubscriber =\n-                subscriberStates.put(new TopicSubscriber(topic, subscriberId), this);\n-\n-            // after put the active subscriber in subscriber states mapping\n-            // trigger the callback to tell it started to deliver the message\n-            // should let subscriber response go first before first delivered message.\n-            cb.operationFinished(ctx, (Void)null);\n-\n-            if (prevSubscriber != null) {\n-                // we already in the delivery thread, we don't need to equeue a stop request\n-                // just stop it now, since stop is not blocking operation.\n-                // and also it cleans the old state of the active subscriber immediately.\n-                SubscriptionEvent se;\n-                if (deliveryEndPoint.equals(prevSubscriber.deliveryEndPoint)) {\n-                    logger.debug(\"Subscriber {} replaced a duplicated subscriber {} at same delivery point {}.\",\n-                                 va(this, prevSubscriber, deliveryEndPoint));\n-                    se = null;\n-                } else {\n-                    logger.debug(\"Subscriber {} from delivery point {} forcelly closed delivery point {}.\",\n-                                 va(this, deliveryEndPoint, prevSubscriber.deliveryEndPoint));\n-                    se = SubscriptionEvent.SUBSCRIPTION_FORCED_CLOSED;\n-                }\n-                doStopServingSubscriber(prevSubscriber, se);\n-            }\n-\n-            synchronized (this) {\n-                lastSeqIdCommunicatedExternally = lastLocalSeqIdDelivered;\n-                addDeliveryPtr(this, lastLocalSeqIdDelivered);\n-            }\n-\n-            deliverNextMessage();\n-        };\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder sb = new StringBuilder();\n-            sb.append(\"Topic: \");\n-            sb.append(topic.toStringUtf8());\n-            sb.append(\"Subscriber: \");\n-            sb.append(subscriberId.toStringUtf8());\n-            sb.append(\", DeliveryPtr: \");\n-            sb.append(lastLocalSeqIdDelivered);\n-            return sb.toString();\n-\n-        }\n-    }\n-\n-    protected class StopServingSubscriber implements DeliveryManagerRequest {\n-        TopicSubscriber ts;\n-        SubscriptionEvent event;\n-        final Callback<Void> cb;\n-        final Object ctx;\n-\n-        public StopServingSubscriber(ByteString topic, ByteString subscriberId,\n-                                     SubscriptionEvent event,\n-                                     Callback<Void> callback, Object ctx) {\n-            this.ts = new TopicSubscriber(topic, subscriberId);\n-            this.event = event;\n-            this.cb = callback;\n-            this.ctx = ctx;\n-        }\n-\n-        @Override\n-        public void performRequest() {\n-            ActiveSubscriberState subscriber = subscriberStates.remove(ts);\n-            if (null != subscriber) {\n-                doStopServingSubscriber(subscriber, event);\n-            }\n-            cb.operationFinished(ctx, null);\n-        }\n-\n-    }\n-\n-    /**\n-     * Stop serving a subscriber. This method should be called in a\n-     * {@link DeliveryManagerRequest}.\n-     *\n-     * @param subscriber\n-     *          Active Subscriber to stop\n-     * @param event\n-     *          Subscription Event for the stop reason\n-     */\n-    private void doStopServingSubscriber(ActiveSubscriberState subscriber, SubscriptionEvent event) {\n-        // This will automatically stop delivery, and disconnect the channel\n-        subscriber.setNotConnected(event);\n-\n-        // if the subscriber has moved on, a move request for its delivery\n-        // pointer must be pending in the request queue. Note that the\n-        // subscriber first changes its delivery pointer and then submits a\n-        // request to move so this works.\n-        removeDeliveryPtr(subscriber, subscriber.getLastSeqIdCommunicatedExternally(), //\n-                          // isAbsenceOk=\n-                          true,\n-                          // pruneTopic=\n-                          true);\n-    }\n-\n-    protected class DeliveryPtrMove implements DeliveryManagerRequest {\n-\n-        ActiveSubscriberState subscriber;\n-        Long oldSeqId;\n-        Long newSeqId;\n-\n-        public DeliveryPtrMove(ActiveSubscriberState subscriber, Long oldSeqId, Long newSeqId) {\n-            this.subscriber = subscriber;\n-            this.oldSeqId = oldSeqId;\n-            this.newSeqId = newSeqId;\n-        }\n-\n-        @Override\n-        public void performRequest() {\n-            ByteString topic = subscriber.getTopic();\n-            long prevMinSeqId = getMinimumSeqId(topic);\n-\n-            if (subscriber.isConnected()) {\n-                removeDeliveryPtr(subscriber, oldSeqId, //\n-                                  // isAbsenceOk=\n-                                  false,\n-                                  // pruneTopic=\n-                                  false);\n-\n-                addDeliveryPtr(subscriber, newSeqId);\n-            } else {\n-                removeDeliveryPtr(subscriber, oldSeqId, //\n-                                  // isAbsenceOk=\n-                                  true,\n-                                  // pruneTopic=\n-                                  true);\n-            }\n-\n-            long nowMinSeqId = getMinimumSeqId(topic);\n-\n-            if (nowMinSeqId > prevMinSeqId) {\n-                persistenceMgr.deliveredUntil(topic, nowMinSeqId);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * ====================================================================\n-     *\n-     * Dumb factories for our map methods\n-     */\n-    protected static class TreeMapLongToSetSubscriberFactory implements\n-        Factory<SortedMap<Long, Set<ActiveSubscriberState>>> {\n-        static TreeMapLongToSetSubscriberFactory instance = new TreeMapLongToSetSubscriberFactory();\n-\n-        @Override\n-        public SortedMap<Long, Set<ActiveSubscriberState>> newInstance() {\n-            return new TreeMap<Long, Set<ActiveSubscriberState>>();\n-        }\n-    }\n-\n-    protected static class HashMapSubscriberFactory implements Factory<Set<ActiveSubscriberState>> {\n-        static HashMapSubscriberFactory instance = new HashMapSubscriberFactory();\n-\n-        @Override\n-        public Set<ActiveSubscriberState> newInstance() {\n-            return new HashSet<ActiveSubscriberState>();\n-        }\n-    }\n-\n-    @Override\n-    public void onSubChannelDisconnected(TopicSubscriber topicSubscriber) {\n-        stopServingSubscriber(topicSubscriber.getTopic(), topicSubscriber.getSubscriberId(),\n-                null, NOP_CALLBACK, null);\n-    }\n-\n-}"},{"sha":"4189eb66e11887c207a4b9b1ff30285f8f244ae9","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/BaseHandler.java","status":"removed","additions":0,"deletions":67,"changes":67,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/BaseHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/BaseHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/BaseHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,67 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-\n-public abstract class BaseHandler implements Handler {\n-\n-    protected TopicManager topicMgr;\n-    protected ServerConfiguration cfg;\n-\n-    protected BaseHandler(TopicManager tm, ServerConfiguration cfg) {\n-        this.topicMgr = tm;\n-        this.cfg = cfg;\n-    }\n-\n-\n-    public void handleRequest(final PubSubRequest request, final Channel channel) {\n-        topicMgr.getOwner(request.getTopic(), request.getShouldClaim(),\n-        new Callback<HedwigSocketAddress>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                ServerStats.getInstance().getOpStats(request.getType()).incrementFailedOps();\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, HedwigSocketAddress owner) {\n-                if (!owner.equals(cfg.getServerAddr())) {\n-                    channel.write(PubSubResponseUtils.getResponseForException(\n-                                      new ServerNotResponsibleForTopicException(owner.toString()), request.getTxnId()));\n-                    ServerStats.getInstance().incrementRequestsRedirect();\n-                    return;\n-                }\n-                handleRequestAtOwner(request, channel);\n-            }\n-        }, null);\n-    }\n-\n-    public abstract void handleRequestAtOwner(PubSubRequest request, Channel channel);\n-\n-}"},{"sha":"458d301fd2f4edce4cf6373979e1e4e149cc5184","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ChannelDisconnectListener.java","status":"removed","additions":0,"deletions":29,"changes":29,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ChannelDisconnectListener.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ChannelDisconnectListener.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ChannelDisconnectListener.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,29 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-public interface ChannelDisconnectListener {\n-\n-    /**\n-     * Act on a particular channel being disconnected\n-     * @param channel\n-     */\n-    public void channelDisconnected(Channel channel);\n-}"},{"sha":"a6ccb7ebbff4fed6a5136e97397ec691203723a5","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/CloseSubscriptionHandler.java","status":"removed","additions":0,"deletions":105,"changes":105,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/CloseSubscriptionHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/CloseSubscriptionHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/CloseSubscriptionHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,105 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.CloseSubscriptionRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.netty.ServerStats.OpStats;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.server.subscriptions.SubscriptionManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class CloseSubscriptionHandler extends BaseHandler {\n-    SubscriptionManager subMgr;\n-    DeliveryManager deliveryMgr;\n-    SubscriptionChannelManager subChannelMgr;\n-    // op stats\n-    final OpStats closesubStats;\n-\n-    public CloseSubscriptionHandler(ServerConfiguration cfg, TopicManager tm,\n-                                    SubscriptionManager subMgr,\n-                                    DeliveryManager deliveryMgr,\n-                                    SubscriptionChannelManager subChannelMgr) {\n-        super(tm, cfg);\n-        this.subMgr = subMgr;\n-        this.deliveryMgr = deliveryMgr;\n-        this.subChannelMgr = subChannelMgr;\n-        closesubStats = ServerStats.getInstance().getOpStats(OperationType.CLOSESUBSCRIPTION);\n-    }\n-\n-    @Override\n-    public void handleRequestAtOwner(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasCloseSubscriptionRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing closesubscription request data\");\n-            closesubStats.incrementFailedOps();\n-            return;\n-        }\n-\n-        final CloseSubscriptionRequest closesubRequest =\n-                request.getCloseSubscriptionRequest();\n-        final ByteString topic = request.getTopic();\n-        final ByteString subscriberId = closesubRequest.getSubscriberId();\n-\n-        final long requestTime = System.currentTimeMillis();\n-\n-        subMgr.closeSubscription(topic, subscriberId, new Callback<Void>() {\n-            @Override\n-            public void operationFinished(Object ctx, Void result) {\n-                // we should not close the channel in delivery manager\n-                // since client waits the response for closeSubscription request\n-                // client side would close the channel\n-                deliveryMgr.stopServingSubscriber(topic, subscriberId, null,\n-                new Callback<Void>() {\n-                    @Override\n-                    public void operationFailed(Object ctx, PubSubException exception) {\n-                        channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                        closesubStats.incrementFailedOps();\n-                    }\n-                    @Override\n-                    public void operationFinished(Object ctx, Void resultOfOperation) {\n-                        // remove the topic subscription from subscription channels\n-                        subChannelMgr.remove(new TopicSubscriber(topic, subscriberId),\n-                                             channel);\n-                        channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-                        closesubStats.updateLatency(System.currentTimeMillis() - requestTime);\n-                    }\n-                }, null);\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                closesubStats.incrementFailedOps();\n-            }\n-        }, null);\n-    }\n-}"},{"sha":"5042a37eea8cbba676750750cda1cdad2e62194e","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ConsumeHandler.java","status":"removed","additions":0,"deletions":72,"changes":72,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ConsumeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ConsumeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/ConsumeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,72 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.ConsumeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.server.netty.ServerStats.OpStats;\n-import org.apache.hedwig.server.subscriptions.SubscriptionManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ConsumeHandler extends BaseHandler {\n-\n-    SubscriptionManager sm;\n-    Callback<Void> noopCallback = new NoopCallback<Void>();\n-    final OpStats consumeStats = ServerStats.getInstance().getOpStats(OperationType.CONSUME);\n-\n-    class NoopCallback<T> implements Callback<T> {\n-        @Override\n-        public void operationFailed(Object ctx, PubSubException exception) {\n-            consumeStats.incrementFailedOps();\n-        }\n-\n-        public void operationFinished(Object ctx, T resultOfOperation) {\n-            // we don't collect consume process time\n-            consumeStats.updateLatency(0);\n-        };\n-    }\n-\n-    @Override\n-    public void handleRequestAtOwner(PubSubRequest request, Channel channel) {\n-        if (!request.hasConsumeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing consume request data\");\n-            consumeStats.incrementFailedOps();\n-            return;\n-        }\n-\n-        ConsumeRequest consumeRequest = request.getConsumeRequest();\n-\n-        sm.setConsumeSeqIdForSubscriber(request.getTopic(), consumeRequest.getSubscriberId(),\n-                                        consumeRequest.getMsgId(), noopCallback, null);\n-\n-    }\n-\n-    public ConsumeHandler(TopicManager tm, SubscriptionManager sm, ServerConfiguration cfg) {\n-        super(tm, cfg);\n-        this.sm = sm;\n-    }\n-}"},{"sha":"c391f5c1c24f9115e96214a7cf4b13c342bd4ace","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/Handler.java","status":"removed","additions":0,"deletions":37,"changes":37,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/Handler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/Handler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/Handler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,37 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-\n-public interface Handler {\n-\n-    /**\n-     * Handle a request synchronously or asynchronously. After handling the\n-     * request, the appropriate response should be written on the given channel\n-     *\n-     * @param request\n-     *            The request to handle\n-     *\n-     * @param channel\n-     *            The channel on which to write the response\n-     */\n-    public void handleRequest(final PubSubRequest request, final Channel channel);\n-}"},{"sha":"e0f14873640e8af0eca4e274ee49d806537c79c8","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerBean.java","status":"removed","additions":0,"deletions":47,"changes":47,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,47 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.handlers;\n-\n-import org.apache.hedwig.server.handlers.SubscriptionChannelManager;\n-import org.apache.hedwig.server.jmx.HedwigMBeanInfo;\n-\n-public class NettyHandlerBean implements NettyHandlerMXBean, HedwigMBeanInfo {\n-\n-    SubscriptionChannelManager subChannelMgr;\n-\n-   public NettyHandlerBean(SubscriptionChannelManager subChannelMgr) {\n-       this.subChannelMgr = subChannelMgr;\n-    }\n-\n-    @Override\n-    public String getName() {\n-        return \"NettyHandlers\";\n-    }\n-\n-    @Override\n-    public boolean isHidden() {\n-        return false;\n-    }\n-\n-    @Override\n-    public int getNumSubscriptionChannels() {\n-        return subChannelMgr.getNumSubscriptionChannels();\n-    }\n-\n-}"},{"sha":"ab8af29648879b66d0bd2f939dfe02dface4a630","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerMXBean.java","status":"removed","additions":0,"deletions":31,"changes":31,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerMXBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerMXBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/NettyHandlerMXBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,31 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.handlers;\n-\n-/**\n- * Netty Handler MBean\n- */\n-public interface NettyHandlerMXBean {\n-\n-    /**\n-     * @return number of subscription channels\n-     */\n-    public int getNumSubscriptionChannels();\n-\n-}"},{"sha":"587f904f1d00375b73fe1b22fc1b395cb44f017a","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/PublishHandler.java","status":"removed","additions":0,"deletions":90,"changes":90,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/PublishHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/PublishHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/PublishHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,90 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.jboss.netty.channel.Channel;\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.netty.ServerStats.OpStats;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.server.persistence.PersistRequest;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class PublishHandler extends BaseHandler {\n-\n-    private PersistenceManager persistenceMgr;\n-    private final OpStats pubStats;\n-\n-    public PublishHandler(TopicManager topicMgr, PersistenceManager persistenceMgr, ServerConfiguration cfg) {\n-        super(topicMgr, cfg);\n-        this.persistenceMgr = persistenceMgr;\n-        this.pubStats = ServerStats.getInstance().getOpStats(OperationType.PUBLISH);\n-    }\n-\n-    @Override\n-    public void handleRequestAtOwner(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasPublishRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing publish request data\");\n-            pubStats.incrementFailedOps();\n-            return;\n-        }\n-\n-        Message msgToSerialize = Message.newBuilder(request.getPublishRequest().getMsg()).setSrcRegion(\n-                                     cfg.getMyRegionByteString()).build();\n-\n-        final long requestTime = MathUtils.now();\n-        PersistRequest persistRequest = new PersistRequest(request.getTopic(), msgToSerialize,\n-        new Callback<PubSubProtocol.MessageSeqId>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                pubStats.incrementFailedOps();\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, PubSubProtocol.MessageSeqId resultOfOperation) {\n-                channel.write(getSuccessResponse(request.getTxnId(), resultOfOperation));\n-                pubStats.updateLatency(MathUtils.now() - requestTime);\n-            }\n-        }, null);\n-\n-        persistenceMgr.persistMessage(persistRequest);\n-    }\n-\n-    private static PubSubProtocol.PubSubResponse getSuccessResponse(long txnId, PubSubProtocol.MessageSeqId publishedMessageSeqId) {\n-        if (null == publishedMessageSeqId) {\n-            return PubSubResponseUtils.getSuccessResponse(txnId);\n-        }\n-        PubSubProtocol.PublishResponse publishResponse = PubSubProtocol.PublishResponse.newBuilder().setPublishedMsgId(publishedMessageSeqId).build();\n-        PubSubProtocol.ResponseBody responseBody = PubSubProtocol.ResponseBody.newBuilder().setPublishResponse(publishResponse).build();\n-        return PubSubProtocol.PubSubResponse.newBuilder().\n-            setProtocolVersion(PubSubResponseUtils.serverVersion).\n-            setStatusCode(PubSubProtocol.StatusCode.SUCCESS).setTxnId(txnId).\n-            setResponseBody(responseBody).build();\n-    }\n-}"},{"sha":"6df70a3f8ac577471556bc477033338a1cc769c6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscribeHandler.java","status":"removed","additions":0,"deletions":221,"changes":221,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscribeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscribeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscribeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,221 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.bookkeeper.util.ReflectionUtils;\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n-import org.apache.hedwig.filter.PipelineFilter;\n-import org.apache.hedwig.filter.ServerMessageFilter;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.ResponseBody;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeResponse;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.delivery.ChannelEndPoint;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.netty.ServerStats.OpStats;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.subscriptions.SubscriptionManager;\n-import org.apache.hedwig.server.subscriptions.AllToAllTopologyFilter;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class SubscribeHandler extends BaseHandler {\n-    private static final Logger logger = LoggerFactory.getLogger(SubscribeHandler.class);\n-\n-    private final DeliveryManager deliveryMgr;\n-    private final PersistenceManager persistenceMgr;\n-    private final SubscriptionManager subMgr;\n-    private final SubscriptionChannelManager subChannelMgr;\n-\n-    // op stats\n-    private final OpStats subStats;\n-\n-    public SubscribeHandler(ServerConfiguration cfg, TopicManager topicMgr,\n-                            DeliveryManager deliveryManager,\n-                            PersistenceManager persistenceMgr,\n-                            SubscriptionManager subMgr,\n-                            SubscriptionChannelManager subChannelMgr) {\n-        super(topicMgr, cfg);\n-        this.deliveryMgr = deliveryManager;\n-        this.persistenceMgr = persistenceMgr;\n-        this.subMgr = subMgr;\n-        this.subChannelMgr = subChannelMgr;\n-        subStats = ServerStats.getInstance().getOpStats(OperationType.SUBSCRIBE);\n-    }\n-\n-    @Override\n-    public void handleRequestAtOwner(final PubSubRequest request, final Channel channel) {\n-\n-        if (!request.hasSubscribeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing subscribe request data\");\n-            subStats.incrementFailedOps();\n-            return;\n-        }\n-\n-        final ByteString topic = request.getTopic();\n-\n-        MessageSeqId seqId;\n-        try {\n-            seqId = persistenceMgr.getCurrentSeqIdForTopic(topic);\n-        } catch (ServerNotResponsibleForTopicException e) {\n-            channel.write(PubSubResponseUtils.getResponseForException(e, request.getTxnId())).addListener(\n-                ChannelFutureListener.CLOSE);\n-            logger.error(\"Error getting current seq id for topic \" + topic.toStringUtf8()\n-                       + \" when processing subscribe request (txnid:\" + request.getTxnId() + \") :\", e);\n-            subStats.incrementFailedOps();\n-            ServerStats.getInstance().incrementRequestsRedirect();\n-            return;\n-        }\n-\n-        final SubscribeRequest subRequest = request.getSubscribeRequest();\n-        final ByteString subscriberId = subRequest.getSubscriberId();\n-\n-        MessageSeqId lastSeqIdPublished = MessageSeqId.newBuilder(seqId).setLocalComponent(seqId.getLocalComponent()).build();\n-\n-        final long requestTime = MathUtils.now();\n-        subMgr.serveSubscribeRequest(topic, subRequest, lastSeqIdPublished, new Callback<SubscriptionData>() {\n-\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId())).addListener(\n-                    ChannelFutureListener.CLOSE);\n-                logger.error(\"Error serving subscribe request (\" + request.getTxnId() + \") for (topic: \"\n-                           + topic.toStringUtf8() + \" , subscriber: \" + subscriberId.toStringUtf8() + \")\", exception);\n-                subStats.incrementFailedOps();\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, final SubscriptionData subData) {\n-\n-                TopicSubscriber topicSub = new TopicSubscriber(topic, subscriberId);\n-                synchronized (channel) {\n-                    if (!channel.isConnected()) {\n-                        // channel got disconnected while we were processing the\n-                        // subscribe request,\n-                        // nothing much we can do in this case\n-                        subStats.incrementFailedOps();\n-                        return;\n-                    }\n-                }\n-                // initialize the message filter\n-                PipelineFilter filter = new PipelineFilter();\n-                try {\n-                    // the filter pipeline should be\n-                    // 1) AllToAllTopologyFilter to filter cross-region messages\n-                    filter.addLast(new AllToAllTopologyFilter());\n-                    // 2) User-Customized MessageFilter\n-                    if (subData.hasPreferences() &&\n-                        subData.getPreferences().hasMessageFilter()) {\n-                        String messageFilterName = subData.getPreferences().getMessageFilter();\n-                        filter.addLast(ReflectionUtils.newInstance(messageFilterName, ServerMessageFilter.class));\n-                    }\n-                    // initialize the filter\n-                    filter.initialize(cfg.getConf());\n-                    filter.setSubscriptionPreferences(topic, subscriberId,\n-                                                      subData.getPreferences());\n-                } catch (RuntimeException re) {\n-                    String errMsg = \"RuntimeException caught when instantiating message filter for (topic:\"\n-                                  + topic.toStringUtf8() + \", subscriber:\" + subscriberId.toStringUtf8() + \").\"\n-                                  + \"It might be introduced by programming error in message filter.\";\n-                    logger.error(errMsg, re);\n-                    PubSubException pse = new PubSubException.InvalidMessageFilterException(errMsg, re);\n-                    subStats.incrementFailedOps();\n-                    // we should not close the subscription channel, just response error\n-                    // client decide to close it or not.\n-                    channel.write(PubSubResponseUtils.getResponseForException(pse, request.getTxnId()));\n-                    return;\n-                } catch (Throwable t) {\n-                    String errMsg = \"Failed to instantiate message filter for (topic:\" + topic.toStringUtf8()\n-                                  + \", subscriber:\" + subscriberId.toStringUtf8() + \").\";\n-                    logger.error(errMsg, t);\n-                    PubSubException pse = new PubSubException.InvalidMessageFilterException(errMsg, t);\n-                    subStats.incrementFailedOps();\n-                    channel.write(PubSubResponseUtils.getResponseForException(pse, request.getTxnId()))\n-                    .addListener(ChannelFutureListener.CLOSE);\n-                    return;\n-                }\n-                boolean forceAttach = false;\n-                if (subRequest.hasForceAttach()) {\n-                    forceAttach = subRequest.getForceAttach();\n-                }\n-                // Try to store the subscription channel for the topic subscriber\n-                Channel oldChannel = subChannelMgr.put(topicSub, channel, forceAttach);\n-                if (null != oldChannel) {\n-                    PubSubException pse = new PubSubException.TopicBusyException(\n-                        \"Subscriber \" + subscriberId.toStringUtf8() + \" for topic \" + topic.toStringUtf8()\n-                        + \" is already being served on a different channel \" + oldChannel + \".\");\n-                    subStats.incrementFailedOps();\n-                    channel.write(PubSubResponseUtils.getResponseForException(pse, request.getTxnId()))\n-                    .addListener(ChannelFutureListener.CLOSE);\n-                    return;\n-                }\n-\n-                // want to start 1 ahead of the consume ptr\n-                MessageSeqId lastConsumedSeqId = subData.getState().getMsgId();\n-                MessageSeqId seqIdToStartFrom = MessageSeqId.newBuilder(lastConsumedSeqId).setLocalComponent(\n-                                                    lastConsumedSeqId.getLocalComponent() + 1).build();\n-                deliveryMgr.startServingSubscription(topic, subscriberId,\n-                        subData.getPreferences(), seqIdToStartFrom, new ChannelEndPoint(channel), filter,\n-                        new Callback<Void>() {\n-                            @Override\n-                            public void operationFinished(Object ctx, Void result) {\n-                                // First write success and then tell the delivery manager,\n-                                // otherwise the first message might go out before the response\n-                                // to the subscribe\n-                                SubscribeResponse.Builder subRespBuilder = SubscribeResponse.newBuilder()\n-                                    .setPreferences(subData.getPreferences());\n-                                ResponseBody respBody = ResponseBody.newBuilder()\n-                                    .setSubscribeResponse(subRespBuilder).build();\n-                                channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId(), respBody));\n-                                logger.info(\"Subscribe request (\" + request.getTxnId() + \") for (topic:\"\n-                                            + topic.toStringUtf8() + \", subscriber:\" + subscriberId.toStringUtf8()\n-                                            + \") from channel \" + channel.getRemoteAddress()\n-                                            + \" succeed - its subscription data is \"\n-                                            + SubscriptionStateUtils.toString(subData));\n-                                subStats.updateLatency(MathUtils.now() - requestTime);\n-                            }\n-                            @Override\n-                            public void operationFailed(Object ctx, PubSubException exception) {\n-                                // would not happened\n-                            }\n-                        }, null);\n-            }\n-        }, null);\n-\n-    }\n-\n-}"},{"sha":"3481d8181292e224e3b91bb0178273c5bad96982","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscriptionChannelManager.java","status":"removed","additions":0,"deletions":213,"changes":213,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscriptionChannelManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscriptionChannelManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/SubscriptionChannelManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,213 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import java.util.ArrayList;\n-import java.util.HashSet;\n-import java.util.List;\n-import java.util.Set;\n-import java.util.concurrent.ConcurrentHashMap;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFuture;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import static org.apache.hedwig.util.VarArgs.va;\n-\n-public class SubscriptionChannelManager implements ChannelDisconnectListener {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(SubscriptionChannelManager.class);\n-\n-    static class CloseSubscriptionListener implements ChannelFutureListener {\n-\n-        final TopicSubscriber ts;\n-\n-        CloseSubscriptionListener(TopicSubscriber topicSubscriber) {\n-            this.ts = topicSubscriber;\n-        }\n-\n-        @Override\n-        public void operationComplete(ChannelFuture future) throws Exception {\n-            if (!future.isSuccess()) {\n-                logger.warn(\"Failed to write response to close old subscription {}.\", ts);\n-            } else {\n-                logger.debug(\"Close old subscription {} succeed.\", ts);\n-            }\n-        }\n-    };\n-\n-    final List<SubChannelDisconnectedListener> listeners;\n-\n-    public interface SubChannelDisconnectedListener {\n-        /**\n-         * Act on a particular topicSubscriber being disconnected\n-         * @param topicSubscriber\n-         */\n-        public void onSubChannelDisconnected(TopicSubscriber topicSubscriber);\n-    }\n-\n-    final ConcurrentHashMap<TopicSubscriber, Channel> sub2Channel;\n-    final ConcurrentHashMap<Channel, Set<TopicSubscriber>> channel2sub;\n-\n-    public SubscriptionChannelManager() {\n-        sub2Channel = new ConcurrentHashMap<TopicSubscriber, Channel>();\n-        channel2sub = new ConcurrentHashMap<Channel, Set<TopicSubscriber>>();\n-        listeners = new ArrayList<SubChannelDisconnectedListener>();\n-    }\n-\n-    public void addSubChannelDisconnectedListener(SubChannelDisconnectedListener listener) {\n-        if (null != listener) {\n-            listeners.add(listener);\n-        }\n-    }\n-\n-    @Override\n-    public void channelDisconnected(Channel channel) {\n-        // Evils of synchronized programming: there is a race between a channel\n-        // getting disconnected, and us adding it to the maps when a subscribe\n-        // succeeds\n-        Set<TopicSubscriber> topicSubs;\n-        synchronized (channel) {\n-            topicSubs = channel2sub.remove(channel);\n-        }\n-        if (topicSubs != null) {\n-            for (TopicSubscriber topicSub : topicSubs) {\n-                logger.info(\"Subscription channel {} for {} is disconnected.\",\n-                            va(channel.getRemoteAddress(), topicSub));\n-                // remove entry only currently mapped to given value.\n-                sub2Channel.remove(topicSub, channel);\n-                for (SubChannelDisconnectedListener listener : listeners) {\n-                    listener.onSubChannelDisconnected(topicSub);\n-                }\n-            }\n-        }\n-    }\n-\n-    public int getNumSubscriptionChannels() {\n-        return channel2sub.size();\n-    }\n-\n-    public int getNumSubscriptions() {\n-        return sub2Channel.size();\n-    }\n-\n-    /**\n-     * Put <code>topicSub</code> on Channel <code>channel</code>.\n-     *\n-     * @param topicSub\n-     *          Topic Subscription\n-     * @param channel\n-     *          Netty channel\n-     * @param mode\n-     *          Create or Attach mode\n-     * @return null succeed, otherwise the old existed channel.\n-     */\n-    public Channel put(TopicSubscriber topicSub, Channel channel, boolean forceAttach) {\n-        // race with channel getting disconnected while we are adding it\n-        // to the 2 maps\n-        synchronized (channel) {\n-            Channel oldChannel = sub2Channel.putIfAbsent(topicSub, channel);\n-            // if a subscribe request send from same channel,\n-            // we treated it a success action.\n-            if (null != oldChannel && !oldChannel.equals(channel)) {\n-                boolean subSuccess = false;\n-                if (forceAttach) {\n-                    // it is safe to close old subscription here since the new subscription\n-                    // has come from other channel succeed.\n-                    synchronized (oldChannel) {\n-                        Set<TopicSubscriber> oldTopicSubs = channel2sub.get(oldChannel);\n-                        if (null != oldTopicSubs) {\n-                            if (!oldTopicSubs.remove(topicSub)) {\n-                                logger.warn(\"Failed to remove old subscription ({}) due to it isn't on channel ({}).\",\n-                                            va(topicSub, oldChannel));\n-                            } else if (oldTopicSubs.isEmpty()) {\n-                                channel2sub.remove(oldChannel);\n-                            }\n-                        }\n-                    }\n-                    PubSubResponse resp = PubSubResponseUtils.getResponseForSubscriptionEvent(\n-                        topicSub.getTopic(), topicSub.getSubscriberId(),\n-                        SubscriptionEvent.SUBSCRIPTION_FORCED_CLOSED\n-                    );\n-                    oldChannel.write(resp).addListener(new CloseSubscriptionListener(topicSub));\n-                    logger.info(\"Subscribe request for ({}) from channel ({}) closes old subscripiton on channel ({}).\",\n-                                va(topicSub, channel, oldChannel));\n-                    // try replace the oldChannel\n-                    // if replace failure, it migth caused because channelDisconnect callback\n-                    // has removed the old channel.\n-                    if (!sub2Channel.replace(topicSub, oldChannel, channel)) {\n-                        // try to add it now.\n-                        // if add failure, it means other one has obtained the channel\n-                        oldChannel = sub2Channel.putIfAbsent(topicSub, channel);\n-                        if (null == oldChannel) {\n-                            subSuccess = true;\n-                        }\n-                    } else {\n-                        subSuccess = true;\n-                    }\n-                }\n-                if (!subSuccess) {\n-                    logger.error(\"Error serving subscribe request for ({}) from ({}) since it already served on ({}).\",\n-                                 va(topicSub, channel, oldChannel));\n-                    return oldChannel;\n-                }\n-            }\n-            // channel2sub is just a cache, so we can add to it\n-            // without synchronization\n-            Set<TopicSubscriber> topicSubs = channel2sub.get(channel);\n-            if (null == topicSubs) {\n-                topicSubs = new HashSet<TopicSubscriber>();\n-                channel2sub.put(channel, topicSubs); \n-            }\n-            topicSubs.add(topicSub);\n-            return null;\n-        }\n-    }\n-\n-    /**\n-     * Remove <code>topicSub</code> from Channel <code>channel</code>\n-     *\n-     * @param topicSub\n-     *          Topic Subscription\n-     * @param channel\n-     *          Netty channel\n-     */\n-    public void remove(TopicSubscriber topicSub, Channel channel) {\n-        synchronized (channel) {\n-            Set<TopicSubscriber> topicSubs = channel2sub.get(channel);\n-            if (null != topicSubs) {\n-                if (!topicSubs.remove(topicSub)) {\n-                    logger.warn(\"Failed to remove subscription ({}) due to it isn't on channel ({}).\",\n-                                va(topicSub, channel));\n-                } else if (topicSubs.isEmpty()) {\n-                    channel2sub.remove(channel);\n-                }\n-            }\n-            if (!sub2Channel.remove(topicSub, channel)) {\n-                logger.warn(\"Failed to remove channel ({}) due to it isn't ({})'s channel.\",\n-                            va(channel, topicSub));\n-            }\n-        }\n-    }\n-}"},{"sha":"3838e96f2a60b493cb28aca7e5b9d660820e91eb","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/handlers/UnsubscribeHandler.java","status":"removed","additions":0,"deletions":105,"changes":105,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/UnsubscribeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/UnsubscribeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/handlers/UnsubscribeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,105 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.handlers;\n-\n-import org.jboss.netty.channel.Channel;\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.UnsubscribeRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.netty.ServerStats;\n-import org.apache.hedwig.server.netty.ServerStats.OpStats;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.server.subscriptions.SubscriptionManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-\n-public class UnsubscribeHandler extends BaseHandler {\n-    SubscriptionManager subMgr;\n-    DeliveryManager deliveryMgr;\n-    SubscriptionChannelManager subChannelMgr;\n-    // op stats\n-    final OpStats unsubStats;\n-\n-    public UnsubscribeHandler(ServerConfiguration cfg,\n-                              TopicManager tm,\n-                              SubscriptionManager subMgr,\n-                              DeliveryManager deliveryMgr,\n-                              SubscriptionChannelManager subChannelMgr) {\n-        super(tm, cfg);\n-        this.subMgr = subMgr;\n-        this.deliveryMgr = deliveryMgr;\n-        this.subChannelMgr = subChannelMgr;\n-        unsubStats = ServerStats.getInstance().getOpStats(OperationType.UNSUBSCRIBE);\n-    }\n-\n-    @Override\n-    public void handleRequestAtOwner(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasUnsubscribeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing unsubscribe request data\");\n-            unsubStats.incrementFailedOps();\n-            return;\n-        }\n-\n-        final UnsubscribeRequest unsubRequest = request.getUnsubscribeRequest();\n-        final ByteString topic = request.getTopic();\n-        final ByteString subscriberId = unsubRequest.getSubscriberId();\n-\n-        final long requestTime = MathUtils.now();\n-        subMgr.unsubscribe(topic, subscriberId, new Callback<Void>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                unsubStats.incrementFailedOps();\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                // we should not close the channel in delivery manager\n-                // since client waits the response for closeSubscription request\n-                // client side would close the channel\n-                deliveryMgr.stopServingSubscriber(topic, subscriberId, null,\n-                new Callback<Void>() {\n-                    @Override\n-                    public void operationFailed(Object ctx, PubSubException exception) {\n-                        channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                        unsubStats.incrementFailedOps();\n-                    }\n-                    @Override\n-                    public void operationFinished(Object ctx, Void resultOfOperation) {\n-                        // remove the topic subscription from subscription channels\n-                        subChannelMgr.remove(new TopicSubscriber(topic, subscriberId),\n-                                             channel);\n-                        channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-                        unsubStats.updateLatency(System.currentTimeMillis() - requestTime);\n-                    }\n-                }, ctx);\n-            }\n-        }, null);\n-\n-    }\n-\n-}"},{"sha":"f0081d99b710564156532379508957019fb9854d","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigJMXService.java","status":"removed","additions":0,"deletions":37,"changes":37,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigJMXService.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigJMXService.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigJMXService.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,37 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.jmx;\n-\n-/**\n- * An implementor of this interface is basiclly responsible for jmx beans.\n- */\n-public interface HedwigJMXService {\n-    /**\n-     * register jmx\n-     *\n-     * @param parent\n-     *          Parent JMX Bean\n-     */\n-    public void registerJMX(HedwigMBeanInfo parent);\n-\n-    /**\n-     * unregister jmx\n-     */\n-    public void unregisterJMX();\n-}"},{"sha":"866a2173ac4a14db6f2e2a5202d4c45a13c7f3db","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanInfo.java","status":"removed","additions":0,"deletions":27,"changes":27,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanInfo.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,27 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.jmx;\n-\n-import org.apache.zookeeper.jmx.ZKMBeanInfo;\n-\n-/**\n- * Hedwig MBean info interface.\n- */\n-public interface HedwigMBeanInfo extends ZKMBeanInfo {\n-}"},{"sha":"563cae8e1b5d87028b380047ddb2ca5ad5695bbb","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanRegistry.java","status":"removed","additions":0,"deletions":48,"changes":48,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanRegistry.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanRegistry.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/jmx/HedwigMBeanRegistry.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,48 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.jmx;\n-\n-import javax.management.MalformedObjectNameException;\n-import javax.management.ObjectName;\n-\n-import org.apache.bookkeeper.jmx.BKMBeanRegistry;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * This class provides a unified interface for registering/unregistering of\n- * Hedwig MBeans with the platform MBean server.\n- */\n-public class HedwigMBeanRegistry extends BKMBeanRegistry {\n-\n-    static final String SERVICE = \"org.apache.HedwigServer\";\n-\n-    static HedwigMBeanRegistry instance = new HedwigMBeanRegistry();\n-\n-    public static HedwigMBeanRegistry getInstance(){\n-        return instance;\n-    }\n-\n-    @Override\n-    protected String getDomainName() {\n-        return SERVICE;\n-    }\n-\n-}"},{"sha":"a4253f89726d5a5582d62977a497fff16b57b88f","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/FactoryLayout.java","status":"removed","additions":0,"deletions":167,"changes":167,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/FactoryLayout.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/FactoryLayout.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/FactoryLayout.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,167 +0,0 @@\n-package org.apache.hedwig.server.meta;\n-\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-import java.io.BufferedReader;\n-import java.io.IOException;\n-import java.io.StringReader;\n-\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.ZooDefs.Ids;\n-import org.apache.zookeeper.ZooKeeper;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.protobuf.TextFormat;\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import org.apache.hedwig.protocol.PubSubProtocol.ManagerMeta;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.zookeeper.ZkUtils;\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-/**\n- * This class encapsulates metadata manager layout information\n- * that is persistently stored in zookeeper.\n- * It provides parsing and serialization methods of such information.\n- *\n- */\n-public class FactoryLayout {\n-    private static final Logger logger = LoggerFactory.getLogger(FactoryLayout.class);\n-\n-    // metadata manager name\n-    public static final String NAME = \"METADATA\";\n-    // Znode name to store layout information\n-    public static final String LAYOUT_ZNODE = \"LAYOUT\";\n-    public static final String LSEP = \"\\n\";\n-\n-    private ManagerMeta managerMeta;\n-\n-    /**\n-     * Construct metadata manager factory layout.\n-     *\n-     * @param meta\n-     *          Meta describes what kind of factory used.\n-     */\n-    public FactoryLayout(ManagerMeta meta) {\n-        this.managerMeta = meta;\n-    }\n-\n-    public static String getFactoryLayoutPath(StringBuilder sb, ServerConfiguration cfg) {\n-        return cfg.getZkManagersPrefix(sb).append(\"/\").append(NAME)\n-               .append(\"/\").append(LAYOUT_ZNODE).toString();\n-    }\n-\n-    public ManagerMeta getManagerMeta() {\n-        return managerMeta;\n-    }\n-\n-    /**\n-     * Store the factory layout into zookeeper\n-     *\n-     * @param zk\n-     *          ZooKeeper Handle\n-     * @param cfg\n-     *          Server Configuration Object\n-     * @throws KeeperException\n-     * @throws IOException\n-     * @throws InterruptedException\n-     */\n-    public void store(ZooKeeper zk, ServerConfiguration cfg)\n-    throws KeeperException, IOException, InterruptedException {\n-        String factoryLayoutPath = getFactoryLayoutPath(new StringBuilder(), cfg);\n-\n-        byte[] layoutData = TextFormat.printToString(managerMeta).getBytes(UTF_8);\n-        ZkUtils.createFullPathOptimistic(zk, factoryLayoutPath, layoutData,\n-                                         Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return managerMeta.hashCode();\n-    }\n-\n-    @Override\n-    public boolean equals(Object o) {\n-        if (null == o ||\n-            !(o instanceof FactoryLayout)) {\n-            return false;\n-        }\n-        FactoryLayout other = (FactoryLayout)o;\n-        return managerMeta.equals(other.managerMeta);\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return TextFormat.printToString(managerMeta);\n-    }\n-\n-    /**\n-     * Read factory layout from zookeeper\n-     *\n-     * @param zk\n-     *          ZooKeeper Client\n-     * @param cfg\n-     *          Server configuration object\n-     * @return Factory layout, or null if none set in zookeeper\n-     */\n-    public static FactoryLayout readLayout(final ZooKeeper zk,\n-                                           final ServerConfiguration cfg)\n-    throws IOException, KeeperException {\n-        String factoryLayoutPath = getFactoryLayoutPath(new StringBuilder(), cfg);\n-        byte[] layoutData;\n-        try {\n-            layoutData = zk.getData(factoryLayoutPath, false, null);\n-        } catch (KeeperException.NoNodeException nne) {\n-            return null;\n-        } catch (InterruptedException ie) {\n-            throw new IOException(ie);\n-        }\n-        ManagerMeta meta;\n-        try {\n-            BufferedReader reader = new BufferedReader(\n-                    new StringReader(new String(layoutData, UTF_8)));\n-            ManagerMeta.Builder metaBuilder = ManagerMeta.newBuilder();\n-            TextFormat.merge(reader, metaBuilder);\n-            meta = metaBuilder.build();\n-        } catch (InvalidProtocolBufferException ipbe) {\n-            throw new IOException(\"Corrupted factory layout : \", ipbe);\n-        }\n-\n-        return new FactoryLayout(meta);\n-    }\n-\n-    /**\n-     * Remove the factory layout from ZooKeeper.\n-     *\n-     * @param zk\n-     *          ZooKeeper instance\n-     * @param cfg\n-     *          Server configuration object\n-     * @throws KeeperException\n-     * @throws InterruptedException\n-     */\n-    public static void deleteLayout(ZooKeeper zk, ServerConfiguration cfg)\n-            throws KeeperException, InterruptedException {\n-        String factoryLayoutPath = getFactoryLayoutPath(new StringBuilder(), cfg);\n-        zk.delete(factoryLayoutPath, -1);\n-    }\n-\n-}"},{"sha":"129d03d33e3bfc48201e0e393b08bf6bb4240321","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/MetadataManagerFactory.java","status":"removed","additions":0,"deletions":213,"changes":213,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MetadataManagerFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MetadataManagerFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MetadataManagerFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,213 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.IOException;\n-import java.util.Iterator;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import org.apache.bookkeeper.util.ReflectionUtils;\n-import org.apache.hedwig.protocol.PubSubProtocol.ManagerMeta;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.ZooKeeper;\n-\n-import com.google.protobuf.ByteString;\n-\n-/**\n- * Metadata Manager used to manage metadata used by hedwig.\n- */\n-public abstract class MetadataManagerFactory {\n-\n-    private static final Logger LOG = LoggerFactory.getLogger(MetadataManagerFactory.class);\n-\n-    /**\n-     * Return current factory version.\n-     *\n-     * @return current version used by factory.\n-     */\n-    public abstract int getCurrentVersion();\n-\n-    /**\n-     * Initialize the metadata manager factory with given\n-     * configuration and version.\n-     *\n-     * @param cfg\n-     *          Server configuration object\n-     * @param zk\n-     *          ZooKeeper handler\n-     * @param version\n-     *          Manager version\n-     * @return metadata manager factory\n-     * @throws IOException when fail to initialize the manager.\n-     */\n-    protected abstract MetadataManagerFactory initialize(\n-        ServerConfiguration cfg, ZooKeeper zk, int version)\n-    throws IOException;\n-\n-    /**\n-     * Uninitialize the factory.\n-     *\n-     * @throws IOException when fail to shutdown the factory.\n-     */\n-    public abstract void shutdown() throws IOException;\n-\n-    /**\n-     * Iterate over the topics list.\n-     * Used by HedwigConsole to list available topics.\n-     *\n-     * @return iterator of the topics list.\n-     * @throws IOException\n-     */\n-    public abstract Iterator<ByteString> getTopics() throws IOException;\n-\n-    /**\n-     * Create topic persistence manager.\n-     *\n-     * @return topic persistence manager\n-     */\n-    public abstract TopicPersistenceManager newTopicPersistenceManager();\n-\n-    /**\n-     * Create subscription data manager.\n-     *\n-     * @return subscription data manager.\n-     */\n-    public abstract SubscriptionDataManager newSubscriptionDataManager();\n-\n-    /**\n-     * Create topic ownership manager.\n-     *\n-     * @return topic ownership manager.\n-     */\n-    public abstract TopicOwnershipManager newTopicOwnershipManager();\n-\n-    /**\n-     * Format the metadata for Hedwig.\n-     *\n-     * @param cfg\n-     *          Configuration instance\n-     * @param zk\n-     *          ZooKeeper instance\n-     */\n-    public abstract void format(ServerConfiguration cfg, ZooKeeper zk) throws IOException;\n-\n-    /**\n-     * Create new Metadata Manager Factory.\n-     *\n-     * @param conf\n-     *          Configuration Object.\n-     * @param zk\n-     *          ZooKeeper Client Handle, talk to zk to know which manager factory is used.\n-     * @return new manager factory.\n-     * @throws IOException\n-     */\n-    public static MetadataManagerFactory newMetadataManagerFactory(\n-        final ServerConfiguration conf, final ZooKeeper zk)\n-    throws IOException, KeeperException, InterruptedException {\n-        Class<? extends MetadataManagerFactory> factoryClass;\n-        try {\n-            factoryClass = conf.getMetadataManagerFactoryClass();\n-        } catch (Exception e) {\n-            throw new IOException(\"Failed to get metadata manager factory class from configuration : \", e);\n-        }\n-        // check that the configured manager is\n-        // compatible with the existing layout\n-        FactoryLayout layout = FactoryLayout.readLayout(zk, conf);\n-        if (layout == null) { // no existing layout\n-            return createMetadataManagerFactory(conf, zk, factoryClass);\n-        }\n-        LOG.debug(\"read meta layout {}\", layout);\n-\n-        if (factoryClass != null &&\n-            !layout.getManagerMeta().getManagerImpl().equals(factoryClass.getName())) {\n-            throw new IOException(\"Configured metadata manager factory \" + factoryClass.getName()\n-                                + \" does not match existing factory \"  + layout.getManagerMeta().getManagerImpl());\n-        }\n-        if (factoryClass == null) {\n-            // no factory specified in configuration\n-            String factoryClsName = layout.getManagerMeta().getManagerImpl();\n-            try {\n-                Class<?> theCls = Class.forName(factoryClsName);\n-                if (!MetadataManagerFactory.class.isAssignableFrom(theCls)) {\n-                    throw new IOException(\"Wrong metadata manager factory \" + factoryClsName);\n-                }\n-                factoryClass = theCls.asSubclass(MetadataManagerFactory.class);\n-            } catch (ClassNotFoundException cnfe) {\n-                throw new IOException(\"No class found to instantiate metadata manager factory \" + factoryClsName);\n-            }\n-        }\n-        // instantiate the metadata manager factory\n-        MetadataManagerFactory managerFactory;\n-        try {\n-            managerFactory = ReflectionUtils.newInstance(factoryClass);\n-        } catch (Throwable t) {\n-            throw new IOException(\"Failed to instantiate metadata manager factory : \" + factoryClass, t);\n-        }\n-        return managerFactory.initialize(conf, zk, layout.getManagerMeta().getManagerVersion());\n-    }\n-\n-    /**\n-     * Create metadata manager factory and write factory layout to ZooKeeper.\n-     *\n-     * @param cfg\n-     *          Server Configuration object.\n-     * @param zk\n-     *          ZooKeeper instance.\n-     * @param factoryClass\n-     *          Metadata Manager Factory Class.\n-     * @return metadata manager factory instance.\n-     * @throws IOException\n-     * @throws KeeperException\n-     * @throws InterruptedException\n-     */\n-    public static MetadataManagerFactory createMetadataManagerFactory(\n-            ServerConfiguration cfg, ZooKeeper zk,\n-            Class<? extends MetadataManagerFactory> factoryClass)\n-            throws IOException, KeeperException, InterruptedException {\n-        // use default manager if no one provided\n-        if (factoryClass == null) {\n-            factoryClass = ZkMetadataManagerFactory.class;\n-        }\n-\n-        MetadataManagerFactory managerFactory;\n-        try {\n-            managerFactory = ReflectionUtils.newInstance(factoryClass);\n-        } catch (Throwable t) {\n-            throw new IOException(\"Fail to instantiate metadata manager factory : \" + factoryClass, t);\n-        }\n-        ManagerMeta managerMeta = ManagerMeta.newBuilder()\n-                                  .setManagerImpl(factoryClass.getName())\n-                                  .setManagerVersion(managerFactory.getCurrentVersion())\n-                                  .build();\n-        FactoryLayout layout = new FactoryLayout(managerMeta);\n-        try {\n-            layout.store(zk, cfg);\n-        } catch (KeeperException.NodeExistsException nee) {\n-            FactoryLayout layout2 = FactoryLayout.readLayout(zk, cfg);\n-            if (!layout2.equals(layout)) {\n-                throw new IOException(\"Contention writing to layout to zookeeper, \"\n-                        + \" other layout \" + layout2 + \" is incompatible with our \"\n-                        + \"layout \" + layout);\n-            }\n-        }\n-        return managerFactory.initialize(cfg, zk, layout.getManagerMeta().getManagerVersion());\n-    }\n-}"},{"sha":"b44ca91ce9e0f672281698e29635411c68e64c60","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/MsMetadataManagerFactory.java","status":"removed","additions":0,"deletions":867,"changes":867,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MsMetadataManagerFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MsMetadataManagerFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/MsMetadataManagerFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,867 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.IOException;\n-import java.io.UnsupportedEncodingException;\n-import java.util.Iterator;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-import com.google.protobuf.ByteString;\n-import com.google.protobuf.TextFormat;\n-import com.google.protobuf.TextFormat.ParseException;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import org.apache.bookkeeper.metastore.MetaStore;\n-import org.apache.bookkeeper.metastore.MetastoreCallback;\n-import org.apache.bookkeeper.metastore.MetastoreCursor;\n-import org.apache.bookkeeper.metastore.MetastoreCursor.ReadEntriesCallback;\n-import org.apache.bookkeeper.metastore.MetastoreException;\n-import org.apache.bookkeeper.metastore.MetastoreFactory;\n-import org.apache.bookkeeper.metastore.MetastoreScannableTable;\n-import org.apache.bookkeeper.metastore.MetastoreScannableTable.Order;\n-import org.apache.bookkeeper.metastore.MetastoreTable;\n-import org.apache.bookkeeper.metastore.MetastoreUtils;\n-\n-import static org.apache.bookkeeper.metastore.MetastoreTable.*;\n-import org.apache.bookkeeper.metastore.MetastoreTableItem;\n-import org.apache.bookkeeper.metastore.MSException;\n-import org.apache.bookkeeper.metastore.Value;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionState;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.topics.HubInfo;\n-import org.apache.hedwig.util.Callback;\n-\n-import org.apache.zookeeper.ZooKeeper;\n-\n-/**\n- * MetadataManagerFactory for plug-in metadata storage.\n- */\n-public class MsMetadataManagerFactory extends MetadataManagerFactory {\n-    protected final static Logger logger = LoggerFactory.getLogger(MsMetadataManagerFactory.class);\n-\n-    static final String UTF8 = \"UTF-8\";\n-\n-    static final int CUR_VERSION = 1;\n-\n-    static final String OWNER_TABLE_NAME = \"owner\";\n-    static final String PERSIST_TABLE_NAME = \"persist\";\n-    static final String SUB_TABLE_NAME = \"sub\";\n-\n-    static class SyncResult<T> {\n-        T value;\n-        int rc;\n-        boolean finished = false;\n-\n-        public synchronized void complete(int rc, T value) {\n-            this.rc = rc;\n-            this.value = value;\n-            finished = true;\n-\n-            notify();\n-        }\n-\n-        public synchronized void block() throws InterruptedException {\n-            while (!finished) {\n-                wait();\n-            }\n-        }\n-\n-        public int getReturnCode() {\n-            return rc;\n-        }\n-\n-        public T getValue() {\n-            return value;\n-        }\n-    }\n-\n-    MetaStore metastore;\n-    MetastoreTable ownerTable;\n-    MetastoreTable persistTable;\n-    MetastoreScannableTable subTable;\n-    ServerConfiguration cfg;\n-\n-    @Override\n-    public MetadataManagerFactory initialize(ServerConfiguration cfg, ZooKeeper zk, int version) throws IOException {\n-        if (CUR_VERSION != version) {\n-            throw new IOException(\"Incompatible MsMetadataManagerFactory version \" + version\n-                    + \" found, expected version \" + CUR_VERSION);\n-        }\n-        this.cfg = cfg;\n-        try {\n-            metastore = MetastoreFactory.createMetaStore(cfg.getMetastoreImplClass());\n-            // TODO: need to store metastore class and version in some place.\n-            metastore.init(cfg.getConf(), metastore.getVersion());\n-        } catch (Exception e) {\n-            throw new IOException(\"Load metastore failed : \", e);\n-        }\n-\n-        try {\n-            ownerTable = metastore.createTable(OWNER_TABLE_NAME);\n-            if (ownerTable == null) {\n-                throw new IOException(\"create owner table failed\");\n-            }\n-\n-            persistTable = metastore.createTable(PERSIST_TABLE_NAME);\n-            if (persistTable == null) {\n-                throw new IOException(\"create persistence table failed\");\n-            }\n-\n-            subTable = metastore.createScannableTable(SUB_TABLE_NAME);\n-            if (subTable == null) {\n-                throw new IOException(\"create subscription table failed\");\n-            }\n-        } catch (MetastoreException me) {\n-            throw new IOException(\"Failed to create tables : \", me);\n-        }\n-\n-        return this;\n-    }\n-\n-    @Override\n-    public int getCurrentVersion() {\n-        return CUR_VERSION;\n-    }\n-\n-    @Override\n-    public void shutdown() {\n-        if (metastore == null) {\n-            return;\n-        }\n-\n-        if (ownerTable != null) {\n-            ownerTable.close();\n-            ownerTable = null;\n-        }\n-\n-        if (persistTable != null) {\n-            persistTable.close();\n-            persistTable = null;\n-        }\n-\n-        if (subTable != null) {\n-            subTable.close();\n-            subTable = null;\n-        }\n-\n-        metastore.close();\n-        metastore = null;\n-    }\n-\n-    @Override\n-    public Iterator<ByteString> getTopics() throws IOException {\n-        SyncResult<MetastoreCursor> syn = new SyncResult<MetastoreCursor>();\n-        persistTable.openCursor(NON_FIELDS, new MetastoreCallback<MetastoreCursor>() {\n-            public void complete(int rc, MetastoreCursor cursor, Object ctx) {\n-                @SuppressWarnings(\"unchecked\")\n-                SyncResult<MetastoreCursor> syn = (SyncResult<MetastoreCursor>) ctx;\n-                syn.complete(rc, cursor);\n-            }\n-        }, syn);\n-        try {\n-            syn.block();\n-        } catch (Exception e) {\n-            throw new IOException(\"Interrupted on getting topics list : \", e);\n-        }\n-\n-        if (syn.getReturnCode() != MSException.Code.OK.getCode()) {\n-            throw new IOException(\"Failed to get topics : \", MSException.create(\n-                    MSException.Code.get(syn.getReturnCode()), \"\"));\n-        }\n-\n-        final MetastoreCursor cursor = syn.getValue();\n-        return new Iterator<ByteString>() {\n-            Iterator<MetastoreTableItem> itemIter = null;\n-\n-            @Override\n-            public boolean hasNext() {\n-                while (null == itemIter || !itemIter.hasNext()) {\n-                    if (!cursor.hasMoreEntries()) {\n-                        return false;\n-                    }\n-\n-                    try {\n-                        itemIter = cursor.readEntries(cfg.getMetastoreMaxEntriesPerScan());\n-                    } catch (MSException mse) {\n-                        logger.warn(\"Interrupted when iterating the topics list : \", mse);\n-                        return false;\n-                    }\n-                }\n-                return true;\n-            }\n-\n-            @Override\n-            public ByteString next() {\n-                MetastoreTableItem t = itemIter.next();\n-                return ByteString.copyFromUtf8(t.getKey());\n-            }\n-\n-            @Override\n-            public void remove() {\n-                throw new UnsupportedOperationException(\"Doesn't support remove topic from topic iterator.\");\n-            }\n-        };\n-    }\n-\n-    @Override\n-    public TopicOwnershipManager newTopicOwnershipManager() {\n-        return new MsTopicOwnershipManagerImpl(ownerTable);\n-    }\n-\n-    static class MsTopicOwnershipManagerImpl implements TopicOwnershipManager {\n-\n-        static final String OWNER_FIELD = \"owner\";\n-\n-        final MetastoreTable ownerTable;\n-\n-        MsTopicOwnershipManagerImpl(MetastoreTable ownerTable) {\n-            this.ownerTable = ownerTable;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing\n-        }\n-\n-        @Override\n-        public void readOwnerInfo(final ByteString topic, final Callback<Versioned<HubInfo>> callback, Object ctx) {\n-            ownerTable.get(topic.toStringUtf8(), new MetastoreCallback<Versioned<Value>>() {\n-                @Override\n-                public void complete(int rc, Versioned<Value> value, Object ctx) {\n-                    if (MSException.Code.NoKey.getCode() == rc) {\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-\n-                    if (MSException.Code.OK.getCode() != rc) {\n-                        logErrorAndFinishOperation(\"Could not read ownership for topic \" + topic.toStringUtf8(),\n-                                callback, ctx, rc);\n-                        return;\n-                    }\n-\n-                    HubInfo owner = null;\n-                    try {\n-                        byte[] data = value.getValue().getField(OWNER_FIELD);\n-                        if (data != null) {\n-                            owner = HubInfo.parse(new String(data, UTF_8));\n-                        }\n-                    } catch (HubInfo.InvalidHubInfoException ihie) {\n-                        logger.warn(\"Failed to parse hub info for topic \" + topic.toStringUtf8(), ihie);\n-                    }\n-                    Version version = value.getVersion();\n-                    callback.operationFinished(ctx, new Versioned<HubInfo>(owner, version));\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void writeOwnerInfo(final ByteString topic, final HubInfo owner, final Version version,\n-                final Callback<Version> callback, Object ctx) {\n-            Value value = new Value();\n-            value.setField(OWNER_FIELD, owner.toString().getBytes(UTF_8));\n-\n-            ownerTable.put(topic.toStringUtf8(), value, version, new MetastoreCallback<Version>() {\n-                @Override\n-                public void complete(int rc, Version ver, Object ctx) {\n-                    if (MSException.Code.OK.getCode() == rc) {\n-                        callback.operationFinished(ctx, ver);\n-                        return;\n-                    } else if (MSException.Code.NoKey.getCode() == rc) {\n-                        // no node\n-                        callback.operationFailed(\n-                                ctx,\n-                                PubSubException.create(StatusCode.NO_TOPIC_OWNER_INFO, \"No owner info found for topic \"\n-                                        + topic.toStringUtf8()));\n-                        return;\n-                    } else if (MSException.Code.KeyExists.getCode() == rc) {\n-                        // key exists\n-                        callback.operationFailed(\n-                                ctx,\n-                                PubSubException.create(StatusCode.TOPIC_OWNER_INFO_EXISTS, \"Owner info of topic \"\n-                                        + topic.toStringUtf8() + \" existed.\"));\n-                        return;\n-                    } else if (MSException.Code.BadVersion.getCode() == rc) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to update owner info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Failed to update ownership of topic \" + topic.toStringUtf8()\n-                                + \" to \" + owner, callback, ctx, rc);\n-                        return;\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteOwnerInfo(final ByteString topic, Version version, final Callback<Void> callback,\n-                Object ctx) {\n-            ownerTable.remove(topic.toStringUtf8(), version, new MetastoreCallback<Void>() {\n-                @Override\n-                public void complete(int rc, Void value, Object ctx) {\n-                    if (MSException.Code.OK.getCode() == rc) {\n-                        logger.debug(\"Successfully deleted owner info for topic {}\", topic.toStringUtf8());\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    } else if (MSException.Code.NoKey.getCode() == rc) {\n-                        // no node\n-                        callback.operationFailed(\n-                                ctx,\n-                                PubSubException.create(StatusCode.NO_TOPIC_OWNER_INFO, \"No owner info found for topic \"\n-                                        + topic.toStringUtf8()));\n-                        return;\n-                    } else if (MSException.Code.BadVersion.getCode() == rc) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to delete owner info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Failed to delete owner info for topic \" + topic.toStringUtf8(),\n-                                callback, ctx, rc);\n-                        return;\n-                    }\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    @Override\n-    public TopicPersistenceManager newTopicPersistenceManager() {\n-        return new MsTopicPersistenceManagerImpl(persistTable);\n-    }\n-\n-    static class MsTopicPersistenceManagerImpl implements TopicPersistenceManager {\n-\n-        static final String PERSIST_FIELD = \"prst\";\n-\n-        final MetastoreTable persistTable;\n-\n-        MsTopicPersistenceManagerImpl(MetastoreTable persistTable) {\n-            this.persistTable = persistTable;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing\n-        }\n-\n-        @Override\n-        public void readTopicPersistenceInfo(final ByteString topic, final Callback<Versioned<LedgerRanges>> callback,\n-                Object ctx) {\n-            persistTable.get(topic.toStringUtf8(), new MetastoreCallback<Versioned<Value>>() {\n-                @Override\n-                public void complete(int rc, Versioned<Value> value, Object ctx) {\n-                    if (MSException.Code.OK.getCode() == rc) {\n-                        byte[] data = value.getValue().getField(PERSIST_FIELD);\n-                        if (data != null) {\n-                            parseAndReturnTopicLedgerRanges(topic, data, value.getVersion(), callback, ctx);\n-                        } else { // null data is same as NoKey\n-                            callback.operationFinished(ctx, null);\n-                        }\n-                    } else if (MSException.Code.NoKey.getCode() == rc) {\n-                        callback.operationFinished(ctx, null);\n-                    } else {\n-                        logErrorAndFinishOperation(\"Could not read ledgers node for topic \" + topic.toStringUtf8(),\n-                                callback, ctx, rc);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        /**\n-         * Parse ledger ranges data and return it thru callback.\n-         *\n-         * @param topic\n-         *            Topic name\n-         * @param data\n-         *            Topic Ledger Ranges data\n-         * @param version\n-         *            Version of the topic ledger ranges data\n-         * @param callback\n-         *            Callback to return ledger ranges\n-         * @param ctx\n-         *            Context of the callback\n-         */\n-        private void parseAndReturnTopicLedgerRanges(ByteString topic, byte[] data, Version version,\n-                Callback<Versioned<LedgerRanges>> callback, Object ctx) {\n-            try {\n-                LedgerRanges.Builder rangesBuilder = LedgerRanges.newBuilder();\n-                TextFormat.merge(new String(data, UTF8), rangesBuilder);\n-                LedgerRanges lr = rangesBuilder.build();\n-                Versioned<LedgerRanges> ranges = new Versioned<LedgerRanges>(lr, version);\n-                callback.operationFinished(ctx, ranges);\n-            } catch (ParseException e) {\n-                StringBuilder sb = new StringBuilder();\n-                sb.append(\"Ledger ranges for topic \").append(topic.toStringUtf8())\n-                        .append(\" could not be deserialized.\");\n-                String msg = sb.toString();\n-                logger.error(msg, e);\n-                callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-            } catch (UnsupportedEncodingException uee) {\n-                StringBuilder sb = new StringBuilder();\n-                sb.append(\"Ledger ranges for topic \").append(topic.toStringUtf8()).append(\" is not UTF-8 encoded.\");\n-                String msg = sb.toString();\n-                logger.error(msg, uee);\n-                callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-            }\n-        }\n-\n-        @Override\n-        public void writeTopicPersistenceInfo(final ByteString topic, LedgerRanges ranges, final Version version,\n-                final Callback<Version> callback, Object ctx) {\n-            Value value = new Value();\n-            value.setField(PERSIST_FIELD, TextFormat.printToString(ranges).getBytes(UTF_8));\n-\n-            persistTable.put(topic.toStringUtf8(), value, version, new MetastoreCallback<Version>() {\n-                @Override\n-                public void complete(int rc, Version ver, Object ctx) {\n-                    if (MSException.Code.OK.getCode() == rc) {\n-                        callback.operationFinished(ctx, ver);\n-                        return;\n-                    } else if (MSException.Code.NoKey.getCode() == rc) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_PERSISTENCE_INFO,\n-                                \"No persistence info found for topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (MSException.Code.KeyExists.getCode() == rc) {\n-                        // key exists\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.TOPIC_PERSISTENCE_INFO_EXISTS,\n-                                \"Persistence info of topic \" + topic.toStringUtf8() + \" existed.\"));\n-                        return;\n-                    } else if (MSException.Code.BadVersion.getCode() == rc) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to update persistence info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Could not write ledgers node for topic \" + topic.toStringUtf8(),\n-                                callback, ctx, rc);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteTopicPersistenceInfo(final ByteString topic, final Version version,\n-                final Callback<Void> callback, Object ctx) {\n-            persistTable.remove(topic.toStringUtf8(), version, new MetastoreCallback<Void>() {\n-                @Override\n-                public void complete(int rc, Void value, Object ctx) {\n-                    if (MSException.Code.OK.getCode() == rc) {\n-                        logger.debug(\"Successfully deleted persistence info for topic {}.\", topic.toStringUtf8());\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    } else if (MSException.Code.NoKey.getCode() == rc) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_PERSISTENCE_INFO,\n-                                \"No persistence info found for topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (MSException.Code.BadVersion.getCode() == rc) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to delete persistence info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Failed to delete persistence info topic: \" + topic.toStringUtf8()\n-                                + \", version: \" + version, callback, ctx, rc, StatusCode.SERVICE_DOWN);\n-                        return;\n-                    }\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    @Override\n-    public SubscriptionDataManager newSubscriptionDataManager() {\n-        return new MsSubscriptionDataManagerImpl(cfg, subTable);\n-    }\n-\n-    static class MsSubscriptionDataManagerImpl implements SubscriptionDataManager {\n-\n-        static final String SUB_STATE_FIELD = \"sub_state\";\n-        static final String SUB_PREFS_FIELD = \"sub_preferences\";\n-\n-        static final char TOPIC_SUB_FIRST_SEPARATOR = '\\001';\n-        static final char TOPIC_SUB_LAST_SEPARATOR = '\\002';\n-\n-        final ServerConfiguration cfg;\n-        final MetastoreScannableTable subTable;\n-\n-        MsSubscriptionDataManagerImpl(ServerConfiguration cfg, MetastoreScannableTable subTable) {\n-            this.cfg = cfg;\n-            this.subTable = subTable;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing\n-        }\n-\n-        private String getSubscriptionKey(ByteString topic, ByteString subscriberId) {\n-            return new StringBuilder(topic.toStringUtf8()).append(TOPIC_SUB_FIRST_SEPARATOR)\n-                    .append(subscriberId.toStringUtf8()).toString();\n-        }\n-\n-        private Value subscriptionData2Value(SubscriptionData subData) {\n-            Value value = new Value();\n-            if (subData.hasState()) {\n-                value.setField(SUB_STATE_FIELD, TextFormat.printToString(subData.getState()).getBytes(UTF_8));\n-            }\n-            if (subData.hasPreferences()) {\n-                value.setField(SUB_PREFS_FIELD, TextFormat.printToString(subData.getPreferences()).getBytes(UTF_8));\n-            }\n-            return value;\n-        }\n-\n-        @Override\n-        public void createSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                final SubscriptionData subData, final Callback<Version> callback, Object ctx) {\n-            String key = getSubscriptionKey(topic, subscriberId);\n-            Value value = subscriptionData2Value(subData);\n-\n-            subTable.put(key, value, Version.NEW, new MetastoreCallback<Version>() {\n-                @Override\n-                public void complete(int rc, Version ver, Object ctx) {\n-                    if (rc == MSException.Code.OK.getCode()) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully create subscription for topic: \" + topic.toStringUtf8()\n-                                    + \", subscriberId: \" + subscriberId.toStringUtf8() + \", data: \"\n-                                    + SubscriptionStateUtils.toString(subData));\n-                        }\n-                        callback.operationFinished(ctx, ver);\n-                    } else if (rc == MSException.Code.KeyExists.getCode()) {\n-                        callback.operationFailed(ctx, PubSubException.create(\n-                                StatusCode.SUBSCRIPTION_STATE_EXISTS,\n-                                \"Subscription data for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                        + subscriberId.toStringUtf8() + \") existed.\"));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Failed to create topic: \" + topic.toStringUtf8()\n-                                + \", subscriberId: \" + subscriberId.toStringUtf8() + \", data: \"\n-                                + SubscriptionStateUtils.toString(subData), callback, ctx, rc);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public boolean isPartialUpdateSupported() {\n-            // TODO: Here we assume Metastore support partial update, but this\n-            // maybe incorrect.\n-            return true;\n-        }\n-\n-        @Override\n-        public void replaceSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                final SubscriptionData subData, final Version version, final Callback<Version> callback,\n-                final Object ctx) {\n-            updateSubscriptionData(topic, subscriberId, subData, version, callback, ctx);\n-        }\n-\n-        @Override\n-        public void updateSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                final SubscriptionData subData, final Version version, final Callback<Version> callback,\n-                final Object ctx) {\n-            String key = getSubscriptionKey(topic, subscriberId);\n-            Value value = subscriptionData2Value(subData);\n-\n-            subTable.put(key, value, version, new MetastoreCallback<Version>() {\n-                @Override\n-                public void complete(int rc, Version version, Object ctx) {\n-                    if (rc == MSException.Code.OK.getCode()) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully updated subscription data for topic: \" + topic.toStringUtf8()\n-                                    + \", subscriberId: \" + subscriberId.toStringUtf8() + \", data: \"\n-                                    + SubscriptionStateUtils.toString(subData) + \", version: \" + version);\n-                        }\n-                        callback.operationFinished(ctx, version);\n-                    } else if (rc == MSException.Code.NoKey.getCode()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_SUBSCRIPTION_STATE,\n-                                \"No subscription data found for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                        + subscriberId.toStringUtf8() + \").\"));\n-                        return;\n-                    } else if (rc == MSException.Code.BadVersion.getCode()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to update subscription data of topic \" + topic.toStringUtf8()\n-                                        + \" subscriberId \" + subscriberId));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\n-                                \"Failed to update subscription data for topic: \" + topic.toStringUtf8()\n-                                        + \", subscriberId: \" + subscriberId.toStringUtf8() + \", data: \"\n-                                        + SubscriptionStateUtils.toString(subData) + \", version: \" + version, callback,\n-                                ctx, rc);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteSubscriptionData(final ByteString topic, final ByteString subscriberId, Version version,\n-                final Callback<Void> callback, Object ctx) {\n-            String key = getSubscriptionKey(topic, subscriberId);\n-            subTable.remove(key, version, new MetastoreCallback<Void>() {\n-                @Override\n-                public void complete(int rc, Void value, Object ctx) {\n-                    if (rc == MSException.Code.OK.getCode()) {\n-                        logger.debug(\"Successfully delete subscription for topic: {}, subscriberId: {}.\",\n-                                topic.toStringUtf8(), subscriberId.toStringUtf8());\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    } else if (rc == MSException.Code.BadVersion.getCode()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                \"Bad version provided to delete subscriptoin data of topic \" + topic.toStringUtf8()\n-                                        + \" subscriberId \" + subscriberId));\n-                        return;\n-                    } else if (rc == MSException.Code.NoKey.getCode()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_SUBSCRIPTION_STATE,\n-                                \"No subscription data found for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                        + subscriberId.toStringUtf8() + \").\"));\n-                        return;\n-                    } else {\n-                        logErrorAndFinishOperation(\"Failed to delete subscription topic: \" + topic.toStringUtf8()\n-                                + \", subscriberId: \" + subscriberId.toStringUtf8(), callback, ctx, rc,\n-                                StatusCode.SERVICE_DOWN);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        private SubscriptionData value2SubscriptionData(Value value) throws ParseException,\n-                UnsupportedEncodingException {\n-            SubscriptionData.Builder builder = SubscriptionData.newBuilder();\n-\n-            byte[] stateData = value.getField(SUB_STATE_FIELD);\n-            if (null != stateData) {\n-                SubscriptionState.Builder stateBuilder = SubscriptionState.newBuilder();\n-                TextFormat.merge(new String(stateData, UTF8), stateBuilder);\n-                SubscriptionState state = stateBuilder.build();\n-                builder.setState(state);\n-            }\n-\n-            byte[] prefsData = value.getField(SUB_PREFS_FIELD);\n-            if (null != prefsData) {\n-                SubscriptionPreferences.Builder preferencesBuilder = SubscriptionPreferences.newBuilder();\n-                TextFormat.merge(new String(prefsData, UTF8), preferencesBuilder);\n-                SubscriptionPreferences preferences = preferencesBuilder.build();\n-                builder.setPreferences(preferences);\n-            }\n-\n-            return builder.build();\n-        }\n-\n-        @Override\n-        public void readSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                final Callback<Versioned<SubscriptionData>> callback, Object ctx) {\n-            String key = getSubscriptionKey(topic, subscriberId);\n-            subTable.get(key, new MetastoreCallback<Versioned<Value>>() {\n-                @Override\n-                public void complete(int rc, Versioned<Value> value, Object ctx) {\n-                    if (rc == MSException.Code.NoKey.getCode()) {\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-\n-                    if (rc != MSException.Code.OK.getCode()) {\n-                        logErrorAndFinishOperation(\n-                                \"Could not read subscription data for topic: \" + topic.toStringUtf8()\n-                                        + \", subscriberId: \" + subscriberId.toStringUtf8(), callback, ctx, rc);\n-                        return;\n-                    }\n-\n-                    try {\n-                        Versioned<SubscriptionData> subData = new Versioned<SubscriptionData>(\n-                                value2SubscriptionData(value.getValue()), value.getVersion());\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Found subscription while acquiring topic: \" + topic.toStringUtf8()\n-                                    + \", subscriberId: \" + subscriberId.toStringUtf8() + \", data: \"\n-                                    + SubscriptionStateUtils.toString(subData.getValue()) + \", version: \"\n-                                    + subData.getVersion());\n-                        }\n-                        callback.operationFinished(ctx, subData);\n-                    } catch (ParseException e) {\n-                        StringBuilder sb = new StringBuilder();\n-                        sb.append(\"Failed to deserialize subscription data for topic:\").append(topic.toStringUtf8())\n-                                .append(\", subscriberId: \").append(subscriberId.toStringUtf8());\n-                        String msg = sb.toString();\n-                        logger.error(msg, e);\n-                        callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                    } catch (UnsupportedEncodingException uee) {\n-                        StringBuilder sb = new StringBuilder();\n-                        sb.append(\"Subscription data for topic: \").append(topic.toStringUtf8())\n-                                .append(\", subscriberId: \").append(subscriberId.toStringUtf8())\n-                                .append(\" is not UFT-8 encoded\");\n-                        String msg = sb.toString();\n-                        logger.error(msg, uee);\n-                        callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        private String getSubscriptionPrefix(ByteString topic, char sep) {\n-            return new StringBuilder(topic.toStringUtf8()).append(sep).toString();\n-        }\n-\n-        private void readSubscriptions(final ByteString topic, final int keyLength, final MetastoreCursor cursor,\n-                final Map<ByteString, Versioned<SubscriptionData>> topicSubs,\n-                final Callback<Map<ByteString, Versioned<SubscriptionData>>> callback, Object ctx) {\n-            if (!cursor.hasMoreEntries()) {\n-                callback.operationFinished(ctx, topicSubs);\n-                return;\n-            }\n-            ReadEntriesCallback readCb = new ReadEntriesCallback() {\n-                @Override\n-                public void complete(int rc, Iterator<MetastoreTableItem> items, Object ctx) {\n-                    if (rc != MSException.Code.OK.getCode()) {\n-                        logErrorAndFinishOperation(\"Could not read subscribers for cursor \" + cursor,\n-                                callback, ctx, rc);\n-                        return;\n-                    }\n-                    while (items.hasNext()) {\n-                        MetastoreTableItem item = items.next();\n-                        final ByteString subscriberId = ByteString.copyFromUtf8(item.getKey().substring(keyLength));\n-                        try {\n-                            Versioned<Value> vv = item.getValue();\n-                            Versioned<SubscriptionData> subData = new Versioned<SubscriptionData>(\n-                                    value2SubscriptionData(vv.getValue()), vv.getVersion());\n-                            topicSubs.put(subscriberId, subData);\n-                        } catch (ParseException e) {\n-                            StringBuilder sb = new StringBuilder();\n-                            sb.append(\"Failed to deserialize subscription data for topic: \")\n-                                    .append(topic.toStringUtf8()).append(\", subscriberId: \")\n-                                    .append(subscriberId.toStringUtf8());\n-                            String msg = sb.toString();\n-                            logger.error(msg, e);\n-                            callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                            return;\n-                        } catch (UnsupportedEncodingException e) {\n-                            StringBuilder sb = new StringBuilder();\n-                            sb.append(\"Subscription data for topic: \").append(topic.toStringUtf8())\n-                                    .append(\", subscriberId: \").append(subscriberId.toStringUtf8())\n-                                    .append(\" is not UTF-8 encoded.\");\n-                            String msg = sb.toString();\n-                            logger.error(msg, e);\n-                            callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                            return;\n-                        }\n-                    }\n-                    readSubscriptions(topic, keyLength, cursor, topicSubs, callback, ctx);\n-                }\n-            };\n-            cursor.asyncReadEntries(cfg.getMetastoreMaxEntriesPerScan(), readCb, ctx);\n-        }\n-\n-        @Override\n-        public void readSubscriptions(final ByteString topic,\n-                final Callback<Map<ByteString, Versioned<SubscriptionData>>> callback, Object ctx) {\n-            final String firstKey = getSubscriptionPrefix(topic, TOPIC_SUB_FIRST_SEPARATOR);\n-            String lastKey = getSubscriptionPrefix(topic, TOPIC_SUB_LAST_SEPARATOR);\n-            subTable.openCursor(firstKey, true, lastKey, true, Order.ASC, ALL_FIELDS,\n-                    new MetastoreCallback<MetastoreCursor>() {\n-                        @Override\n-                        public void complete(int rc, MetastoreCursor cursor, Object ctx) {\n-                            if (rc != MSException.Code.OK.getCode()) {\n-                                logErrorAndFinishOperation(\n-                                        \"Could not read subscribers for topic \" + topic.toStringUtf8(), callback, ctx,\n-                                        rc);\n-                                return;\n-                            }\n-\n-                            final Map<ByteString, Versioned<SubscriptionData>> topicSubs =\n-                                    new ConcurrentHashMap<ByteString, Versioned<SubscriptionData>>();\n-                            readSubscriptions(topic, firstKey.length(), cursor, topicSubs, callback, ctx);\n-                        }\n-                    }, ctx);\n-        }\n-    }\n-\n-    /**\n-     * callback finish operation with exception specify by code, regardless of\n-     * the value of return code rc.\n-     */\n-    private static <T> void logErrorAndFinishOperation(String msg, Callback<T> callback, Object ctx, int rc,\n-            StatusCode code) {\n-        logger.error(msg, MSException.create(MSException.Code.get(rc), \"\"));\n-        callback.operationFailed(ctx, PubSubException.create(code, msg));\n-    }\n-\n-    /**\n-     * callback finish operation with corresponding PubSubException converted\n-     * from return code rc.\n-     */\n-    private static <T> void logErrorAndFinishOperation(String msg, Callback<T> callback, Object ctx, int rc) {\n-        StatusCode code;\n-\n-        if (rc == MSException.Code.NoKey.getCode()) {\n-            code = StatusCode.NO_SUCH_TOPIC;\n-        } else if (rc == MSException.Code.ServiceDown.getCode()) {\n-            code = StatusCode.SERVICE_DOWN;\n-        } else {\n-            code = StatusCode.UNEXPECTED_CONDITION;\n-        }\n-\n-        logErrorAndFinishOperation(msg, callback, ctx, rc, code);\n-    }\n-\n-    @Override\n-    public void format(ServerConfiguration cfg, ZooKeeper zk) throws IOException {\n-        try {\n-            int maxEntriesPerScan = cfg.getMetastoreMaxEntriesPerScan();\n-\n-            // clean topic ownership table.\n-            logger.info(\"Cleaning topic ownership table ...\");\n-            MetastoreUtils.cleanTable(ownerTable, maxEntriesPerScan);\n-            logger.info(\"Cleaned topic ownership table successfully.\");\n-\n-            // clean topic subscription table.\n-            logger.info(\"Cleaning topic subscription table ...\");\n-            MetastoreUtils.cleanTable(subTable, maxEntriesPerScan);\n-            logger.info(\"Cleaned topic subscription table successfully.\");\n-\n-            // clean topic persistence info table.\n-            logger.info(\"Cleaning topic persistence info table ...\");\n-            MetastoreUtils.cleanTable(persistTable, maxEntriesPerScan);\n-            logger.info(\"Cleaned topic persistence info table successfully.\");\n-        } catch (MSException mse) {\n-            throw new IOException(\"Exception when formatting hedwig metastore : \", mse);\n-        } catch (InterruptedException ie) {\n-            throw new IOException(\"Interrupted when formatting hedwig metastore : \", ie);\n-        }\n-    }\n-\n-}"},{"sha":"0bebd457990555b18d13eddd889ef9ccc38e2135","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/SubscriptionDataManager.java","status":"removed","additions":0,"deletions":158,"changes":158,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/SubscriptionDataManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/SubscriptionDataManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/SubscriptionDataManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,158 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.Closeable;\n-import java.util.Map;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * Manage subscription data.\n- */\n-public interface SubscriptionDataManager extends Closeable {\n-\n-    /**\n-     * Create subscription data.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param subscriberId\n-     *          Subscriber id\n-     * @param data \n-     *          Subscription data\n-     * @param callback\n-     *          Callback when subscription state created. New version would be returned.\n-     *          {@link PubSubException.SubscriptionStateExistsException} is returned when subscription state\n-     *          existed before.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void createSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData data,\n-                                       Callback<Version> callback, Object ctx);\n-\n-    /**\n-     * Whether the metadata manager supports partial update.\n-     *\n-     * @return true if the metadata manager supports partial update.\n-     *         otherwise, return false.\n-     */\n-    public boolean isPartialUpdateSupported();\n-\n-    /**\n-     * Update subscription data.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param subscriberId\n-     *          Subscriber id\n-     * @param dataToUpdate\n-     *          Subscription data to update. So it is a partial data, which contains\n-     *          the part of data to update. The implementation should not replace\n-     *          existing subscription data with <i>dataToUpdate</i> directly.\n-     *          E.g. if there is only state in it, you should update state only.\n-     * @param version\n-     *          Current version of subscription data.\n-     * @param callback\n-     *          Callback when subscription state updated. New version would be returned.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match,\n-     *          {@link PubSubException.NoSubscriptionStateException} is returned when no subscription state\n-     *          is found.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void updateSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData dataToUpdate, \n-                                       Version version, Callback<Version> callback, Object ctx);\n-\n-    /**\n-     * Replace subscription data.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param subscriberId\n-     *          Subscriber id\n-     * @param dataToReplace\n-     *          Subscription data to replace.\n-     * @param version\n-     *          Current version of subscription data.\n-     * @param callback\n-     *          Callback when subscription state updated. New version would be returned.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match,\n-     *          {@link PubSubException.NoSubscriptionStateException} is returned when no subscription state\n-     *          is found.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void replaceSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData dataToReplace,\n-                                        Version version, Callback<Version> callback, Object ctx);\n-\n-    /**\n-     * Remove subscription data.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param subscriberId\n-     *          Subscriber id\n-     * @param version\n-     *          Current version of subscription data.\n-     * @param callback\n-     *          Callback when subscription state deleted\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match,\n-     *          {@link PubSubException.NoSubscriptionStateException} is returned when no subscription state\n-     *          is found.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void deleteSubscriptionData(ByteString topic, ByteString subscriberId, Version version,\n-                                       Callback<Void> callback, Object ctx);\n-\n-    /**\n-     * Read subscription data with version.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber id\n-     * @param callback\n-     *          Callback when subscription data read.\n-     *          Null is returned when no subscription data is found.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void readSubscriptionData(ByteString topic, ByteString subscriberId,\n-                                     Callback<Versioned<SubscriptionData>> callback, Object ctx);\n-\n-    /**\n-     * Read all subscriptions of a topic.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param callback\n-     *          Callback to return subscriptions with version information\n-     * @param ctx\n-     *          Contxt of the callback\n-     */\n-    public void readSubscriptions(ByteString topic, Callback<Map<ByteString, Versioned<SubscriptionData>>> cb,\n-                                  Object ctx);\n-}"},{"sha":"f17011caeddf83bc8e64fb7ff6d622d5110d69f7","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicOwnershipManager.java","status":"removed","additions":0,"deletions":93,"changes":93,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicOwnershipManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicOwnershipManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicOwnershipManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,93 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.Closeable;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.hedwig.server.topics.HubInfo;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * Manage topic ownership\n- */\n-public interface TopicOwnershipManager extends Closeable {\n-\n-    /**\n-     * Read owner information of a topic.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param callback\n-     *          Callback to return hub info. If there is no owner info, return null;\n-     *          If there is data but not valid owner info, return a Versioned object with null hub info;\n-     *          If there is valid owner info, return versioned hub info.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void readOwnerInfo(ByteString topic, Callback<Versioned<HubInfo>> callback, Object ctx);\n-\n-    /**\n-     * Write owner info for a specified topic.\n-     * A new owner info would be created if there is no one existed before.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param owner\n-     *          Owner hub info\n-     * @param version\n-     *          Current version of owner info\n-     *          If <code>version</code> is {@link Version.NEW}, create owner info.\n-     *          {@link PubSubException.TopicOwnerInfoExistsException} is returned when\n-     *          owner info existed before.\n-     *          Otherwise, the owner info is updated only when\n-     *          provided version equals to its current version.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match,\n-     *          {@link PubSubException.NoTopicOwnerInfoException} is returned when no owner info\n-     *          found to update.\n-     * @param callback\n-     *          Callback when owner info updated. New version would be returned if succeed to write.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void writeOwnerInfo(ByteString topic, HubInfo owner, Version version,\n-                               Callback<Version> callback, Object ctx);\n-\n-    /**\n-     * Delete owner info for a specified topic.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param version\n-     *          Current version of owner info\n-     *          If <code>version</code> is {@link Version.ANY}, delete owner info no matter its current version.\n-     *          Otherwise, the owner info is deleted only when\n-     *          provided version equals to its current version.\n-     * @param callback\n-     *          Callback when owner info deleted.\n-     *          {@link PubSubException.NoTopicOwnerInfoException} is returned when no owner info.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match.\n-     * @param ctx\n-     *          Context of the callback.\n-     */\n-    public void deleteOwnerInfo(ByteString topic, Version version,\n-                                Callback<Void> callback, Object ctx);\n-}"},{"sha":"69ee709c4dd2b484d2efe0b85838ba62142776f7","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicPersistenceManager.java","status":"removed","additions":0,"deletions":96,"changes":96,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicPersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicPersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/TopicPersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,96 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.Closeable;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * Manage topic persistence metadata.\n- */\n-public interface TopicPersistenceManager extends Closeable {\n-\n-    /**\n-     * Read persistence info of a specified topic.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param callback\n-     *          Callback when read persistence info.\n-     *          If no persistence info found, return null.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void readTopicPersistenceInfo(ByteString topic,\n-                                         Callback<Versioned<LedgerRanges>> callback, Object ctx);\n-\n-    /**\n-     * Update persistence info of a specified topic.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param ranges\n-     *          Persistence info\n-     * @param version\n-     *          Current version of persistence info.\n-     *          If <code>version</code> is {@link Version.NEW}, create persistence info;\n-     *          {@link PubSubException.TopicPersistenceInfoExistsException} is returned when\n-     *          persistence info existed before.\n-     *          Otherwise, the persitence info is updated only when\n-     *          provided version equals to its current version.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match,\n-     *          {@link PubSubException.NoTopicPersistenceInfoException} is returned when no\n-     *          persistence info found to update.\n-     * @param callback\n-     *          Callback when persistence info updated. New version would be returned.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void writeTopicPersistenceInfo(ByteString topic, LedgerRanges ranges, Version version,\n-                                          Callback<Version> callback, Object ctx);\n-\n-    /**\n-     * Delete persistence info of a specified topic.\n-     * Currently used in test cases.\n-     *\n-     * @param topic\n-     *          Topic name\n-     * @param version\n-     *          Current version of persistence info\n-     *          If <code>version</code> is {@link Version.ANY}, delete persistence info no matter its current version.\n-     *          Otherwise, the persitence info is deleted only when\n-     *          provided version equals to its current version.\n-     * @param callback\n-     *          Callback return whether the deletion succeed.\n-     *          {@link PubSubException.NoTopicPersistenceInfoException} is returned when no persistence.\n-     *          {@link PubSubException.BadVersionException} is returned when version doesn't match.\n-     *          info found to delete.\n-     * @param ctx\n-     *          Context of the callback\n-     */\n-    public void deleteTopicPersistenceInfo(ByteString topic, Version version,\n-                                           Callback<Void> callback, Object ctx);\n-\n-}"},{"sha":"e50bc7f28ce1596339769053c675ac9809ccc9cf","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/meta/ZkMetadataManagerFactory.java","status":"removed","additions":0,"deletions":840,"changes":840,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/ZkMetadataManagerFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/meta/ZkMetadataManagerFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/meta/ZkMetadataManagerFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,840 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.meta;\n-\n-import java.io.IOException;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Iterator;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-import java.util.concurrent.atomic.AtomicInteger;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.KeeperException.Code;\n-import org.apache.zookeeper.ZKUtil;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.ZooDefs.Ids;\n-import org.apache.zookeeper.data.Stat;\n-import com.google.protobuf.ByteString;\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.apache.bookkeeper.meta.ZkVersion;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.topics.HubInfo;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.zookeeper.SafeAsyncZKCallback;\n-import org.apache.hedwig.zookeeper.ZkUtils;\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-/**\n- * ZooKeeper-based Metadata Manager.\n- */\n-public class ZkMetadataManagerFactory extends MetadataManagerFactory {\n-    protected final static Logger logger = LoggerFactory.getLogger(ZkMetadataManagerFactory.class);\n-\n-    static final int CUR_VERSION = 1;\n-\n-    ZooKeeper zk;\n-    ServerConfiguration cfg;\n-\n-    @Override\n-    public int getCurrentVersion() {\n-        return CUR_VERSION;\n-    }\n-\n-    @Override\n-    public MetadataManagerFactory initialize(ServerConfiguration cfg,\n-                                             ZooKeeper zk,\n-                                             int version)\n-    throws IOException {\n-        if (CUR_VERSION != version) {\n-            throw new IOException(\"Incompatible ZkMetadataManagerFactory version \" + version\n-                                + \" found, expected version \" + CUR_VERSION);\n-        }\n-        this.cfg = cfg;\n-        this.zk = zk;\n-        return this;\n-    }\n-\n-    @Override\n-    public void shutdown() {\n-        // do nothing here, because zookeeper handle is passed from outside\n-        // we don't need to stop it.\n-    }\n-\n-    @Override\n-    public Iterator<ByteString> getTopics() throws IOException {\n-        List<String> topics;\n-        try {\n-            topics = zk.getChildren(cfg.getZkTopicsPrefix(new StringBuilder()).toString(), false);\n-        } catch (KeeperException ke) {\n-            throw new IOException(\"Failed to get topics list : \", ke);\n-        } catch (InterruptedException ie) {\n-            throw new IOException(\"Interrupted on getting topics list : \", ie);\n-        }\n-        final Iterator<String> iter = topics.iterator();\n-        return new Iterator<ByteString>() {\n-            @Override\n-            public boolean hasNext() {\n-                return iter.hasNext();\n-            }\n-            @Override\n-            public ByteString next() {\n-                String t = iter.next();\n-                return ByteString.copyFromUtf8(t);\n-            }\n-            @Override\n-            public void remove() {\n-                iter.remove();\n-            }\n-        };\n-    }\n-\n-    @Override\n-    public TopicPersistenceManager newTopicPersistenceManager() {\n-        return new ZkTopicPersistenceManagerImpl(cfg, zk);\n-    }\n-\n-    @Override\n-    public SubscriptionDataManager newSubscriptionDataManager() {\n-        return new ZkSubscriptionDataManagerImpl(cfg, zk);\n-    }\n-\n-    @Override\n-    public TopicOwnershipManager newTopicOwnershipManager() {\n-        return new ZkTopicOwnershipManagerImpl(cfg, zk);\n-    }\n-\n-    /**\n-     * ZooKeeper based topic persistence manager.\n-     */\n-    static class ZkTopicPersistenceManagerImpl implements TopicPersistenceManager {\n-\n-        ZooKeeper zk;\n-        ServerConfiguration cfg;\n-\n-        ZkTopicPersistenceManagerImpl(ServerConfiguration conf, ZooKeeper zk) {\n-            this.cfg = conf;\n-            this.zk = zk;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing in zookeeper based impl\n-        }\n-\n-        /**\n-         * Get znode path to store persistence info of a topic.\n-         *\n-         * @param topic\n-         *          Topic name\n-         * @return znode path to store persistence info.\n-         */\n-        private String ledgersPath(ByteString topic) {\n-            return cfg.getZkTopicPath(new StringBuilder(), topic).append(\"/ledgers\").toString();\n-        }\n-\n-        /**\n-         * Parse ledger ranges data and return it thru callback.\n-         *\n-         * @param topic\n-         *          Topic name\n-         * @param data\n-         *          Topic Ledger Ranges data\n-         * @param version\n-         *          Version of the topic ledger ranges data\n-         * @param callback\n-         *          Callback to return ledger ranges\n-         * @param ctx\n-         *          Context of the callback\n-         */\n-        private void parseAndReturnTopicLedgerRanges(ByteString topic, byte[] data, int version,\n-                                                     Callback<Versioned<LedgerRanges>> callback, Object ctx) {\n-            try {\n-                Versioned<LedgerRanges> ranges = new Versioned<LedgerRanges>(LedgerRanges.parseFrom(data),\n-                                                                             new ZkVersion(version));\n-                callback.operationFinished(ctx, ranges);\n-                return;\n-            } catch (InvalidProtocolBufferException e) {\n-                String msg = \"Ledger ranges for topic:\" + topic.toStringUtf8() + \" could not be deserialized\";\n-                logger.error(msg, e);\n-                callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                return;\n-            }\n-        }\n-\n-        @Override\n-        public void readTopicPersistenceInfo(final ByteString topic,\n-                                             final Callback<Versioned<LedgerRanges>> callback,\n-                                             Object ctx) {\n-            // read topic ledgers node data\n-            final String zNodePath = ledgersPath(topic);\n-\n-            zk.getData(zNodePath, false, new SafeAsyncZKCallback.DataCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n-                    if (rc == Code.OK.intValue()) {\n-                        parseAndReturnTopicLedgerRanges(topic, data, stat.getVersion(), callback, ctx);\n-                        return;\n-                    }\n-\n-                    if (rc == Code.NONODE.intValue()) {\n-                        // we don't create the znode until we first write it.\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-\n-                    // otherwise some other error\n-                    KeeperException ke =\n-                        ZkUtils.logErrorAndCreateZKException(\"Could not read ledgers node for topic: \"\n-                                                             + topic.toStringUtf8(), path, rc);\n-                    callback.operationFailed(ctx, new PubSubException.ServiceDownException(ke));\n-                }\n-            }, ctx);\n-        }\n-\n-        private void createTopicPersistenceInfo(final ByteString topic, LedgerRanges ranges,\n-                                                final Callback<Version> callback, Object ctx) {\n-            final String zNodePath = ledgersPath(topic);\n-            final byte[] data = ranges.toByteArray();\n-            // create it\n-            ZkUtils.createFullPathOptimistic(zk, zNodePath, data, Ids.OPEN_ACL_UNSAFE,\n-            CreateMode.PERSISTENT, new SafeAsyncZKCallback.StringCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, String name) {\n-                    if (rc == Code.NODEEXISTS.intValue()) {\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.TOPIC_PERSISTENCE_INFO_EXISTS,\n-                                                      \"Persistence info of topic \" + topic.toStringUtf8() + \" existed.\"));\n-                        return;\n-                    }\n-                    if (rc != Code.OK.intValue()) {\n-                        KeeperException ke = ZkUtils.logErrorAndCreateZKException(\n-                                             \"Could not create ledgers node for topic: \" + topic.toStringUtf8(),\n-                                             path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(ke));\n-                        return;\n-                    }\n-                    // initial version is version 0\n-                    callback.operationFinished(ctx, new ZkVersion(0));\n-                }\n-            }, ctx);\n-            return;\n-        }\n-\n-        @Override\n-        public void writeTopicPersistenceInfo(final ByteString topic, LedgerRanges ranges, final Version version,\n-                                              final Callback<Version> callback, Object ctx) {\n-            if (Version.NEW == version) {\n-                createTopicPersistenceInfo(topic, ranges, callback, ctx);\n-                return;\n-            }\n-\n-            final String zNodePath = ledgersPath(topic);\n-            final byte[] data = ranges.toByteArray();\n-\n-            if (!(version instanceof ZkVersion)) {\n-                callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                              \"Invalid version provided to update persistence info for topic \" + topic.toStringUtf8()));\n-                return;\n-            }\n-\n-            int znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-            zk.setData(zNodePath, data, znodeVersion, new SafeAsyncZKCallback.StatCallback() {\n-                    @Override\n-                    public void safeProcessResult(int rc, String path, Object ctx, Stat stat) {\n-                        if (rc == Code.NONODE.intValue()) {\n-                            // no node\n-                            callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_PERSISTENCE_INFO,\n-                                                          \"No persistence info found for topic \" + topic.toStringUtf8()));\n-                            return;\n-                        } else if (rc == Code.BADVERSION.intValue()) {\n-                            // bad version\n-                            callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                          \"Bad version provided to update persistence info of topic \" + topic.toStringUtf8()));\n-                            return;\n-                        } else if (rc == Code.OK.intValue()) {\n-                            callback.operationFinished(ctx, new ZkVersion(stat.getVersion()));\n-                            return;\n-                        } else {\n-                            KeeperException ke = ZkUtils.logErrorAndCreateZKException(\n-                                    \"Could not write ledgers node for topic: \" + topic.toStringUtf8(), path, rc);\n-                            callback.operationFailed(ctx, new PubSubException.ServiceDownException(ke));\n-                            return;\n-                        }\n-                    }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteTopicPersistenceInfo(final ByteString topic, final Version version,\n-                                               final Callback<Void> callback, Object ctx) {\n-            final String zNodePath = ledgersPath(topic);\n-\n-            int znodeVersion = -1;\n-            if (Version.ANY != version) {\n-                if (!(version instanceof ZkVersion)) {\n-                    callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                                  \"Invalid version provided to delete persistence info for topic \" + topic.toStringUtf8()));\n-                    return;\n-                } else {\n-                    znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-                }\n-            }\n-            zk.delete(zNodePath, znodeVersion, new SafeAsyncZKCallback.VoidCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx) {\n-                    if (rc == Code.OK.intValue()) {\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    } else if (rc == Code.NONODE.intValue()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_PERSISTENCE_INFO,\n-                                                      \"No persistence info found for topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (rc == Code.BADVERSION.intValue()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                      \"Bad version provided to delete persistence info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    }\n-\n-                    KeeperException e = ZkUtils.logErrorAndCreateZKException(\"Topic: \" + topic.toStringUtf8()\n-                                        + \" failed to delete persistence info @version \" + version + \" : \", path, rc);\n-                    callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    /**\n-     * ZooKeeper based subscription data manager.\n-     */\n-    static class ZkSubscriptionDataManagerImpl implements SubscriptionDataManager {\n-\n-        ZooKeeper zk;\n-        ServerConfiguration cfg;\n-\n-        ZkSubscriptionDataManagerImpl(ServerConfiguration conf, ZooKeeper zk) {\n-            this.cfg = conf;\n-            this.zk = zk;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing in zookeeper based impl\n-        }\n-\n-        /**\n-         * Get znode path to store subscription states.\n-         *\n-         * @param sb\n-         *          String builder to store the znode path.\n-         * @param topic\n-         *          Topic name.\n-         *\n-         * @return string builder to store znode path.\n-         */\n-        private StringBuilder topicSubscribersPath(StringBuilder sb, ByteString topic) {\n-            return cfg.getZkTopicPath(sb, topic).append(\"/subscribers\");\n-        }\n-\n-        /**\n-         * Get znode path to store subscription state for a specified subscriber.\n-         *\n-         * @param topic\n-         *          Topic name.\n-         * @param subscriber\n-         *          Subscriber id.\n-         * @return znode path to store subscription state.\n-         */\n-        private String topicSubscriberPath(ByteString topic, ByteString subscriber) {\n-            return topicSubscribersPath(new StringBuilder(), topic).append(\"/\").append(subscriber.toStringUtf8())\n-                   .toString();\n-        }\n-\n-        @Override\n-        public boolean isPartialUpdateSupported() {\n-            return false;\n-        }\n-\n-        @Override\n-        public void createSubscriptionData(final ByteString topic, final ByteString subscriberId, final SubscriptionData data,\n-                                           final Callback<Version> callback, final Object ctx) {\n-            ZkUtils.createFullPathOptimistic(zk, topicSubscriberPath(topic, subscriberId), data.toByteArray(),\n-            Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT, new SafeAsyncZKCallback.StringCallback() {\n-\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, String name) {\n-\n-                    if (rc == Code.NODEEXISTS.intValue()) {\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.SUBSCRIPTION_STATE_EXISTS,\n-                                                      \"Subscription state for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                                      + subscriberId.toStringUtf8() + \") existed.\"));\n-                        return;\n-                    } else if (rc == Code.OK.intValue()) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully recorded subscription for topic: \" + topic.toStringUtf8()\n-                                         + \" subscriberId: \" + subscriberId.toStringUtf8() + \" data: \"\n-                                         + SubscriptionStateUtils.toString(data));\n-                        }\n-                        callback.operationFinished(ctx, new ZkVersion(0));\n-                    } else {\n-                        KeeperException ke = ZkUtils.logErrorAndCreateZKException(\n-                                                 \"Could not record new subscription for topic: \" + topic.toStringUtf8()\n-                                                 + \" subscriberId: \" + subscriberId.toStringUtf8(), path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(ke));\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void updateSubscriptionData(final ByteString topic, final ByteString subscriberId, final SubscriptionData data,\n-                                           final Version version, final Callback<Version> callback, final Object ctx) {\n-            throw new UnsupportedOperationException(\"ZooKeeper based metadata manager doesn't support partial update!\");\n-        }\n-\n-        @Override\n-        public void replaceSubscriptionData(final ByteString topic, final ByteString subscriberId, final SubscriptionData data,\n-                                            final Version version, final Callback<Version> callback, final Object ctx) {\n-            int znodeVersion = -1;\n-            if (Version.NEW == version) {\n-                callback.operationFailed(ctx, \n-                        new PubSubException.BadVersionException(\"Can not replace Version.New subscription data\"));\n-                return;\n-            } else if (Version.ANY != version) {\n-                if (!(version instanceof ZkVersion)) {\n-                    callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                                  \"Invalid version provided to replace subscription data for topic  \" \n-                                                  + topic.toStringUtf8() + \" subscribe id: \" + subscriberId));\n-                    return;\n-                } else {\n-                    znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-                }\n-            }\n-            zk.setData(topicSubscriberPath(topic, subscriberId), data.toByteArray(), \n-                    znodeVersion, new SafeAsyncZKCallback.StatCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, Stat stat) {\n-                    if (rc == Code.NONODE.intValue()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_SUBSCRIPTION_STATE,\n-                                                      \"No subscription state found for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                                      + subscriberId.toStringUtf8() + \").\"));\n-                        return;\n-                    } else if (rc == Code.BADVERSION.intValue()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                      \"Bad version provided to replace subscription data of topic \" \n-                                                      + topic.toStringUtf8() + \" subscriberId \" + subscriberId));\n-                        return;\n-                    } else if (rc != Code.OK.intValue()) {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\"Topic: \" + topic.toStringUtf8()\n-                                            + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                            + \" could not set subscription data: \" + SubscriptionStateUtils.toString(data),\n-                                            path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                    } else {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully updated subscription for topic: \" + topic.toStringUtf8()\n-                                         + \" subscriberId: \" + subscriberId.toStringUtf8() + \" data: \"\n-                                         + SubscriptionStateUtils.toString(data));\n-                        }\n-\n-                        callback.operationFinished(ctx, new ZkVersion(stat.getVersion()));\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteSubscriptionData(final ByteString topic, final ByteString subscriberId, Version version,\n-                                           final Callback<Void> callback, Object ctx) {\n-            \n-            int znodeVersion = -1;\n-            if (Version.NEW == version) {\n-                callback.operationFailed(ctx, \n-                        new PubSubException.BadVersionException(\"Can not delete Version.New subscription data\"));\n-                return;\n-            } else if (Version.ANY != version) {\n-                if (!(version instanceof ZkVersion)) {\n-                    callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                                  \"Invalid version provided to delete subscription data for topic  \" \n-                                                  + topic.toStringUtf8() + \" subscribe id: \" + subscriberId));\n-                    return;\n-                } else {\n-                    znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-                }\n-            }\n-            \n-            zk.delete(topicSubscriberPath(topic, subscriberId), znodeVersion, new SafeAsyncZKCallback.VoidCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx) {\n-                    if (rc == Code.NONODE.intValue()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_SUBSCRIPTION_STATE,\n-                                                      \"No subscription state found for (topic:\" + topic.toStringUtf8() + \", subscriber:\"\n-                                                      + subscriberId.toStringUtf8() + \").\"));\n-                        return;\n-                    } else if (rc == Code.BADVERSION.intValue()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                      \"Bad version provided to delete subscription data of topic \" \n-                                                      + topic.toStringUtf8() + \" subscriberId \" + subscriberId));\n-                        return;\n-                    } else if (rc == Code.OK.intValue()) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully deleted subscription for topic: \" + topic.toStringUtf8()\n-                                         + \" subscriberId: \" + subscriberId.toStringUtf8());\n-                        }\n-\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-\n-                    KeeperException e = ZkUtils.logErrorAndCreateZKException(\"Topic: \" + topic.toStringUtf8()\n-                                        + \" subscriberId: \" + subscriberId.toStringUtf8() + \" failed to delete subscription\", path, rc);\n-                    callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void readSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                                         final Callback<Versioned<SubscriptionData>> callback, final Object ctx) {\n-            zk.getData(topicSubscriberPath(topic, subscriberId), false, new SafeAsyncZKCallback.DataCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n-                    if (rc == Code.NONODE.intValue()) {\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-                    if (rc != Code.OK.intValue()) {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\n-                                                \"Could not read subscription data for topic: \" + topic.toStringUtf8()\n-                                                + \", subscriberId: \" + subscriberId.toStringUtf8(), path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                        return;\n-                    }\n-                    \n-                    Versioned<SubscriptionData> subData;\n-                    try {\n-                        subData = new Versioned<SubscriptionData>(\n-                                        SubscriptionStateUtils.parseSubscriptionData(data), \n-                                        new ZkVersion(stat.getVersion()));\n-                    } catch (InvalidProtocolBufferException ex) {\n-                        String msg = \"Failed to deserialize subscription data for topic: \" + topic.toStringUtf8()\n-                                     + \" subscriberId: \" + subscriberId.toStringUtf8();\n-                        logger.error(msg, ex);\n-                        callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                        return;\n-                    }\n-\n-                    if (logger.isDebugEnabled()) {\n-                        logger.debug(\"Found subscription while acquiring topic: \" + topic.toStringUtf8()\n-                                     + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                     + \" data: \" + SubscriptionStateUtils.toString(subData.getValue()));\n-                    }\n-                    callback.operationFinished(ctx, subData);\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void readSubscriptions(final ByteString topic,\n-                                      final Callback<Map<ByteString, Versioned<SubscriptionData>>> cb, final Object ctx) {\n-            String topicSubscribersPath = topicSubscribersPath(new StringBuilder(), topic).toString();\n-            zk.getChildren(topicSubscribersPath, false, new SafeAsyncZKCallback.ChildrenCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, final Object ctx, final List<String> children) {\n-\n-                    if (rc != Code.OK.intValue() && rc != Code.NONODE.intValue()) {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\"Could not read subscribers for topic \"\n-                                            + topic.toStringUtf8(), path, rc);\n-                        cb.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                        return;\n-                    }\n-\n-                    final Map<ByteString, Versioned<SubscriptionData>> topicSubs = \n-                            new ConcurrentHashMap<ByteString, Versioned<SubscriptionData>>();\n-\n-                    if (rc == Code.NONODE.intValue() || children.size() == 0) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"No subscriptions found while acquiring topic: \" + topic.toStringUtf8());\n-                        }\n-                        cb.operationFinished(ctx, topicSubs);\n-                        return;\n-                    }\n-\n-                    final AtomicBoolean failed = new AtomicBoolean();\n-                    final AtomicInteger count = new AtomicInteger();\n-\n-                    for (final String child : children) {\n-\n-                        final ByteString subscriberId = ByteString.copyFromUtf8(child);\n-                        final String childPath = path + \"/\" + child;\n-\n-                        zk.getData(childPath, false, new SafeAsyncZKCallback.DataCallback() {\n-                            @Override\n-                            public void safeProcessResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n-\n-                                if (rc != Code.OK.intValue()) {\n-                                    KeeperException e = ZkUtils.logErrorAndCreateZKException(\n-                                                            \"Could not read subscription data for topic: \" + topic.toStringUtf8()\n-                                                            + \", subscriberId: \" + subscriberId.toStringUtf8(), path, rc);\n-                                    reportFailure(new PubSubException.ServiceDownException(e));\n-                                    return;\n-                                }\n-\n-                                if (failed.get()) {\n-                                    return;\n-                                }\n-\n-                                Versioned<SubscriptionData> subData;\n-                                try {\n-                                    subData = new Versioned<SubscriptionData>(\n-                                            SubscriptionStateUtils.parseSubscriptionData(data), \n-                                            new ZkVersion(stat.getVersion()));\n-                                } catch (InvalidProtocolBufferException ex) {\n-                                    String msg = \"Failed to deserialize subscription data for topic: \" + topic.toStringUtf8()\n-                                                 + \" subscriberId: \" + subscriberId.toStringUtf8();\n-                                    logger.error(msg, ex);\n-                                    reportFailure(new PubSubException.UnexpectedConditionException(msg));\n-                                    return;\n-                                }\n-\n-                                if (logger.isDebugEnabled()) {\n-                                    logger.debug(\"Found subscription while acquiring topic: \" + topic.toStringUtf8()\n-                                                 + \" subscriberId: \" + child + \"state: \"\n-                                                 + SubscriptionStateUtils.toString(subData.getValue()));\n-                                }\n-\n-                                topicSubs.put(subscriberId, subData);\n-                                if (count.incrementAndGet() == children.size()) {\n-                                    assert topicSubs.size() == count.get();\n-                                    cb.operationFinished(ctx, topicSubs);\n-                                }\n-                            }\n-\n-                            private void reportFailure(PubSubException e) {\n-                                if (failed.compareAndSet(false, true))\n-                                    cb.operationFailed(ctx, e);\n-                            }\n-                        }, ctx);\n-                    }\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    /**\n-     * ZooKeeper base topic ownership manager.\n-     */\n-    static class ZkTopicOwnershipManagerImpl implements TopicOwnershipManager {\n-\n-        ZooKeeper zk;\n-        ServerConfiguration cfg;\n-\n-        ZkTopicOwnershipManagerImpl(ServerConfiguration conf, ZooKeeper zk) {\n-            this.cfg = conf;\n-            this.zk = zk;\n-        }\n-\n-        @Override\n-        public void close() throws IOException {\n-            // do nothing in zookeeper based impl\n-        }\n-\n-        /**\n-         * Return znode path to store topic owner.\n-         *\n-         * @param topic\n-         *          Topic Name\n-         * @return znode path to store topic owner.\n-         */\n-        String hubPath(ByteString topic) {\n-            return cfg.getZkTopicPath(new StringBuilder(), topic).append(\"/hub\").toString();\n-        }\n-\n-        @Override\n-        public void readOwnerInfo(final ByteString topic, final Callback<Versioned<HubInfo>> callback, Object ctx) {\n-            String ownerPath = hubPath(topic);\n-            zk.getData(ownerPath, false, new SafeAsyncZKCallback.DataCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, byte[] data, Stat stat) {\n-                    if (Code.NONODE.intValue() == rc) {\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    }\n-\n-                    if (Code.OK.intValue() != rc) {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\"Could not read ownership for topic: \"\n-                                            + topic.toStringUtf8(), path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                        return;\n-                    }\n-                    HubInfo owner = null;\n-                    try {\n-                        owner = HubInfo.parse(new String(data, UTF_8));\n-                    } catch (HubInfo.InvalidHubInfoException ihie) {\n-                        logger.warn(\"Failed to parse hub info for topic \" + topic.toStringUtf8() + \" : \", ihie);\n-                    }\n-                    int version = stat.getVersion();\n-                    callback.operationFinished(ctx, new Versioned<HubInfo>(owner, new ZkVersion(version)));\n-                    return;\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void writeOwnerInfo(final ByteString topic, final HubInfo owner, final Version version,\n-                                   final Callback<Version> callback, Object ctx) {\n-            if (Version.NEW == version) {\n-                createOwnerInfo(topic, owner, callback, ctx);\n-                return;\n-            }\n-\n-            if (!(version instanceof ZkVersion)) {\n-                callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                              \"Invalid version provided to update owner info for topic \" + topic.toStringUtf8()));\n-                return;\n-            }\n-\n-            int znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-            zk.setData(hubPath(topic), owner.toString().getBytes(UTF_8), znodeVersion,\n-                       new SafeAsyncZKCallback.StatCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, Stat stat) {\n-                    if (rc == Code.NONODE.intValue()) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_OWNER_INFO,\n-                                                      \"No owner info found for topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (rc == Code.BADVERSION.intValue()) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                      \"Bad version provided to update owner info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (Code.OK.intValue() == rc) {\n-                        callback.operationFinished(ctx, new ZkVersion(stat.getVersion()));\n-                        return;\n-                    } else {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\n-                            \"Failed to update ownership of topic \" + topic.toStringUtf8() +\n-                            \" to \" + owner, path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                        return;\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        protected void createOwnerInfo(final ByteString topic, final HubInfo owner,\n-                                       final Callback<Version> callback, Object ctx) {\n-            String ownerPath = hubPath(topic);\n-            ZkUtils.createFullPathOptimistic(zk, ownerPath, owner.toString().getBytes(UTF_8), Ids.OPEN_ACL_UNSAFE,\n-                                             CreateMode.PERSISTENT, new SafeAsyncZKCallback.StringCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx, String name) {\n-                    if (Code.OK.intValue() == rc) {\n-                        // assume the initial version is 0\n-                        callback.operationFinished(ctx, new ZkVersion(0));\n-                        return;\n-                    } else if (Code.NODEEXISTS.intValue() == rc) {\n-                        // node existed\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.TOPIC_OWNER_INFO_EXISTS,\n-                                                      \"Owner info of topic \" + topic.toStringUtf8() + \" existed.\"));\n-                        return;\n-                    } else {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\n-                                                \"Failed to create znode for ownership of topic: \"\n-                                                + topic.toStringUtf8(), path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                        return;\n-                    }\n-                }\n-            }, ctx);\n-        }\n-\n-        @Override\n-        public void deleteOwnerInfo(final ByteString topic, final Version version,\n-                                    final Callback<Void> callback, Object ctx) {\n-            int znodeVersion = -1;\n-            if (Version.ANY != version) {\n-                if (!(version instanceof ZkVersion)) {\n-                    callback.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\n-                                                  \"Invalid version provided to delete owner info for topic \" + topic.toStringUtf8()));\n-                    return;\n-                } else {\n-                    znodeVersion = ((ZkVersion)version).getZnodeVersion();\n-                }\n-            }\n-\n-            zk.delete(hubPath(topic), znodeVersion, new SafeAsyncZKCallback.VoidCallback() {\n-                @Override\n-                public void safeProcessResult(int rc, String path, Object ctx) {\n-                    if (Code.OK.intValue() == rc) {\n-                        if (logger.isDebugEnabled()) {\n-                            logger.debug(\"Successfully deleted owner info for topic \" + topic.toStringUtf8() + \".\");\n-                        }\n-                        callback.operationFinished(ctx, null);\n-                        return;\n-                    } else if (Code.NONODE.intValue() == rc) {\n-                        // no node\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.NO_TOPIC_OWNER_INFO,\n-                                                      \"No owner info found for topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else if (Code.BADVERSION.intValue() == rc) {\n-                        // bad version\n-                        callback.operationFailed(ctx, PubSubException.create(StatusCode.BAD_VERSION,\n-                                                      \"Bad version provided to delete owner info of topic \" + topic.toStringUtf8()));\n-                        return;\n-                    } else {\n-                        KeeperException e = ZkUtils.logErrorAndCreateZKException(\n-                                                \"Failed to delete owner info for topic \"\n-                                                + topic.toStringUtf8(), path, rc);\n-                        callback.operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-                    }\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    @Override\n-    public void format(ServerConfiguration cfg, ZooKeeper zk) throws IOException {\n-        try {\n-            ZKUtil.deleteRecursive(zk, cfg.getZkTopicsPrefix(new StringBuilder()).toString());\n-        } catch (KeeperException.NoNodeException e) {\n-            logger.debug(\"Hedwig root node doesn't exist in zookeeper to delete\");\n-        } catch (KeeperException ke) {\n-            throw new IOException(ke);\n-        } catch (InterruptedException ie) {\n-            throw new IOException(ie);\n-        }\n-    }\n-}"},{"sha":"23e04e3d3df7d9f9865819eec424c7852a47e3b6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServer.java","status":"removed","additions":0,"deletions":535,"changes":535,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServer.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServer.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServer.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,535 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.netty;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.net.InetSocketAddress;\n-import java.net.MalformedURLException;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.CountDownLatch;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.SynchronousQueue;\n-import java.util.concurrent.TimeUnit;\n-\n-import com.google.common.annotations.VisibleForTesting;\n-import com.google.common.util.concurrent.ThreadFactoryBuilder;\n-\n-import org.apache.bookkeeper.conf.ClientConfiguration;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.jboss.netty.bootstrap.ServerBootstrap;\n-import org.jboss.netty.channel.group.ChannelGroup;\n-import org.jboss.netty.channel.group.DefaultChannelGroup;\n-import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n-import org.jboss.netty.channel.socket.ServerSocketChannelFactory;\n-import org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory;\n-import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory;\n-import org.jboss.netty.logging.InternalLoggerFactory;\n-import org.jboss.netty.logging.Log4JLoggerFactory;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TerminateJVMExceptionHandler;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.delivery.FIFODeliveryManager;\n-import org.apache.hedwig.server.handlers.CloseSubscriptionHandler;\n-import org.apache.hedwig.server.handlers.ConsumeHandler;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.handlers.NettyHandlerBean;\n-import org.apache.hedwig.server.handlers.PublishHandler;\n-import org.apache.hedwig.server.handlers.SubscribeHandler;\n-import org.apache.hedwig.server.handlers.SubscriptionChannelManager;\n-import org.apache.hedwig.server.handlers.SubscriptionChannelManager.SubChannelDisconnectedListener;\n-import org.apache.hedwig.server.handlers.UnsubscribeHandler;\n-import org.apache.hedwig.server.jmx.HedwigMBeanRegistry;\n-import org.apache.hedwig.server.meta.MetadataManagerFactory;\n-import org.apache.hedwig.server.meta.ZkMetadataManagerFactory;\n-import org.apache.hedwig.server.persistence.BookkeeperPersistenceManager;\n-import org.apache.hedwig.server.persistence.LocalDBPersistenceManager;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.persistence.PersistenceManagerWithRangeScan;\n-import org.apache.hedwig.server.persistence.ReadAheadCache;\n-import org.apache.hedwig.server.regions.HedwigHubClientFactory;\n-import org.apache.hedwig.server.regions.RegionManager;\n-import org.apache.hedwig.server.ssl.SslServerContextFactory;\n-import org.apache.hedwig.server.subscriptions.InMemorySubscriptionManager;\n-import org.apache.hedwig.server.subscriptions.SubscriptionManager;\n-import org.apache.hedwig.server.subscriptions.MMSubscriptionManager;\n-import org.apache.hedwig.server.topics.MMTopicManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.server.topics.TrivialOwnAllTopicManager;\n-import org.apache.hedwig.server.topics.ZkTopicManager;\n-import org.apache.hedwig.util.ConcurrencyUtils;\n-import org.apache.hedwig.util.Either;\n-import org.apache.hedwig.zookeeper.SafeAsyncCallback;\n-\n-public class PubSubServer {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(PubSubServer.class);\n-\n-    private static final String JMXNAME_PREFIX = \"PubSubServer_\";\n-\n-    // Netty related variables\n-    ServerSocketChannelFactory serverChannelFactory;\n-    ClientSocketChannelFactory clientChannelFactory;\n-    ServerConfiguration conf;\n-    org.apache.hedwig.client.conf.ClientConfiguration clientConfiguration;\n-    ChannelGroup allChannels;\n-\n-    // Manager components that make up the PubSubServer\n-    PersistenceManager pm;\n-    DeliveryManager dm;\n-    TopicManager tm;\n-    SubscriptionManager sm;\n-    RegionManager rm;\n-\n-    // Metadata Manager Factory\n-    MetadataManagerFactory mm;\n-\n-    ZooKeeper zk; // null if we are in standalone mode\n-    BookKeeper bk; // null if we are in standalone mode\n-\n-    // we use this to prevent long stack chains from building up in callbacks\n-    ScheduledExecutorService scheduler;\n-\n-    // JMX Beans\n-    NettyHandlerBean jmxNettyBean;\n-    PubSubServerBean jmxServerBean;\n-    final ThreadGroup tg;\n-\n-    protected PersistenceManager instantiatePersistenceManager(TopicManager topicMgr) throws IOException,\n-        InterruptedException {\n-\n-        PersistenceManagerWithRangeScan underlyingPM;\n-\n-        if (conf.isStandalone()) {\n-\n-            underlyingPM = LocalDBPersistenceManager.instance();\n-\n-        } else {\n-            try {\n-                ClientConfiguration bkConf = new ClientConfiguration();\n-                bkConf.addConfiguration(conf.getConf());\n-                bk = new BookKeeper(bkConf, zk, clientChannelFactory);\n-            } catch (KeeperException e) {\n-                logger.error(\"Could not instantiate bookkeeper client\", e);\n-                throw new IOException(e);\n-            }\n-            underlyingPM = new BookkeeperPersistenceManager(bk, mm, topicMgr, conf, scheduler);\n-\n-        }\n-\n-        PersistenceManager pm = underlyingPM;\n-\n-        if (conf.getReadAheadEnabled()) {\n-            pm = new ReadAheadCache(underlyingPM, conf).start();\n-        }\n-\n-        return pm;\n-    }\n-\n-    protected SubscriptionManager instantiateSubscriptionManager(TopicManager tm, PersistenceManager pm,\n-                                                                 DeliveryManager dm) {\n-        if (conf.isStandalone()) {\n-            return new InMemorySubscriptionManager(conf, tm, pm, dm, scheduler);\n-        } else {\n-            return new MMSubscriptionManager(conf, mm, tm, pm, dm, scheduler);\n-        }\n-\n-    }\n-\n-    protected RegionManager instantiateRegionManager(PersistenceManager pm, ScheduledExecutorService scheduler) {\n-        return new RegionManager(pm, conf, zk, scheduler, new HedwigHubClientFactory(conf, clientConfiguration,\n-                clientChannelFactory));\n-    }\n-\n-    protected void instantiateZookeeperClient() throws Exception {\n-        if (!conf.isStandalone()) {\n-            final CountDownLatch signalZkReady = new CountDownLatch(1);\n-\n-            zk = new ZooKeeper(conf.getZkHost(), conf.getZkTimeout(), new Watcher() {\n-                @Override\n-                public void process(WatchedEvent event) {\n-                    if(Event.KeeperState.SyncConnected.equals(event.getState())) {\n-                        signalZkReady.countDown();\n-                    }\n-                }\n-            });\n-            // wait until connection is effective\n-            if (!signalZkReady.await(conf.getZkTimeout()*2, TimeUnit.MILLISECONDS)) {\n-                logger.error(\"Could not establish connection with ZooKeeper after zk_timeout*2 = \" +\n-                             conf.getZkTimeout()*2 + \" ms. (Default value for zk_timeout is 2000).\");\n-                throw new Exception(\"Could not establish connection with ZooKeeper after zk_timeout*2 = \" +\n-                                    conf.getZkTimeout()*2 + \" ms. (Default value for zk_timeout is 2000).\");\n-            }\n-        }\n-    }\n-\n-    protected void instantiateMetadataManagerFactory() throws Exception {\n-        if (conf.isStandalone()) {\n-            return;\n-        }\n-        mm = MetadataManagerFactory.newMetadataManagerFactory(conf, zk);\n-    }\n-\n-    protected TopicManager instantiateTopicManager() throws IOException {\n-        TopicManager tm;\n-\n-        if (conf.isStandalone()) {\n-            tm = new TrivialOwnAllTopicManager(conf, scheduler);\n-        } else {\n-            try {\n-                if (conf.isMetadataManagerBasedTopicManagerEnabled()) {\n-                    tm = new MMTopicManager(conf, zk, mm, scheduler);\n-                } else {\n-                    if (!(mm instanceof ZkMetadataManagerFactory)) {\n-                        throw new IOException(\"Uses \" + mm.getClass().getName() + \" to store hedwig metadata, \"\n-                                            + \"but uses zookeeper ephemeral znodes to store topic ownership. \"\n-                                            + \"Check your configuration as this could lead to scalability issues.\");\n-                    }\n-                    tm = new ZkTopicManager(zk, conf, scheduler);\n-                }\n-            } catch (PubSubException e) {\n-                logger.error(\"Could not instantiate TopicOwnershipManager based topic manager\", e);\n-                throw new IOException(e);\n-            }\n-        }\n-        return tm;\n-    }\n-\n-   protected Map<OperationType, Handler> initializeNettyHandlers(\n-           TopicManager tm, DeliveryManager dm,\n-           PersistenceManager pm, SubscriptionManager sm,\n-           SubscriptionChannelManager subChannelMgr) {\n-        Map<OperationType, Handler> handlers = new HashMap<OperationType, Handler>();\n-        handlers.put(OperationType.PUBLISH, new PublishHandler(tm, pm, conf));\n-        handlers.put(OperationType.SUBSCRIBE,\n-                     new SubscribeHandler(conf, tm, dm, pm, sm, subChannelMgr));\n-        handlers.put(OperationType.UNSUBSCRIBE,\n-                     new UnsubscribeHandler(conf, tm, sm, dm, subChannelMgr));\n-        handlers.put(OperationType.CONSUME, new ConsumeHandler(tm, sm, conf));\n-        handlers.put(OperationType.CLOSESUBSCRIPTION,\n-                     new CloseSubscriptionHandler(conf, tm, sm, dm, subChannelMgr));\n-        handlers = Collections.unmodifiableMap(handlers);\n-        return handlers;\n-    }\n-\n-    protected void initializeNetty(SslServerContextFactory sslFactory,\n-                                   Map<OperationType, Handler> handlers,\n-                                   SubscriptionChannelManager subChannelMgr) {\n-        boolean isSSLEnabled = (sslFactory != null) ? true : false;\n-        InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory());\n-        ServerBootstrap bootstrap = new ServerBootstrap(serverChannelFactory);\n-        UmbrellaHandler umbrellaHandler =\n-            new UmbrellaHandler(allChannels, handlers, subChannelMgr, isSSLEnabled);\n-        PubSubServerPipelineFactory pipeline =\n-            new PubSubServerPipelineFactory(umbrellaHandler, sslFactory,\n-                                            conf.getMaximumMessageSize());\n-\n-        bootstrap.setPipelineFactory(pipeline);\n-        bootstrap.setOption(\"child.tcpNoDelay\", true);\n-        bootstrap.setOption(\"child.keepAlive\", true);\n-        bootstrap.setOption(\"reuseAddress\", true);\n-\n-        // Bind and start to accept incoming connections.\n-        allChannels.add(bootstrap.bind(isSSLEnabled ? new InetSocketAddress(conf.getSSLServerPort())\n-                                       : new InetSocketAddress(conf.getServerPort())));\n-        logger.info(\"Going into receive loop\");\n-    }\n-\n-    public void shutdown() {\n-        // TODO: tell bk to close logs\n-\n-        // Stop topic manager first since it is core of Hub server\n-        tm.stop();\n-\n-        // Stop the RegionManager.\n-        rm.stop();\n-\n-        // Stop the DeliveryManager and ReadAheadCache threads (if\n-        // applicable).\n-        dm.stop();\n-        pm.stop();\n-\n-        // Stop the SubscriptionManager if needed.\n-        sm.stop();\n-\n-        // Shutdown metadata manager if needed\n-        if (null != mm) {\n-            try {\n-                mm.shutdown();\n-            } catch (IOException ie) {\n-                logger.error(\"Error while shutdown metadata manager factory!\", ie);\n-            }\n-        }\n-\n-        // Shutdown the ZooKeeper and BookKeeper clients only if we are\n-        // not in stand-alone mode.\n-        try {\n-            if (bk != null)\n-                bk.close();\n-            if (zk != null)\n-                zk.close();\n-        } catch (InterruptedException e) {\n-            logger.error(\"Error while closing ZooKeeper client : \", e);\n-        } catch (BKException bke) {\n-            logger.error(\"Error while closing BookKeeper client : \", bke);\n-        }\n-\n-        // Close and release the Netty channels and resources\n-        allChannels.close().awaitUninterruptibly();\n-        serverChannelFactory.releaseExternalResources();\n-        clientChannelFactory.releaseExternalResources();\n-        scheduler.shutdown();\n-\n-        // unregister jmx\n-        unregisterJMX();\n-    }\n-\n-    protected void registerJMX(SubscriptionChannelManager subChannelMgr) {\n-        try {\n-            String jmxName = JMXNAME_PREFIX + conf.getServerPort() + \"_\"\n-                                            + conf.getSSLServerPort();\n-            jmxServerBean = new PubSubServerBean(jmxName);\n-            HedwigMBeanRegistry.getInstance().register(jmxServerBean, null);\n-            try {\n-                jmxNettyBean = new NettyHandlerBean(subChannelMgr);\n-                HedwigMBeanRegistry.getInstance().register(jmxNettyBean, jmxServerBean);\n-            } catch (Exception e) {\n-                logger.warn(\"Failed to register with JMX\", e);\n-                jmxNettyBean = null;\n-            }\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to register with JMX\", e);\n-            jmxServerBean = null;\n-        }\n-        if (pm instanceof ReadAheadCache) {\n-            ((ReadAheadCache)pm).registerJMX(jmxServerBean);\n-        }\n-    }\n-\n-    protected void unregisterJMX() {\n-        if (pm != null && pm instanceof ReadAheadCache) {\n-            ((ReadAheadCache)pm).unregisterJMX();\n-        }\n-        try {\n-            if (jmxNettyBean != null) {\n-                HedwigMBeanRegistry.getInstance().unregister(jmxNettyBean);\n-            }\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to unregister with JMX\", e);\n-        }\n-        try {\n-            if (jmxServerBean != null) {\n-                HedwigMBeanRegistry.getInstance().unregister(jmxServerBean);\n-            }\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to unregister with JMX\", e);\n-        }\n-        jmxNettyBean = null;\n-        jmxServerBean = null;\n-    }\n-\n-    /**\n-     * Starts the hedwig server on the given port\n-     *\n-     * @param port\n-     * @throws ConfigurationException\n-     *             if there is something wrong with the given configuration\n-     * @throws IOException\n-     * @throws InterruptedException\n-     * @throws ConfigurationException\n-     */\n-    public PubSubServer(final ServerConfiguration serverConfiguration,\n-                        final org.apache.hedwig.client.conf.ClientConfiguration clientConfiguration,\n-                        final Thread.UncaughtExceptionHandler exceptionHandler)\n-            throws ConfigurationException {\n-\n-        // First validate the serverConfiguration\n-        this.conf = serverConfiguration;\n-        serverConfiguration.validate();\n-\n-        // Validate the client configuration\n-        this.clientConfiguration = clientConfiguration;\n-        clientConfiguration.validate();\n-\n-        // We need a custom thread group, so that we can override the uncaught\n-        // exception method\n-        tg = new ThreadGroup(\"hedwig\") {\n-            @Override\n-            public void uncaughtException(Thread t, Throwable e) {\n-                exceptionHandler.uncaughtException(t, e);\n-            }\n-        };\n-        // ZooKeeper threads register their own handler. But if some work that\n-        // we do in ZK threads throws an exception, we want our handler to be\n-        // called, not theirs.\n-        SafeAsyncCallback.setUncaughtExceptionHandler(exceptionHandler);\n-    }\n-\n-    public void start() throws Exception {\n-        final SynchronousQueue<Either<Object, Exception>> queue = new SynchronousQueue<Either<Object, Exception>>();\n-\n-        new Thread(tg, new Runnable() {\n-            @Override\n-            public void run() {\n-                try {\n-                    // Since zk is needed by almost everyone,try to see if we\n-                    // need that first\n-                    ThreadFactoryBuilder tfb = new ThreadFactoryBuilder();\n-                    scheduler = Executors.newSingleThreadScheduledExecutor(tfb\n-                            .setNameFormat(\"PubSubServerScheduler-%d\").build());\n-                    serverChannelFactory = new NioServerSocketChannelFactory(\n-                            Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                    \"PubSub-Server-NIOBoss-%d\").build()),\n-                            Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                    \"PubSub-Server-NIOWorker-%d\").build()));\n-                    clientChannelFactory = new NioClientSocketChannelFactory(\n-                            Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                    \"PubSub-Client-NIOBoss-%d\").build()),\n-                            Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                    \"PubSub-Client-NIOWorker-%d\").build()));\n-\n-                    instantiateZookeeperClient();\n-                    instantiateMetadataManagerFactory();\n-                    tm = instantiateTopicManager();\n-                    pm = instantiatePersistenceManager(tm);\n-                    dm = new FIFODeliveryManager(tm, pm, conf);\n-                    dm.start();\n-\n-                    sm = instantiateSubscriptionManager(tm, pm, dm);\n-                    rm = instantiateRegionManager(pm, scheduler);\n-                    sm.addListener(rm);\n-\n-                    allChannels = new DefaultChannelGroup(\"hedwig\");\n-                    // Initialize the Netty Handlers (used by the\n-                    // UmbrellaHandler) once so they can be shared by\n-                    // both the SSL and non-SSL channels.\n-                    SubscriptionChannelManager subChannelMgr = new SubscriptionChannelManager();\n-                    subChannelMgr.addSubChannelDisconnectedListener((SubChannelDisconnectedListener) dm);\n-                    Map<OperationType, Handler> handlers =\n-                        initializeNettyHandlers(tm, dm, pm, sm, subChannelMgr);\n-                    // Initialize Netty for the regular non-SSL channels\n-                    initializeNetty(null, handlers, subChannelMgr);\n-                    if (conf.isSSLEnabled()) {\n-                        initializeNetty(new SslServerContextFactory(conf),\n-                                        handlers, subChannelMgr);\n-                    }\n-                    // register jmx\n-                    registerJMX(subChannelMgr);\n-                } catch (Exception e) {\n-                    ConcurrencyUtils.put(queue, Either.right(e));\n-                    return;\n-                }\n-\n-                ConcurrencyUtils.put(queue, Either.of(new Object(), (Exception) null));\n-            }\n-\n-        }).start();\n-\n-        Either<Object, Exception> either = ConcurrencyUtils.take(queue);\n-        if (either.left() == null) {\n-            throw either.right();\n-        }\n-    }\n-\n-    public PubSubServer(ServerConfiguration serverConfiguration,\n-                        org.apache.hedwig.client.conf.ClientConfiguration clientConfiguration) throws Exception {\n-        this(serverConfiguration, clientConfiguration, new TerminateJVMExceptionHandler());\n-    }\n-\n-    public PubSubServer(ServerConfiguration serverConfiguration) throws Exception {\n-        this(serverConfiguration, new org.apache.hedwig.client.conf.ClientConfiguration());\n-    }\n-\n-    @VisibleForTesting\n-    public DeliveryManager getDeliveryManager() {\n-        return dm;\n-    }\n-\n-    /**\n-     *\n-     * @param msg\n-     * @param rc\n-     *            : code to exit with\n-     */\n-    public static void errorMsgAndExit(String msg, Throwable t, int rc) {\n-        logger.error(msg, t);\n-        System.err.println(msg);\n-        System.exit(rc);\n-    }\n-\n-    public final static int RC_INVALID_CONF_FILE = 1;\n-    public final static int RC_MISCONFIGURED = 2;\n-    public final static int RC_OTHER = 3;\n-\n-    /**\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-\n-        logger.info(\"Attempting to start Hedwig\");\n-        ServerConfiguration serverConfiguration = new ServerConfiguration();\n-        // The client configuration for the hedwig client in the region manager.\n-        org.apache.hedwig.client.conf.ClientConfiguration regionMgrClientConfiguration\n-                = new org.apache.hedwig.client.conf.ClientConfiguration();\n-        if (args.length > 0) {\n-            String confFile = args[0];\n-            try {\n-                serverConfiguration.loadConf(new File(confFile).toURI().toURL());\n-            } catch (MalformedURLException e) {\n-                String msg = \"Could not open server configuration file: \" + confFile;\n-                errorMsgAndExit(msg, e, RC_INVALID_CONF_FILE);\n-            } catch (ConfigurationException e) {\n-                String msg = \"Malformed server configuration file: \" + confFile;\n-                errorMsgAndExit(msg, e, RC_MISCONFIGURED);\n-            }\n-            logger.info(\"Using configuration file \" + confFile);\n-        }\n-        if (args.length > 1) {\n-            // args[1] is the client configuration file.\n-            String confFile = args[1];\n-            try {\n-                regionMgrClientConfiguration.loadConf(new File(confFile).toURI().toURL());\n-            } catch (MalformedURLException e) {\n-                String msg = \"Could not open client configuration file: \" + confFile;\n-                errorMsgAndExit(msg, e, RC_INVALID_CONF_FILE);\n-            } catch (ConfigurationException e) {\n-                String msg = \"Malformed client configuration file: \" + confFile;\n-                errorMsgAndExit(msg, e, RC_MISCONFIGURED);\n-            }\n-        }\n-        try {\n-            new PubSubServer(serverConfiguration, regionMgrClientConfiguration).start();\n-        } catch (Throwable t) {\n-            errorMsgAndExit(\"Error during startup\", t, RC_OTHER);\n-        }\n-    }\n-}"},{"sha":"c1acbbc32782f7aec6f74f194533f45534eda8d6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerBean.java","status":"removed","additions":0,"deletions":83,"changes":83,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,83 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.netty;\n-\n-import org.apache.hedwig.server.jmx.HedwigMBeanInfo;\n-import org.apache.hedwig.server.netty.ServerStats.OpStatData;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-\n-/**\n- * PubSub Server Bean\n- */\n-public class PubSubServerBean implements PubSubServerMXBean, HedwigMBeanInfo {\n-\n-    private final String name;\n-\n-    public PubSubServerBean(String jmxName) {\n-        this.name = jmxName;\n-    }\n-\n-    @Override\n-    public String getName() {\n-        return name;\n-    }\n-\n-    @Override\n-    public boolean isHidden() {\n-        return false;\n-    }\n-\n-    @Override\n-    public OpStatData getPubStats() {\n-        return ServerStats.getInstance().getOpStats(OperationType.PUBLISH).toOpStatData();\n-    }\n-\n-    @Override\n-    public OpStatData getSubStats() {\n-        return ServerStats.getInstance().getOpStats(OperationType.SUBSCRIBE).toOpStatData();\n-    }\n-\n-    @Override\n-    public OpStatData getUnsubStats() {\n-        return ServerStats.getInstance().getOpStats(OperationType.UNSUBSCRIBE).toOpStatData();\n-    }\n-\n-    @Override\n-    public OpStatData getConsumeStats() {\n-        return ServerStats.getInstance().getOpStats(OperationType.CONSUME).toOpStatData();\n-    }\n-\n-    @Override\n-    public long getNumRequestsReceived() {\n-        return ServerStats.getInstance().getNumRequestsReceived();\n-    }\n-\n-    @Override\n-    public long getNumRequestsRedirect() {\n-        return ServerStats.getInstance().getNumRequestsRedirect();\n-    }\n-\n-    @Override\n-    public long getNumMessagesDelivered() {\n-        return ServerStats.getInstance().getNumMessagesDelivered();\n-    }\n-\n-\n-}"},{"sha":"15e860fb04812d5d290170eb638e306e5a032c8d","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerMXBean.java","status":"removed","additions":0,"deletions":63,"changes":63,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerMXBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerMXBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerMXBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,63 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.netty;\n-\n-import org.apache.hedwig.server.netty.ServerStats.OpStatData;\n-\n-/**\n- * PubSub Server MBean\n- */\n-public interface PubSubServerMXBean {\n-\n-    /**\n-     * @return publish stats\n-     */\n-    public OpStatData getPubStats();\n-\n-    /**\n-     * @return subscription stats\n-     */\n-    public OpStatData getSubStats();\n-\n-    /**\n-     * @return unsub stats\n-     */\n-    public OpStatData getUnsubStats();\n-\n-    /**\n-     * @return consume stats\n-     */\n-    public OpStatData getConsumeStats();\n-\n-    /**\n-     * @return number of requests received\n-     */\n-    public long getNumRequestsReceived();\n-\n-    /**\n-     * @return number of requests redirect\n-     */\n-    public long getNumRequestsRedirect();\n-\n-    /**\n-     * @return number of messages delivered\n-     */\n-    public long getNumMessagesDelivered();\n-\n-}"},{"sha":"c96f438e2d6d21182d671ecf558b578b8c333103","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerPipelineFactory.java","status":"removed","additions":0,"deletions":76,"changes":76,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerPipelineFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerPipelineFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/PubSubServerPipelineFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,76 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.netty;\n-\n-import org.jboss.netty.channel.ChannelPipeline;\n-import org.jboss.netty.channel.ChannelPipelineFactory;\n-import org.jboss.netty.channel.Channels;\n-import org.jboss.netty.handler.codec.frame.LengthFieldBasedFrameDecoder;\n-import org.jboss.netty.handler.codec.frame.LengthFieldPrepender;\n-import org.jboss.netty.handler.codec.protobuf.ProtobufDecoder;\n-import org.jboss.netty.handler.codec.protobuf.ProtobufEncoder;\n-import org.jboss.netty.handler.ssl.SslHandler;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.apache.hedwig.server.ssl.SslServerContextFactory;\n-\n-public class PubSubServerPipelineFactory implements ChannelPipelineFactory {\n-\n-    // TODO: make these conf settings\n-    final static int MAX_WORKER_THREADS = 32;\n-    final static int MAX_CHANNEL_MEMORY_SIZE = 10 * 1024 * 1024;\n-    final static int MAX_TOTAL_MEMORY_SIZE = 100 * 1024 * 1024;\n-\n-    private UmbrellaHandler uh;\n-    private SslServerContextFactory sslFactory;\n-    private int maxMessageSize;\n-\n-    /**\n-     *\n-     * @param uh\n-     * @param sslFactory\n-     *            may be null if ssl is disabled\n-     * @param cfg\n-     */\n-    public PubSubServerPipelineFactory(UmbrellaHandler uh, SslServerContextFactory sslFactory, int maxMessageSize) {\n-        this.uh = uh;\n-        this.sslFactory = sslFactory;\n-        this.maxMessageSize = maxMessageSize;\n-    }\n-\n-    public ChannelPipeline getPipeline() throws Exception {\n-        ChannelPipeline pipeline = Channels.pipeline();\n-        if (sslFactory != null) {\n-            pipeline.addLast(\"ssl\", new SslHandler(sslFactory.getEngine()));\n-        }\n-        pipeline.addLast(\"lengthbaseddecoder\",\n-                         new LengthFieldBasedFrameDecoder(maxMessageSize, 0, 4, 0, 4));\n-        pipeline.addLast(\"lengthprepender\", new LengthFieldPrepender(4));\n-\n-        pipeline.addLast(\"protobufdecoder\", new ProtobufDecoder(PubSubProtocol.PubSubRequest.getDefaultInstance()));\n-        pipeline.addLast(\"protobufencoder\", new ProtobufEncoder());\n-\n-        // pipeline.addLast(\"executor\", new ExecutionHandler(\n-        // new OrderedMemoryAwareThreadPoolExecutor(MAX_WORKER_THREADS,\n-        // MAX_CHANNEL_MEMORY_SIZE, MAX_TOTAL_MEMORY_SIZE)));\n-        //\n-        // Dependency injection.\n-        pipeline.addLast(\"umbrellahandler\", uh);\n-        return pipeline;\n-    }\n-}"},{"sha":"69ee6efd5eae294973becf03c1909a2c8f30ab0c","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/ServerStats.java","status":"removed","additions":0,"deletions":202,"changes":202,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/ServerStats.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/ServerStats.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/ServerStats.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,202 +0,0 @@\n-/*\n- * Licensed under the Apache License, Version 2.0 (the \"License\");\n- * you may not use this file except in compliance with the License.\n- * You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.netty;\n-\n-import java.util.HashMap;\n-import java.util.Map;\n-\n-import java.beans.ConstructorProperties;\n-import java.util.concurrent.atomic.AtomicLong;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * Server Stats\n- */\n-public class ServerStats {\n-    private static final Logger LOG = LoggerFactory.getLogger(ServerStats.class);\n-    static ServerStats instance = new ServerStats();\n-\n-    /**\n-     * A read view of stats, also used in CompositeViewData to expose to JMX\n-     */\n-    public static class OpStatData {\n-        private final long maxLatency, minLatency;\n-        private final double avgLatency;\n-        private final long numSuccessOps, numFailedOps;\n-        private final String latencyHist;\n-\n-        @ConstructorProperties({\"maxLatency\", \"minLatency\", \"avgLatency\",\n-                                \"numSuccessOps\", \"numFailedOps\", \"latencyHist\"})\n-        public OpStatData(long maxLatency, long minLatency, double avgLatency,\n-                          long numSuccessOps, long numFailedOps, String latencyHist) {\n-            this.maxLatency = maxLatency;\n-            this.minLatency = minLatency == Long.MAX_VALUE ? 0 : minLatency;\n-            this.avgLatency = avgLatency;\n-            this.numSuccessOps = numSuccessOps;\n-            this.numFailedOps = numFailedOps;\n-            this.latencyHist = latencyHist;\n-        }\n-\n-        public long getMaxLatency() {\n-            return maxLatency;\n-        }\n-\n-        public long getMinLatency() {\n-            return minLatency;\n-        }\n-\n-        public double getAvgLatency() {\n-            return avgLatency;\n-        }\n-\n-        public long getNumSuccessOps() {\n-            return numSuccessOps;\n-        }\n-\n-        public long getNumFailedOps() {\n-            return numFailedOps;\n-        }\n-\n-        public String getLatencyHist() {\n-            return latencyHist;\n-        }\n-    }\n-\n-    /**\n-     * Operation Statistics\n-     */\n-    public static class OpStats {\n-        static final int NUM_BUCKETS = 3*9 + 2;\n-\n-        long maxLatency = 0;\n-        long minLatency = Long.MAX_VALUE;\n-        double totalLatency = 0.0f;\n-        long numSuccessOps = 0;\n-        long numFailedOps = 0;\n-        long[] latencyBuckets = new long[NUM_BUCKETS];\n-\n-        OpStats() {}\n-\n-        /**\n-         * Increment number of failed operations\n-         */\n-        synchronized public void incrementFailedOps() {\n-            ++numFailedOps;\n-        }\n-\n-        /**\n-         * Update Latency\n-         */\n-        synchronized public void updateLatency(long latency) {\n-            if (latency < 0) {\n-                // less than 0ms . Ideally this should not happen.\n-                // We have seen this latency negative in some cases due to the\n-                // behaviors of JVM. Ignoring the statistics updation for such\n-                // cases.\n-                LOG.warn(\"Latency time coming negative\");\n-                return;\n-            }\n-            totalLatency += latency;\n-            ++numSuccessOps;\n-            if (latency < minLatency) {\n-                minLatency = latency;\n-            }\n-            if (latency > maxLatency) {\n-                maxLatency = latency;\n-            }\n-            int bucket;\n-            if (latency <= 100) { // less than 100ms\n-                bucket = (int)(latency / 10);\n-            } else if (latency <= 1000) { // 100ms ~ 1000ms\n-                bucket = 1 * 9 + (int)(latency / 100);\n-            } else if (latency <= 10000) { // 1s ~ 10s\n-                bucket = 2 * 9 + (int)(latency / 1000);\n-            } else { // more than 10s\n-                bucket = 3 * 9 + 1;\n-            }\n-            ++latencyBuckets[bucket];\n-        }\n-\n-        synchronized public OpStatData toOpStatData() {\n-            double avgLatency = numSuccessOps > 0 ? totalLatency / numSuccessOps : 0.0f;\n-            StringBuilder sb = new StringBuilder();\n-            for (int i=0; i<NUM_BUCKETS; i++) {\n-                sb.append(latencyBuckets[i]);\n-                if (i != NUM_BUCKETS - 1) {\n-                    sb.append(',');\n-                }\n-            }\n-\n-            return new OpStatData(maxLatency, minLatency, avgLatency,\n-                                  numSuccessOps, numFailedOps, sb.toString());\n-        }\n-\n-    }\n-\n-    public static ServerStats getInstance() {\n-        return instance;\n-    }\n-\n-    protected ServerStats() {\n-        stats = new HashMap<OperationType, OpStats>();\n-        for (OperationType type : OperationType.values()) {\n-            stats.put(type, new OpStats());\n-        }\n-    }\n-    Map<OperationType, OpStats> stats;\n-\n-\n-    AtomicLong numRequestsReceived = new AtomicLong(0);\n-    AtomicLong numRequestsRedirect = new AtomicLong(0);\n-    AtomicLong numMessagesDelivered = new AtomicLong(0);\n-\n-    /**\n-     * Stats of operations\n-     *\n-     * @param type\n-     *          Operation Type\n-     * @return op stats\n-     */\n-    public OpStats getOpStats(OperationType type) {\n-        return stats.get(type);\n-    }\n-\n-    public void incrementRequestsReceived() {\n-        numRequestsReceived.incrementAndGet();\n-    }\n-\n-    public void incrementRequestsRedirect() {\n-        numRequestsRedirect.incrementAndGet();\n-    }\n-\n-    public void incrementMessagesDelivered() {\n-        numMessagesDelivered.incrementAndGet();\n-    }\n-\n-    public long getNumRequestsReceived() {\n-        return numRequestsReceived.get();\n-    }\n-\n-    public long getNumRequestsRedirect() {\n-        return numRequestsRedirect.get();\n-    }\n-\n-    public long getNumMessagesDelivered() {\n-        return numMessagesDelivered.get();\n-    }\n-}"},{"sha":"00a52bfb937f145eb82958472f5fc9ebec8bca23","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/netty/UmbrellaHandler.java","status":"removed","additions":0,"deletions":155,"changes":155,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/UmbrellaHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/netty/UmbrellaHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/netty/UmbrellaHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,155 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.netty;\n-\n-import java.io.IOException;\n-import java.util.Map;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFuture;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-import org.jboss.netty.channel.ChannelHandlerContext;\n-import org.jboss.netty.channel.ChannelHandler.Sharable;\n-import org.jboss.netty.channel.ChannelStateEvent;\n-import org.jboss.netty.channel.ExceptionEvent;\n-import org.jboss.netty.channel.MessageEvent;\n-import org.jboss.netty.channel.SimpleChannelHandler;\n-import org.jboss.netty.channel.group.ChannelGroup;\n-import org.jboss.netty.handler.codec.frame.CorruptedFrameException;\n-import org.jboss.netty.handler.codec.frame.TooLongFrameException;\n-import org.jboss.netty.handler.ssl.SslHandler;\n-\n-import org.apache.hedwig.exceptions.PubSubException.MalformedRequestException;\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.ChannelDisconnectListener;\n-import org.apache.hedwig.server.handlers.Handler;\n-\n-@Sharable\n-public class UmbrellaHandler extends SimpleChannelHandler {\n-    private static final Logger logger = LoggerFactory.getLogger(UmbrellaHandler.class);\n-\n-    private final Map<OperationType, Handler> handlers;\n-    private final ChannelGroup allChannels;\n-    private final ChannelDisconnectListener channelDisconnectListener;\n-    private final boolean isSSLEnabled; \n-\n-    public UmbrellaHandler(ChannelGroup allChannels, Map<OperationType, Handler> handlers,\n-                           ChannelDisconnectListener channelDisconnectListener,\n-                           boolean isSSLEnabled) {\n-        this.allChannels = allChannels;\n-        this.isSSLEnabled = isSSLEnabled;\n-        this.handlers = handlers;\n-        this.channelDisconnectListener = channelDisconnectListener;\n-    }\n-\n-    @Override\n-    public void exceptionCaught(ChannelHandlerContext ctx, ExceptionEvent e) throws Exception {\n-        Throwable throwable = e.getCause();\n-\n-        // Add here if there are more exceptions we need to be able to tolerate.\n-        // 1. IOException may be thrown when a channel is forcefully closed by\n-        // the other end, or by the ProtobufDecoder when an invalid protobuf is\n-        // received\n-        // 2. TooLongFrameException is thrown by the LengthBasedDecoder if it\n-        // receives a packet that is too big\n-        // 3. CorruptedFramException is thrown by the LengthBasedDecoder when\n-        // the length is negative etc.\n-        if (throwable instanceof IOException || throwable instanceof TooLongFrameException\n-                || throwable instanceof CorruptedFrameException) {\n-            e.getChannel().close();\n-            logger.debug(\"Uncaught exception\", throwable);\n-        } else {\n-            // call our uncaught exception handler, which might decide to\n-            // shutdown the system\n-            Thread thread = Thread.currentThread();\n-            thread.getUncaughtExceptionHandler().uncaughtException(thread, throwable);\n-        }\n-\n-    }\n-\n-    @Override\n-    public void channelOpen(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n-        // If SSL is NOT enabled, then we can add this channel to the\n-        // ChannelGroup. Otherwise, that is done when the channel is connected\n-        // and the SSL handshake has completed successfully.\n-        if (!isSSLEnabled) {\n-            allChannels.add(ctx.getChannel());\n-        }\n-    }\n-\n-    @Override\n-    public void channelConnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n-        if (isSSLEnabled) {\n-            ctx.getPipeline().get(SslHandler.class).handshake().addListener(new ChannelFutureListener() {\n-                public void operationComplete(ChannelFuture future) throws Exception {\n-                    if (future.isSuccess()) {\n-                        logger.debug(\"SSL handshake has completed successfully!\");\n-                        allChannels.add(future.getChannel());\n-                    } else {\n-                        future.getChannel().close();\n-                    }\n-                }\n-            });\n-        }\n-    }\n-\n-    @Override\n-    public void channelDisconnected(ChannelHandlerContext ctx, ChannelStateEvent e) throws Exception {\n-        Channel channel = ctx.getChannel();\n-        // subscribe handler needs to know about channel disconnects\n-        channelDisconnectListener.channelDisconnected(channel);\n-        channel.close();\n-    }\n-\n-    public static void sendErrorResponseToMalformedRequest(Channel channel, long txnId, String msg) {\n-        logger.debug(\"Malformed request from {}, msg = {}\", channel.getRemoteAddress(), msg);\n-        MalformedRequestException mre = new MalformedRequestException(msg);\n-        PubSubResponse response = PubSubResponseUtils.getResponseForException(mre, txnId);\n-        channel.write(response);\n-    }\n-\n-    @Override\n-    public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception {\n-\n-        if (!(e.getMessage() instanceof PubSubProtocol.PubSubRequest)) {\n-            ctx.sendUpstream(e);\n-            return;\n-        }\n-\n-        PubSubProtocol.PubSubRequest request = (PubSubProtocol.PubSubRequest) e.getMessage();\n-\n-        Handler handler = handlers.get(request.getType());\n-        Channel channel = ctx.getChannel();\n-        long txnId = request.getTxnId();\n-\n-        if (handler == null) {\n-            sendErrorResponseToMalformedRequest(channel, txnId, \"Request type \" + request.getType().getNumber()\n-                                                + \" unknown\");\n-            return;\n-        }\n-\n-        handler.handleRequest(request, channel);\n-        ServerStats.getInstance().incrementRequestsReceived();\n-    }\n-\n-}"},{"sha":"b0b5a80d2e137c9522cc4a1de55ac1d5ea9ee32f","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/BookkeeperPersistenceManager.java","status":"removed","additions":0,"deletions":1263,"changes":1263,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/BookkeeperPersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/BookkeeperPersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/BookkeeperPersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,1263 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import java.io.IOException;\n-import java.util.Enumeration;\n-import java.util.Iterator;\n-import java.util.HashSet;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.Map;\n-import java.util.Set;\n-import java.util.TreeMap;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-\n-import org.apache.bookkeeper.client.AsyncCallback.CloseCallback;\n-import org.apache.bookkeeper.client.AsyncCallback.DeleteCallback;\n-import org.apache.bookkeeper.client.BKException;\n-import org.apache.bookkeeper.client.BookKeeper;\n-import org.apache.bookkeeper.client.LedgerEntry;\n-import org.apache.bookkeeper.client.LedgerHandle;\n-import org.apache.bookkeeper.client.BookKeeper.DigestType;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.protobuf.ByteString;\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRange;\n-import org.apache.hedwig.protocol.PubSubProtocol.LedgerRanges;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protoextensions.MessageIdUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TopicOpQueuer;\n-import org.apache.hedwig.server.common.UnexpectedError;\n-import org.apache.hedwig.server.meta.MetadataManagerFactory;\n-import org.apache.hedwig.server.meta.TopicPersistenceManager;\n-import org.apache.hedwig.server.persistence.ScanCallback.ReasonForFinish;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.server.topics.TopicOwnershipChangeListener;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.zookeeper.SafeAsynBKCallback;\n-import static org.apache.hedwig.util.VarArgs.va;\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-/**\n- * This persistence manager uses zookeeper and bookkeeper to store messages.\n- *\n- * Information about topics are stored in zookeeper with a znode named after the\n- * topic that contains an ASCII encoded list with records of the following form:\n- *\n- * <pre>\n- * startSeqId(included)\\tledgerId\\n\n- * </pre>\n- *\n- */\n-\n-public class BookkeeperPersistenceManager implements PersistenceManagerWithRangeScan, TopicOwnershipChangeListener {\n-    private static final Logger logger = LoggerFactory.getLogger(BookkeeperPersistenceManager.class);\n-    static byte[] passwd = \"sillysecret\".getBytes(UTF_8);\n-    private BookKeeper bk;\n-    private TopicPersistenceManager tpManager;\n-    private ServerConfiguration cfg;\n-    private TopicManager tm;\n-\n-    private static final long START_SEQ_ID = 1L;\n-    // max number of entries allowed in a ledger\n-    private static final long UNLIMITED_ENTRIES = 0L;\n-    private final long maxEntriesPerLedger;\n-\n-    static class InMemoryLedgerRange {\n-        LedgerRange range;\n-        LedgerHandle handle;\n-\n-        public InMemoryLedgerRange(LedgerRange range, LedgerHandle handle) {\n-            this.range = range;\n-            this.handle = handle;\n-        }\n-\n-        public InMemoryLedgerRange(LedgerRange range) {\n-            this(range, null);\n-        }\n-\n-        public long getStartSeqIdIncluded() {\n-            assert range.hasStartSeqIdIncluded();\n-            return range.getStartSeqIdIncluded();\n-        }\n-    }\n-\n-    static class TopicInfo {\n-        /**\n-         * stores the last message-seq-id vector that has been pushed to BK for\n-         * persistence (but not necessarily acked yet by BK)\n-         *\n-         */\n-        MessageSeqId lastSeqIdPushed;\n-\n-        /**\n-         * stores the last message-id that has been acked by BK. This number is\n-         * basically used for limiting scans to not read past what has been\n-         * persisted by BK\n-         */\n-        long lastEntryIdAckedInCurrentLedger = -1; // because BK ledgers starts\n-        // at 0\n-\n-        /**\n-         * stores a sorted structure of the ledgers for a topic, mapping from\n-         * the endSeqIdIncluded to the ledger info. This structure does not\n-         * include the current ledger\n-         */\n-        TreeMap<Long, InMemoryLedgerRange> ledgerRanges = new TreeMap<Long, InMemoryLedgerRange>();\n-        Version ledgerRangesVersion = Version.NEW;\n-\n-        /**\n-         * This is the handle of the current ledger that is being used to write\n-         * messages\n-         */\n-        InMemoryLedgerRange currentLedgerRange;\n-\n-        /**\n-         * Flag to release topic when encountering unrecoverable exceptions\n-         */\n-        AtomicBoolean doRelease = new AtomicBoolean(false);\n-\n-        /**\n-         * Flag indicats the topic is changing ledger\n-         */\n-        AtomicBoolean doChangeLedger = new AtomicBoolean(false);\n-        /**\n-         * Last seq id to change ledger.\n-         */\n-        long lastSeqIdBeforeLedgerChange = -1;\n-        /**\n-         * List to buffer all persist requests during changing ledger.\n-         */\n-        LinkedList<PersistRequest> deferredRequests = null;\n-\n-        final static int UNLIMITED = 0;\n-        int messageBound = UNLIMITED;\n-    }\n-\n-    Map<ByteString, TopicInfo> topicInfos = new ConcurrentHashMap<ByteString, TopicInfo>();\n-\n-    TopicOpQueuer queuer;\n-\n-    /**\n-     * Instantiates a BookKeeperPersistence manager.\n-     *\n-     * @param bk\n-     *            a reference to bookkeeper to use.\n-     * @param metaManagerFactory\n-     *            a metadata manager factory handle to use.\n-     * @param tm\n-     *            a reference to topic manager.\n-     * @param cfg\n-     *            Server configuration object\n-     * @param executor\n-     *            A executor\n-     */\n-    public BookkeeperPersistenceManager(BookKeeper bk, MetadataManagerFactory metaManagerFactory,\n-                                        TopicManager tm, ServerConfiguration cfg,\n-                                        ScheduledExecutorService executor) {\n-        this.bk = bk;\n-        this.tpManager = metaManagerFactory.newTopicPersistenceManager();\n-        this.cfg = cfg;\n-        this.tm = tm;\n-        this.maxEntriesPerLedger = cfg.getMaxEntriesPerLedger();\n-        queuer = new TopicOpQueuer(executor);\n-        tm.addTopicOwnershipChangeListener(this);\n-    }\n-\n-    private static LedgerRange buildLedgerRange(long ledgerId, long startOfLedger,\n-                                                MessageSeqId endOfLedger) {\n-        LedgerRange.Builder builder =\n-            LedgerRange.newBuilder().setLedgerId(ledgerId).setStartSeqIdIncluded(startOfLedger)\n-                       .setEndSeqIdIncluded(endOfLedger);\n-        return builder.build();\n-    }\n-\n-    class RangeScanOp extends TopicOpQueuer.SynchronousOp {\n-        RangeScanRequest request;\n-        int numMessagesRead = 0;\n-        long totalSizeRead = 0;\n-        TopicInfo topicInfo;\n-        long startSeqIdToScan;\n-\n-        public RangeScanOp(RangeScanRequest request) {\n-            this(request, -1L, 0, 0L);\n-        }\n-\n-        public RangeScanOp(RangeScanRequest request, long startSeqId, int numMessagesRead, long totalSizeRead) {\n-            queuer.super(request.topic);\n-            this.request = request;\n-            this.startSeqIdToScan = startSeqId;\n-            this.numMessagesRead = numMessagesRead;\n-            this.totalSizeRead = totalSizeRead;\n-        }\n-\n-        @Override\n-        protected void runInternal() {\n-            topicInfo = topicInfos.get(topic);\n-\n-            if (topicInfo == null) {\n-                request.callback.scanFailed(request.ctx, new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-                return;\n-            }\n-\n-            // if startSeqIdToScan is less than zero, which means it is an unfinished scan request\n-            // we continue the scan from the provided position\n-            startReadingFrom(startSeqIdToScan < 0 ? request.startSeqId : startSeqIdToScan);\n-        }\n-\n-        protected void read(final InMemoryLedgerRange imlr, final long startSeqId, final long endSeqId) {\n-            // Verify whether startSeqId falls in ledger range.\n-            // Only the left endpoint of range needs to be checked.\n-            if (imlr.getStartSeqIdIncluded() > startSeqId) {\n-                logger.error(\n-                        \"Invalid RangeScan read, startSeqId {} doesn't fall in ledger range [{} ~ {}]\",\n-                        va(startSeqId, imlr.getStartSeqIdIncluded(), imlr.range.hasEndSeqIdIncluded() ? imlr.range\n-                                .getEndSeqIdIncluded().getLocalComponent() : \"\"));\n-                request.callback.scanFailed(request.ctx, new PubSubException.UnexpectedConditionException(\"Scan request is out of range\"));\n-\n-                // try release topic to reset the state\n-                lostTopic(topic);\n-                return;\n-            }\n-\n-            if (imlr.handle == null) {\n-\n-                bk.asyncOpenLedger(imlr.range.getLedgerId(), DigestType.CRC32, passwd,\n-                new SafeAsynBKCallback.OpenCallback() {\n-                    @Override\n-                    public void safeOpenComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n-                        if (rc == BKException.Code.OK) {\n-                            imlr.handle = ledgerHandle;\n-                            read(imlr, startSeqId, endSeqId);\n-                            return;\n-                        }\n-                        BKException bke = BKException.create(rc);\n-                        logger.error(\"Could not open ledger: \" + imlr.range.getLedgerId() + \" for topic: \"\n-                                     + topic);\n-                        request.callback.scanFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                        return;\n-                    }\n-                }, request.ctx);\n-                return;\n-            }\n-\n-            // ledger handle is not null, we can read from it\n-            long correctedEndSeqId = Math.min(startSeqId + request.messageLimit - numMessagesRead - 1, endSeqId);\n-\n-            if (logger.isDebugEnabled()) {\n-                logger.debug(\"Issuing a bk read for ledger: \" + imlr.handle.getId() + \" from entry-id: \"\n-                             + (startSeqId - imlr.getStartSeqIdIncluded()) + \" to entry-id: \"\n-                             + (correctedEndSeqId - imlr.getStartSeqIdIncluded()));\n-            }\n-\n-            imlr.handle.asyncReadEntries(startSeqId - imlr.getStartSeqIdIncluded(), correctedEndSeqId\n-            - imlr.getStartSeqIdIncluded(), new SafeAsynBKCallback.ReadCallback() {\n-\n-                long expectedEntryId = startSeqId - imlr.getStartSeqIdIncluded();\n-\n-                @Override\n-                public void safeReadComplete(int rc, LedgerHandle lh, Enumeration<LedgerEntry> seq, Object ctx) {\n-                    if (rc != BKException.Code.OK || !seq.hasMoreElements()) {\n-                        if (rc == BKException.Code.OK) {\n-                            // means that there is no entries read, provide a meaningful exception\n-                            rc = BKException.Code.NoSuchEntryException;\n-                        }\n-                        BKException bke = BKException.create(rc);\n-                        logger.error(\"Error while reading from ledger: \" + imlr.range.getLedgerId() + \" for topic: \"\n-                                     + topic.toStringUtf8(), bke);\n-                        request.callback.scanFailed(request.ctx, new PubSubException.ServiceDownException(bke));\n-                        return;\n-                    }\n-\n-                    LedgerEntry entry = null;\n-                    while (seq.hasMoreElements()) {\n-                        entry = seq.nextElement();\n-                        Message message;\n-                        try {\n-                            message = Message.parseFrom(entry.getEntryInputStream());\n-                        } catch (IOException e) {\n-                            String msg = \"Unreadable message found in ledger: \" + imlr.range.getLedgerId()\n-                                         + \" for topic: \" + topic.toStringUtf8();\n-                            logger.error(msg, e);\n-                            request.callback.scanFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                            return;\n-                        }\n-\n-                        logger.debug(\"Read response from ledger: {} entry-id: {}\",\n-                                     lh.getId(), entry.getEntryId());\n-\n-                        assert expectedEntryId == entry.getEntryId() : \"expectedEntryId (\" + expectedEntryId\n-                        + \") != entry.getEntryId() (\" + entry.getEntryId() + \")\";\n-                        assert (message.getMsgId().getLocalComponent() - imlr.getStartSeqIdIncluded()) == expectedEntryId;\n-\n-                        expectedEntryId++;\n-                        request.callback.messageScanned(ctx, message);\n-                        numMessagesRead++;\n-                        totalSizeRead += message.getBody().size();\n-\n-                        if (numMessagesRead >= request.messageLimit) {\n-                            request.callback.scanFinished(ctx, ReasonForFinish.NUM_MESSAGES_LIMIT_EXCEEDED);\n-                            return;\n-                        }\n-\n-                        if (totalSizeRead >= request.sizeLimit) {\n-                            request.callback.scanFinished(ctx, ReasonForFinish.SIZE_LIMIT_EXCEEDED);\n-                            return;\n-                        }\n-                    }\n-\n-                    // continue scanning messages\n-                    scanMessages(request, imlr.getStartSeqIdIncluded() + entry.getEntryId() + 1, numMessagesRead, totalSizeRead);\n-                }\n-            }, request.ctx);\n-        }\n-\n-        protected void startReadingFrom(long startSeqId) {\n-\n-            Map.Entry<Long, InMemoryLedgerRange> entry = topicInfo.ledgerRanges.ceilingEntry(startSeqId);\n-\n-            if (entry == null) {\n-                // None of the old ledgers have this seq-id, we must use the\n-                // current ledger\n-                long endSeqId = topicInfo.currentLedgerRange.getStartSeqIdIncluded()\n-                                + topicInfo.lastEntryIdAckedInCurrentLedger;\n-\n-                if (endSeqId < startSeqId) {\n-                    request.callback.scanFinished(request.ctx, ReasonForFinish.NO_MORE_MESSAGES);\n-                    return;\n-                }\n-\n-                read(topicInfo.currentLedgerRange, startSeqId, endSeqId);\n-            } else {\n-                read(entry.getValue(), startSeqId, entry.getValue().range.getEndSeqIdIncluded().getLocalComponent());\n-            }\n-\n-        }\n-\n-    }\n-\n-    @Override\n-    public void scanMessages(RangeScanRequest request) {\n-        queuer.pushAndMaybeRun(request.topic, new RangeScanOp(request));\n-    }\n-\n-    protected void scanMessages(RangeScanRequest request, long scanSeqId, int numMsgsRead, long totalSizeRead) {\n-        queuer.pushAndMaybeRun(request.topic, new RangeScanOp(request, scanSeqId, numMsgsRead, totalSizeRead));\n-    }\n-\n-    public void deliveredUntil(ByteString topic, Long seqId) {\n-        // Nothing to do here. this is just a hint that we cannot use.\n-    }\n-\n-    class UpdateLedgerOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        private Set<Long> ledgersDeleted;\n-\n-        public UpdateLedgerOp(ByteString topic, final Callback<Void> cb, final Object ctx,\n-                              Set<Long> ledgersDeleted) {\n-            queuer.super(topic, cb, ctx);\n-            this.ledgersDeleted = ledgersDeleted;\n-        }\n-\n-        @Override\n-        public void run() {\n-            final TopicInfo topicInfo = topicInfos.get(topic);\n-            if (topicInfo == null) {\n-                logger.error(\"Server is not responsible for topic!\");\n-                cb.operationFailed(ctx, new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-                return;\n-            }\n-            LedgerRanges.Builder builder = LedgerRanges.newBuilder();\n-            final Set<Long> keysToRemove = new HashSet<Long>();\n-            boolean foundUnconsumedLedger = false;\n-            for (Map.Entry<Long, InMemoryLedgerRange> e : topicInfo.ledgerRanges.entrySet()) {\n-                LedgerRange lr = e.getValue().range;\n-                long ledgerId = lr.getLedgerId();\n-                if (!foundUnconsumedLedger && ledgersDeleted.contains(ledgerId)) {\n-                    keysToRemove.add(e.getKey());\n-                    if (!lr.hasEndSeqIdIncluded()) {\n-                        String msg = \"Should not remove unclosed ledger \" + ledgerId + \" for topic \" + topic.toStringUtf8();\n-                        logger.error(msg);\n-                        cb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                        return;\n-                    }\n-                } else {\n-                    foundUnconsumedLedger = true;\n-                    builder.addRanges(lr);\n-                }\n-            }\n-            builder.addRanges(topicInfo.currentLedgerRange.range);\n-\n-            if (!keysToRemove.isEmpty()) {\n-                final LedgerRanges newRanges = builder.build();\n-                tpManager.writeTopicPersistenceInfo(\n-                topic, newRanges, topicInfo.ledgerRangesVersion, new Callback<Version>() {\n-                    public void operationFinished(Object ctx, Version newVersion) {\n-                        // Finally, all done\n-                        for (Long k : keysToRemove) {\n-                            topicInfo.ledgerRanges.remove(k);\n-                        }\n-                        topicInfo.ledgerRangesVersion = newVersion;\n-                        cb.operationFinished(ctx, null);\n-                    }\n-                    public void operationFailed(Object ctx, PubSubException exception) {\n-                        cb.operationFailed(ctx, exception);\n-                    }\n-                }, ctx);\n-            } else {\n-                cb.operationFinished(ctx, null);\n-            }\n-        }\n-    }\n-\n-    class ConsumeUntilOp extends TopicOpQueuer.SynchronousOp {\n-        private final long seqId;\n-\n-        public ConsumeUntilOp(ByteString topic, long seqId) {\n-            queuer.super(topic);\n-            this.seqId = seqId;\n-        }\n-\n-        @Override\n-        public void runInternal() {\n-            TopicInfo topicInfo = topicInfos.get(topic);\n-            if (topicInfo == null) {\n-                logger.error(\"Server is not responsible for topic!\");\n-                return;\n-            }\n-\n-            final LinkedList<Long> ledgersToDelete = new LinkedList<Long>();\n-            for (Long endSeqIdIncluded : topicInfo.ledgerRanges.keySet()) {\n-                if (endSeqIdIncluded <= seqId) {\n-                    // This ledger's message entries have all been consumed already\n-                    // so it is safe to delete it from BookKeeper.\n-                    long ledgerId = topicInfo.ledgerRanges.get(endSeqIdIncluded).range.getLedgerId();\n-                    ledgersToDelete.add(ledgerId);\n-                } else {\n-                    break;\n-                }\n-            }\n-\n-            // no ledgers need to delete\n-            if (ledgersToDelete.isEmpty()) {\n-                return;\n-            }\n-\n-            Set<Long> ledgersDeleted = new HashSet<Long>();\n-            deleteLedgersAndUpdateLedgersRange(topic, ledgersToDelete, ledgersDeleted);\n-        }\n-    }\n-\n-    private void deleteLedgersAndUpdateLedgersRange(final ByteString topic,\n-                                                    final LinkedList<Long> ledgersToDelete,\n-                                                    final Set<Long> ledgersDeleted) {\n-        if (ledgersToDelete.isEmpty()) {\n-            Callback<Void> cb = new Callback<Void>() {\n-                public void operationFinished(Object ctx, Void result) {\n-                    // do nothing, op is async to stop other ops\n-                    // occurring on the topic during the update\n-                }\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    logger.error(\"Failed to update ledger znode for topic {} deleting ledgers {} : {}\",\n-                                 va(topic.toStringUtf8(), ledgersDeleted, exception.getMessage()));\n-                }\n-            };\n-            queuer.pushAndMaybeRun(topic, new UpdateLedgerOp(topic, cb, null, ledgersDeleted));\n-            return;\n-        }\n-\n-        final Long ledger = ledgersToDelete.poll();\n-        if (null == ledger) {\n-            deleteLedgersAndUpdateLedgersRange(topic, ledgersToDelete, ledgersDeleted);\n-            return;\n-        }\n-\n-        bk.asyncDeleteLedger(ledger, new DeleteCallback() {\n-            @Override\n-            public void deleteComplete(int rc, Object ctx) {\n-                if (BKException.Code.NoSuchLedgerExistsException == rc ||\n-                    BKException.Code.OK == rc) {\n-                    ledgersDeleted.add(ledger);\n-                    deleteLedgersAndUpdateLedgersRange(topic, ledgersToDelete, ledgersDeleted);\n-                    return;\n-                } else {\n-                    logger.warn(\"Exception while deleting consumed ledger {}, stop deleting other ledgers {} \"\n-                                + \"and update ledger ranges with deleted ledgers {} : {}\",\n-                                va(ledger, ledgersToDelete, ledgersDeleted, BKException.create(rc)));\n-                    // We should not continue when failed to delete ledger\n-                    Callback<Void> cb = new Callback<Void>() {\n-                        public void operationFinished(Object ctx, Void result) {\n-                            // do nothing, op is async to stop other ops\n-                            // occurring on the topic during the update\n-                        }\n-                        public void operationFailed(Object ctx, PubSubException exception) {\n-                            logger.error(\"Failed to update ledger znode for topic {} deleting ledgers {} : {}\",\n-                                         va(topic, ledgersDeleted, exception.getMessage()));\n-                        }\n-                    };\n-                    queuer.pushAndMaybeRun(topic, new UpdateLedgerOp(topic, cb, null, ledgersDeleted));\n-                    return;\n-                }\n-            }\n-        }, null);\n-    }\n-\n-    public void consumedUntil(ByteString topic, Long seqId) {\n-        queuer.pushAndMaybeRun(topic, new ConsumeUntilOp(topic, Math.max(seqId, getMinSeqIdForTopic(topic))));\n-    }\n-\n-    public void consumeToBound(ByteString topic) {\n-        TopicInfo topicInfo = topicInfos.get(topic);\n-\n-        if (topicInfo == null || topicInfo.messageBound == topicInfo.UNLIMITED) {\n-            return;\n-        }\n-        queuer.pushAndMaybeRun(topic, new ConsumeUntilOp(topic, getMinSeqIdForTopic(topic)));\n-    }\n-\n-    public long getMinSeqIdForTopic(ByteString topic) {\n-        TopicInfo topicInfo = topicInfos.get(topic);\n-\n-        if (topicInfo == null || topicInfo.messageBound == topicInfo.UNLIMITED) {\n-            return Long.MIN_VALUE;\n-        } else {\n-            return (topicInfo.lastSeqIdPushed.getLocalComponent() - topicInfo.messageBound) + 1;\n-        }\n-    }\n-\n-    public MessageSeqId getCurrentSeqIdForTopic(ByteString topic) throws ServerNotResponsibleForTopicException {\n-        TopicInfo topicInfo = topicInfos.get(topic);\n-\n-        if (topicInfo == null) {\n-            throw new PubSubException.ServerNotResponsibleForTopicException(\"\");\n-        }\n-\n-        return topicInfo.lastSeqIdPushed;\n-    }\n-\n-    public long getSeqIdAfterSkipping(ByteString topic, long seqId, int skipAmount) {\n-        return Math.max(seqId + skipAmount, getMinSeqIdForTopic(topic));\n-    }\n-\n-    /**\n-     * Release topic on failure\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param e\n-     *          Failure Exception\n-     * @param ctx\n-     *          Callback context\n-     */\n-    protected void releaseTopicIfRequested(final ByteString topic, Exception e, Object ctx) {\n-        TopicInfo topicInfo = topicInfos.get(topic);\n-        if (topicInfo == null) {\n-            logger.warn(\"No topic found when trying to release ownership of topic \" + topic.toStringUtf8()\n-                      + \" on failure.\");\n-            return;\n-        }\n-        // do release owner ship of topic\n-        if (topicInfo.doRelease.compareAndSet(false, true)) {\n-            logger.info(\"Release topic \" + topic.toStringUtf8() + \" when bookkeeper persistence mananger encounters failure :\",\n-                        e);\n-            tm.releaseTopic(topic, new Callback<Void>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    logger.error(\"Exception found on releasing topic \" + topic.toStringUtf8()\n-                               + \" when encountering exception from bookkeeper:\", exception);\n-                }\n-                @Override\n-                public void operationFinished(Object ctx, Void resultOfOperation) {\n-                    logger.info(\"successfully releasing topic {} when encountering\"\n-                              + \" exception from bookkeeper\", topic.toStringUtf8());\n-                }\n-            }, null);\n-        }\n-        // if release happens when the topic is changing ledger\n-        // we need to fail all queued persist requests\n-        if (topicInfo.doChangeLedger.get()) {\n-            for (PersistRequest pr : topicInfo.deferredRequests) {\n-                pr.getCallback().operationFailed(ctx, new PubSubException.ServiceDownException(e));\n-            }\n-            topicInfo.deferredRequests.clear();\n-            topicInfo.lastSeqIdBeforeLedgerChange = -1;\n-        }\n-    }\n-\n-    public class PersistOp extends TopicOpQueuer.SynchronousOp {\n-        PersistRequest request;\n-\n-        public PersistOp(PersistRequest request) {\n-            queuer.super(request.topic);\n-            this.request = request;\n-        }\n-\n-        @Override\n-        public void runInternal() {\n-            doPersistMessage(request);\n-        }\n-    }\n-\n-    /**\n-     * Persist a message by executing a persist request.\n-     */\n-    protected void doPersistMessage(final PersistRequest request) {\n-        final ByteString topic = request.topic;\n-        final TopicInfo topicInfo = topicInfos.get(topic);\n-\n-        if (topicInfo == null) {\n-            request.getCallback().operationFailed(request.ctx,\n-                                             new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-            return;\n-        }\n-\n-        if (topicInfo.doRelease.get()) {\n-            request.getCallback().operationFailed(request.ctx, new PubSubException.ServiceDownException(\n-                \"The ownership of the topic is releasing due to unrecoverable issue.\"));\n-            return;\n-        }\n-\n-        // if the topic is changing ledger, queue following persist requests until ledger is changed\n-        if (topicInfo.doChangeLedger.get()) {\n-            logger.info(\"Topic {} is changing ledger, so queue persist request for message.\",\n-                        topic.toStringUtf8());\n-            topicInfo.deferredRequests.add(request);\n-            return;\n-        }\n-\n-        final long localSeqId = topicInfo.lastSeqIdPushed.getLocalComponent() + 1;\n-        MessageSeqId.Builder builder = MessageSeqId.newBuilder();\n-        if (request.message.hasMsgId()) {\n-            MessageIdUtils.takeRegionMaximum(builder, topicInfo.lastSeqIdPushed, request.message.getMsgId());\n-        } else {\n-            builder.addAllRemoteComponents(topicInfo.lastSeqIdPushed.getRemoteComponentsList());\n-        }\n-        builder.setLocalComponent(localSeqId);\n-\n-        // check whether reach the threshold of a ledger, if it does,\n-        // open a ledger to write\n-        long entriesInThisLedger = localSeqId - topicInfo.currentLedgerRange.getStartSeqIdIncluded() + 1;\n-        if (UNLIMITED_ENTRIES != maxEntriesPerLedger &&\n-            entriesInThisLedger >= maxEntriesPerLedger) {\n-            if (topicInfo.doChangeLedger.compareAndSet(false, true)) {\n-                // for order guarantees, we should wait until all the adding operations for current ledger\n-                // are succeed. so we just mark it as lastSeqIdBeforeLedgerChange\n-                // when the lastSeqIdBeforeLedgerChange acked, we do changing the ledger\n-                if (null == topicInfo.deferredRequests) {\n-                    topicInfo.deferredRequests = new LinkedList<PersistRequest>();\n-                }\n-                topicInfo.lastSeqIdBeforeLedgerChange = localSeqId;\n-            }\n-        }\n-\n-        topicInfo.lastSeqIdPushed = builder.build();\n-        Message msgToSerialize = Message.newBuilder(request.message).setMsgId(topicInfo.lastSeqIdPushed).build();\n-\n-        final MessageSeqId responseSeqId = msgToSerialize.getMsgId();\n-        topicInfo.currentLedgerRange.handle.asyncAddEntry(msgToSerialize.toByteArray(),\n-        new SafeAsynBKCallback.AddCallback() {\n-            AtomicBoolean processed = new AtomicBoolean(false);\n-            @Override\n-            public void safeAddComplete(int rc, LedgerHandle lh, long entryId, Object ctx) {\n-\n-                // avoid double callback by mistake, since we may do change ledger in this callback.\n-                if (!processed.compareAndSet(false, true)) {\n-                    return;\n-                }\n-                if (rc != BKException.Code.OK) {\n-                    BKException bke = BKException.create(rc);\n-                    logger.error(\"Error while persisting entry to ledger: \" + lh.getId() + \" for topic: \"\n-                                 + topic.toStringUtf8(), bke);\n-                    request.getCallback().operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-\n-                    // To preserve ordering guarantees, we\n-                    // should give up the topic and not let\n-                    // other operations through\n-                    releaseTopicIfRequested(request.topic, bke, ctx);\n-                    return;\n-                }\n-\n-                if (entryId + topicInfo.currentLedgerRange.getStartSeqIdIncluded() != localSeqId) {\n-                    String msg = \"Expected BK to assign entry-id: \"\n-                                 + (localSeqId - topicInfo.currentLedgerRange.getStartSeqIdIncluded())\n-                                 + \" but it instead assigned entry-id: \" + entryId + \" topic: \"\n-                                 + topic.toStringUtf8() + \"ledger: \" + lh.getId();\n-                    logger.error(msg);\n-                    throw new UnexpectedError(msg);\n-                }\n-\n-                topicInfo.lastEntryIdAckedInCurrentLedger = entryId;\n-                request.getCallback().operationFinished(ctx, responseSeqId);\n-                // if this acked entry is the last entry of current ledger\n-                // we can add a ChangeLedgerOp to execute to change ledger\n-                if (topicInfo.doChangeLedger.get() &&\n-                    entryId + topicInfo.currentLedgerRange.getStartSeqIdIncluded() == topicInfo.lastSeqIdBeforeLedgerChange) {\n-                    // change ledger\n-                    changeLedger(topic, new Callback<Void>() {\n-                        @Override\n-                        public void operationFailed(Object ctx, PubSubException exception) {\n-                            logger.error(\"Failed to change ledger for topic \" + topic.toStringUtf8(), exception);\n-                            // change ledger failed, we should give up topic\n-                            releaseTopicIfRequested(request.topic, exception, ctx);\n-                        }\n-                        @Override\n-                        public void operationFinished(Object ctx, Void resultOfOperation) {\n-                            topicInfo.doChangeLedger.set(false);\n-                            topicInfo.lastSeqIdBeforeLedgerChange = -1;\n-                            // the ledger is changed, persist queued requests\n-                            // if the number of queued persist requests is more than maxEntriesPerLedger\n-                            // we just persist maxEntriesPerLedger requests, other requests are still queued\n-                            // until next ledger changed.\n-                            int numRequests = 0;\n-                            while (!topicInfo.deferredRequests.isEmpty() &&\n-                                   numRequests < maxEntriesPerLedger) {\n-                                PersistRequest pr = topicInfo.deferredRequests.removeFirst();\n-                                doPersistMessage(pr);\n-                                ++numRequests;\n-                            }\n-                            logger.debug(\"Finished persisting {} queued requests, but there are still {} requests in queue.\",\n-                                         numRequests, topicInfo.deferredRequests.size());\n-                        }\n-                    }, ctx);\n-                }\n-            }\n-        }, request.ctx);\n-    }\n-\n-    public void persistMessage(PersistRequest request) {\n-        queuer.pushAndMaybeRun(request.topic, new PersistOp(request));\n-    }\n-\n-    public void scanSingleMessage(ScanRequest request) {\n-        throw new RuntimeException(\"Not implemented\");\n-    }\n-\n-    static SafeAsynBKCallback.CloseCallback noOpCloseCallback = new SafeAsynBKCallback.CloseCallback() {\n-        @Override\n-        public void safeCloseComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n-        };\n-    };\n-\n-    class AcquireOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        public AcquireOp(ByteString topic, Callback<Void> cb, Object ctx) {\n-            queuer.super(topic, cb, ctx);\n-        }\n-\n-        @Override\n-        public void run() {\n-            if (topicInfos.containsKey(topic)) {\n-                // Already acquired, do nothing\n-                cb.operationFinished(ctx, null);\n-                return;\n-            }\n-\n-            // read persistence info\n-            tpManager.readTopicPersistenceInfo(topic, new Callback<Versioned<LedgerRanges>>() {\n-                @Override\n-                public void operationFinished(Object ctx, Versioned<LedgerRanges> ranges) {\n-                    if (null != ranges) {\n-                        processTopicLedgerRanges(ranges.getValue(), ranges.getVersion());\n-                    } else {\n-                        processTopicLedgerRanges(LedgerRanges.getDefaultInstance(), Version.NEW);\n-                    }\n-                }\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    cb.operationFailed(ctx, exception);\n-                }\n-            }, ctx);\n-        }\n-\n-        void processTopicLedgerRanges(final LedgerRanges ranges, final Version version) {\n-            final List<LedgerRange> rangesList = ranges.getRangesList();\n-            if (!rangesList.isEmpty()) {\n-                LedgerRange range = rangesList.get(0);\n-                if (range.hasStartSeqIdIncluded()) {\n-                    // we already have start seq id\n-                    processTopicLedgerRanges(rangesList, version, range.getStartSeqIdIncluded());\n-                    return;\n-                }\n-                getStartSeqIdToProcessTopicLedgerRanges(rangesList, version);\n-                return;\n-            }\n-            // process topic ledger ranges directly\n-            processTopicLedgerRanges(rangesList, version, START_SEQ_ID);\n-        }\n-\n-        /**\n-         * Process old version ledger ranges to fetch start seq id.\n-         */\n-        void getStartSeqIdToProcessTopicLedgerRanges(\n-            final List<LedgerRange> rangesList, final Version version) {\n-\n-            final LedgerRange range = rangesList.get(0);\n-\n-            if (!range.hasEndSeqIdIncluded()) {\n-                // process topic ledger ranges directly\n-                processTopicLedgerRanges(rangesList, version, START_SEQ_ID);\n-                return;\n-            }\n-\n-            final long ledgerId = range.getLedgerId();\n-            // open the first ledger to compute right start seq id\n-            bk.asyncOpenLedger(ledgerId, DigestType.CRC32, passwd,\n-            new SafeAsynBKCallback.OpenCallback() {\n-\n-                @Override\n-                public void safeOpenComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n-\n-                    if (rc == BKException.Code.NoSuchLedgerExistsException) {\n-                        // process next ledger \n-                        processTopicLedgerRanges(rangesList, version, START_SEQ_ID);\n-                        return;\n-                    } else if (rc != BKException.Code.OK) {\n-                        BKException bke = BKException.create(rc);\n-                        logger.error(\"Could not open ledger {} to get start seq id while acquiring topic {} : {}\",\n-                                     va(ledgerId, topic.toStringUtf8(), bke));\n-                        cb.operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                        return;\n-                    }\n-\n-                    final long numEntriesInLastLedger = ledgerHandle.getLastAddConfirmed() + 1;\n-\n-                    // the ledger is closed before, calling close is just a nop operation.\n-                    try {\n-                        ledgerHandle.close();\n-                    } catch (InterruptedException ie) {\n-                        // the exception would never be thrown for a read only ledger handle.\n-                    } catch (BKException bke) {\n-                        // the exception would never be thrown for a read only ledger handle.\n-                    }\n-\n-                    if (numEntriesInLastLedger <= 0) {\n-                        String msg = \"No entries found in a have-end-seq-id ledger \" + ledgerId\n-                                     + \" when acquiring topic \" + topic.toStringUtf8() + \".\";\n-                        logger.error(msg);\n-                        cb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                        return;\n-                    }\n-                    long endOfLedger = range.getEndSeqIdIncluded().getLocalComponent();\n-                    long startOfLedger = endOfLedger - numEntriesInLastLedger + 1;\n-\n-                    processTopicLedgerRanges(rangesList, version, startOfLedger);\n-                }\n-\n-            }, ctx);\n-        }\n-\n-        void processTopicLedgerRanges(final List<LedgerRange> rangesList, final Version version,\n-                                      long startOfLedger) {\n-            logger.info(\"Process {} ledgers for topic {} starting from seq id {}.\",\n-                        va(rangesList.size(), topic.toStringUtf8(), startOfLedger));\n-\n-            Iterator<LedgerRange> lrIterator = rangesList.iterator();\n-\n-            TopicInfo topicInfo = new TopicInfo();\n-            while (lrIterator.hasNext()) {\n-                LedgerRange range = lrIterator.next();\n-\n-                if (range.hasEndSeqIdIncluded()) {\n-                    // this means it was a valid and completely closed ledger\n-                    long endOfLedger = range.getEndSeqIdIncluded().getLocalComponent();\n-                    if (range.hasStartSeqIdIncluded()) {\n-                        startOfLedger = range.getStartSeqIdIncluded();\n-                    } else {\n-                        range = buildLedgerRange(range.getLedgerId(), startOfLedger,\n-                                                 range.getEndSeqIdIncluded());\n-                    }\n-                    topicInfo.ledgerRanges.put(endOfLedger, new InMemoryLedgerRange(range));\n-                    if (startOfLedger < endOfLedger + 1) {\n-                        startOfLedger = endOfLedger + 1;\n-                    }\n-                    continue;\n-                }\n-\n-                // If it doesn't have a valid end, it must be the last ledger\n-                if (lrIterator.hasNext()) {\n-                    String msg = \"Ledger-id: \" + range.getLedgerId() + \" for topic: \" + topic.toStringUtf8()\n-                                 + \" is not the last one but still does not have an end seq-id\";\n-                    logger.error(msg);\n-                    cb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                    return;\n-                }\n-\n-                if (range.hasStartSeqIdIncluded()) {\n-                    startOfLedger = range.getStartSeqIdIncluded();\n-                }\n-\n-                // The last ledger does not have a valid seq-id, lets try to\n-                // find it out\n-                recoverLastTopicLedgerAndOpenNewOne(range.getLedgerId(), startOfLedger,\n-                                                    version, topicInfo);\n-                return;\n-            }\n-\n-            // All ledgers were found properly closed, just start a new one\n-            openNewTopicLedger(topic, version, topicInfo, startOfLedger, false, cb, ctx);\n-        }\n-\n-        /**\n-         * Recovers the last ledger, opens a new one, and persists the new\n-         * information to ZK\n-         *\n-         * @param ledgerId\n-         *            Ledger to be recovered\n-         * @param expectedStartSeqId \n-         *            Start seq id of the ledger to recover\n-         * @param expectedVersionOfLedgerNode\n-         *            Expected version to update ledgers range\n-         * @param topicInfo\n-         *            Topic info\n-         */\n-        private void recoverLastTopicLedgerAndOpenNewOne(final long ledgerId, final long expectedStartSeqId,\n-                final Version expectedVersionOfLedgerNode, final TopicInfo topicInfo) {\n-\n-            bk.asyncOpenLedger(ledgerId, DigestType.CRC32, passwd, new SafeAsynBKCallback.OpenCallback() {\n-                @Override\n-                public void safeOpenComplete(int rc, LedgerHandle ledgerHandle, Object ctx) {\n-\n-                    if (rc != BKException.Code.OK) {\n-                        BKException bke = BKException.create(rc);\n-                        logger.error(\"While acquiring topic: \" + topic.toStringUtf8()\n-                                     + \", could not open unrecovered ledger: \" + ledgerId, bke);\n-                        cb.operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                        return;\n-                    }\n-\n-                    final long numEntriesInLastLedger = ledgerHandle.getLastAddConfirmed() + 1;\n-\n-                    if (numEntriesInLastLedger <= 0) {\n-                        // this was an empty ledger that someone created but\n-                        // couldn't write to, so just ignore it\n-                        logger.info(\"Pruning empty ledger: \" + ledgerId + \" for topic: \" + topic.toStringUtf8());\n-                        closeLedger(ledgerHandle);\n-                        openNewTopicLedger(topic, expectedVersionOfLedgerNode, topicInfo,\n-                                           expectedStartSeqId, false, cb, ctx);\n-                        return;\n-                    }\n-\n-                    // we have to read the last entry of the ledger to find\n-                    // out the last seq-id\n-\n-                    ledgerHandle.asyncReadEntries(numEntriesInLastLedger - 1, numEntriesInLastLedger - 1,\n-                    new SafeAsynBKCallback.ReadCallback() {\n-                        @Override\n-                        public void safeReadComplete(int rc, LedgerHandle lh, Enumeration<LedgerEntry> seq,\n-                        Object ctx) {\n-                            if (rc != BKException.Code.OK || !seq.hasMoreElements()) {\n-                                if (rc == BKException.Code.OK) {\n-                                    // means that there is no entries read, provide a meaningful exception\n-                                    rc = BKException.Code.NoSuchEntryException;\n-                                }\n-                                logger.info(\"Received error code {}\", rc);\n-                                BKException bke = BKException.create(rc);\n-                                logger.error(\"While recovering ledger: \" + ledgerId + \" for topic: \"\n-                                             + topic.toStringUtf8() + \", could not read last entry\", bke);\n-                                cb.operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                                return;\n-                            }\n-\n-                            Message lastMessage;\n-                            try {\n-                                lastMessage = Message.parseFrom(seq.nextElement().getEntry());\n-                            } catch (InvalidProtocolBufferException e) {\n-                                String msg = \"While recovering ledger: \" + ledgerId + \" for topic: \"\n-                                             + topic.toStringUtf8() + \", could not deserialize last message\";\n-                                logger.error(msg, e);\n-                                cb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));\n-                                return;\n-                            }\n-\n-                            long endOfLedger  = lastMessage.getMsgId().getLocalComponent();\n-                            long startOfLedger = endOfLedger - numEntriesInLastLedger + 1;\n-\n-                            if (startOfLedger != expectedStartSeqId) {\n-                                // gap would be introduced by old version when gc consumed ledgers\n-                                String msg = \"Expected start seq id of recovered ledger \" + ledgerId\n-                                             + \" to be \" + expectedStartSeqId + \" but it was \"\n-                                             + startOfLedger + \".\";\n-                                logger.warn(msg);\n-                            }\n-\n-                            LedgerRange lr = buildLedgerRange(ledgerId, startOfLedger, lastMessage.getMsgId());\n-                            topicInfo.ledgerRanges.put(endOfLedger,\n-                                    new InMemoryLedgerRange(lr, lh));\n-\n-                            logger.info(\"Recovered unclosed ledger: {} for topic: {} with {} entries starting from seq id {}\",\n-                                        va(ledgerId, topic.toStringUtf8(), numEntriesInLastLedger, startOfLedger));\n-\n-                            openNewTopicLedger(topic, expectedVersionOfLedgerNode, topicInfo, endOfLedger + 1, false, cb, ctx);\n-                        }\n-                    }, ctx);\n-\n-                }\n-\n-            }, ctx);\n-        }\n-    }\n-\n-    /**\n-     * Open New Ledger to write for a topic.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param expectedVersionOfLedgersNode\n-     *          Expected Version to Update Ledgers Node.\n-     * @param topicInfo\n-     *          Topic Information\n-     * @param startSeqId\n-     *          Start of sequence id for new ledger\n-     * @param changeLedger\n-     *          Whether is it called when changing ledger\n-     * @param cb\n-     *          Callback to trigger after opening new ledger.\n-     * @param ctx\n-     *          Callback context.\n-     */\n-    void openNewTopicLedger(final ByteString topic,\n-                            final Version expectedVersionOfLedgersNode, final TopicInfo topicInfo,\n-                            final long startSeqId, final boolean changeLedger,\n-                            final Callback<Void> cb, final Object ctx) {\n-        bk.asyncCreateLedger(cfg.getBkEnsembleSize(), cfg.getBkWriteQuorumSize(),\n-                             cfg.getBkAckQuorumSize(), DigestType.CRC32, passwd,\n-        new SafeAsynBKCallback.CreateCallback() {\n-            AtomicBoolean processed = new AtomicBoolean(false);\n-\n-            @Override\n-            public void safeCreateComplete(int rc, LedgerHandle lh, Object ctx) {\n-                if (!processed.compareAndSet(false, true)) {\n-                    return;\n-                }\n-\n-                if (rc != BKException.Code.OK) {\n-                    BKException bke = BKException.create(rc);\n-                    logger.error(\"Could not create new ledger while acquiring topic: \"\n-                                 + topic.toStringUtf8(), bke);\n-                    cb.operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                    return;\n-                }\n-\n-                // compute last seq id\n-                if (!changeLedger) {\n-                    topicInfo.lastSeqIdPushed = topicInfo.ledgerRanges.isEmpty() ? MessageSeqId.newBuilder()\n-                                                .setLocalComponent(startSeqId - 1).build() : topicInfo.ledgerRanges.lastEntry().getValue().range\n-                                                .getEndSeqIdIncluded();\n-                }\n-\n-                LedgerRange lastRange = LedgerRange.newBuilder().setLedgerId(lh.getId())\n-                                        .setStartSeqIdIncluded(startSeqId).build();\n-                topicInfo.currentLedgerRange = new InMemoryLedgerRange(lastRange, lh);\n-                topicInfo.lastEntryIdAckedInCurrentLedger = -1;\n-\n-                // Persist the fact that we started this new\n-                // ledger to ZK\n-\n-                LedgerRanges.Builder builder = LedgerRanges.newBuilder();\n-                for (InMemoryLedgerRange imlr : topicInfo.ledgerRanges.values()) {\n-                    builder.addRanges(imlr.range);\n-                }\n-                builder.addRanges(lastRange);\n-\n-                tpManager.writeTopicPersistenceInfo(\n-                topic, builder.build(), expectedVersionOfLedgersNode, new Callback<Version>() {\n-                    @Override\n-                    public void operationFinished(Object ctx, Version newVersion) {\n-                        // Finally, all done\n-                        topicInfo.ledgerRangesVersion = newVersion;\n-                        topicInfos.put(topic, topicInfo);\n-                        cb.operationFinished(ctx, null);\n-                    }\n-                    @Override\n-                    public void operationFailed(Object ctx, PubSubException exception) {\n-                        cb.operationFailed(ctx, exception);\n-                    }\n-                }, ctx);\n-                return;\n-            }\n-        }, ctx);\n-    }\n-\n-    /**\n-     * acquire ownership of a topic, doing whatever is needed to be able to\n-     * perform reads and writes on that topic from here on\n-     *\n-     * @param topic\n-     * @param callback\n-     * @param ctx\n-     */\n-    @Override\n-    public void acquiredTopic(ByteString topic, Callback<Void> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new AcquireOp(topic, callback, ctx));\n-    }\n-\n-    /**\n-     * Change ledger to write for a topic.\n-     */\n-    class ChangeLedgerOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-\n-        public ChangeLedgerOp(ByteString topic, Callback<Void> cb, Object ctx) {\n-            queuer.super(topic, cb, ctx);\n-        }\n-\n-        @Override\n-        public void run() {\n-            TopicInfo topicInfo = topicInfos.get(topic);\n-            if (null == topicInfo) {\n-                logger.error(\"Weired! hub server doesn't own topic \" + topic.toStringUtf8()\n-                           + \" when changing ledger to write.\");\n-                cb.operationFailed(ctx, new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-                return;\n-            }\n-            closeLastTopicLedgerAndOpenNewOne(topicInfo);\n-        }\n-\n-        private void closeLastTopicLedgerAndOpenNewOne(final TopicInfo topicInfo) {\n-            final long ledgerId = topicInfo.currentLedgerRange.handle.getId();\n-            topicInfo.currentLedgerRange.handle.asyncClose(new CloseCallback() {\n-                AtomicBoolean processed = new AtomicBoolean(false);\n-                @Override\n-                public void closeComplete(int rc, LedgerHandle lh, Object ctx) {\n-                    if (!processed.compareAndSet(false, true)) {\n-                        return;\n-                    }\n-                    if (BKException.Code.OK != rc) {\n-                        BKException bke = BKException.create(rc);\n-                        logger.error(\"Could not close ledger \" + ledgerId\n-                                   + \" while changing ledger of topic \" + topic.toStringUtf8(), bke);\n-                        cb.operationFailed(ctx, new PubSubException.ServiceDownException(bke));\n-                        return;\n-                    }\n-                    long endSeqId = topicInfo.lastSeqIdPushed.getLocalComponent();\n-                    // update last range\n-                    LedgerRange lastRange =\n-                        buildLedgerRange(ledgerId, topicInfo.currentLedgerRange.getStartSeqIdIncluded(),\n-                                         topicInfo.lastSeqIdPushed);\n-\n-                    topicInfo.currentLedgerRange.range = lastRange;\n-                    // put current ledger to ledger ranges\n-                    topicInfo.ledgerRanges.put(endSeqId, topicInfo.currentLedgerRange);\n-                    logger.info(\"Closed written ledger \" + ledgerId + \" for topic \"\n-                              + topic.toStringUtf8() + \" to change ledger.\");\n-                    openNewTopicLedger(topic, topicInfo.ledgerRangesVersion,\n-                                       topicInfo, endSeqId + 1, true, cb, ctx);\n-                }\n-            }, ctx);\n-        }\n-\n-    }\n-\n-    /**\n-     * Change ledger to write for a topic.\n-     *\n-     * @param topic\n-     *          Topic Name\n-     */\n-    protected void changeLedger(ByteString topic, Callback<Void> cb, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new ChangeLedgerOp(topic, cb, ctx));\n-    }\n-\n-    public void closeLedger(LedgerHandle lh) {\n-        // try {\n-        // lh.asyncClose(noOpCloseCallback, null);\n-        // } catch (InterruptedException e) {\n-        // logger.error(e);\n-        // Thread.currentThread().interrupt();\n-        // }\n-    }\n-\n-    class ReleaseOp extends TopicOpQueuer.SynchronousOp {\n-\n-        public ReleaseOp(ByteString topic) {\n-            queuer.super(topic);\n-        }\n-\n-        @Override\n-        public void runInternal() {\n-            TopicInfo topicInfo = topicInfos.remove(topic);\n-\n-            if (topicInfo == null) {\n-                return;\n-            }\n-\n-            for (InMemoryLedgerRange imlr : topicInfo.ledgerRanges.values()) {\n-                if (imlr.handle != null) {\n-                    closeLedger(imlr.handle);\n-                }\n-            }\n-\n-            if (topicInfo.currentLedgerRange != null && topicInfo.currentLedgerRange.handle != null) {\n-                closeLedger(topicInfo.currentLedgerRange.handle);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Release any resources for the topic that might be currently held. There\n-     * wont be any subsequent reads or writes on that topic coming\n-     *\n-     * @param topic\n-     */\n-    @Override\n-    public void lostTopic(ByteString topic) {\n-        queuer.pushAndMaybeRun(topic, new ReleaseOp(topic));\n-    }\n-\n-    class SetMessageBoundOp extends TopicOpQueuer.SynchronousOp {\n-        final int bound;\n-\n-        public SetMessageBoundOp(ByteString topic, int bound) {\n-            queuer.super(topic);\n-            this.bound = bound;\n-        }\n-\n-        @Override\n-        public void runInternal() {\n-            TopicInfo topicInfo = topicInfos.get(topic);\n-            if (topicInfo != null) {\n-                topicInfo.messageBound = bound;\n-            }\n-        }\n-    }\n-\n-    public void setMessageBound(ByteString topic, Integer bound) {\n-        queuer.pushAndMaybeRun(topic, new SetMessageBoundOp(topic, bound));\n-    }\n-\n-    public void clearMessageBound(ByteString topic) {\n-        queuer.pushAndMaybeRun(topic, new SetMessageBoundOp(topic, TopicInfo.UNLIMITED));\n-    }\n-\n-    @Override\n-    public void stop() {\n-        try {\n-            tpManager.close();\n-        } catch (IOException ioe) {\n-            logger.warn(\"Exception closing topic persistence manager : \", ioe);\n-        }\n-    }\n-}"},{"sha":"26bdb942f8fe1982085f13ffa419290d5ac081e6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheKey.java","status":"removed","additions":0,"deletions":74,"changes":74,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheKey.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheKey.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheKey.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,74 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.server.common.ByteStringInterner;\n-\n-public class CacheKey {\n-\n-    ByteString topic;\n-    long seqId;\n-\n-    public CacheKey(ByteString topic, long seqId) {\n-        this.topic = ByteStringInterner.intern(topic);\n-        this.seqId = seqId;\n-    }\n-\n-    public ByteString getTopic() {\n-        return topic;\n-    }\n-\n-    public long getSeqId() {\n-        return seqId;\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        final int prime = 31;\n-        int result = 1;\n-        result = prime * result + (int) (seqId ^ (seqId >>> 32));\n-        result = prime * result + ((topic == null) ? 0 : topic.hashCode());\n-        return result;\n-    }\n-\n-    @Override\n-    public boolean equals(Object obj) {\n-        if (this == obj)\n-            return true;\n-        if (obj == null)\n-            return false;\n-        if (getClass() != obj.getClass())\n-            return false;\n-        CacheKey other = (CacheKey) obj;\n-        if (seqId != other.seqId)\n-            return false;\n-        if (topic == null) {\n-            if (other.topic != null)\n-                return false;\n-        } else if (!topic.equals(other.topic))\n-            return false;\n-        return true;\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return \"(\" + topic.toStringUtf8() + \",\" + seqId + \")\";\n-    }\n-\n-}"},{"sha":"992ff11980b07429ad3430a9de88feee68389e8f","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheValue.java","status":"removed","additions":0,"deletions":101,"changes":101,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheValue.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheValue.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CacheValue.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,101 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import java.util.HashSet;\n-import java.util.Set;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.server.common.UnexpectedError;\n-\n-/**\n- * This class is NOT thread safe. It need not be thread-safe because our\n- * read-ahead cache will operate with only 1 thread\n- *\n- */\n-public class CacheValue {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ReadAheadCache.class);\n-\n-    // Actually we don't care the order of callbacks\n-    // when a scan callback, it should be delivered to both callbacks\n-    Set<ScanCallbackWithContext> callbacks = new HashSet<ScanCallbackWithContext>();\n-    Message message;\n-    long timeOfAddition = 0;\n-\n-    public CacheValue() {\n-    }\n-\n-    public boolean isStub() {\n-        return message == null;\n-    }\n-\n-    public long getTimeOfAddition() {\n-        if (message == null) {\n-            throw new UnexpectedError(\"Time of add requested from a stub\");\n-        }\n-        return timeOfAddition;\n-    }\n-\n-    public void setMessageAndInvokeCallbacks(Message message, long currTime) {\n-        if (this.message != null) {\n-            // Duplicate read for the same message coming back\n-            return;\n-        }\n-\n-        this.message = message;\n-        this.timeOfAddition = currTime;\n-\n-        logger.debug(\"Invoking {} callbacks for {} message added to cache\", callbacks.size(), message);\n-        for (ScanCallbackWithContext callbackWithCtx : callbacks) {\n-            if (null != callbackWithCtx) {\n-                callbackWithCtx.getScanCallback().messageScanned(callbackWithCtx.getCtx(), message);\n-            }\n-        }\n-    }\n-\n-    public boolean removeCallback(ScanCallback callback, Object ctx) {\n-        return callbacks.remove(new ScanCallbackWithContext(callback, ctx));\n-    }\n-\n-    public void addCallback(ScanCallback callback, Object ctx) {\n-        if (!isStub()) {\n-            // call the callback right away\n-            callback.messageScanned(ctx, message);\n-            return;\n-        }\n-\n-        callbacks.add(new ScanCallbackWithContext(callback, ctx));\n-    }\n-\n-    public Message getMessage() {\n-        return message;\n-    }\n-\n-    public void setErrorAndInvokeCallbacks(Exception exception) {\n-        for (ScanCallbackWithContext callbackWithCtx : callbacks) {\n-            if (null != callbackWithCtx) {\n-                callbackWithCtx.getScanCallback().scanFailed(callbackWithCtx.getCtx(), exception);\n-            }\n-        }\n-    }\n-\n-}"},{"sha":"c3b521433975277e16be35f50ef66f53cc2d5cf5","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CancelScanRequest.java","status":"removed","additions":0,"deletions":27,"changes":27,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CancelScanRequest.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CancelScanRequest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/CancelScanRequest.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,27 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-public interface CancelScanRequest {\n-\n-    /**\n-     * @return the scan request to cancel\n-     */\n-    public ScanRequest getScanRequest();\n-\n-}"},{"sha":"c1ee24ccfcd1c440533183366fb9ab92005afe6b","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/Factory.java","status":"removed","additions":0,"deletions":22,"changes":22,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/Factory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/Factory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/Factory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,22 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-public interface Factory<T> {\n-    public T newInstance();\n-}"},{"sha":"b3c5dc9699b922890fc985a8bf3b78f9d0e1cd13","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/LocalDBPersistenceManager.java","status":"removed","additions":0,"deletions":491,"changes":491,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/LocalDBPersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/LocalDBPersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/LocalDBPersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,491 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import java.io.File;\n-import java.io.IOException;\n-import java.sql.Connection;\n-import java.sql.DriverManager;\n-import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n-import java.sql.SQLException;\n-import java.sql.Statement;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-\n-import java.math.BigInteger;\n-import java.security.MessageDigest;\n-import java.security.NoSuchAlgorithmException;\n-\n-import javax.sql.rowset.serial.SerialBlob;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.exceptions.PubSubException.ServiceDownException;\n-import org.apache.hedwig.exceptions.PubSubException.UnexpectedConditionException;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protoextensions.MessageIdUtils;\n-import org.apache.hedwig.server.persistence.ScanCallback.ReasonForFinish;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.FileUtils;\n-\n-public class LocalDBPersistenceManager implements PersistenceManagerWithRangeScan {\n-    private static final Logger logger = LoggerFactory.getLogger(LocalDBPersistenceManager.class);\n-\n-    static String connectionURL;\n-\n-    static {\n-        try {\n-            File tempDir = FileUtils.createTempDirectory(\"derby\", null);\n-\n-            // Since derby needs to create it, I will have to delete it first\n-            if (!tempDir.delete()) {\n-                throw new IOException(\"Could not delete dir: \" + tempDir.getAbsolutePath());\n-            }\n-            connectionURL = \"jdbc:derby:\" + tempDir.getAbsolutePath() + \";create=true\";\n-        } catch (IOException e) {\n-            throw new RuntimeException(e);\n-        }\n-\n-    }\n-\n-    private static final ThreadLocal<Connection> threadLocalConnection = new ThreadLocal<Connection>() {\n-        @Override\n-        protected Connection initialValue() {\n-            try {\n-                return DriverManager.getConnection(connectionURL);\n-            } catch (SQLException e) {\n-                logger.error(\"Could not connect to derby\", e);\n-                return null;\n-            }\n-        }\n-    };\n-\n-    private static final ThreadLocal<MessageDigest> threadLocalDigest = new ThreadLocal<MessageDigest>() {\n-        @Override\n-        protected MessageDigest initialValue() {\n-            try {\n-                return MessageDigest.getInstance(\"MD5\");\n-            } catch (NoSuchAlgorithmException e) {\n-                logger.error(\"Could not find MD5 hash\", e);\n-                return null;\n-            }\n-        }\n-    };\n-    static final String ID_FIELD_NAME = \"id\";\n-    static final String MSG_FIELD_NAME = \"msg\";\n-    static final String driver = \"org.apache.derby.jdbc.EmbeddedDriver\";\n-\n-    static final int SCAN_CHUNK = 1000;\n-\n-    /**\n-     * Having trouble restarting the database multiple times from within the\n-     * same jvm. Hence to facilitate units tests, we are just going to have a\n-     * version number that we will append to every table name. This version\n-     * number will be incremented in lieu of shutting down the database and\n-     * restarting it, so that we get different table names, and it behaves like\n-     * a brand new database\n-     */\n-    private int version = 0;\n-\n-    ConcurrentMap<ByteString, MessageSeqId> currTopicSeqIds = new ConcurrentHashMap<ByteString, MessageSeqId>();\n-\n-    static LocalDBPersistenceManager instance = new LocalDBPersistenceManager();\n-\n-    public static LocalDBPersistenceManager instance() {\n-        return instance;\n-    }\n-\n-    private LocalDBPersistenceManager() {\n-\n-        try {\n-            Class.forName(driver).newInstance();\n-            logger.info(\"Derby Driver loaded\");\n-        } catch (java.lang.ClassNotFoundException e) {\n-            logger.error(\"Derby driver not found\", e);\n-        } catch (InstantiationException e) {\n-            logger.error(\"Could not instantiate derby driver\", e);\n-        } catch (IllegalAccessException e) {\n-            logger.error(\"Could not instantiate derby driver\", e);\n-        }\n-    }\n-\n-    @Override\n-    public void stop() {\n-        // do nothing\n-    }\n-\n-    /**\n-     * Ensures that at least the default seq-id exists in the map for the given\n-     * topic. Checks for race conditions (.e.g, another thread inserts the\n-     * default id before us), and returns the latest seq-id value in the map\n-     *\n-     * @param topic\n-     * @return\n-     */\n-    private MessageSeqId ensureSeqIdExistsForTopic(ByteString topic) {\n-        MessageSeqId presentSeqIdInMap = currTopicSeqIds.get(topic);\n-\n-        if (presentSeqIdInMap != null) {\n-            return presentSeqIdInMap;\n-        }\n-\n-        presentSeqIdInMap = MessageSeqId.newBuilder().setLocalComponent(0).build();\n-        MessageSeqId oldSeqIdInMap = currTopicSeqIds.putIfAbsent(topic, presentSeqIdInMap);\n-\n-        if (oldSeqIdInMap != null) {\n-            return oldSeqIdInMap;\n-        }\n-        return presentSeqIdInMap;\n-\n-    }\n-\n-    /**\n-     * Adjust the current seq id of the topic based on the message we are about\n-     * to publish. The local component of the current seq-id is always\n-     * incremented by 1. For the other components, there are two cases:\n-     *\n-     * 1. If the message to be published doesn't have a seq-id (locally\n-     * published messages), the other components are left as is.\n-     *\n-     * 2. If the message to be published has a seq-id, we take the max of the\n-     * current one we have, and that in the message to be published.\n-     *\n-     * @param topic\n-     * @param messageToPublish\n-     * @return The value of the local seq-id obtained after incrementing the\n-     *         local component. This value should be used as an id while\n-     *         persisting to Derby\n-     * @throws UnexpectedConditionException\n-     */\n-    private long adjustTopicSeqIdForPublish(ByteString topic, Message messageToPublish)\n-            throws UnexpectedConditionException {\n-        long retValue = 0;\n-        MessageSeqId oldId;\n-        MessageSeqId.Builder newIdBuilder = MessageSeqId.newBuilder();\n-\n-        do {\n-            oldId = ensureSeqIdExistsForTopic(topic);\n-\n-            // Increment our own component by 1\n-            retValue = oldId.getLocalComponent() + 1;\n-            newIdBuilder.setLocalComponent(retValue);\n-\n-            if (messageToPublish.hasMsgId()) {\n-                // take a region-wise max\n-                MessageIdUtils.takeRegionMaximum(newIdBuilder, messageToPublish.getMsgId(), oldId);\n-\n-            } else {\n-                newIdBuilder.addAllRemoteComponents(oldId.getRemoteComponentsList());\n-            }\n-        } while (!currTopicSeqIds.replace(topic, oldId, newIdBuilder.build()));\n-\n-        return retValue;\n-\n-    }\n-\n-    public long getSeqIdAfterSkipping(ByteString topic, long seqId, int skipAmount) {\n-        return seqId + skipAmount;\n-    }\n-\n-    public void persistMessage(PersistRequest request) {\n-\n-        Connection conn = threadLocalConnection.get();\n-\n-        Callback<MessageSeqId> callback = request.getCallback();\n-        Object ctx = request.getCtx();\n-        ByteString topic = request.getTopic();\n-        Message message = request.getMessage();\n-\n-        if (conn == null) {\n-            callback.operationFailed(ctx, new ServiceDownException(\"Not connected to derby\"));\n-            return;\n-        }\n-\n-        long seqId;\n-\n-        try {\n-            seqId = adjustTopicSeqIdForPublish(topic, message);\n-        } catch (UnexpectedConditionException e) {\n-            callback.operationFailed(ctx, e);\n-            return;\n-        }\n-        PreparedStatement stmt;\n-\n-        boolean triedCreatingTable = false;\n-        while (true) {\n-            try {\n-                message.getBody();\n-                stmt = conn.prepareStatement(\"INSERT INTO \" + getTableNameForTopic(topic) + \" VALUES(?,?)\");\n-                stmt.setLong(1, seqId);\n-                stmt.setBlob(2, new SerialBlob(message.toByteArray()));\n-\n-                int rowCount = stmt.executeUpdate();\n-                stmt.close();\n-                if (rowCount != 1) {\n-                    logger.error(\"Unexpected number of affected rows from derby\");\n-                    callback.operationFailed(ctx, new ServiceDownException(\"Unexpected response from derby\"));\n-                    return;\n-                }\n-                break;\n-            } catch (SQLException sqle) {\n-                String theError = (sqle).getSQLState();\n-                if (theError.equals(\"42X05\") && !triedCreatingTable) {\n-                    createTable(conn, topic);\n-                    triedCreatingTable = true;\n-                    continue;\n-                }\n-\n-                logger.error(\"Error while executing derby insert\", sqle);\n-                callback.operationFailed(ctx, new ServiceDownException(sqle));\n-                return;\n-            }\n-        }\n-        callback.operationFinished(ctx, MessageIdUtils.mergeLocalSeqId(message, seqId).getMsgId());\n-    }\n-\n-    /*\n-     * This method does not throw an exception because another thread might\n-     * sneak in and create the table before us\n-     */\n-    private void createTable(Connection conn, ByteString topic) {\n-        Statement stmt = null;\n-        try {\n-            stmt = conn.createStatement();\n-            String tableName = getTableNameForTopic(topic);\n-            stmt.execute(\"CREATE TABLE \" + tableName + \" (\" + ID_FIELD_NAME + \" BIGINT NOT NULL CONSTRAINT ID_PK_\"\n-                    + tableName + \" PRIMARY KEY,\" + MSG_FIELD_NAME + \" BLOB(2M) NOT NULL)\");\n-        } catch (SQLException e) {\n-            logger.debug(\"Could not create table\", e);\n-        } finally {\n-            try {\n-                if (stmt != null) {\n-                    stmt.close();\n-                }\n-            } catch (SQLException e) {\n-                logger.error(\"Error closing statement\", e);\n-            }\n-        }\n-    }\n-\n-    public MessageSeqId getCurrentSeqIdForTopic(ByteString topic) {\n-        return ensureSeqIdExistsForTopic(topic);\n-    }\n-\n-    public void scanSingleMessage(ScanRequest request) {\n-        scanMessagesInternal(request.getTopic(), request.getStartSeqId(), 1, Long.MAX_VALUE, request.getCallback(),\n-                             request.getCtx(), 1);\n-        return;\n-    }\n-\n-    public void scanMessages(RangeScanRequest request) {\n-        scanMessagesInternal(request.getTopic(), request.getStartSeqId(), request.getMessageLimit(), request\n-                             .getSizeLimit(), request.getCallback(), request.getCtx(), SCAN_CHUNK);\n-        return;\n-    }\n-\n-    private String getTableNameForTopic(ByteString topic) {\n-        String src = (topic.toStringUtf8() + \"_\" + version);\n-        threadLocalDigest.get().reset();\n-        byte[] digest = threadLocalDigest.get().digest(src.getBytes(UTF_8));\n-        BigInteger bigInt = new BigInteger(1,digest);\n-        return String.format(\"TABLE_%032X\", bigInt);\n-    }\n-\n-    private void scanMessagesInternal(ByteString topic, long startSeqId, int messageLimit, long sizeLimit,\n-                                      ScanCallback callback, Object ctx, int scanChunk) {\n-\n-        Connection conn = threadLocalConnection.get();\n-\n-        if (conn == null) {\n-            callback.scanFailed(ctx, new ServiceDownException(\"Not connected to derby\"));\n-            return;\n-        }\n-\n-        long currentSeqId;\n-        currentSeqId = startSeqId;\n-\n-        PreparedStatement stmt = null;\n-        try {\n-            try {\n-                stmt = conn.prepareStatement(\"SELECT * FROM \" + getTableNameForTopic(topic) + \" WHERE \" + ID_FIELD_NAME\n-                                             + \" >= ?  AND \" + ID_FIELD_NAME + \" <= ?\");\n-\n-            } catch (SQLException sqle) {\n-                String theError = (sqle).getSQLState();\n-                if (theError.equals(\"42X05\")) {\n-                    // No table, scan is over\n-                    callback.scanFinished(ctx, ReasonForFinish.NO_MORE_MESSAGES);\n-                    return;\n-                } else {\n-                    throw sqle;\n-                }\n-            }\n-\n-            int numMessages = 0;\n-            long totalSize = 0;\n-\n-            while (true) {\n-\n-                stmt.setLong(1, currentSeqId);\n-                stmt.setLong(2, currentSeqId + scanChunk);\n-\n-                if (!stmt.execute()) {\n-                    String errorMsg = \"Select query did not return a result set\";\n-                    logger.error(errorMsg);\n-                    stmt.close();\n-                    callback.scanFailed(ctx, new ServiceDownException(errorMsg));\n-                    return;\n-                }\n-\n-                ResultSet resultSet = stmt.getResultSet();\n-\n-                if (!resultSet.next()) {\n-                    stmt.close();\n-                    callback.scanFinished(ctx, ReasonForFinish.NO_MORE_MESSAGES);\n-                    return;\n-                }\n-\n-                do {\n-\n-                    long localSeqId = resultSet.getLong(1);\n-\n-                    Message.Builder messageBuilder = Message.newBuilder().mergeFrom(resultSet.getBinaryStream(2));\n-\n-                    // Merge in the local seq-id since that is not stored with\n-                    // the message\n-                    Message message = MessageIdUtils.mergeLocalSeqId(messageBuilder, localSeqId);\n-\n-                    callback.messageScanned(ctx, message);\n-                    numMessages++;\n-                    totalSize += message.getBody().size();\n-\n-                    if (numMessages > messageLimit) {\n-                        stmt.close();\n-                        callback.scanFinished(ctx, ReasonForFinish.NUM_MESSAGES_LIMIT_EXCEEDED);\n-                        return;\n-                    } else if (totalSize > sizeLimit) {\n-                        stmt.close();\n-                        callback.scanFinished(ctx, ReasonForFinish.SIZE_LIMIT_EXCEEDED);\n-                        return;\n-                    }\n-\n-                } while (resultSet.next());\n-\n-                currentSeqId += SCAN_CHUNK;\n-            }\n-        } catch (SQLException e) {\n-            logger.error(\"SQL Exception\", e);\n-            callback.scanFailed(ctx, new ServiceDownException(e));\n-            return;\n-        } catch (IOException e) {\n-            logger.error(\"Message stored in derby is not parseable\", e);\n-            callback.scanFailed(ctx, new ServiceDownException(e));\n-            return;\n-        } finally {\n-            try {\n-                if (stmt != null) {\n-                    stmt.close();\n-                }\n-            } catch (SQLException e) {\n-                logger.error(\"Error closing statement\", e);\n-            }\n-        }\n-    }\n-\n-    public void deliveredUntil(ByteString topic, Long seqId) {\n-        // noop\n-    }\n-\n-    public void consumedUntil(ByteString topic, Long seqId) {\n-        Connection conn = threadLocalConnection.get();\n-        if (conn == null) {\n-            logger.error(\"Not connected to derby\");\n-            return;\n-        }\n-        PreparedStatement stmt = null;\n-        try {\n-            stmt = conn.prepareStatement(\"DELETE FROM \" + getTableNameForTopic(topic) + \" WHERE \" + ID_FIELD_NAME\n-                                         + \" <= ?\");\n-            stmt.setLong(1, seqId);\n-            int rowCount = stmt.executeUpdate();\n-            if (logger.isDebugEnabled()) {\n-              logger.debug(\"Deleted \" + rowCount + \" records for topic: \" + topic.toStringUtf8()\n-                  + \", seqId: \" + seqId);\n-            }\n-        } catch (SQLException sqle) {\n-            String theError = (sqle).getSQLState();\n-            if (theError.equals(\"42X05\")) {\n-                logger.warn(\"Table for topic (\" + topic + \") does not exist so no consumed messages to delete!\");\n-            } else\n-                logger.error(\"Error while executing derby delete for consumed messages\", sqle);\n-        } finally {\n-            try {\n-                if (stmt != null) {\n-                    stmt.close();\n-                }\n-            } catch (SQLException e) {\n-                logger.error(\"Error closing statement\", e);\n-            }\n-        }\n-    }\n-\n-    public void setMessageBound(ByteString topic, Integer bound) {\n-        // noop; Maybe implement later\n-    }\n-\n-    public void clearMessageBound(ByteString topic) {\n-        // noop; Maybe implement later\n-    }\n-\n-    public void consumeToBound(ByteString topic) {\n-        // noop; Maybe implement later\n-    }\n-\n-    @Override\n-    protected void finalize() throws Throwable {\n-        if (driver.equals(\"org.apache.derby.jdbc.EmbeddedDriver\")) {\n-            boolean gotSQLExc = false;\n-            // This is weird: on normal shutdown, it throws an exception\n-            try {\n-                DriverManager.getConnection(\"jdbc:derby:;shutdown=true\").close();\n-            } catch (SQLException se) {\n-                if (se.getSQLState().equals(\"XJ015\")) {\n-                    gotSQLExc = true;\n-                }\n-            }\n-            if (!gotSQLExc) {\n-                logger.error(\"Database did not shut down normally\");\n-            } else {\n-                logger.info(\"Database shut down normally\");\n-            }\n-        }\n-        super.finalize();\n-    }\n-\n-    public void reset() {\n-        // just move the namespace over to the next one\n-        version++;\n-        currTopicSeqIds.clear();\n-    }\n-}"},{"sha":"f640723514d6b88839705a6e248d8bb5b35138cb","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/MapMethods.java","status":"removed","additions":0,"deletions":62,"changes":62,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/MapMethods.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/MapMethods.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/MapMethods.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,62 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import java.util.Collection;\n-import java.util.Map;\n-\n-public class MapMethods {\n-\n-    public static <K, V> V getAfterInsertingIfAbsent(Map<K, V> map, K key, Factory<V> valueFactory) {\n-        V value = map.get(key);\n-\n-        if (value == null) {\n-            value = valueFactory.newInstance();\n-            map.put(key, value);\n-        }\n-\n-        return value;\n-    }\n-\n-    public static <K, V, Z extends Collection<V>> void addToMultiMap(Map<K, Z> map, K key, V value,\n-            Factory<Z> valueFactory) {\n-        Collection<V> collection = getAfterInsertingIfAbsent(map, key, valueFactory);\n-\n-        collection.add(value);\n-\n-    }\n-\n-    public static <K, V, Z extends Collection<V>> boolean removeFromMultiMap(Map<K, Z> map, K key, V value) {\n-        Collection<V> collection = map.get(key);\n-\n-        if (collection == null) {\n-            return false;\n-        }\n-\n-        if (!collection.remove(value)) {\n-            return false;\n-        } else {\n-            if (collection.isEmpty()) {\n-                map.remove(key);\n-            }\n-            return true;\n-        }\n-\n-    }\n-\n-}"},{"sha":"d137fe6731c049d151b5142fbf94d44e1a3326a3","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistRequest.java","status":"removed","additions":0,"deletions":59,"changes":59,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistRequest.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistRequest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistRequest.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,59 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * Encapsulates a request to persist a given message on a given topic. The\n- * request is completed asynchronously, callback and context are provided\n- *\n- */\n-public class PersistRequest {\n-    ByteString topic;\n-    Message message;\n-    private Callback<PubSubProtocol.MessageSeqId> callback;\n-    Object ctx;\n-\n-    public PersistRequest(ByteString topic, Message message, Callback<PubSubProtocol.MessageSeqId> callback, Object ctx) {\n-        this.topic = topic;\n-        this.message = message;\n-        this.callback = callback;\n-        this.ctx = ctx;\n-    }\n-\n-    public ByteString getTopic() {\n-        return topic;\n-    }\n-\n-    public Message getMessage() {\n-        return message;\n-    }\n-\n-    public Callback<PubSubProtocol.MessageSeqId> getCallback() {\n-        return callback;\n-    }\n-\n-    public Object getCtx() {\n-        return ctx;\n-    }\n-\n-}"},{"sha":"a295fc755d0a8d0af4d64776257d4a9925bc26ec","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManager.java","status":"removed","additions":0,"deletions":99,"changes":99,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,99 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-\n-/**\n- * An implementation of this interface will persist messages in order and assign\n- * a seqId to each persisted message. SeqId need not be a single number in\n- * general. SeqId is opaque to all layers above {@link PersistenceManager}. Only\n- * the {@link PersistenceManager} needs to understand the format of the seqId\n- * and maintain it in such a way that there is a total order on the seqIds of a\n- * topic.\n- *\n- */\n-public interface PersistenceManager {\n-\n-    /**\n-     * Executes the given persist request asynchronously. When done, the\n-     * callback specified in the request object is called with the result of the\n-     * operation set to the {@link LocalMessageSeqId} assigned to the persisted\n-     * message.\n-     */\n-    public void persistMessage(PersistRequest request);\n-\n-    /**\n-     * Get the seqId of the last message that has been persisted to the given\n-     * topic. The returned seqId will be set as the consume position of any\n-     * brand new subscription on this topic.\n-     *\n-     * Note that the return value may quickly become invalid because a\n-     * {@link #persistMessage(String, PublishedMessage)} call from another\n-     * thread succeeds. For us, the typical use case is choosing the consume\n-     * position of a new subscriber. Since the subscriber need not receive all\n-     * messages that are published while the subscribe call is in progress, such\n-     * loose semantics from this method is acceptable.\n-     *\n-     * @param topic\n-     * @return the seqId of the last persisted message.\n-     * @throws ServerNotResponsibleForTopicException\n-     */\n-    public MessageSeqId getCurrentSeqIdForTopic(ByteString topic) throws ServerNotResponsibleForTopicException;\n-\n-    /**\n-     * Executes the given scan request\n-     *\n-     */\n-    public void scanSingleMessage(ScanRequest request);\n-\n-    /**\n-     * Gets the next seq-id. This method should never block.\n-     */\n-    public long getSeqIdAfterSkipping(ByteString topic, long seqId, int skipAmount);\n-\n-    /**\n-     * Hint that the messages until the given seqId have been delivered and wont\n-     * be needed unless there is a failure of some kind\n-     */\n-    public void deliveredUntil(ByteString topic, Long seqId);\n-\n-    /**\n-     * Hint that the messages until the given seqId have been consumed by all\n-     * subscribers to the topic and no longer need to be stored. The\n-     * implementation classes can decide how and if they want to garbage collect\n-     * and delete these older topic messages that are no longer needed.\n-     *\n-     * @param topic\n-     *            Topic\n-     * @param seqId\n-     *            Message local sequence ID\n-     */\n-    public void consumedUntil(ByteString topic, Long seqId);\n-\n-    public void setMessageBound(ByteString topic, Integer bound);\n-    public void clearMessageBound(ByteString topic);\n-    public void consumeToBound(ByteString topic);\n-\n-    /**\n-     * Stop persistence manager.\n-     */\n-    public void stop();\n-}"},{"sha":"f12174f098df09d97ccc36e0fdb4c04791df2bca","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManagerWithRangeScan.java","status":"removed","additions":0,"deletions":27,"changes":27,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManagerWithRangeScan.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManagerWithRangeScan.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/PersistenceManagerWithRangeScan.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,27 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-public interface PersistenceManagerWithRangeScan extends PersistenceManager {\n-    /**\n-     * Executes the given range scan request\n-     *\n-     * @param request\n-     */\n-    public void scanMessages(RangeScanRequest request);\n-}"},{"sha":"3ac324df537fd37463b455c0823e5bd07f3fc815","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/RangeScanRequest.java","status":"removed","additions":0,"deletions":77,"changes":77,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/RangeScanRequest.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/RangeScanRequest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/RangeScanRequest.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,77 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import com.google.protobuf.ByteString;\n-\n-/**\n- * Encapsulates a request to scan messages on the given topic starting from the\n- * given seqId (included). A call-back {@link ScanCallback} is provided. As\n- * messages are scanned, the relevant methods of the {@link ScanCallback} are\n- * called. Two hints are provided as to when scanning should stop: in terms of\n- * number of messages scanned, or in terms of the total size of messages\n- * scanned. Scanning stops whenever one of these limits is exceeded. These\n- * checks, especially the one about message size, are only approximate. The\n- * {@link ScanCallback} used should be prepared to deal with more or less\n- * messages scanned. If an error occurs during scanning, the\n- * {@link ScanCallback} is notified of the error.\n- *\n- */\n-public class RangeScanRequest {\n-    ByteString topic;\n-    long startSeqId;\n-    int messageLimit;\n-    long sizeLimit;\n-    ScanCallback callback;\n-    Object ctx;\n-\n-    public RangeScanRequest(ByteString topic, long startSeqId, int messageLimit, long sizeLimit, ScanCallback callback,\n-                            Object ctx) {\n-        this.topic = topic;\n-        this.startSeqId = startSeqId;\n-        this.messageLimit = messageLimit;\n-        this.sizeLimit = sizeLimit;\n-        this.callback = callback;\n-        this.ctx = ctx;\n-    }\n-\n-    public ByteString getTopic() {\n-        return topic;\n-    }\n-\n-    public long getStartSeqId() {\n-        return startSeqId;\n-    }\n-\n-    public int getMessageLimit() {\n-        return messageLimit;\n-    }\n-\n-    public long getSizeLimit() {\n-        return sizeLimit;\n-    }\n-\n-    public ScanCallback getCallback() {\n-        return callback;\n-    }\n-\n-    public Object getCtx() {\n-        return ctx;\n-    }\n-\n-}"},{"sha":"48be3e8e1efae23d4ca6b521cdc26a8dfbc38cf6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","status":"removed","additions":0,"deletions":865,"changes":865,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,865 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import java.util.HashSet;\n-import java.util.Iterator;\n-import java.util.LinkedList;\n-import java.util.Queue;\n-import java.util.Set;\n-import java.util.SortedMap;\n-import java.util.SortedSet;\n-import java.util.TreeMap;\n-import java.util.TreeSet;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-import java.util.concurrent.RejectedExecutionException;\n-import java.util.concurrent.atomic.AtomicInteger;\n-import java.util.concurrent.atomic.AtomicLong;\n-\n-import org.apache.bookkeeper.util.MathUtils;\n-import org.apache.bookkeeper.util.OrderedSafeExecutor;\n-import org.apache.bookkeeper.util.SafeRunnable;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ServerNotResponsibleForTopicException;\n-import org.apache.hedwig.protocol.PubSubProtocol;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protoextensions.MessageIdUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.jmx.HedwigJMXService;\n-import org.apache.hedwig.server.jmx.HedwigMBeanInfo;\n-import org.apache.hedwig.server.jmx.HedwigMBeanRegistry;\n-import org.apache.hedwig.util.Callback;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.protobuf.ByteString;\n-\n-public class ReadAheadCache implements PersistenceManager, HedwigJMXService {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ReadAheadCache.class);\n-\n-    protected interface CacheRequest {\n-        public void performRequest();\n-    }\n-\n-    /**\n-     * The underlying persistence manager that will be used for persistence and\n-     * scanning below the cache\n-     */\n-    protected PersistenceManagerWithRangeScan realPersistenceManager;\n-\n-    /**\n-     * The structure for the cache\n-     */\n-    protected ConcurrentMap<CacheKey, CacheValue> cache =\n-        new ConcurrentHashMap<CacheKey, CacheValue>();\n-\n-    /**\n-     * We also want to track the entries in seq-id order so that we can clean up\n-     * entries after the last subscriber\n-     */\n-    protected ConcurrentMap<ByteString, SortedSet<Long>> orderedIndexOnSeqId =\n-        new ConcurrentHashMap<ByteString, SortedSet<Long>>();\n-\n-    /**\n-     * Partition Cache into Serveral Segments for simplify synchronization.\n-     * Each segment maintains its time index and segment size.\n-     */\n-    static class CacheSegment {\n-\n-        /**\n-         * We want to keep track of when entries were added in the cache, so that we\n-         * can remove them in a FIFO fashion\n-         */\n-        protected SortedMap<Long, Set<CacheKey>> timeIndexOfAddition = new TreeMap<Long, Set<CacheKey>>();\n-\n-        /**\n-         * We maintain an estimate of the current size of each cache segment,\n-         * so that the thread know when to evict entries from cache segment.\n-         */\n-        protected AtomicLong presentSegmentSize = new AtomicLong(0);\n-\n-    }\n-\n-    /**\n-     * We maintain an estimate of the current size of the cache, so that we know\n-     * when to evict entries.\n-     */\n-    protected AtomicLong presentCacheSize = new AtomicLong(0);\n-\n-    /**\n-     * Num pending requests.\n-     */\n-    protected AtomicInteger numPendingRequests = new AtomicInteger(0);\n-\n-    /**\n-     * Cache segment for different threads\n-     */\n-    protected final ThreadLocal<CacheSegment> cacheSegment =\n-        new ThreadLocal<CacheSegment>() {\n-            @Override\n-            protected CacheSegment initialValue() {\n-                return new CacheSegment();\n-            }\n-        };\n-\n-    /**\n-     * One instance of a callback that we will pass to the underlying\n-     * persistence manager when asking it to persist messages\n-     */\n-    protected PersistCallback persistCallbackInstance = new PersistCallback();\n-\n-    /**\n-     * 2 kinds of exceptions that we will use to signal error from readahead\n-     */\n-    protected NoSuchSeqIdException noSuchSeqIdExceptionInstance = new NoSuchSeqIdException();\n-    protected ReadAheadException readAheadExceptionInstance = new ReadAheadException();\n-\n-    protected ServerConfiguration cfg;\n-    // Boolean indicating if this thread should continue running. This is used\n-    // when we want to stop the thread during a PubSubServer shutdown.\n-    protected volatile boolean keepRunning = true;\n-\n-    protected final OrderedSafeExecutor cacheWorkers;\n-    protected final int numCacheWorkers;\n-    protected volatile long maxSegmentSize;\n-    protected volatile long cacheEntryTTL;\n-\n-    // JMX Beans\n-    ReadAheadCacheBean jmxCacheBean = null;\n-\n-    /**\n-     * Constructor. Starts the cache maintainer thread\n-     *\n-     * @param realPersistenceManager\n-     */\n-    public ReadAheadCache(PersistenceManagerWithRangeScan realPersistenceManager, ServerConfiguration cfg) {\n-        this.realPersistenceManager = realPersistenceManager;\n-        this.cfg = cfg;\n-        numCacheWorkers = cfg.getNumReadAheadCacheThreads();\n-        cacheWorkers = OrderedSafeExecutor.newBuilder()\n-                .name(\"ReadAheadCacheScheduler\")\n-                .numThreads(numCacheWorkers)\n-                .build();\n-        reloadConf(cfg);\n-    }\n-\n-    /**\n-     * Reload configuration\n-     *\n-     * @param conf\n-     *          Server configuration object\n-     */\n-    protected void reloadConf(ServerConfiguration cfg) {\n-        maxSegmentSize = cfg.getMaximumCacheSize() / numCacheWorkers;\n-        cacheEntryTTL = cfg.getCacheEntryTTL();\n-    }\n-\n-    public ReadAheadCache start() {\n-        return this;\n-    }\n-\n-    /**\n-     * ========================================================================\n-     * Methods of {@link PersistenceManager} that we will pass straight down to\n-     * the real persistence manager.\n-     */\n-\n-    @Override\n-    public long getSeqIdAfterSkipping(ByteString topic, long seqId, int skipAmount) {\n-        return realPersistenceManager.getSeqIdAfterSkipping(topic, seqId, skipAmount);\n-    }\n-\n-    @Override\n-    public MessageSeqId getCurrentSeqIdForTopic(ByteString topic) throws ServerNotResponsibleForTopicException {\n-        return realPersistenceManager.getCurrentSeqIdForTopic(topic);\n-    }\n-\n-    /**\n-     * ========================================================================\n-     * Other methods of {@link PersistenceManager} that the cache needs to take\n-     * some action on.\n-     *\n-     * 1. Persist: We pass it through to the real persistence manager but insert\n-     * our callback on the return path\n-     *\n-     */\n-    @Override\n-    public void persistMessage(PersistRequest request) {\n-        // make a new PersistRequest object so that we can insert our own\n-        // callback in the middle. Assign the original request as the context\n-        // for the callback.\n-\n-        PersistRequest newRequest = new PersistRequest(request.getTopic(), request.getMessage(),\n-                persistCallbackInstance, request);\n-        realPersistenceManager.persistMessage(newRequest);\n-    }\n-\n-    /**\n-     * The callback that we insert on the persist request return path. The\n-     * callback simply forms a {@link PersistResponse} object and inserts it in\n-     * the request queue to be handled serially by the cache maintainer thread.\n-     *\n-     */\n-    public class PersistCallback implements Callback<PubSubProtocol.MessageSeqId> {\n-\n-        /**\n-         * In case there is a failure in persisting, just pass it to the\n-         * original callback\n-         */\n-        @Override\n-        public void operationFailed(Object ctx, PubSubException exception) {\n-            PersistRequest originalRequest = (PersistRequest) ctx;\n-            Callback<PubSubProtocol.MessageSeqId> originalCallback = originalRequest.getCallback();\n-            Object originalContext = originalRequest.getCtx();\n-            originalCallback.operationFailed(originalContext, exception);\n-        }\n-\n-        /**\n-         * When the persist finishes, we first notify the original callback of\n-         * success, and then opportunistically treat the message as if it just\n-         * came in through a scan\n-         */\n-        @Override\n-        public void operationFinished(Object ctx, PubSubProtocol.MessageSeqId resultOfOperation) {\n-            PersistRequest originalRequest = (PersistRequest) ctx;\n-\n-            // Lets call the original callback first so that the publisher can\n-            // hear success\n-            originalRequest.getCallback().operationFinished(originalRequest.getCtx(), resultOfOperation);\n-\n-            // Original message that was persisted didn't have the local seq-id.\n-            // Lets add that in\n-            Message messageWithLocalSeqId = MessageIdUtils.mergeLocalSeqId(originalRequest.getMessage(),\n-                                            resultOfOperation.getLocalComponent());\n-\n-            // Now enqueue a request to add this newly persisted message to our\n-            // cache\n-            CacheKey cacheKey = new CacheKey(originalRequest.getTopic(), resultOfOperation.getLocalComponent());\n-\n-            enqueueWithoutFailureByTopic(cacheKey.getTopic(),\n-                    new ScanResponse(cacheKey, messageWithLocalSeqId));\n-        }\n-\n-    }\n-\n-    protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest obj) {\n-        if (!keepRunning) {\n-            return;\n-        }\n-        try {\n-            numPendingRequests.incrementAndGet();\n-            cacheWorkers.submitOrdered(topic, new SafeRunnable() {\n-                @Override\n-                public void safeRun() {\n-                    numPendingRequests.decrementAndGet();\n-                    obj.performRequest();\n-                }\n-            });\n-        } catch (RejectedExecutionException ree) {\n-            logger.error(\"Failed to submit cache request for topic \" + topic.toStringUtf8() + \" : \", ree);\n-        }\n-    }\n-\n-    /**\n-     * Another method from {@link PersistenceManager}.\n-     *\n-     * 2. Scan - Since the scan needs to touch the cache, we will just enqueue\n-     * the scan request and let the cache maintainer thread handle it.\n-     */\n-    @Override\n-    public void scanSingleMessage(ScanRequest request) {\n-        // Let the scan requests be serialized through the queue\n-        enqueueWithoutFailureByTopic(request.getTopic(),\n-                new ScanRequestWrapper(request));\n-    }\n-\n-    /**\n-     * Another method from {@link PersistenceManager}.\n-     *\n-     * 3. Enqueue the request so that the cache maintainer thread can delete all\n-     * message-ids older than the one specified\n-     */\n-    @Override\n-    public void deliveredUntil(ByteString topic, Long seqId) {\n-        enqueueWithoutFailureByTopic(topic, new DeliveredUntil(topic, seqId));\n-    }\n-\n-    /**\n-     * Another method from {@link PersistenceManager}.\n-     *\n-     * Since this is a cache layer on top of an underlying persistence manager,\n-     * we can just call the consumedUntil method there. The messages older than\n-     * the latest one passed here won't be accessed anymore so they should just\n-     * get aged out of the cache eventually. For now, there is no need to\n-     * proactively remove those entries from the cache.\n-     */\n-    @Override\n-    public void consumedUntil(ByteString topic, Long seqId) {\n-        realPersistenceManager.consumedUntil(topic, seqId);\n-    }\n-\n-    @Override\n-    public void setMessageBound(ByteString topic, Integer bound) {\n-        realPersistenceManager.setMessageBound(topic, bound);\n-    }\n-\n-    @Override\n-    public void clearMessageBound(ByteString topic) {\n-        realPersistenceManager.clearMessageBound(topic);\n-    }\n-\n-    @Override\n-    public void consumeToBound(ByteString topic) {\n-        realPersistenceManager.consumeToBound(topic);\n-    }\n-\n-    /**\n-     * Stop the readahead cache.\n-     */\n-    @Override\n-    public void stop() {\n-        try {\n-            keepRunning = false;\n-            cacheWorkers.shutdown();\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to shut down cache workers : \", e);\n-        }\n-    }\n-\n-    /**\n-     * The readahead policy is simple: We check if an entry already exists for\n-     * the message being requested. If an entry exists, it means that either\n-     * that message is already in the cache, or a read for that message is\n-     * outstanding. In that case, we look a little ahead (by readAheadCount/2)\n-     * and issue a range read of readAheadCount/2 messages. The idea is to\n-     * ensure that the next readAheadCount messages are always available.\n-     *\n-     * @return the range scan that should be issued for read ahead\n-     */\n-    protected RangeScanRequest doReadAhead(ScanRequest request) {\n-        ByteString topic = request.getTopic();\n-        Long seqId = request.getStartSeqId();\n-\n-        int readAheadCount = cfg.getReadAheadCount();\n-        // To prevent us from getting screwed by bad configuration\n-        readAheadCount = Math.max(1, readAheadCount);\n-\n-        RangeScanRequest readAheadRequest = doReadAheadStartingFrom(topic, seqId, readAheadCount);\n-\n-        if (readAheadRequest != null) {\n-            return readAheadRequest;\n-        }\n-\n-        // start key was already there in the cache so no readahead happened,\n-        // lets look a little beyond\n-        seqId = realPersistenceManager.getSeqIdAfterSkipping(topic, seqId, readAheadCount / 2);\n-\n-        readAheadRequest = doReadAheadStartingFrom(topic, seqId, readAheadCount / 2);\n-\n-        return readAheadRequest;\n-    }\n-\n-    /**\n-     * This method just checks if the provided seq-id already exists in the\n-     * cache. If not, a range read of the specified amount is issued.\n-     *\n-     * @param topic\n-     * @param seqId\n-     * @param readAheadCount\n-     * @return The range read that should be issued\n-     */\n-    protected RangeScanRequest doReadAheadStartingFrom(ByteString topic, long seqId, int readAheadCount) {\n-\n-        long startSeqId = seqId;\n-        Queue<CacheKey> installedStubs = new LinkedList<CacheKey>();\n-\n-        int i = 0;\n-\n-        for (; i < readAheadCount; i++) {\n-            CacheKey cacheKey = new CacheKey(topic, seqId);\n-\n-            // Even if a stub exists, it means that a scan for that is\n-            // outstanding\n-            if (cache.containsKey(cacheKey)) {\n-                break;\n-            }\n-            CacheValue cacheValue = new CacheValue();\n-            if (null != cache.putIfAbsent(cacheKey, cacheValue)) {\n-                logger.warn(\"It is unexpected that more than one threads are adding message to cache key {}\"\n-                            +\" at the same time.\", cacheKey);\n-            }\n-\n-            logger.debug(\"Adding cache stub for: {}\", cacheKey);\n-            installedStubs.add(cacheKey);\n-\n-            seqId = realPersistenceManager.getSeqIdAfterSkipping(topic, seqId, 1);\n-        }\n-\n-        // so how many did we decide to readahead\n-        if (i == 0) {\n-            // no readahead, hence return false\n-            return null;\n-        }\n-\n-        long readAheadSizeLimit = cfg.getReadAheadSizeBytes();\n-        ReadAheadScanCallback callback = new ReadAheadScanCallback(installedStubs, topic);\n-        RangeScanRequest rangeScanRequest = new RangeScanRequest(topic, startSeqId, i, readAheadSizeLimit, callback,\n-                null);\n-\n-        return rangeScanRequest;\n-\n-    }\n-\n-    /**\n-     * This is the callback that is used for the range scans.\n-     */\n-    protected class ReadAheadScanCallback implements ScanCallback {\n-        Queue<CacheKey> installedStubs;\n-        ByteString topic;\n-\n-        /**\n-         * Constructor\n-         *\n-         * @param installedStubs\n-         *            The list of stubs that were installed for this range scan\n-         * @param topic\n-         */\n-        public ReadAheadScanCallback(Queue<CacheKey> installedStubs, ByteString topic) {\n-            this.installedStubs = installedStubs;\n-            this.topic = topic;\n-        }\n-\n-        @Override\n-        public void messageScanned(Object ctx, Message message) {\n-\n-            // Any message we read is potentially useful for us, so lets first\n-            // enqueue it\n-            CacheKey cacheKey = new CacheKey(topic, message.getMsgId().getLocalComponent());\n-            enqueueWithoutFailureByTopic(topic, new ScanResponse(cacheKey, message));\n-\n-            // Now lets see if this message is the one we were expecting\n-            CacheKey expectedKey = installedStubs.peek();\n-\n-            if (expectedKey == null) {\n-                // Was not expecting any more messages to come in, but they came\n-                // in so we will keep them\n-                return;\n-            }\n-\n-            if (expectedKey.equals(cacheKey)) {\n-                // what we got is what we expected, dequeue it so we get the\n-                // next expected one\n-                installedStubs.poll();\n-                return;\n-            }\n-\n-            // If reached here, what we scanned was not what we were expecting.\n-            // This means that we have wrong stubs installed in the cache. We\n-            // should remove them, so that whoever is waiting on them can retry.\n-            // This shouldn't be happening usually\n-            logger.warn(\"Unexpected message seq-id: \" + message.getMsgId().getLocalComponent() + \" on topic: \"\n-                        + topic.toStringUtf8() + \" from readahead scan, was expecting seq-id: \" + expectedKey.seqId\n-                        + \" topic: \" + expectedKey.topic.toStringUtf8() + \" installedStubs: \" + installedStubs);\n-            enqueueDeleteOfRemainingStubs(noSuchSeqIdExceptionInstance);\n-\n-        }\n-\n-        @Override\n-        public void scanFailed(Object ctx, Exception exception) {\n-            enqueueDeleteOfRemainingStubs(exception);\n-        }\n-\n-        @Override\n-        public void scanFinished(Object ctx, ReasonForFinish reason) {\n-            // If the scan finished because no more messages are present, its ok\n-            // to leave the stubs in place because they will get filled in as\n-            // new publishes happen. However, if the scan finished due to some\n-            // other reason, e.g., read ahead size limit was reached, we want to\n-            // delete the stubs, so that when the time comes, we can schedule\n-            // another readahead request.\n-            if (reason != ReasonForFinish.NO_MORE_MESSAGES) {\n-                enqueueDeleteOfRemainingStubs(readAheadExceptionInstance);\n-            }\n-        }\n-\n-        private void enqueueDeleteOfRemainingStubs(Exception reason) {\n-            CacheKey installedStub;\n-            while ((installedStub = installedStubs.poll()) != null) {\n-                enqueueWithoutFailureByTopic(installedStub.getTopic(),\n-                        new ExceptionOnCacheKey(installedStub, reason));\n-            }\n-        }\n-    }\n-\n-    protected static class HashSetCacheKeyFactory implements Factory<Set<CacheKey>> {\n-        protected final static HashSetCacheKeyFactory instance = new HashSetCacheKeyFactory();\n-\n-        @Override\n-        public Set<CacheKey> newInstance() {\n-            return new HashSet<CacheKey>();\n-        }\n-    }\n-\n-    protected static class TreeSetLongFactory implements Factory<SortedSet<Long>> {\n-        protected final static TreeSetLongFactory instance = new TreeSetLongFactory();\n-\n-        @Override\n-        public SortedSet<Long> newInstance() {\n-            return new TreeSet<Long>();\n-        }\n-    }\n-\n-    /**\n-     * For adding the message to the cache, we do some bookeeping such as the\n-     * total size of cache, order in which entries were added etc. If the size\n-     * of the cache has exceeded our budget, old entries are collected.\n-     *\n-     * @param cacheKey\n-     * @param message\n-     */\n-    protected void addMessageToCache(final CacheKey cacheKey,\n-                                     final Message message, final long currTime) {\n-        logger.debug(\"Adding msg {} to readahead cache\", cacheKey);\n-\n-        CacheValue cacheValue;\n-        if ((cacheValue = cache.get(cacheKey)) == null) {\n-            cacheValue = new CacheValue();\n-            CacheValue oldValue = cache.putIfAbsent(cacheKey, cacheValue);\n-            if (null != oldValue) {\n-                logger.warn(\"Weird! Should not have two threads adding message to cache key {} at the same time.\",\n-                            cacheKey);\n-                cacheValue = oldValue;\n-            }\n-        }\n-\n-        CacheSegment segment = cacheSegment.get();\n-        if (cacheValue.isStub()) { // update cache size only when cache value is a stub\n-            int size = message.getBody().size();\n-\n-            // update the cache size\n-            segment.presentSegmentSize.addAndGet(size);\n-            presentCacheSize.addAndGet(size);\n-        }\n-\n-        synchronized (cacheValue) {\n-            // finally add the message to the cache\n-            cacheValue.setMessageAndInvokeCallbacks(message, currTime);\n-        }\n-\n-        // maintain the index of seq-id\n-        // no lock since threads are partitioned by topics\n-        MapMethods.addToMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n-                                 cacheKey.getSeqId(), TreeSetLongFactory.instance);\n-\n-        // maintain the time index of addition\n-        MapMethods.addToMultiMap(segment.timeIndexOfAddition, currTime,\n-                                 cacheKey, HashSetCacheKeyFactory.instance);\n-\n-        collectOldOrExpiredCacheEntries(segment);\n-    }\n-\n-    protected void removeMessageFromCache(final CacheKey cacheKey, Exception exception,\n-                                          final boolean maintainTimeIndex,\n-                                          final boolean maintainSeqIdIndex) {\n-        CacheValue cacheValue = cache.remove(cacheKey);\n-\n-        if (cacheValue == null) {\n-            return;\n-        }\n-\n-        CacheSegment segment = cacheSegment.get();\n-\n-        long timeOfAddition = 0;\n-        synchronized (cacheValue) {\n-            if (cacheValue.isStub()) {\n-                cacheValue.setErrorAndInvokeCallbacks(exception);\n-                // Stubs are not present in the indexes, so don't need to maintain\n-                // indexes here\n-                return;\n-            }\n-\n-            int size = 0 - cacheValue.getMessage().getBody().size();\n-            presentCacheSize.addAndGet(size);\n-            segment.presentSegmentSize.addAndGet(size);\n-            timeOfAddition = cacheValue.getTimeOfAddition();\n-        }\n-\n-        if (maintainSeqIdIndex) {\n-            MapMethods.removeFromMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n-                                          cacheKey.getSeqId());\n-        }\n-        if (maintainTimeIndex) {\n-            MapMethods.removeFromMultiMap(segment.timeIndexOfAddition,\n-                                          timeOfAddition, cacheKey);\n-        }\n-    }\n-\n-    /**\n-     * Collection of old entries is simple. Just collect in insert-time order,\n-     * oldest to newest.\n-     */\n-    protected void collectOldOrExpiredCacheEntries(CacheSegment segment) {\n-        if (cacheEntryTTL > 0) {\n-            // clear expired entries\n-            while (!segment.timeIndexOfAddition.isEmpty()) {\n-                Long earliestTime = segment.timeIndexOfAddition.firstKey();\n-                if (MathUtils.now() - earliestTime < cacheEntryTTL) {\n-                    break;\n-                }\n-                collectCacheEntriesAtTimestamp(segment, earliestTime);\n-            }\n-        }\n-\n-        while (segment.presentSegmentSize.get() > maxSegmentSize &&\n-               !segment.timeIndexOfAddition.isEmpty()) {\n-            Long earliestTime = segment.timeIndexOfAddition.firstKey();\n-            collectCacheEntriesAtTimestamp(segment, earliestTime);\n-        }\n-    }\n-\n-    private void collectCacheEntriesAtTimestamp(CacheSegment segment, long timestamp) {\n-        Set<CacheKey> oldCacheEntries = segment.timeIndexOfAddition.get(timestamp);\n-\n-        // Note: only concrete cache entries, and not stubs are in the time\n-        // index. Hence there can be no callbacks pending on these cache\n-        // entries. Hence safe to remove them directly.\n-        for (Iterator<CacheKey> iter = oldCacheEntries.iterator(); iter.hasNext();) {\n-            final CacheKey cacheKey = iter.next();\n-\n-            logger.debug(\"Removing {} from cache because it's the oldest.\", cacheKey);\n-            removeMessageFromCache(cacheKey, readAheadExceptionInstance, //\n-                                   // maintainTimeIndex=\n-                                   false,\n-                                   // maintainSeqIdIndex=\n-                                   true);\n-        }\n-\n-        segment.timeIndexOfAddition.remove(timestamp);\n-    }\n-\n-    /**\n-     * ========================================================================\n-     * The rest is just simple wrapper classes.\n-     *\n-     */\n-\n-    protected class ExceptionOnCacheKey implements CacheRequest {\n-        CacheKey cacheKey;\n-        Exception exception;\n-\n-        public ExceptionOnCacheKey(CacheKey cacheKey, Exception exception) {\n-            this.cacheKey = cacheKey;\n-            this.exception = exception;\n-        }\n-\n-        /**\n-         * If for some reason, an outstanding read on a cache stub fails,\n-         * exception for that key is enqueued by the\n-         * {@link ReadAheadScanCallback}. To handle this, we simply send error\n-         * on the callbacks registered for that stub, and delete the entry from\n-         * the cache\n-         */\n-        @Override\n-        public void performRequest() {\n-            removeMessageFromCache(cacheKey, exception,\n-                                   // maintainTimeIndex=\n-                                   true,\n-                                   // maintainSeqIdIndex=\n-                                   true);\n-        }\n-\n-    }\n-\n-    @SuppressWarnings(\"serial\")\n-    protected static class NoSuchSeqIdException extends Exception {\n-\n-        public NoSuchSeqIdException() {\n-            super(\"No such seq-id\");\n-        }\n-    }\n-\n-    @SuppressWarnings(\"serial\")\n-    protected static class ReadAheadException extends Exception {\n-        public ReadAheadException() {\n-            super(\"Readahead failed\");\n-        }\n-    }\n-\n-    public class CancelScanRequestOp implements CacheRequest {\n-\n-        final CancelScanRequest request;\n-\n-        public CancelScanRequestOp(CancelScanRequest request) {\n-            this.request = request;\n-        }\n-\n-        @Override\n-        public void performRequest() {\n-            // cancel scan request\n-            cancelScanRequest(request.getScanRequest());\n-        }\n-\n-        void cancelScanRequest(ScanRequest request) {\n-            if (null == request) {\n-                // nothing to cancel\n-                return;\n-            }\n-\n-            CacheKey cacheKey = new CacheKey(request.getTopic(), request.getStartSeqId());\n-            CacheValue cacheValue = cache.get(cacheKey);\n-            if (null == cacheValue) {\n-                // cache value is evicted\n-                // so it's callback would be called, we don't need to worry about\n-                // cancel it. since it was treated as executed.\n-                return;\n-            }\n-            cacheValue.removeCallback(request.getCallback(), request.getCtx());\n-        }\n-    }\n-\n-    public void cancelScanRequest(ByteString topic, CancelScanRequest request) {\n-        enqueueWithoutFailureByTopic(topic, new CancelScanRequestOp(request));\n-    }\n-\n-    protected class ScanResponse implements CacheRequest {\n-        CacheKey cacheKey;\n-        Message message;\n-\n-        public ScanResponse(CacheKey cacheKey, Message message) {\n-            this.cacheKey = cacheKey;\n-            this.message = message;\n-        }\n-\n-        @Override\n-        public void performRequest() {\n-            addMessageToCache(cacheKey, message, MathUtils.now());\n-        }\n-\n-    }\n-\n-    protected class DeliveredUntil implements CacheRequest {\n-        ByteString topic;\n-        Long seqId;\n-\n-        public DeliveredUntil(ByteString topic, Long seqId) {\n-            this.topic = topic;\n-            this.seqId = seqId;\n-        }\n-\n-        @Override\n-        public void performRequest() {\n-            SortedSet<Long> orderedSeqIds = orderedIndexOnSeqId.get(topic);\n-            if (orderedSeqIds == null) {\n-                return;\n-            }\n-\n-            // focus on the set of messages with seq-ids <= the one that\n-            // has been delivered until\n-            SortedSet<Long> headSet = orderedSeqIds.headSet(seqId + 1);\n-\n-            for (Iterator<Long> iter = headSet.iterator(); iter.hasNext();) {\n-                Long seqId = iter.next();\n-                CacheKey cacheKey = new CacheKey(topic, seqId);\n-\n-                logger.debug(\"Removing {} from cache because every subscriber has moved past\",\n-                    cacheKey);\n-\n-                removeMessageFromCache(cacheKey, readAheadExceptionInstance, //\n-                                       // maintainTimeIndex=\n-                                       true,\n-                                       // maintainSeqIdIndex=\n-                                       false);\n-                iter.remove();\n-            }\n-\n-            if (orderedSeqIds.isEmpty()) {\n-                orderedIndexOnSeqId.remove(topic);\n-            }\n-        }\n-    }\n-\n-    protected class ScanRequestWrapper implements CacheRequest {\n-        ScanRequest request;\n-\n-        public ScanRequestWrapper(ScanRequest request) {\n-            this.request = request;\n-        }\n-\n-        /**\n-         * To handle a scan request, we first try to do readahead (which might\n-         * cause a range read to be issued to the underlying persistence\n-         * manager). The readahead will put a stub in the cache, if the message\n-         * is not already present in the cache. The scan callback that is part\n-         * of the scan request is added to this stub, and will be called later\n-         * when the message arrives as a result of the range scan issued to the\n-         * underlying persistence manager.\n-         */\n-\n-        @Override\n-        public void performRequest() {\n-\n-            RangeScanRequest readAheadRequest = doReadAhead(request);\n-\n-            // Read ahead must have installed at least a stub for us, so this\n-            // can't be null\n-            CacheKey cacheKey = new CacheKey(request.getTopic(), request.getStartSeqId());\n-            CacheValue cacheValue = cache.get(cacheKey);\n-            if (null == cacheValue) {\n-                logger.error(\"Cache key {} is removed after installing stub when scanning.\", cacheKey);\n-                // reissue the request\n-                scanSingleMessage(request);\n-                return;\n-            }\n-\n-            synchronized (cacheValue) {\n-                // Add our callback to the stub. If the cache value was already a\n-                // concrete message, the callback will be called right away\n-                cacheValue.addCallback(request.getCallback(), request.getCtx());\n-            }\n-\n-            if (readAheadRequest != null) {\n-                realPersistenceManager.scanMessages(readAheadRequest);\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void registerJMX(HedwigMBeanInfo parent) {\n-        try {\n-            jmxCacheBean = new ReadAheadCacheBean(this);\n-            HedwigMBeanRegistry.getInstance().register(jmxCacheBean, parent);\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to register readahead cache with JMX\", e);\n-            jmxCacheBean = null;\n-        }\n-    }\n-\n-    @Override\n-    public void unregisterJMX() {\n-        try {\n-            if (jmxCacheBean != null) {\n-                HedwigMBeanRegistry.getInstance().unregister(jmxCacheBean);\n-            }\n-        } catch (Exception e) {\n-            logger.warn(\"Failed to unregister readahead cache with JMX\", e);\n-        }\n-    }\n-}"},{"sha":"1f43095e62b70872f006ddffd001dc25520159b1","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","status":"removed","additions":0,"deletions":64,"changes":64,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,64 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.persistence;\n-\n-import org.apache.hedwig.server.jmx.HedwigMBeanInfo;\n-\n-/**\n- * Read Ahead Cache Bean\n- */\n-public class ReadAheadCacheBean implements ReadAheadCacheMXBean,\n-        HedwigMBeanInfo {\n-\n-    ReadAheadCache cache;\n-    public ReadAheadCacheBean(ReadAheadCache cache) {\n-        this.cache = cache;\n-    }\n-\n-    @Override\n-    public String getName() {\n-        return \"ReadAheadCache\";\n-    }\n-\n-    @Override\n-    public boolean isHidden() {\n-        return false;\n-    }\n-\n-    @Override\n-    public long getMaxCacheSize() {\n-        return cache.cfg.getMaximumCacheSize();\n-    }\n-\n-    @Override\n-    public long getPresentCacheSize() {\n-        return cache.presentCacheSize.get();\n-    }\n-\n-    @Override\n-    public int getNumCachedEntries() {\n-        return cache.cache.size();\n-    }\n-\n-    @Override\n-    public int getNumPendingCacheRequests() {\n-        return cache.numPendingRequests.get();\n-    }\n-\n-}"},{"sha":"eba77a074d349e27b186e47c6c0edc925980ecf4","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheMXBean.java","status":"removed","additions":0,"deletions":45,"changes":45,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheMXBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheMXBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheMXBean.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,45 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-\n-package org.apache.hedwig.server.persistence;\n-\n-/**\n- * Read Ahead Cache MBean\n- */\n-public interface ReadAheadCacheMXBean {\n-\n-    /**\n-     * @return max cache size\n-     */\n-    public long getMaxCacheSize();\n-\n-    /**\n-     * @return present cache size\n-     */\n-    public long getPresentCacheSize();\n-\n-    /**\n-     * @return number of cached entries\n-     */\n-    public int getNumCachedEntries();\n-\n-    /**\n-     * @return number of pending cache requests\n-     */\n-    public int getNumPendingCacheRequests();\n-}"},{"sha":"42ebb93394b251258b23ea2eecd712b82279c44f","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallback.java","status":"removed","additions":0,"deletions":63,"changes":63,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,63 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-\n-public interface ScanCallback {\n-\n-    enum ReasonForFinish {\n-        NO_MORE_MESSAGES, SIZE_LIMIT_EXCEEDED, NUM_MESSAGES_LIMIT_EXCEEDED\n-    };\n-\n-    /**\n-     * This method is called when a message is read from the persistence layer\n-     * as part of a scan. The message just read is handed to this listener which\n-     * can then take the desired action on it. The return value from the method\n-     * indicates whether the scan should continue or not.\n-     *\n-     * @param ctx\n-     *            The context for the callback\n-     * @param message\n-     *            The message just scanned from the log\n-     * @return true if the scan should continue, false otherwise\n-     */\n-    public void messageScanned(Object ctx, Message message);\n-\n-    /**\n-     * This method is called when the scan finishes\n-     *\n-     *\n-     * @param ctx\n-     * @param reason\n-     */\n-\n-    public abstract void scanFinished(Object ctx, ReasonForFinish reason);\n-\n-    /**\n-     * This method is called when the operation failed due to some reason. The\n-     * reason for failure is passed in.\n-     *\n-     * @param ctx\n-     *            The context for the callback\n-     * @param exception\n-     *            The reason for the failure of the scan\n-     */\n-    public abstract void scanFailed(Object ctx, Exception exception);\n-\n-}"},{"sha":"a39a1974d9a97417faea79e91c22ff76bbe20940","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallbackWithContext.java","status":"removed","additions":0,"deletions":54,"changes":54,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallbackWithContext.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallbackWithContext.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanCallbackWithContext.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,54 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-public class ScanCallbackWithContext {\n-    ScanCallback scanCallback;\n-    Object ctx;\n-\n-    public ScanCallbackWithContext(ScanCallback callback, Object ctx) {\n-        this.scanCallback = callback;\n-        this.ctx = ctx;\n-    }\n-\n-    public ScanCallback getScanCallback() {\n-        return scanCallback;\n-    }\n-\n-    public Object getCtx() {\n-        return ctx;\n-    }\n-\n-    @Override\n-    public boolean equals(Object other) {\n-        if (!(other instanceof ScanCallbackWithContext)) {\n-            return false;\n-        }\n-        ScanCallbackWithContext otherCb =\n-            (ScanCallbackWithContext) other;\n-        // Ensure that it was same callback & same ctx\n-        return scanCallback == otherCb.scanCallback &&\n-               ctx == otherCb.ctx;\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return scanCallback.hashCode();\n-    }\n-\n-}"},{"sha":"c985840316db631aeeaa3b8bd0e1cfcbd64360da","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanRequest.java","status":"removed","additions":0,"deletions":64,"changes":64,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanRequest.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanRequest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ScanRequest.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,64 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.persistence;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-\n-/**\n- * Encapsulates a request for reading a single message. The message on the given\n- * topic <b>at</b> the given seqId is scanned. A call-back {@link ScanCallback}\n- * is provided. When the message is scanned, the\n- * {@link ScanCallback#messageScanned(Object, Message)} method is called. Since\n- * there is only 1 record to be scanned the\n- * {@link ScanCallback#operationFinished(Object)} method may not be called since\n- * its redundant.\n- * {@link ScanCallback#scanFailed(Object, org.apache.hedwig.exceptions.PubSubException)}\n- * method is called in case of error.\n- *\n- */\n-public class ScanRequest {\n-    ByteString topic;\n-    long startSeqId;\n-    ScanCallback callback;\n-    Object ctx;\n-\n-    public ScanRequest(ByteString topic, long startSeqId, ScanCallback callback, Object ctx) {\n-        this.topic = topic;\n-        this.startSeqId = startSeqId;\n-        this.callback = callback;\n-        this.ctx = ctx;\n-    }\n-\n-    public ByteString getTopic() {\n-        return topic;\n-    }\n-\n-    public long getStartSeqId() {\n-        return startSeqId;\n-    }\n-\n-    public ScanCallback getCallback() {\n-        return callback;\n-    }\n-\n-    public Object getCtx() {\n-        return ctx;\n-    }\n-\n-}"},{"sha":"10f08890bb7a25d264aa1265169cd2688ca8192b","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ChannelTracker.java","status":"removed","additions":0,"deletions":132,"changes":132,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ChannelTracker.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ChannelTracker.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ChannelTracker.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,132 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.TopicBusyException;\n-import org.apache.hedwig.server.handlers.ChannelDisconnectListener;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ChannelTracker implements ChannelDisconnectListener {\n-    HashMap<TopicSubscriber, Channel> topicSub2Channel = new HashMap<TopicSubscriber, Channel>();\n-    HashMap<Channel, List<TopicSubscriber>> channel2TopicSubs = new HashMap<Channel, List<TopicSubscriber>>();\n-    Subscriber subscriber;\n-\n-    public ChannelTracker(Subscriber subscriber) {\n-        this.subscriber = subscriber;\n-    }\n-\n-    static Callback<Void> noOpCallback = new Callback<Void>() {\n-        public void operationFailed(Object ctx, PubSubException exception) {\n-        };\n-\n-        public void operationFinished(Object ctx, Void resultOfOperation) {\n-        };\n-    };\n-\n-    public synchronized void channelDisconnected(Channel channel) {\n-        List<TopicSubscriber> topicSubs = channel2TopicSubs.remove(channel);\n-\n-        if (topicSubs == null) {\n-            return;\n-        }\n-\n-        for (TopicSubscriber topicSub : topicSubs) {\n-            topicSub2Channel.remove(topicSub);\n-            subscriber.asyncCloseSubscription(topicSub.getTopic(), topicSub.getSubscriberId(), noOpCallback, null);\n-        }\n-    }\n-\n-    public synchronized void subscribeSucceeded(TopicSubscriber topicSubscriber, Channel channel)\n-            throws TopicBusyException {\n-\n-        if (!channel.isConnected()) {\n-            // channel got disconnected while we were processing the\n-            // subscribe request, nothing much we can do in this case\n-            return;\n-        }\n-\n-        if (topicSub2Channel.containsKey(topicSubscriber)) {\n-            TopicBusyException pse = new PubSubException.TopicBusyException(\n-                \"subscription for this topic, subscriberId is already being served on a different channel\");\n-            throw pse;\n-        }\n-\n-        topicSub2Channel.put(topicSubscriber, channel);\n-\n-        List<TopicSubscriber> topicSubs = channel2TopicSubs.get(channel);\n-\n-        if (topicSubs == null) {\n-            topicSubs = new LinkedList<TopicSubscriber>();\n-            channel2TopicSubs.put(channel, topicSubs);\n-        }\n-        topicSubs.add(topicSubscriber);\n-\n-    }\n-\n-    public void aboutToCloseSubscription(ByteString topic, ByteString subscriberId) {\n-        removeSubscriber(topic, subscriberId);\n-    } \n-\n-    public void aboutToUnsubscribe(ByteString topic, ByteString subscriberId) {\n-        removeSubscriber(topic, subscriberId);\n-    }\n-\n-    private synchronized void removeSubscriber(ByteString topic, ByteString subscriberId) {\n-        TopicSubscriber topicSub = new TopicSubscriber(topic, subscriberId);\n-\n-        Channel channel = topicSub2Channel.remove(topicSub);\n-\n-        if (channel != null) {\n-            List<TopicSubscriber> topicSubs = channel2TopicSubs.get(channel);\n-            if (topicSubs != null) {\n-                topicSubs.remove(topicSub);\n-            }\n-        }\n-    }\n-\n-    public synchronized void checkChannelMatches(ByteString topic, ByteString subscriberId, Channel channel)\n-            throws PubSubException {\n-        Channel subscribedChannel = getChannel(topic, subscriberId);\n-\n-        if (subscribedChannel == null) {\n-            throw new PubSubException.ClientNotSubscribedException(\n-                \"Can't start delivery since client is not subscribed\");\n-        }\n-\n-        if (subscribedChannel != channel) {\n-            throw new PubSubException.TopicBusyException(\n-                \"Can't start delivery since client is subscribed on a different channel\");\n-        }\n-\n-    }\n-\n-    public synchronized Channel getChannel(ByteString topic, ByteString subscriberId) {\n-        return topicSub2Channel.get(new TopicSubscriber(topic, subscriberId));\n-    }\n-\n-}"},{"sha":"45272e2297f7e6e73f501a15ac97d91ca54bd6a6","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/HedwigProxy.java","status":"removed","additions":0,"deletions":182,"changes":182,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/HedwigProxy.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/HedwigProxy.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/HedwigProxy.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,182 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import java.io.File;\n-import java.lang.Thread.UncaughtExceptionHandler;\n-import java.net.InetSocketAddress;\n-import java.net.MalformedURLException;\n-import java.util.HashMap;\n-import java.util.Map;\n-import java.util.concurrent.Executors;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.bootstrap.ServerBootstrap;\n-import org.jboss.netty.channel.group.ChannelGroup;\n-import org.jboss.netty.channel.group.DefaultChannelGroup;\n-import org.jboss.netty.channel.socket.ServerSocketChannelFactory;\n-import org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory;\n-import org.jboss.netty.logging.InternalLoggerFactory;\n-import org.jboss.netty.logging.Log4JLoggerFactory;\n-\n-import org.apache.hedwig.client.HedwigClient;\n-import org.apache.hedwig.protocol.PubSubProtocol.OperationType;\n-import org.apache.hedwig.server.common.TerminateJVMExceptionHandler;\n-import org.apache.hedwig.server.handlers.ChannelDisconnectListener;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.PubSubServer;\n-import org.apache.hedwig.server.netty.PubSubServerPipelineFactory;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-\n-import com.google.common.util.concurrent.ThreadFactoryBuilder;\n-\n-public class HedwigProxy {\n-    private static final Logger logger = LoggerFactory.getLogger(HedwigProxy.class);\n-\n-    HedwigClient client;\n-    ServerSocketChannelFactory serverSocketChannelFactory;\n-    ChannelGroup allChannels;\n-    Map<OperationType, Handler> handlers;\n-    ProxyConfiguration cfg;\n-    ChannelTracker tracker;\n-    ThreadGroup tg;\n-\n-    public HedwigProxy(final ProxyConfiguration cfg, final UncaughtExceptionHandler exceptionHandler) {\n-        this.cfg = cfg;\n-\n-        tg = new ThreadGroup(\"hedwigproxy\") {\n-            @Override\n-            public void uncaughtException(Thread t, Throwable e) {\n-                exceptionHandler.uncaughtException(t, e);\n-            }\n-        };\n-    }\n-\n-    public HedwigProxy(ProxyConfiguration conf) throws InterruptedException {\n-        this(conf, new TerminateJVMExceptionHandler());\n-    }\n-\n-    public void start() throws InterruptedException {\n-        final LinkedBlockingQueue<Boolean> queue = new LinkedBlockingQueue<Boolean>();\n-\n-        new Thread(tg, new Runnable() {\n-            @Override\n-            public void run() {\n-                client = new HedwigClient(cfg);\n-                ThreadFactoryBuilder tfb = new ThreadFactoryBuilder();\n-                serverSocketChannelFactory = new NioServerSocketChannelFactory(\n-                        Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                \"HedwigProxy-NIOBoss-%d\").build()),\n-                        Executors.newCachedThreadPool(tfb.setNameFormat(\n-                                \"HedwigProxy-NIOWorker-%d\").build()));\n-                initializeHandlers();\n-                initializeNetty();\n-\n-                queue.offer(true);\n-            }\n-        }).start();\n-\n-        queue.take();\n-    }\n-\n-    // used for testing\n-    public ChannelTracker getChannelTracker() {\n-        return tracker;\n-    }\n-\n-    protected void initializeHandlers() {\n-        handlers = new HashMap<OperationType, Handler>();\n-        tracker = new ChannelTracker(client.getSubscriber());\n-\n-        handlers.put(OperationType.PUBLISH, new ProxyPublishHander(client.getPublisher()));\n-        handlers.put(OperationType.SUBSCRIBE, new ProxySubscribeHandler(client.getSubscriber(), tracker));\n-        handlers.put(OperationType.UNSUBSCRIBE, new ProxyUnsubscribeHandler(client.getSubscriber(), tracker));\n-        handlers.put(OperationType.CONSUME, new ProxyConsumeHandler(client.getSubscriber()));\n-        handlers.put(OperationType.STOP_DELIVERY, new ProxyStopDeliveryHandler(client.getSubscriber(), tracker));\n-        handlers.put(OperationType.START_DELIVERY, new ProxyStartDeliveryHandler(client.getSubscriber(), tracker));\n-        handlers.put(OperationType.CLOSESUBSCRIPTION,\n-                     new ProxyCloseSubscriptionHandler(client.getSubscriber(), tracker));\n-    }\n-\n-    protected void initializeNetty() {\n-        InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory());\n-        allChannels = new DefaultChannelGroup(\"hedwigproxy\");\n-        ServerBootstrap bootstrap = new ServerBootstrap(serverSocketChannelFactory);\n-        ChannelDisconnectListener disconnectListener =\n-            (ChannelDisconnectListener) handlers.get(OperationType.SUBSCRIBE);\n-        UmbrellaHandler umbrellaHandler =\n-            new UmbrellaHandler(allChannels, handlers, disconnectListener, false);\n-        PubSubServerPipelineFactory pipeline = new PubSubServerPipelineFactory(umbrellaHandler, null, cfg\n-                .getMaximumMessageSize());\n-\n-        bootstrap.setPipelineFactory(pipeline);\n-        bootstrap.setOption(\"child.tcpNoDelay\", true);\n-        bootstrap.setOption(\"child.keepAlive\", true);\n-        bootstrap.setOption(\"reuseAddress\", true);\n-\n-        // Bind and start to accept incoming connections.\n-        allChannels.add(bootstrap.bind(new InetSocketAddress(cfg.getProxyPort())));\n-        logger.info(\"Going into receive loop\");\n-    }\n-\n-    public void shutdown() {\n-        allChannels.close().awaitUninterruptibly();\n-        client.close();\n-        serverSocketChannelFactory.releaseExternalResources();\n-    }\n-\n-    // the following method only exists for unit-testing purposes, should go\n-    // away once we make start delivery totally server-side\n-    public Handler getStartDeliveryHandler() {\n-        return handlers.get(OperationType.START_DELIVERY);\n-    }\n-\n-    public Handler getStopDeliveryHandler() {\n-        return handlers.get(OperationType.STOP_DELIVERY);\n-    }\n-\n-    /**\n-     * @param args\n-     */\n-    public static void main(String[] args) {\n-\n-        logger.info(\"Attempting to start Hedwig Proxy\");\n-        ProxyConfiguration conf = new ProxyConfiguration();\n-        if (args.length > 0) {\n-            String confFile = args[0];\n-            try {\n-                conf.loadConf(new File(confFile).toURI().toURL());\n-            } catch (MalformedURLException e) {\n-                String msg = \"Could not open configuration file: \" + confFile;\n-                PubSubServer.errorMsgAndExit(msg, e, PubSubServer.RC_INVALID_CONF_FILE);\n-            } catch (ConfigurationException e) {\n-                String msg = \"Malformed configuration file: \" + confFile;\n-                PubSubServer.errorMsgAndExit(msg, e, PubSubServer.RC_MISCONFIGURED);\n-            }\n-            logger.info(\"Using configuration file \" + confFile);\n-        }\n-        try {\n-            new HedwigProxy(conf).start();\n-        } catch (Throwable t) {\n-            PubSubServer.errorMsgAndExit(\"Error during startup\", t, PubSubServer.RC_OTHER);\n-        }\n-    }\n-\n-}"},{"sha":"13d3993b68d5998a66b737d4e47afc735c7e6201","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyCloseSubscriptionHandler.java","status":"removed","additions":0,"deletions":70,"changes":70,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyCloseSubscriptionHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyCloseSubscriptionHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyCloseSubscriptionHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,70 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ProxyCloseSubscriptionHandler implements Handler {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ProxyCloseSubscriptionHandler.class);\n-\n-    Subscriber subscriber;\n-    ChannelTracker tracker;\n-\n-    public ProxyCloseSubscriptionHandler(Subscriber subscriber, ChannelTracker tracker) {\n-        this.subscriber = subscriber;\n-        this.tracker = tracker;\n-    }\n-\n-    @Override\n-    public void handleRequest(final PubSubRequest request, final Channel channel) {\n-\n-        if (!request.hasCloseSubscriptionRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing close subscription request data\");\n-            return;\n-        }\n-\n-        final ByteString topic = request.getTopic();\n-        final ByteString subscriberId = request.getCloseSubscriptionRequest().getSubscriberId();\n-\n-        subscriber.asyncCloseSubscription(topic, subscriberId, new Callback<Void>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void result) {\n-                tracker.aboutToCloseSubscription(topic, subscriberId);         \n-                channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-            }\n-        }, null);\n-    }\n-}"},{"sha":"051a7829022cfc2c78628cb1731e935f3371252e","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConfiguration.java","status":"removed","additions":0,"deletions":36,"changes":36,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConfiguration.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,36 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.apache.hedwig.client.conf.ClientConfiguration;\n-\n-public class ProxyConfiguration extends ClientConfiguration {\n-\n-    protected final static String PROXY_PORT = \"proxy_port\";\n-    protected final static String MAX_MESSAGE_SIZE = \"max_message_size\";\n-\n-    public int getProxyPort() {\n-        return conf.getInt(PROXY_PORT, 9099);\n-    }\n-\n-    @Override\n-    public int getMaximumMessageSize() {\n-        return conf.getInt(MAX_MESSAGE_SIZE, 1258291); /* 1.2M */\n-    }\n-\n-}"},{"sha":"c37ac4829e12dc589fadfa0fb946c96e5341498d","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConsumeHandler.java","status":"removed","additions":0,"deletions":58,"changes":58,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConsumeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConsumeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyConsumeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,58 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.exceptions.PubSubException.ClientNotSubscribedException;\n-import org.apache.hedwig.protocol.PubSubProtocol.ConsumeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-\n-public class ProxyConsumeHandler implements Handler {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ProxyConsumeHandler.class);\n-\n-    Subscriber subscriber;\n-\n-    public ProxyConsumeHandler(Subscriber subscriber) {\n-        this.subscriber = subscriber;\n-    }\n-\n-    @Override\n-    public void handleRequest(PubSubRequest request, Channel channel) {\n-        if (!request.hasConsumeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing consume request data\");\n-            return;\n-        }\n-\n-        ConsumeRequest consumeRequest = request.getConsumeRequest();\n-        try {\n-            subscriber.consume(request.getTopic(), consumeRequest.getSubscriberId(), consumeRequest.getMsgId());\n-        } catch (ClientNotSubscribedException e) {\n-            // ignore\n-            logger.warn(\"Unexpected consume request\", e);\n-        }\n-\n-    }\n-}"},{"sha":"7ffdb92492be9d112a7081ddae6cf21a8ba280bb","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyPublishHander.java","status":"removed","additions":0,"deletions":62,"changes":62,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyPublishHander.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyPublishHander.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyPublishHander.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,62 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import org.apache.hedwig.client.api.Publisher;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.PublishRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ProxyPublishHander implements Handler {\n-    Publisher publisher;\n-\n-    public ProxyPublishHander(Publisher publisher) {\n-        this.publisher = publisher;\n-    }\n-\n-    @Override\n-    public void handleRequest(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasPublishRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing publish request data\");\n-            return;\n-        }\n-\n-        final PublishRequest publishRequest = request.getPublishRequest();\n-\n-        publisher.asyncPublish(request.getTopic(), publishRequest.getMsg(), new Callback<Void>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-            }\n-        }, null);\n-\n-    }\n-\n-}"},{"sha":"d1cbb6b72076bcf77f507c6d99e04127518a205b","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStartDeliveryHandler.java","status":"removed","additions":0,"deletions":132,"changes":132,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStartDeliveryHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStartDeliveryHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStartDeliveryHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,132 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-import org.jboss.netty.channel.ChannelFuture;\n-import org.jboss.netty.channel.ChannelFutureListener;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.MessageHandler;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.client.exceptions.AlreadyStartDeliveryException;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ClientNotSubscribedException;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.ProtocolVersion;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubResponse;\n-import org.apache.hedwig.protocol.PubSubProtocol.StatusCode;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ProxyStartDeliveryHandler implements Handler {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ProxyStartDeliveryHandler.class);\n-\n-    Subscriber subscriber;\n-    ChannelTracker tracker;\n-\n-    public ProxyStartDeliveryHandler(Subscriber subscriber, ChannelTracker tracker) {\n-        this.subscriber = subscriber;\n-        this.tracker = tracker;\n-    }\n-\n-    @Override\n-    public void handleRequest(PubSubRequest request, Channel channel) {\n-\n-        if (!request.hasStartDeliveryRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing start delivery request data\");\n-            return;\n-        }\n-\n-        final ByteString topic = request.getTopic();\n-        final ByteString subscriberId = request.getStartDeliveryRequest().getSubscriberId();\n-\n-        synchronized (tracker) {\n-            // try {\n-            // tracker.checkChannelMatches(topic, subscriberId, channel);\n-            // } catch (PubSubException e) {\n-            // channel.write(PubSubResponseUtils.getResponseForException(e,\n-            // request.getTxnId()));\n-            // return;\n-            // }\n-\n-            final Channel subscribedChannel = tracker.getChannel(topic, subscriberId);\n-\n-            if (subscribedChannel == null) {\n-                channel.write(PubSubResponseUtils.getResponseForException(\n-                                  new PubSubException.ClientNotSubscribedException(\"no subscription to start delivery on\"),\n-                                  request.getTxnId()));\n-                return;\n-            }\n-\n-            MessageHandler handler = new MessageHandler() {\n-                @Override\n-                public void deliver(ByteString topic, ByteString subscriberId, Message msg,\n-                final Callback<Void> callback, final Object context) {\n-\n-                    PubSubResponse response = PubSubResponse.newBuilder().setProtocolVersion(\n-                                                  ProtocolVersion.VERSION_ONE).setStatusCode(StatusCode.SUCCESS).setTxnId(0).setMessage(msg)\n-                                              .setTopic(topic).setSubscriberId(subscriberId).build();\n-\n-                    ChannelFuture future = subscribedChannel.write(response);\n-\n-                    future.addListener(new ChannelFutureListener() {\n-                        @Override\n-                        public void operationComplete(ChannelFuture future) throws Exception {\n-                            if (!future.isSuccess()) {\n-                                // ignoring this failure, because this will\n-                                // only happen due to channel disconnect.\n-                                // Channel disconnect will in turn stop\n-                                // delivery, and stop these errors\n-                                return;\n-                            }\n-\n-                            // Tell the hedwig client, that it can send me\n-                            // more messages\n-                            callback.operationFinished(context, null);\n-                        }\n-                    });\n-                }\n-            };\n-\n-            channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-\n-            try {\n-                subscriber.startDelivery(topic, subscriberId, handler);\n-            } catch (ClientNotSubscribedException e) {\n-                // This should not happen, since we already checked the correct\n-                // channel and so on\n-                logger.error(\"Unexpected: No subscription when attempting to start delivery\", e);\n-                throw new RuntimeException(e);\n-            } catch (AlreadyStartDeliveryException e) {\n-                logger.error(\"Unexpected: Already start delivery when attempting to start delivery\", e);\n-                throw new RuntimeException(e);\n-            }\n-\n-        }\n-\n-    }\n-\n-}"},{"sha":"f66f9f1ef1a3ecddd94326320a7d081cab20eff1","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStopDeliveryHandler.java","status":"removed","additions":0,"deletions":74,"changes":74,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStopDeliveryHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStopDeliveryHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyStopDeliveryHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,74 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.ClientNotSubscribedException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-\n-public class ProxyStopDeliveryHandler implements Handler {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ProxyStopDeliveryHandler.class);\n-\n-    Subscriber subscriber;\n-    ChannelTracker tracker;\n-\n-    public ProxyStopDeliveryHandler(Subscriber subscriber, ChannelTracker tracker) {\n-        this.subscriber = subscriber;\n-        this.tracker = tracker;\n-    }\n-\n-    @Override\n-    public void handleRequest(PubSubRequest request, Channel channel) {\n-        if (!request.hasStopDeliveryRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing stop delivery request data\");\n-            return;\n-        }\n-\n-        final ByteString topic = request.getTopic();\n-        final ByteString subscriberId = request.getStopDeliveryRequest().getSubscriberId();\n-\n-        synchronized (tracker) {\n-            try {\n-                tracker.checkChannelMatches(topic, subscriberId, channel);\n-            } catch (PubSubException e) {\n-                // intentionally ignore this error, since stop delivery doesn't\n-                // send back a response\n-                return;\n-            }\n-\n-            try {\n-                subscriber.stopDelivery(topic, subscriberId);\n-            } catch (ClientNotSubscribedException e) {\n-                // This should not happen, since we already checked the correct\n-                // channel and so on\n-                logger.warn(\"Unexpected: No subscription when attempting to stop delivery\", e);\n-            }\n-        }\n-\n-    }\n-}"},{"sha":"a291dad770ae54add12208d5f55f7669ee660935","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxySubscribeHandler.java","status":"removed","additions":0,"deletions":86,"changes":86,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxySubscribeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxySubscribeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxySubscribeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,86 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.jboss.netty.channel.Channel;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.client.data.TopicSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.exceptions.PubSubException.TopicBusyException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionOptions;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.ChannelDisconnectListener;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ProxySubscribeHandler implements Handler, ChannelDisconnectListener {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(ProxySubscribeHandler.class);\n-\n-    Subscriber subscriber;\n-    ChannelTracker tracker;\n-\n-    public ProxySubscribeHandler(Subscriber subscriber, ChannelTracker tracker) {\n-        this.subscriber = subscriber;\n-        this.tracker = tracker;\n-    }\n-\n-    @Override\n-    public void channelDisconnected(Channel channel) {\n-        tracker.channelDisconnected(channel);\n-    }\n-\n-    @Override\n-    public void handleRequest(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasSubscribeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing subscribe request data\");\n-            return;\n-        }\n-\n-        SubscribeRequest subRequest = request.getSubscribeRequest();\n-        final TopicSubscriber topicSubscriber = new TopicSubscriber(request.getTopic(), subRequest.getSubscriberId());\n-        SubscriptionOptions opts = SubscriptionOptions.newBuilder()\n-            .setCreateOrAttach(subRequest.getCreateOrAttach()).build();\n-\n-        subscriber.asyncSubscribe(topicSubscriber.getTopic(), subRequest.getSubscriberId(),\n-                                  opts, new Callback<Void>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                try {\n-                    tracker.subscribeSucceeded(topicSubscriber, channel);\n-                } catch (TopicBusyException e) {\n-                    channel.write(PubSubResponseUtils.getResponseForException(e, request.getTxnId()));\n-                    return;\n-                }\n-                channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-            }\n-        }, null);\n-    }\n-\n-}"},{"sha":"f6119056d871aa515e6e17755b15068014c34134","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyUnsubscribeHandler.java","status":"removed","additions":0,"deletions":74,"changes":74,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyUnsubscribeHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyUnsubscribeHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/proxy/ProxyUnsubscribeHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,74 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.proxy;\n-\n-import org.jboss.netty.channel.Channel;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.Subscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.PubSubRequest;\n-import org.apache.hedwig.protoextensions.PubSubResponseUtils;\n-import org.apache.hedwig.server.handlers.Handler;\n-import org.apache.hedwig.server.netty.UmbrellaHandler;\n-import org.apache.hedwig.util.Callback;\n-\n-public class ProxyUnsubscribeHandler implements Handler {\n-\n-    Subscriber subscriber;\n-    ChannelTracker tracker;\n-\n-    public ProxyUnsubscribeHandler(Subscriber subscriber, ChannelTracker tracker) {\n-        this.subscriber = subscriber;\n-        this.tracker = tracker;\n-    }\n-\n-    @Override\n-    public void handleRequest(final PubSubRequest request, final Channel channel) {\n-        if (!request.hasUnsubscribeRequest()) {\n-            UmbrellaHandler.sendErrorResponseToMalformedRequest(channel, request.getTxnId(),\n-                    \"Missing unsubscribe request data\");\n-            return;\n-        }\n-\n-        ByteString topic = request.getTopic();\n-        ByteString subscriberId = request.getUnsubscribeRequest().getSubscriberId();\n-\n-        synchronized (tracker) {\n-\n-            // Even if unsubscribe fails, the hedwig client closes the channel\n-            // on which the subscription is being served. Hence better to tell\n-            // the tracker beforehand that this subscription is no longer served\n-            tracker.aboutToUnsubscribe(topic, subscriberId);\n-\n-            subscriber.asyncUnsubscribe(topic, subscriberId, new Callback<Void>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    channel.write(PubSubResponseUtils.getResponseForException(exception, request.getTxnId()));\n-                }\n-\n-                @Override\n-                public void operationFinished(Object ctx, Void resultOfOperation) {\n-                    channel.write(PubSubResponseUtils.getSuccessResponse(request.getTxnId()));\n-                }\n-            }, null);\n-        }\n-\n-    }\n-\n-}"},{"sha":"063a99c11a1ab2009fe550b2a50ae06367937950","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClient.java","status":"removed","additions":0,"deletions":48,"changes":48,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClient.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClient.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClient.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,48 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.regions;\n-\n-import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n-\n-import org.apache.hedwig.client.conf.ClientConfiguration;\n-import org.apache.hedwig.client.netty.HedwigClientImpl;\n-\n-/**\n- * This is a hub specific implementation of the HedwigClient. All this does\n- * though is to override the HedwigSubscriber with the hub specific child class.\n- * Creating this class so we can call the protected method in the parent to set\n- * the subscriber since we don't want to expose that API to the public.\n- */\n-public class HedwigHubClient extends HedwigClientImpl {\n-\n-    // Constructor when we already have a ChannelFactory instantiated.\n-    public HedwigHubClient(ClientConfiguration cfg, ClientSocketChannelFactory channelFactory) {\n-        super(cfg, channelFactory);\n-        // Override the type of HedwigSubscriber with the hub specific one.\n-        setSubscriber(new HedwigHubSubscriber(this));\n-    }\n-\n-    // Constructor when we don't have a ChannelFactory. The super constructor\n-    // will create one for us.\n-    public HedwigHubClient(ClientConfiguration cfg) {\n-        super(cfg);\n-        // Override the type of HedwigSubscriber with the hub specific one.\n-        setSubscriber(new HedwigHubSubscriber(this));\n-    }\n-\n-}"},{"sha":"68d317e10ab9a148c9a6a4916c414a8b122110d3","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClientFactory.java","status":"removed","additions":0,"deletions":74,"changes":74,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClientFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClientFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubClientFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,74 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.regions;\n-\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.jboss.netty.channel.socket.ClientSocketChannelFactory;\n-\n-import org.apache.hedwig.client.conf.ClientConfiguration;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class HedwigHubClientFactory {\n-\n-    private final ServerConfiguration cfg;\n-    private final ClientConfiguration clientConfiguration;\n-    private final ClientSocketChannelFactory channelFactory;\n-    private static final Logger logger = LoggerFactory.getLogger(HedwigHubClientFactory.class);\n-\n-    // Constructor that takes in a ServerConfiguration, ClientConfiguration and a ChannelFactory\n-    // so we can reuse it for all Clients created here.\n-    public HedwigHubClientFactory(ServerConfiguration cfg, ClientConfiguration clientConfiguration,\n-                                  ClientSocketChannelFactory channelFactory) {\n-        this.cfg = cfg;\n-        this.clientConfiguration = clientConfiguration;\n-        this.channelFactory = channelFactory;\n-    }\n-\n-    /**\n-     * Manufacture a hub client whose default server to connect to is the input\n-     * HedwigSocketAddress hub.\n-     *\n-     * @param hub\n-     *            The hub in another region to connect to.\n-     */\n-    HedwigHubClient create(final HedwigSocketAddress hub) {\n-        // Create a hub specific version of the client to use\n-        ClientConfiguration hubClientConfiguration = new ClientConfiguration() {\n-            @Override\n-            protected HedwigSocketAddress getDefaultServerHedwigSocketAddress() {\n-                return hub;\n-            }\n-\n-            @Override\n-            public boolean isSSLEnabled() {\n-                return cfg.isInterRegionSSLEnabled() || clientConfiguration.isSSLEnabled();\n-            }\n-        };\n-        try {\n-            hubClientConfiguration.addConf(this.clientConfiguration.getConf());\n-        } catch (ConfigurationException e) {\n-            String msg = \"Configuration exception while loading the client configuration for the region manager.\";\n-            logger.error(msg);\n-            throw new RuntimeException(msg);\n-        }\n-        return new HedwigHubClient(hubClientConfiguration, channelFactory);\n-    }\n-}"},{"sha":"70552516fab84719da35326ac8fe2381b0fb009a","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubSubscriber.java","status":"removed","additions":0,"deletions":86,"changes":86,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubSubscriber.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubSubscriber.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/regions/HedwigHubSubscriber.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,86 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.regions;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.exceptions.InvalidSubscriberIdException;\n-import org.apache.hedwig.client.netty.HedwigClientImpl;\n-import org.apache.hedwig.client.netty.HedwigSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException.ClientAlreadySubscribedException;\n-import org.apache.hedwig.exceptions.PubSubException.ClientNotSubscribedException;\n-import org.apache.hedwig.exceptions.PubSubException.CouldNotConnectException;\n-import org.apache.hedwig.exceptions.PubSubException.ServiceDownException;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest.CreateOrAttach;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionOptions;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * This is a hub specific child class of the HedwigSubscriber. The main thing is\n- * does is wrap the public subscribe/unsubscribe methods by calling the\n- * overloaded protected ones passing in a true value for the input boolean\n- * parameter isHub. That will just make sure we validate the subscriberId\n- * passed, ensuring it is of the right format either for a local or hub\n- * subscriber.\n- */\n-public class HedwigHubSubscriber extends HedwigSubscriber {\n-\n-    public HedwigHubSubscriber(HedwigClientImpl client) {\n-        super(client);\n-    }\n-\n-    @Override\n-    public void subscribe(ByteString topic, ByteString subscriberId, CreateOrAttach mode)\n-            throws CouldNotConnectException, ClientAlreadySubscribedException, ServiceDownException,\n-        InvalidSubscriberIdException {\n-        SubscriptionOptions options = SubscriptionOptions.newBuilder().setCreateOrAttach(mode).build();\n-        subscribe(topic, subscriberId, options);\n-    }\n-\n-    @Override\n-    public void asyncSubscribe(ByteString topic, ByteString subscriberId, CreateOrAttach mode, Callback<Void> callback,\n-                               Object context) {\n-        SubscriptionOptions options = SubscriptionOptions.newBuilder().setCreateOrAttach(mode).build();\n-        asyncSubscribe(topic, subscriberId, options, callback, context);\n-    }\n-\n-    @Override\n-    public void subscribe(ByteString topic, ByteString subscriberId, SubscriptionOptions options)\n-            throws CouldNotConnectException, ClientAlreadySubscribedException, ServiceDownException,\n-        InvalidSubscriberIdException {\n-        subscribe(topic, subscriberId, options, true);\n-    }\n-\n-    @Override\n-    public void asyncSubscribe(ByteString topic, ByteString subscriberId,\n-                               SubscriptionOptions options, Callback<Void> callback, Object context) {\n-        asyncSubscribe(topic, subscriberId, options, callback, context, true);\n-    }\n-\n-    @Override\n-    public void unsubscribe(ByteString topic, ByteString subscriberId) throws CouldNotConnectException,\n-        ClientNotSubscribedException, ServiceDownException, InvalidSubscriberIdException {\n-        unsubscribe(topic, subscriberId, true);\n-    }\n-\n-    @Override\n-    public void asyncUnsubscribe(final ByteString topic, final ByteString subscriberId, final Callback<Void> callback,\n-                                 final Object context) {\n-        asyncUnsubscribe(topic, subscriberId, callback, context, true);\n-    }\n-\n-}"},{"sha":"bae960b942bfe1f4c6202123db2eb24dc8c02cb3","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/regions/RegionManager.java","status":"removed","additions":0,"deletions":355,"changes":355,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/RegionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/regions/RegionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/regions/RegionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,355 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.regions;\n-\n-import java.util.ArrayList;\n-import java.util.HashMap;\n-import java.util.HashSet;\n-import java.util.Set;\n-import java.util.Timer;\n-import java.util.TimerTask;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ConcurrentMap;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.CountDownLatch;\n-\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.ZooKeeper;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.client.api.MessageHandler;\n-import org.apache.hedwig.client.exceptions.AlreadyStartDeliveryException;\n-import org.apache.hedwig.client.netty.HedwigSubscriber;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.RegionSpecificSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest.CreateOrAttach;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TopicOpQueuer;\n-import org.apache.hedwig.server.persistence.PersistRequest;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.subscriptions.SubscriptionEventListener;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.CallbackUtils;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-\n-public class RegionManager implements SubscriptionEventListener {\n-\n-    protected static final Logger LOGGER = LoggerFactory.getLogger(RegionManager.class);\n-\n-    private final ByteString mySubId;\n-    private final PersistenceManager pm;\n-    private final ArrayList<HedwigHubClient> clients = new ArrayList<HedwigHubClient>();\n-    private final TopicOpQueuer queue;\n-    private final String myRegion;\n-    // Timer for running a retry thread task to retry remote-subscription in asynchronous mode.\n-    private final Timer timer = new Timer(true);\n-    private final HashMap<HedwigHubClient, Set<ByteString>> retryMap =\n-            new HashMap<HedwigHubClient, Set<ByteString>>();\n-    // map used to track whether a topic is remote subscribed or not\n-    private final ConcurrentMap<ByteString, Boolean> topicStatuses =\n-            new ConcurrentHashMap<ByteString, Boolean>();\n-\n-    /**\n-     * This is the Timer Task for retrying subscribing to remote regions\n-     */\n-    class RetrySubscribeTask extends TimerTask {\n-\n-        @Override\n-        public void run() {\n-            Set<HedwigHubClient> hubClients = new HashSet<HedwigHubClient>();\n-            synchronized (retryMap) {\n-                hubClients.addAll(retryMap.keySet());\n-            }\n-            if (hubClients.isEmpty()) {\n-                if (LOGGER.isDebugEnabled()) {\n-                    LOGGER.debug(\"[\" + myRegion + \"] There is no hub client needs to retry subscriptions.\");\n-                }\n-                return;\n-            }\n-            for (HedwigHubClient client : hubClients) {\n-                Set<ByteString> topics = null;\n-                synchronized (retryMap) {\n-                    topics = retryMap.remove(client);\n-                }\n-                if (null == topics || topics.isEmpty()) {\n-                    continue;\n-                }\n-                final CountDownLatch done = new CountDownLatch(1);\n-                Callback<Void> postCb = new Callback<Void>() {\n-                    @Override\n-                    public void operationFinished(Object ctx,\n-                            Void resultOfOperation) {\n-                        finish();\n-                    }\n-                    @Override\n-                    public void operationFailed(Object ctx,\n-                            PubSubException exception) {\n-                        finish();\n-                    }\n-                    void finish() {\n-                        done.countDown();\n-                    }\n-                };\n-                Callback<Void> mcb = CallbackUtils.multiCallback(topics.size(), postCb, null);\n-                for (ByteString topic : topics) {\n-                    Boolean doRemoteSubscribe = topicStatuses.get(topic);\n-                    // topic has been removed, no retry again\n-                    if (null == doRemoteSubscribe) {\n-                        mcb.operationFinished(null, null);\n-                        continue;\n-                    }\n-                    retrySubscribe(client, topic, mcb);\n-                }\n-                try {\n-                    done.await();\n-                } catch (InterruptedException e) {\n-                    LOGGER.warn(\"Exception during retrying remote subscriptions : \", e);\n-                }\n-            }\n-        }\n-\n-    }\n-\n-    public RegionManager(final PersistenceManager pm, final ServerConfiguration cfg, final ZooKeeper zk,\n-                         ScheduledExecutorService scheduler, HedwigHubClientFactory hubClientFactory) {\n-        this.pm = pm;\n-        mySubId = ByteString.copyFromUtf8(SubscriptionStateUtils.HUB_SUBSCRIBER_PREFIX + cfg.getMyRegion());\n-        queue = new TopicOpQueuer(scheduler);\n-        for (final String hub : cfg.getRegions()) {\n-            clients.add(hubClientFactory.create(new HedwigSocketAddress(hub)));\n-        }\n-        myRegion = cfg.getMyRegionByteString().toStringUtf8();\n-        if (cfg.getRetryRemoteSubscribeThreadRunInterval() > 0) {\n-            timer.schedule(new RetrySubscribeTask(), 0, cfg.getRetryRemoteSubscribeThreadRunInterval());\n-        }\n-    }\n-\n-    private void putTopicInRetryMap(HedwigHubClient client, ByteString topic) {\n-        if (LOGGER.isDebugEnabled()) {\n-            LOGGER.debug(\"[\" + myRegion + \"] Put topic in retry map : \" + topic.toStringUtf8());\n-        }\n-        synchronized (retryMap) {\n-            Set<ByteString> topics = retryMap.get(client);\n-            if (null == topics) {\n-                topics = new HashSet<ByteString>();\n-                retryMap.put(client, topics);\n-            }\n-            topics.add(topic);\n-        }\n-    }\n-    \n-    /**\n-     * Do remote subscribe for a specified topic.\n-     *\n-     * @param client\n-     *          Hedwig Hub Client to subscribe remote topic.\n-     * @param topic\n-     *          Topic to subscribe.\n-     * @param synchronous\n-     *          Whether to wait for the callback of subscription.\n-     * @param mcb\n-     *          Callback to trigger after subscription is done.\n-     * @param contex\n-     *          Callback context\n-     */\n-    private void doRemoteSubscribe(final HedwigHubClient client, final ByteString topic, final boolean synchronous,\n-                                   final Callback<Void> mcb, final Object context) {\n-        final HedwigSubscriber sub = client.getSubscriber();\n-        try {\n-            if (sub.hasSubscription(topic, mySubId)) {\n-                if (LOGGER.isDebugEnabled()) {\n-                    LOGGER.debug(\"[\" + myRegion + \"] cross-region subscription for topic \"\n-                                 + topic.toStringUtf8() + \" has existed before.\");\n-                }\n-                mcb.operationFinished(null, null);\n-                return;\n-            }\n-        } catch (PubSubException e) {\n-            LOGGER.error(\"[\" + myRegion + \"] checking cross-region subscription for topic \"\n-                         + topic.toStringUtf8() + \" failed (this is should not happen): \", e);\n-            mcb.operationFailed(context, e);\n-            return;\n-        }\n-        sub.asyncSubscribe(topic, mySubId, CreateOrAttach.CREATE_OR_ATTACH, new Callback<Void>() {\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                if (LOGGER.isDebugEnabled())\n-                    LOGGER.debug(\"[\" + myRegion + \"] cross-region subscription done for topic \" + topic.toStringUtf8());\n-                try {\n-                    sub.startDelivery(topic, mySubId, new MessageHandler() {\n-                        @Override\n-                        public void deliver(final ByteString topic, ByteString subscriberId, Message msg,\n-                        final Callback<Void> callback, final Object context) {\n-                            // When messages are first published\n-                            // locally, the PublishHandler sets the\n-                            // source region in the Message.\n-                            if (msg.hasSrcRegion()) {\n-                                Message.newBuilder(msg).setMsgId(\n-                                    MessageSeqId.newBuilder(msg.getMsgId()).addRemoteComponents(\n-                                        RegionSpecificSeqId.newBuilder().setRegion(\n-                                            msg.getSrcRegion()).setSeqId(\n-                                            msg.getMsgId().getLocalComponent())));\n-                            }\n-                            pm.persistMessage(new PersistRequest(topic, msg, new Callback<MessageSeqId>() {\n-                                @Override\n-                                public void operationFinished(Object ctx, MessageSeqId resultOfOperation) {\n-                                    if (LOGGER.isDebugEnabled())\n-                                        LOGGER.debug(\"[\" + myRegion + \"] cross-region recv-fwd succeeded for topic \"\n-                                                     + topic.toStringUtf8());\n-                                    callback.operationFinished(context, null);\n-                                }\n-\n-                                @Override\n-                                public void operationFailed(Object ctx, PubSubException exception) {\n-                                    if (LOGGER.isDebugEnabled())\n-                                        LOGGER.error(\"[\" + myRegion + \"] cross-region recv-fwd failed for topic \"\n-                                                     + topic.toStringUtf8(), exception);\n-                                    callback.operationFailed(context, exception);\n-                                }\n-                            }, null));\n-                        }\n-                    });\n-                    if (LOGGER.isDebugEnabled())\n-                        LOGGER.debug(\"[\" + myRegion + \"] cross-region start-delivery succeeded for topic \"\n-                                     + topic.toStringUtf8());\n-                    mcb.operationFinished(ctx, null);\n-                } catch (PubSubException ex) {\n-                    if (LOGGER.isDebugEnabled())\n-                        LOGGER.error(\n-                                \"[\" + myRegion + \"] cross-region start-delivery failed for topic \" + topic.toStringUtf8(), ex);\n-                    mcb.operationFailed(ctx, ex);\n-                } catch (AlreadyStartDeliveryException ex) {\n-                    LOGGER.error(\"[\" + myRegion + \"] cross-region start-delivery failed for topic \"\n-                               + topic.toStringUtf8(), ex);\n-                    mcb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(\"cross-region start-delivery failed : \" + ex.getMessage()));\n-                }\n-            }\n-\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                if (LOGGER.isDebugEnabled())\n-                    LOGGER.error(\"[\" + myRegion + \"] cross-region subscribe failed for topic \" + topic.toStringUtf8(),\n-                                 exception);\n-                if (!synchronous) {\n-                    putTopicInRetryMap(client, topic);\n-                }\n-                mcb.operationFailed(ctx, exception);\n-            }\n-        }, null);\n-    }\n-\n-    private void retrySubscribe(final HedwigHubClient client, final ByteString topic, final Callback<Void> cb) {\n-        if (LOGGER.isDebugEnabled()) {\n-            LOGGER.debug(\"[\" + myRegion + \"] Retry remote subscribe topic : \" + topic.toStringUtf8());\n-        }\n-        queue.pushAndMaybeRun(topic, queue.new AsynchronousOp<Void>(topic, cb, null) {\n-            @Override\n-            public void run() {\n-                Boolean doRemoteSubscribe = topicStatuses.get(topic);\n-                // topic has been removed, no retry again\n-                if (null == doRemoteSubscribe) {\n-                    cb.operationFinished(ctx, null);\n-                    return;\n-                }\n-                doRemoteSubscribe(client, topic, false, cb, ctx);\n-            }\n-        });\n-    }\n-\n-    @Override\n-    public void onFirstLocalSubscribe(final ByteString topic, final boolean synchronous, final Callback<Void> cb) {\n-        topicStatuses.put(topic, true);\n-        // Whenever we acquire a topic due to a (local) subscribe, subscribe on\n-        // it to all the other regions (currently using simple all-to-all\n-        // topology).\n-        queue.pushAndMaybeRun(topic, queue.new AsynchronousOp<Void>(topic, cb, null) {\n-            @Override\n-            public void run() {\n-                Callback<Void> postCb = synchronous ? cb : CallbackUtils.logger(LOGGER, \n-                        \"[\" + myRegion + \"] all cross-region subscriptions succeeded\", \n-                        \"[\" + myRegion + \"] at least one cross-region subscription failed\");\n-                final Callback<Void> mcb = CallbackUtils.multiCallback(clients.size(), postCb, ctx);\n-                for (final HedwigHubClient client : clients) {\n-                    doRemoteSubscribe(client, topic, synchronous, mcb, ctx);\n-                }\n-                if (!synchronous)\n-                    cb.operationFinished(null, null);\n-            }\n-        });\n-\n-    }\n-\n-    @Override\n-    public void onLastLocalUnsubscribe(final ByteString topic) {\n-        topicStatuses.remove(topic);\n-        // TODO may want to ease up on the eager unsubscribe; this is dropping\n-        // cross-region subscriptions ASAP\n-        queue.pushAndMaybeRun(topic, queue.new AsynchronousOp<Void>(topic, new Callback<Void>() {\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void result) {\n-                if (LOGGER.isDebugEnabled())\n-                    LOGGER.debug(\"[\" + myRegion + \"] cross-region unsubscribes succeeded for topic \" + topic.toStringUtf8());\n-            }\n-\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                if (LOGGER.isDebugEnabled())\n-                    LOGGER.error(\"[\" + myRegion + \"] cross-region unsubscribes failed for topic \" + topic.toStringUtf8(), exception);\n-            }\n-\n-        }, null) {\n-            @Override\n-            public void run() {\n-                Callback<Void> mcb = CallbackUtils.multiCallback(clients.size(), cb, ctx);\n-                for (final HedwigHubClient client : clients) {\n-                    final HedwigSubscriber sub = client.getSubscriber();\n-                    try {\n-                        if (!sub.hasSubscription(topic, mySubId)) {\n-                            if (LOGGER.isDebugEnabled()) {\n-                                LOGGER.debug(\"[\" + myRegion + \"] cross-region subscription for topic \"\n-                                             + topic.toStringUtf8() + \" has existed before.\");\n-                            }\n-                            mcb.operationFinished(null, null);\n-                            continue;\n-                        }\n-                    } catch (PubSubException e) {\n-                        LOGGER.error(\"[\" + myRegion + \"] checking cross-region subscription for topic \"\n-                                     + topic.toStringUtf8() + \" failed (this is should not happen): \", e);\n-                        mcb.operationFailed(ctx, e);\n-                        continue;\n-                    }\n-                    sub.asyncUnsubscribe(topic, mySubId, mcb, null);\n-                }\n-            }\n-        });\n-    }\n-\n-    // Method to shutdown and stop all of the cross-region Hedwig clients.\n-    public void stop() {\n-        timer.cancel();\n-        for (HedwigHubClient client : clients) {\n-            client.close();\n-        }\n-    }\n-\n-}"},{"sha":"83d6961698d9289940b0477823b2e6efb98e54f5","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/ssl/SslServerContextFactory.java","status":"removed","additions":0,"deletions":53,"changes":53,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/ssl/SslServerContextFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/ssl/SslServerContextFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/ssl/SslServerContextFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,53 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.ssl;\n-\n-import java.security.KeyStore;\n-\n-import javax.net.ssl.KeyManagerFactory;\n-import javax.net.ssl.SSLContext;\n-\n-import org.apache.hedwig.client.ssl.SslContextFactory;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-\n-public class SslServerContextFactory extends SslContextFactory {\n-\n-    public SslServerContextFactory(ServerConfiguration cfg) {\n-        try {\n-            // Load our Java key store.\n-            KeyStore ks = KeyStore.getInstance(\"pkcs12\");\n-            ks.load(cfg.getCertStream(), cfg.getPassword().toCharArray());\n-\n-            // Like ssh-agent.\n-            KeyManagerFactory kmf = KeyManagerFactory.getInstance(\"SunX509\");\n-            kmf.init(ks, cfg.getPassword().toCharArray());\n-\n-            // Create the SSL context.\n-            ctx = SSLContext.getInstance(\"TLS\");\n-            ctx.init(kmf.getKeyManagers(), getTrustManagers(), null);\n-        } catch (Exception ex) {\n-            throw new RuntimeException(ex);\n-        }\n-    }\n-\n-    @Override\n-    protected boolean isClient() {\n-        return false;\n-    }\n-\n-}"},{"sha":"eaed39d0b9660397f132f59293ff13f41d471237","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AbstractSubscriptionManager.java","status":"removed","additions":0,"deletions":798,"changes":798,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AbstractSubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AbstractSubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AbstractSubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,798 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import java.util.ArrayList;\n-import java.util.Map;\n-import java.util.Map.Entry;\n-import java.util.Timer;\n-import java.util.TimerTask;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.ScheduledExecutorService;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import com.google.protobuf.ByteString;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionState;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest.CreateOrAttach;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionEvent;\n-import org.apache.hedwig.protoextensions.MessageIdUtils;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TopicOpQueuer;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.server.topics.TopicOwnershipChangeListener;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.CallbackUtils;\n-import org.apache.hedwig.util.ConcurrencyUtils;\n-\n-public abstract class AbstractSubscriptionManager implements SubscriptionManager, TopicOwnershipChangeListener {\n-\n-    private static final Logger logger = LoggerFactory.getLogger(AbstractSubscriptionManager.class);\n-\n-    protected final ServerConfiguration cfg;\n-    protected final ConcurrentHashMap<ByteString, Map<ByteString, InMemorySubscriptionState>> top2sub2seq =\n-      new ConcurrentHashMap<ByteString, Map<ByteString, InMemorySubscriptionState>>();\n-    protected final TopicOpQueuer queuer;\n-    private final ArrayList<SubscriptionEventListener> listeners = new ArrayList<SubscriptionEventListener>();\n-\n-    // Handle to the DeliveryManager for the server so we can stop serving subscribers\n-    // when losing topics\n-    private final DeliveryManager dm;\n-    // Handle to the PersistenceManager for the server so we can pass along the\n-    // message consume pointers for each topic.\n-    private final PersistenceManager pm;\n-    // Timer for running a recurring thread task to get the minimum message\n-    // sequence ID for each topic that all subscribers for it have consumed\n-    // already. With that information, we can call the PersistenceManager to\n-    // update it on the messages that are safe to be garbage collected.\n-    private final Timer timer = new Timer(true);\n-    // In memory mapping of topics to the minimum consumed message sequence ID\n-    // for all subscribers to the topic.\n-    private final ConcurrentHashMap<ByteString, Long> topic2MinConsumedMessagesMap = new ConcurrentHashMap<ByteString, Long>();\n-\n-    protected final Callback<Void> noopCallback = new NoopCallback<Void>();\n-\n-    static class NoopCallback<T> implements Callback<T> {\n-        @Override\n-        public void operationFailed(Object ctx, PubSubException exception) {\n-            logger.warn(\"Exception found in AbstractSubscriptionManager : \", exception);\n-        }\n-\n-        public void operationFinished(Object ctx, T resultOfOperation) {\n-        };\n-    }\n-\n-    public AbstractSubscriptionManager(ServerConfiguration cfg, TopicManager tm,\n-                                       PersistenceManager pm, DeliveryManager dm,\n-                                       ScheduledExecutorService scheduler) {\n-        this.cfg = cfg;\n-        queuer = new TopicOpQueuer(scheduler);\n-        tm.addTopicOwnershipChangeListener(this);\n-        this.pm = pm;\n-        this.dm = dm;\n-        // Schedule the recurring MessagesConsumedTask only if a\n-        // PersistenceManager is passed.\n-        if (pm != null) {\n-            timer.schedule(new MessagesConsumedTask(), 0, cfg.getMessagesConsumedThreadRunInterval());\n-        }\n-    }\n-\n-    /**\n-     * This is the Timer Task for finding out for each topic, what the minimum\n-     * consumed message by the subscribers are. This information is used to pass\n-     * along to the server's PersistenceManager so it can garbage collect older\n-     * topic messages that are no longer needed by the subscribers.\n-     */\n-    class MessagesConsumedTask extends TimerTask {\n-        /**\n-         * Implement the TimerTask's abstract run method.\n-         */\n-        @Override\n-        public void run() {\n-            // We are looping through relatively small in memory data structures\n-            // so it should be safe to run this fairly often.\n-            for (ByteString topic : top2sub2seq.keySet()) {\n-                final Map<ByteString, InMemorySubscriptionState> topicSubscriptions = top2sub2seq.get(topic);\n-                if (topicSubscriptions == null) {\n-                    continue;\n-                }\n-\n-                long minConsumedMessage = Long.MAX_VALUE;\n-                boolean hasBound = true;\n-                // Loop through all subscribers on the current topic to find the\n-                // minimum persisted message id. The reason not using in-memory\n-                // consumed message id is LedgerRangs and InMemorySubscriptionState\n-                // may be inconsistent in case of a server crash.\n-                for (InMemorySubscriptionState curSubscription : topicSubscriptions.values()) {\n-                    if (curSubscription.getLastPersistedSeqId() < minConsumedMessage) {\n-                        minConsumedMessage = curSubscription.getLastPersistedSeqId();\n-                    }\n-                    hasBound = hasBound && curSubscription.getSubscriptionPreferences().hasMessageBound();\n-                }\n-                boolean callPersistenceManager = true;\n-                // Call the PersistenceManager if nobody subscribes to the topic\n-                // yet, or the consume pointer has moved ahead since the last\n-                // time, or if this is the initial subscription.\n-                Long minConsumedFromMap = topic2MinConsumedMessagesMap.get(topic);\n-                if (topicSubscriptions.isEmpty()\n-                    || (minConsumedFromMap != null && minConsumedFromMap < minConsumedMessage)\n-                    || (minConsumedFromMap == null && minConsumedMessage != 0)) {\n-                    // Replace or put the new min consumed value. If it has changed\n-                    // do nothing, as another thread has updated the min consumed message\n-                    if ((minConsumedFromMap != null\n-                         && (topic2MinConsumedMessagesMap.replace(topic, minConsumedFromMap,\n-                                                                  minConsumedMessage)))\n-                        || (topic2MinConsumedMessagesMap.putIfAbsent(topic, minConsumedMessage) == null)) {\n-                        pm.consumedUntil(topic, minConsumedMessage);\n-                    }\n-                } else if (hasBound) {\n-                    pm.consumeToBound(topic);\n-                }\n-            }\n-        }\n-    }\n-\n-    private class AcquireOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        public AcquireOp(ByteString topic, Callback<Void> callback, Object ctx) {\n-            queuer.super(topic, callback, ctx);\n-        }\n-\n-        @Override\n-        public void run() {\n-            if (top2sub2seq.containsKey(topic)) {\n-                cb.operationFinished(ctx, null);\n-                return;\n-            }\n-\n-            readSubscriptions(topic, new Callback<Map<ByteString, InMemorySubscriptionState>>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    cb.operationFailed(ctx, exception);\n-                }\n-\n-                @Override\n-                public void operationFinished(final Object ctx,\n-                final Map<ByteString, InMemorySubscriptionState> resultOfOperation) {\n-                    // We've just inherited a bunch of subscriber for this\n-                    // topic, some of which may be local. If they are, then we\n-                    // need to (1) notify listeners of this and (2) record the\n-                    // number for bookkeeping so that future\n-                    // subscribes/unsubscribes can efficiently notify listeners.\n-\n-                    // The final \"commit\" (and \"abort\") operations.\n-                    final Callback<Void> cb2 = new Callback<Void>() {\n-\n-                        @Override\n-                        public void operationFailed(Object ctx, PubSubException exception) {\n-                            logger.error(\"Subscription manager failed to acquired topic \" + topic.toStringUtf8(),\n-                                         exception);\n-                            cb.operationFailed(ctx, null);\n-                        }\n-\n-                        @Override\n-                        public void operationFinished(Object ctx, Void voidObj) {\n-                            top2sub2seq.put(topic, resultOfOperation);\n-                            logger.info(\"Subscription manager successfully acquired topic: \" + topic.toStringUtf8());\n-                            cb.operationFinished(ctx, null);\n-                        }\n-\n-                    };\n-\n-                    // Notify listeners if necessary.\n-                    if (hasLocalSubscriptions(resultOfOperation)) {\n-                        notifyFirstLocalSubscribe(topic, false, cb2, ctx);\n-                    } else {\n-                        cb2.operationFinished(ctx, null);\n-                    }\n-\n-                    updateMessageBound(topic);\n-                }\n-\n-            }, ctx);\n-\n-        }\n-\n-    }\n-\n-    private void notifyFirstLocalSubscribe(ByteString topic, boolean synchronous, final Callback<Void> cb, final Object ctx) {\n-        Callback<Void> mcb = CallbackUtils.multiCallback(listeners.size(), cb, ctx);\n-        for (SubscriptionEventListener listener : listeners) {\n-            listener.onFirstLocalSubscribe(topic, synchronous, mcb);\n-        }\n-    }\n-\n-    /**\n-     * Figure out who is subscribed. Do nothing if already acquired. If there's\n-     * an error reading the subscribers' sequence IDs, then the topic is not\n-     * acquired.\n-     *\n-     * @param topic\n-     * @param callback\n-     * @param ctx\n-     */\n-    @Override\n-    public void acquiredTopic(final ByteString topic, final Callback<Void> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new AcquireOp(topic, callback, ctx));\n-    }\n-\n-    class ReleaseOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-\n-        public ReleaseOp(final ByteString topic, final Callback<Void> cb, Object ctx) {\n-            queuer.super(topic, cb, ctx);\n-        }\n-\n-        @Override\n-        public void run() {\n-            Callback<Void> finalCb = new Callback<Void>() {\n-                @Override\n-                public void operationFinished(Object ctx, Void resultOfOperation) {\n-                    logger.info(\"Finished update subscription states when losting topic \"\n-                              + topic.toStringUtf8());\n-                    finish();\n-                }\n-\n-                @Override\n-                public void operationFailed(Object ctx,\n-                        PubSubException exception) {\n-                    logger.warn(\"Error when releasing topic : \" + topic.toStringUtf8(), exception);\n-                    finish();\n-                }\n-\n-                private void finish() {\n-                    // tell delivery manager to stop delivery for subscriptions of this topic\n-                    final Map<ByteString, InMemorySubscriptionState> topicSubscriptions = top2sub2seq.remove(topic);\n-                    // no subscriptions now, it may be removed by other release ops\n-                    if (null != topicSubscriptions) {\n-                        for (ByteString subId : topicSubscriptions.keySet()) {\n-                            if (logger.isDebugEnabled()) {\n-                                logger.debug(\"Stop serving subscriber (\" + topic.toStringUtf8() + \", \"\n-                                           + subId.toStringUtf8() + \") when losing topic\");\n-                            }\n-                            if (null != dm) {\n-                                dm.stopServingSubscriber(topic, subId, SubscriptionEvent.TOPIC_MOVED,\n-                                                         noopCallback, null);\n-                            }\n-                        }\n-                    }\n-                    if (logger.isDebugEnabled()) {\n-                        logger.debug(\"Stop serving topic \" + topic.toStringUtf8());\n-                    }\n-                    // Since we decrement local count when some of remote subscriptions failed,\n-                    // while we don't unsubscribe those succeed subscriptions. so we can't depends\n-                    // on local count, just try to notify unsubscribe.\n-                    notifyLastLocalUnsubscribe(topic);\n-                    cb.operationFinished(ctx, null);\n-                }\n-            };\n-            if (logger.isDebugEnabled()) {\n-                logger.debug(\"Try to update subscription states when losing topic \" + topic.toStringUtf8());\n-            }\n-            updateSubscriptionStates(topic, finalCb, ctx);\n-        }\n-    }\n-\n-    void updateSubscriptionStates(ByteString topic, Callback<Void> finalCb, Object ctx) {\n-        // Try to update subscription states of a specified topic\n-        Map<ByteString, InMemorySubscriptionState> states = top2sub2seq.get(topic);\n-        if (null == states) {\n-            finalCb.operationFinished(ctx, null);\n-        } else {\n-            Callback<Void> mcb = CallbackUtils.multiCallback(states.size(), finalCb, ctx);\n-            for (Entry<ByteString, InMemorySubscriptionState> entry : states.entrySet()) {\n-                InMemorySubscriptionState memState = entry.getValue();\n-                if (memState.setLastConsumeSeqIdImmediately()) {\n-                    updateSubscriptionState(topic, entry.getKey(), memState, mcb, ctx);\n-                } else {\n-                    mcb.operationFinished(ctx, null);\n-                }\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Remove the local mapping.\n-     */\n-    @Override\n-    public void lostTopic(ByteString topic) {\n-        queuer.pushAndMaybeRun(topic, new ReleaseOp(topic, noopCallback, null));\n-    }\n-\n-    private void notifyLastLocalUnsubscribe(ByteString topic) {\n-        for (SubscriptionEventListener listener : listeners)\n-            listener.onLastLocalUnsubscribe(topic);\n-    }\n-\n-    protected abstract void readSubscriptions(final ByteString topic,\n-            final Callback<Map<ByteString, InMemorySubscriptionState>> cb, final Object ctx);\n-    \n-    protected abstract void readSubscriptionData(final ByteString topic, final ByteString subscriberId, \n-            final Callback<InMemorySubscriptionState> cb, Object ctx);\n-    \n-    private class SubscribeOp extends TopicOpQueuer.AsynchronousOp<SubscriptionData> {\n-        SubscribeRequest subRequest;\n-        MessageSeqId consumeSeqId;\n-\n-        public SubscribeOp(ByteString topic, SubscribeRequest subRequest, MessageSeqId consumeSeqId,\n-                           Callback<SubscriptionData> callback, Object ctx) {\n-            queuer.super(topic, callback, ctx);\n-            this.subRequest = subRequest;\n-            this.consumeSeqId = consumeSeqId;\n-        }\n-\n-        @Override\n-        public void run() {\n-\n-            final Map<ByteString, InMemorySubscriptionState> topicSubscriptions = top2sub2seq.get(topic);\n-            if (topicSubscriptions == null) {\n-                cb.operationFailed(ctx, new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-                return;\n-            }\n-\n-            final ByteString subscriberId = subRequest.getSubscriberId();\n-            final InMemorySubscriptionState subscriptionState = topicSubscriptions.get(subscriberId);\n-            CreateOrAttach createOrAttach = subRequest.getCreateOrAttach();\n-\n-            if (subscriptionState != null) {\n-\n-                if (createOrAttach.equals(CreateOrAttach.CREATE)) {\n-                    String msg = \"Topic: \" + topic.toStringUtf8() + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                 + \" requested creating a subscription but it is already subscribed with state: \"\n-                                 + SubscriptionStateUtils.toString(subscriptionState.getSubscriptionState());\n-                    logger.error(msg);\n-                    cb.operationFailed(ctx, new PubSubException.ClientAlreadySubscribedException(msg));\n-                    return;\n-                }\n-\n-                // Subscription existed before, check whether new preferences provided\n-                // if new preferences provided, merged the subscription data and updated them\n-                // TODO: needs ACL mechanism when changing preferences\n-                if (subRequest.hasPreferences() &&\n-                    subscriptionState.updatePreferences(subRequest.getPreferences())) {\n-                    updateSubscriptionPreferences(topic, subscriberId, subscriptionState, new Callback<Void>() {\n-                        @Override\n-                        public void operationFailed(Object ctx, PubSubException exception) {\n-                            cb.operationFailed(ctx, exception);\n-                        }\n-\n-                        @Override\n-                        public void operationFinished(Object ctx, Void resultOfOperation) {\n-                            if (logger.isDebugEnabled()) {\n-                                logger.debug(\"Topic: \" + topic.toStringUtf8() + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                             + \" attaching to subscription with state: \"\n-                                             + SubscriptionStateUtils.toString(subscriptionState.getSubscriptionState())\n-                                             + \", with preferences: \"\n-                                             + SubscriptionStateUtils.toString(subscriptionState.getSubscriptionPreferences()));\n-                            }\n-                            // update message bound if necessary\n-                            updateMessageBound(topic);\n-                            cb.operationFinished(ctx, subscriptionState.toSubscriptionData());\n-                        }\n-                    }, ctx);\n-                    return;\n-                }\n-\n-                // otherwise just attach\n-                if (logger.isDebugEnabled()) {\n-                    logger.debug(\"Topic: \" + topic.toStringUtf8() + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                 + \" attaching to subscription with state: \"\n-                                 + SubscriptionStateUtils.toString(subscriptionState.getSubscriptionState())\n-                                 + \", with preferences: \"\n-                                 + SubscriptionStateUtils.toString(subscriptionState.getSubscriptionPreferences()));\n-                }\n-\n-                cb.operationFinished(ctx, subscriptionState.toSubscriptionData());\n-                return;\n-            }\n-\n-            // we don't have a mapping for this subscriber\n-            if (createOrAttach.equals(CreateOrAttach.ATTACH)) {\n-                String msg = \"Topic: \" + topic.toStringUtf8() + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                             + \" requested attaching to an existing subscription but it is not subscribed\";\n-                logger.error(msg);\n-                cb.operationFailed(ctx, new PubSubException.ClientNotSubscribedException(msg));\n-                return;\n-            }\n-\n-            // now the hard case, this is a brand new subscription, must record\n-            SubscriptionState.Builder stateBuilder = SubscriptionState.newBuilder().setMsgId(consumeSeqId);\n-\n-            SubscriptionPreferences.Builder preferencesBuilder;\n-            if (subRequest.hasPreferences()) {\n-                preferencesBuilder = SubscriptionPreferences.newBuilder(subRequest.getPreferences());\n-            } else {\n-                preferencesBuilder = SubscriptionPreferences.newBuilder();\n-            }\n-\n-            // backward compability\n-            if (subRequest.hasMessageBound()) {\n-                preferencesBuilder = preferencesBuilder.setMessageBound(subRequest.getMessageBound());\n-            }\n-\n-            SubscriptionData.Builder subDataBuilder =\n-                SubscriptionData.newBuilder().setState(stateBuilder).setPreferences(preferencesBuilder);\n-            final SubscriptionData subData = subDataBuilder.build();\n-\n-            createSubscriptionData(topic, subscriberId, subData, new Callback<Version>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    cb.operationFailed(ctx, exception);\n-                }\n-\n-                @Override\n-                public void operationFinished(Object ctx, final Version version) {\n-                    Callback<Void> cb2 = new Callback<Void>() {\n-                        @Override\n-                        public void operationFailed(final Object ctx, final PubSubException exception) {\n-                            logger.error(\"subscription for subscriber \" + subscriberId.toStringUtf8() + \" to topic \"\n-                                         + topic.toStringUtf8() + \" failed due to failed listener callback\", exception);\n-                            // should remove subscription when synchronized cross-region subscription failed\n-                            deleteSubscriptionData(topic, subscriberId, version, new Callback<Void>() {\n-                                @Override\n-                                public void operationFinished(Object context,\n-                                        Void resultOfOperation) {\n-                                    finish();\n-                                }\n-                                @Override\n-                                public void operationFailed(Object context,\n-                                        PubSubException ex) {\n-                                    logger.error(\"Remove subscription for subscriber \" + subscriberId.toStringUtf8() + \" to topic \"\n-                                                 + topic.toStringUtf8() + \" failed : \", ex);\n-                                    finish();\n-                                }\n-                                private void finish() {\n-                                    cb.operationFailed(ctx, exception);\n-                                }\n-                            }, ctx);\n-                        }\n-\n-                        @Override\n-                        public void operationFinished(Object ctx, Void resultOfOperation) {\n-                            topicSubscriptions.put(subscriberId, new InMemorySubscriptionState(subData, version));\n-\n-                            updateMessageBound(topic);\n-\n-                            cb.operationFinished(ctx, subData);\n-                        }\n-\n-                    };\n-\n-                    // if this will be the first local subscription, notifyFirstLocalSubscribe\n-                    if (!SubscriptionStateUtils.isHubSubscriber(subRequest.getSubscriberId())\n-                        && !hasLocalSubscriptions(topicSubscriptions))\n-                        notifyFirstLocalSubscribe(topic, subRequest.getSynchronous(), cb2, ctx);\n-                    else\n-                        cb2.operationFinished(ctx, null);\n-                }\n-            }, ctx);\n-        }\n-    }\n-\n-    /**\n-     * @return True if the given subscriberId-to-subscriberState map contains a local subscription:\n-     * the vast majority of subscriptions are local, so we will quickly encounter one if it exists.\n-     */\n-    private static boolean hasLocalSubscriptions(Map<ByteString, InMemorySubscriptionState> topicSubscriptions) {\n-      for (ByteString subId : topicSubscriptions.keySet())\n-        if (!SubscriptionStateUtils.isHubSubscriber(subId))\n-          return true;\n-      return false;\n-    }\n-\n-    public void updateMessageBound(ByteString topic) {\n-        final Map<ByteString, InMemorySubscriptionState> topicSubscriptions = top2sub2seq.get(topic);\n-        if (topicSubscriptions == null) {\n-            return;\n-        }\n-        int maxBound = Integer.MIN_VALUE;\n-        for (Map.Entry<ByteString, InMemorySubscriptionState> e : topicSubscriptions.entrySet()) {\n-            if (!e.getValue().getSubscriptionPreferences().hasMessageBound()) {\n-                maxBound = Integer.MIN_VALUE;\n-                break;\n-            } else {\n-                maxBound = Math.max(maxBound, e.getValue().getSubscriptionPreferences().getMessageBound());\n-            }\n-        }\n-        if (maxBound == Integer.MIN_VALUE) {\n-            pm.clearMessageBound(topic);\n-        } else {\n-            pm.setMessageBound(topic, maxBound);\n-        }\n-    }\n-\n-    @Override\n-    public void serveSubscribeRequest(ByteString topic, SubscribeRequest subRequest, MessageSeqId consumeSeqId,\n-                                      Callback<SubscriptionData> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new SubscribeOp(topic, subRequest, consumeSeqId, callback, ctx));\n-    }\n-\n-    private class ConsumeOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        ByteString subscriberId;\n-        MessageSeqId consumeSeqId;\n-\n-        public ConsumeOp(ByteString topic, ByteString subscriberId, MessageSeqId consumeSeqId, Callback<Void> callback,\n-                         Object ctx) {\n-            queuer.super(topic, callback, ctx);\n-            this.subscriberId = subscriberId;\n-            this.consumeSeqId = consumeSeqId;\n-        }\n-\n-        @Override\n-        public void run() {\n-            Map<ByteString, InMemorySubscriptionState> topicSubs = top2sub2seq.get(topic);\n-            if (topicSubs == null) {\n-                cb.operationFinished(ctx, null);\n-                return;\n-            }\n-\n-            final InMemorySubscriptionState subState = topicSubs.get(subscriberId);\n-            if (subState == null) {\n-                cb.operationFinished(ctx, null);\n-                return;\n-            }\n-\n-            if (subState.setLastConsumeSeqId(consumeSeqId, cfg.getConsumeInterval())) {\n-                updateSubscriptionState(topic, subscriberId, subState, new Callback<Void>() {\n-                    @Override\n-                    public void operationFinished(Object ctx, Void resultOfOperation) {\n-                        subState.setLastPersistedSeqId(consumeSeqId.getLocalComponent());\n-                        cb.operationFinished(ctx, resultOfOperation);\n-                    }\n-\n-                    @Override\n-                    public void operationFailed(Object ctx, PubSubException exception) {\n-                        cb.operationFailed(ctx, exception);\n-                    }\n-                }, ctx);\n-            } else {\n-                if (logger.isDebugEnabled()) {\n-                    logger.debug(\"Only advanced consume pointer in memory, will persist later, topic: \"\n-                                 + topic.toStringUtf8() + \" subscriberId: \" + subscriberId.toStringUtf8()\n-                                 + \" persistentState: \" + SubscriptionStateUtils.toString(subState.getSubscriptionState())\n-                                 + \" in-memory consume-id: \"\n-                                 + MessageIdUtils.msgIdToReadableString(subState.getLastConsumeSeqId()));\n-                }\n-                cb.operationFinished(ctx, null);\n-            }\n-            // tell delivery manage about the consume event\n-            if (null != dm) {\n-                dm.messageConsumed(topic, subscriberId, consumeSeqId);\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public void setConsumeSeqIdForSubscriber(ByteString topic, ByteString subscriberId, MessageSeqId consumeSeqId,\n-            Callback<Void> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new ConsumeOp(topic, subscriberId, consumeSeqId, callback, ctx));\n-    }\n-\n-    private class CloseSubscriptionOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-\n-        public CloseSubscriptionOp(ByteString topic, ByteString subscriberId,\n-                                   Callback<Void> callback, Object ctx) {\n-            queuer.super(topic, callback, ctx);\n-        }\n-\n-        @Override\n-        public void run() {\n-            // TODO: BOOKKEEPER-412: we might need to move the loaded subscription\n-            //                       to reclaim memory\n-            // But for now we do nothing\n-            cb.operationFinished(ctx, null);\n-        }\n-    }\n-\n-    @Override\n-    public void closeSubscription(ByteString topic, ByteString subscriberId,\n-                                  Callback<Void> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new CloseSubscriptionOp(topic, subscriberId, callback, ctx));\n-    }\n-\n-    private class UnsubscribeOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        ByteString subscriberId;\n-\n-        public UnsubscribeOp(ByteString topic, ByteString subscriberId, Callback<Void> callback, Object ctx) {\n-            queuer.super(topic, callback, ctx);\n-            this.subscriberId = subscriberId;\n-        }\n-\n-        @Override\n-        public void run() {\n-            final Map<ByteString, InMemorySubscriptionState> topicSubscriptions = top2sub2seq.get(topic);\n-            if (topicSubscriptions == null) {\n-                cb.operationFailed(ctx, new PubSubException.ServerNotResponsibleForTopicException(\"\"));\n-                return;\n-            }\n-\n-            if (!topicSubscriptions.containsKey(subscriberId)) {\n-                cb.operationFailed(ctx, new PubSubException.ClientNotSubscribedException(\"\"));\n-                return;\n-            }\n-            \n-            deleteSubscriptionData(topic, subscriberId, topicSubscriptions.get(subscriberId).getVersion(),\n-                    new Callback<Void>() {\n-                @Override\n-                public void operationFailed(Object ctx, PubSubException exception) {\n-                    cb.operationFailed(ctx, exception);\n-                }\n-\n-                @Override\n-                public void operationFinished(Object ctx, Void resultOfOperation) {\n-                    topicSubscriptions.remove(subscriberId);\n-                    // Notify listeners if necessary.\n-                    if (!SubscriptionStateUtils.isHubSubscriber(subscriberId)\n-                        && !hasLocalSubscriptions(topicSubscriptions))\n-                        notifyLastLocalUnsubscribe(topic);\n-\n-                    updateMessageBound(topic);\n-                    cb.operationFinished(ctx, null);\n-                }\n-            }, ctx);\n-\n-        }\n-\n-    }\n-\n-    @Override\n-    public void unsubscribe(ByteString topic, ByteString subscriberId, Callback<Void> callback, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new UnsubscribeOp(topic, subscriberId, callback, ctx));\n-    }\n-\n-    /**\n-     * Not thread-safe.\n-     */\n-    @Override\n-    public void addListener(SubscriptionEventListener listener) {\n-        listeners.add(listener);\n-    }\n-\n-    /**\n-     * Method to stop this class gracefully including releasing any resources\n-     * used and stopping all threads spawned.\n-     */\n-    public void stop() {\n-        timer.cancel();\n-        try {\n-            final LinkedBlockingQueue<Boolean> queue = new LinkedBlockingQueue<Boolean>();\n-            // update dirty subscriptions\n-            for (ByteString topic : top2sub2seq.keySet()) {\n-                Callback<Void> finalCb = new Callback<Void>() {\n-                    @Override\n-                    public void operationFinished(Object ctx, Void resultOfOperation) {\n-                        ConcurrencyUtils.put(queue, true);\n-                    }\n-                    @Override\n-                    public void operationFailed(Object ctx,\n-                            PubSubException exception) {\n-                        ConcurrencyUtils.put(queue, false);\n-                    }\n-                };\n-                updateSubscriptionStates(topic, finalCb, null);\n-                queue.take();\n-            }\n-        } catch (InterruptedException ie) {\n-            logger.warn(\"Error during updating subscription states : \", ie);\n-        }\n-    }\n-\n-    private void updateSubscriptionState(final ByteString topic, final ByteString subscriberId,\n-                                         final InMemorySubscriptionState state,\n-                                         final Callback<Void> callback, Object ctx) {\n-        SubscriptionData subData;\n-        Callback<Version> cb = new Callback<Version>() {\n-            @Override\n-            public void operationFinished(Object ctx, Version version) {\n-                state.setVersion(version);\n-                callback.operationFinished(ctx, null);\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                if (exception instanceof PubSubException.BadVersionException) {\n-                    readSubscriptionData(topic, subscriberId, new Callback<InMemorySubscriptionState>() {\n-                        @Override\n-                        public void operationFinished(Object ctx,\n-                                InMemorySubscriptionState resultOfOperation) {\n-                            state.setVersion(resultOfOperation.getVersion());\n-                            updateSubscriptionState(topic, subscriberId, state, callback, ctx);\n-                        }\n-                        @Override\n-                        public void operationFailed(Object ctx,\n-                                PubSubException exception) {\n-                            callback.operationFailed(ctx, exception);\n-                        }\n-                    }, ctx);\n-                    \n-                    return;\n-                } \n-                callback.operationFailed(ctx, exception);\n-            }\n-        };\n-        if (isPartialUpdateSupported()) {\n-            subData = SubscriptionData.newBuilder().setState(state.getSubscriptionState()).build();\n-            updateSubscriptionData(topic, subscriberId, subData, state.getVersion(), cb, ctx);\n-        } else {\n-            subData = state.toSubscriptionData();\n-            replaceSubscriptionData(topic, subscriberId, subData, state.getVersion(), cb, ctx);\n-        }\n-    }\n-\n-    private void updateSubscriptionPreferences(final ByteString topic, final ByteString subscriberId,\n-                                               final InMemorySubscriptionState state,\n-                                               final Callback<Void> callback, Object ctx) {\n-        SubscriptionData subData;\n-        Callback<Version> cb = new Callback<Version>() {\n-            @Override\n-            public void operationFinished(Object ctx, Version version) {\n-                state.setVersion(version);\n-                callback.operationFinished(ctx, null);\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                if (exception instanceof PubSubException.BadVersionException) {\n-                    readSubscriptionData(topic, subscriberId, new Callback<InMemorySubscriptionState>() {\n-                        @Override\n-                        public void operationFinished(Object ctx,\n-                                InMemorySubscriptionState resultOfOperation) {\n-                            state.setVersion(resultOfOperation.getVersion());\n-                            updateSubscriptionPreferences(topic, subscriberId, state, callback, ctx);\n-                        }\n-                        @Override\n-                        public void operationFailed(Object ctx,\n-                                PubSubException exception) {\n-                            callback.operationFailed(ctx, exception);\n-                        }\n-                    }, ctx);\n-                    \n-                    return;\n-                } \n-                callback.operationFailed(ctx, exception);\n-            }\n-        };\n-        if (isPartialUpdateSupported()) {\n-            subData = SubscriptionData.newBuilder().setPreferences(state.getSubscriptionPreferences()).build();\n-            updateSubscriptionData(topic, subscriberId, subData, state.getVersion(), cb, ctx);\n-        } else {\n-            subData = state.toSubscriptionData();\n-            replaceSubscriptionData(topic, subscriberId, subData, state.getVersion(), cb, ctx);\n-        }\n-    }\n-\n-    protected abstract boolean isPartialUpdateSupported();\n-\n-    protected abstract void createSubscriptionData(final ByteString topic, ByteString subscriberId,\n-            SubscriptionData data, Callback<Version> callback, Object ctx);\n-\n-    protected abstract void updateSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData data,\n-            Version version, Callback<Version> callback, Object ctx);\n-\n-    protected abstract void replaceSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData data,\n-            Version version, Callback<Version> callback, Object ctx);\n-\n-    protected abstract void deleteSubscriptionData(ByteString topic, ByteString subscriberId, Version version, Callback<Void> callback,\n-            Object ctx);\n-\n-}"},{"sha":"389ccc9d5ba972f6cf0b9c167f6baf2cc4cc95be","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AllToAllTopologyFilter.java","status":"removed","additions":0,"deletions":75,"changes":75,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AllToAllTopologyFilter.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AllToAllTopologyFilter.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/AllToAllTopologyFilter.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,75 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import java.io.IOException;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.commons.configuration.Configuration;\n-import org.apache.commons.configuration.ConfigurationException;\n-import org.apache.hedwig.filter.MessageFilterBase;\n-import org.apache.hedwig.filter.ServerMessageFilter;\n-import org.apache.hedwig.protocol.PubSubProtocol.Message;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-\n-public class AllToAllTopologyFilter implements ServerMessageFilter {\n-\n-    ByteString subscriberRegion;\n-    boolean isHubSubscriber;\n-\n-    @Override\n-    public ServerMessageFilter initialize(Configuration conf)\n-    throws ConfigurationException, IOException {\n-        String region = conf.getString(ServerConfiguration.REGION, \"standalone\");\n-        if (null == region) {\n-            throw new IOException(\"No region found to run \" + getClass().getName());\n-        }\n-        subscriberRegion = ByteString.copyFromUtf8(region);\n-        return this;\n-    }\n-\n-    @Override\n-    public void uninitialize() {\n-        // do nothing now\n-    }\n-\n-    @Override\n-    public MessageFilterBase setSubscriptionPreferences(ByteString topic, ByteString subscriberId,\n-                                                        SubscriptionPreferences preferences) {\n-        isHubSubscriber = SubscriptionStateUtils.isHubSubscriber(subscriberId);\n-        return this;\n-    }\n-\n-    @Override\n-    public boolean testMessage(Message message) {\n-        // We're using a simple all-to-all network topology, so no region\n-        // should ever need to forward messages to any other region.\n-        // Otherwise, with the current logic, messages will end up\n-        // ping-pong-ing back and forth between regions with subscriptions\n-        // to each other without termination (or in any other cyclic\n-        // configuration).\n-        if (isHubSubscriber && !message.getSrcRegion().equals(subscriberRegion)) {\n-            return false;\n-        } else {\n-            return true;\n-        }\n-    }\n-\n-}"},{"sha":"4adbf1c91290a20f0e90401dcfe60807a49614e0","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionManager.java","status":"removed","additions":0,"deletions":128,"changes":128,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,128 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ScheduledExecutorService;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-public class InMemorySubscriptionManager extends AbstractSubscriptionManager {\n-\t private static final Logger logger = LoggerFactory.getLogger(InMemorySubscriptionManager.class);\n-\t// Backup for top2sub2seq\n-    final ConcurrentHashMap<ByteString, Map<ByteString, InMemorySubscriptionState>> top2sub2seqBackup =\n-        new ConcurrentHashMap<ByteString, Map<ByteString, InMemorySubscriptionState>>();\n-\n-    public InMemorySubscriptionManager(ServerConfiguration conf,\n-                                       TopicManager tm, PersistenceManager pm,\n-                                       DeliveryManager dm,\n-                                       ScheduledExecutorService scheduler) {\n-        super(conf, tm, pm, dm, scheduler);\n-    }\n-\n-    @Override\n-    protected void createSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData subData,\n-                                           Callback<Version> callback, Object ctx) {\n-        // nothing to do, in-memory info is already recorded by base class\n-        callback.operationFinished(ctx, null);\n-    }\n-\n-    @Override\n-    protected void deleteSubscriptionData(ByteString topic, ByteString subscriberId, Version version, Callback<Void> callback,\n-                                          Object ctx) {\n-        // nothing to do, in-memory info is already deleted by base class\n-        callback.operationFinished(ctx, null);\n-    }\n-\n-    @Override\n-    protected boolean isPartialUpdateSupported() {\n-        return false;\n-    }\n-\n-    @Override\n-    protected void updateSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData data,\n-                                          Version version, Callback<Version> callback, Object ctx) {\n-        throw new UnsupportedOperationException(\"Doesn't support partial update\");\n-    }\n-\n-    @Override\n-    protected void replaceSubscriptionData(ByteString topic, ByteString subscriberId, SubscriptionData data,\n-                                           Version version, Callback<Version> callback, Object ctx) {\n-        // nothing to do, in-memory info is already updated by base class\n-        callback.operationFinished(ctx, null);\n-    }\n-\n-    @Override\n-    public void lostTopic(ByteString topic) {\n-        // Backup topic-sub2seq map for readSubscriptions\n-        final Map<ByteString, InMemorySubscriptionState> sub2seq = top2sub2seq.get(topic);\n-        if (null != sub2seq)\n-            top2sub2seqBackup.put(topic, sub2seq);\n-\n-        if (logger.isDebugEnabled()) {\n-            logger.debug(\"InMemorySubscriptionManager is losing topic \" + topic.toStringUtf8());\n-        }\n-        queuer.pushAndMaybeRun(topic, new ReleaseOp(topic, noopCallback, null));\n-    }\n-\n-    @Override\n-    protected void readSubscriptions(ByteString topic,\n-                                     Callback<Map<ByteString, InMemorySubscriptionState>> cb, Object ctx) {\n-        // Since we backed up in-memory information on lostTopic, we can just return that back\n-        Map<ByteString, InMemorySubscriptionState> topicSubs = top2sub2seqBackup.remove(topic);\n-\n-        if (topicSubs != null) {\n-            cb.operationFinished(ctx, topicSubs);\n-        } else {\n-            cb.operationFinished(ctx, new ConcurrentHashMap<ByteString, InMemorySubscriptionState>());\n-        }\n-\n-    }\n-\n-    @Override\n-    protected void readSubscriptionData(ByteString topic,\n-            ByteString subscriberId, Callback<InMemorySubscriptionState> cb, Object ctx) {\n-        // Since we backed up in-memory information on lostTopic, we can just return that back\n-        Map<ByteString, InMemorySubscriptionState> sub2seqBackup = top2sub2seqBackup.get(topic);\n-        if (sub2seqBackup == null) {\n-            cb.operationFinished(ctx, new InMemorySubscriptionState(\n-                    SubscriptionData.getDefaultInstance(), Version.NEW));\n-            return;\n-        }\n-        InMemorySubscriptionState subState = sub2seqBackup.remove(subscriberId);\n-        \n-        if (subState != null) {\n-            cb.operationFinished(ctx, subState);\n-        } else {\n-            cb.operationFinished(ctx, new InMemorySubscriptionState(\n-                    SubscriptionData.getDefaultInstance(), Version.NEW));\n-        }\n-    }\n-\n-}"},{"sha":"ea74599a78957989662d26222c854de09978c33e","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionState.java","status":"removed","additions":0,"deletions":198,"changes":198,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionState.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionState.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/InMemorySubscriptionState.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,198 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-\n-import java.util.Map;\n-import com.google.protobuf.ByteString;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionPreferences;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionState;\n-import org.apache.hedwig.protoextensions.MapUtils;\n-import org.apache.hedwig.protoextensions.SubscriptionStateUtils;\n-\n-public class InMemorySubscriptionState {\n-    SubscriptionState subscriptionState;\n-    SubscriptionPreferences subscriptionPreferences;\n-    MessageSeqId lastConsumeSeqId;\n-    Version version;\n-    long lastPersistedSeqId;\n-\n-    public InMemorySubscriptionState(SubscriptionData subscriptionData, Version version, MessageSeqId lastConsumeSeqId) {\n-        this.subscriptionState = subscriptionData.getState();\n-        if (subscriptionData.hasPreferences()) {\n-            this.subscriptionPreferences = subscriptionData.getPreferences();\n-        } else {\n-            // set initial subscription preferences\n-            SubscriptionPreferences.Builder prefsBuilder = SubscriptionPreferences.newBuilder();\n-            // progate the old system preferences from subscription state to preferences\n-            prefsBuilder.setMessageBound(subscriptionState.getMessageBound());\n-            this.subscriptionPreferences = prefsBuilder.build();\n-\n-        }\n-        this.lastConsumeSeqId = lastConsumeSeqId;\n-        this.version = version;\n-        this.lastPersistedSeqId = subscriptionState.getMsgId().getLocalComponent();\n-    }\n-\n-    public InMemorySubscriptionState(SubscriptionData subscriptionData, Version version) {\n-        this(subscriptionData, version, subscriptionData.getState().getMsgId());\n-    }\n-\n-    public SubscriptionData toSubscriptionData() {\n-        SubscriptionState.Builder stateBuilder =\n-            SubscriptionState.newBuilder(subscriptionState).setMsgId(lastConsumeSeqId);\n-        return SubscriptionData.newBuilder().setState(stateBuilder)\n-                                            .setPreferences(subscriptionPreferences)\n-                                            .build();\n-    }\n-\n-    public SubscriptionState getSubscriptionState() {\n-        return subscriptionState;\n-    }\n-\n-    public SubscriptionPreferences getSubscriptionPreferences() {\n-        return subscriptionPreferences;\n-    }\n-\n-    public MessageSeqId getLastConsumeSeqId() {\n-        return lastConsumeSeqId;\n-    }\n-     \n-    public Version getVersion() {\n-        return version;\n-    }\n-    \n-    public void setVersion(Version version) {\n-        this.version = version;\n-    }\n-\n-    /**\n-     *\n-     * @param lastConsumeSeqId\n-     * @param consumeInterval\n-     *            The amount of laziness we want in persisting the consume\n-     *            pointers\n-     * @return true if the resulting structure needs to be persisted, false\n-     *         otherwise\n-     */\n-    public boolean setLastConsumeSeqId(MessageSeqId lastConsumeSeqId, int consumeInterval) {\n-        long interval = lastConsumeSeqId.getLocalComponent() - subscriptionState.getMsgId().getLocalComponent();\n-        if (interval <= 0) {\n-            return false;\n-        }\n-\n-        // set consume seq id when it is larger\n-        this.lastConsumeSeqId = lastConsumeSeqId;\n-        if (interval < consumeInterval) {\n-            return false;\n-        }\n-\n-        // subscription state will be updated, marked it as clean\n-        subscriptionState = SubscriptionState.newBuilder(subscriptionState).setMsgId(lastConsumeSeqId).build();\n-        return true;\n-    }\n-\n-    /**\n-     * Set lastConsumeSeqId Immediately\n-     *\n-     * @return true if the resulting structure needs to be persisted, false otherwise\n-     */\n-    public boolean setLastConsumeSeqIdImmediately() {\n-        long interval = lastConsumeSeqId.getLocalComponent() - subscriptionState.getMsgId().getLocalComponent();\n-        // no need to set\n-        if (interval <= 0) {\n-            return false;\n-        }\n-        subscriptionState = SubscriptionState.newBuilder(subscriptionState).setMsgId(lastConsumeSeqId).build();\n-        return true;\n-    }\n-\n-    public long getLastPersistedSeqId() {\n-        return lastPersistedSeqId;\n-    }\n-\n-    public void setLastPersistedSeqId(long lastPersistedSeqId) {\n-        this.lastPersistedSeqId = lastPersistedSeqId;\n-    }\n-\n-    /**\n-     * Update preferences.\n-     *\n-     * @return true if preferences is updated, which needs to be persisted, false otherwise.\n-     */\n-    public boolean updatePreferences(SubscriptionPreferences preferences) {\n-        boolean changed = false;\n-        SubscriptionPreferences.Builder newPreferencesBuilder = SubscriptionPreferences.newBuilder(subscriptionPreferences);\n-        if (preferences.hasMessageBound()) {\n-            if (!subscriptionPreferences.hasMessageBound() ||\n-                subscriptionPreferences.getMessageBound() != preferences.getMessageBound()) {\n-                newPreferencesBuilder.setMessageBound(preferences.getMessageBound());\n-                changed = true;\n-            }\n-        }\n-        if (preferences.hasMessageFilter()) {\n-            if (!subscriptionPreferences.hasMessageFilter() ||\n-                !subscriptionPreferences.getMessageFilter().equals(preferences.getMessageFilter())) {\n-                newPreferencesBuilder.setMessageFilter(preferences.getMessageFilter());\n-                changed = true;\n-            }\n-        }\n-        if (preferences.hasMessageWindowSize()) {\n-            if (!subscriptionPreferences.hasMessageWindowSize() ||\n-                subscriptionPreferences.getMessageWindowSize() !=\n-                preferences.getMessageWindowSize()) {\n-                newPreferencesBuilder.setMessageWindowSize(preferences.getMessageWindowSize());\n-                changed = true;\n-            }\n-        }\n-        if (preferences.hasOptions()) {\n-            Map<String, ByteString> userOptions = SubscriptionStateUtils.buildUserOptions(subscriptionPreferences);\n-            Map<String, ByteString> optUpdates = SubscriptionStateUtils.buildUserOptions(preferences);\n-            boolean optChanged = false;\n-            for (Map.Entry<String, ByteString> entry : optUpdates.entrySet()) {\n-                String key = entry.getKey();\n-                if (userOptions.containsKey(key)) {\n-                    if (null == entry.getValue()) {\n-                        userOptions.remove(key);\n-                        optChanged = true;\n-                    } else {\n-                        if (!entry.getValue().equals(userOptions.get(key))) {\n-                            userOptions.put(key, entry.getValue());\n-                            optChanged = true;\n-                        }\n-                    }\n-                } else {\n-                    userOptions.put(key, entry.getValue());\n-                    optChanged = true;\n-                }\n-            }\n-            if (optChanged) {\n-                changed = true;\n-                newPreferencesBuilder.setOptions(MapUtils.buildMapBuilder(userOptions));\n-            }\n-        }\n-        if (changed) {\n-            subscriptionPreferences = newPreferencesBuilder.build();\n-        }\n-        return changed;\n-    }\n-\n-}"},{"sha":"47fdfd293de09f7eedde7079a2e7d544bdc3fd4d","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/MMSubscriptionManager.java","status":"removed","additions":0,"deletions":138,"changes":138,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/MMSubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/MMSubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/MMSubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,138 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import java.io.IOException;\n-import java.util.Map;\n-import java.util.concurrent.ConcurrentHashMap;\n-import java.util.concurrent.ScheduledExecutorService;\n-\n-import com.google.protobuf.ByteString;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.delivery.DeliveryManager;\n-import org.apache.hedwig.server.meta.MetadataManagerFactory;\n-import org.apache.hedwig.server.meta.SubscriptionDataManager;\n-import org.apache.hedwig.server.persistence.PersistenceManager;\n-import org.apache.hedwig.server.topics.TopicManager;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.bookkeeper.versioning.Version;\n-import org.apache.bookkeeper.versioning.Versioned;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-/**\n- * MetaManager-based subscription manager.\n- */\n-public class MMSubscriptionManager extends AbstractSubscriptionManager {\n-\n-\tprivate static final Logger logger = LoggerFactory.getLogger(MMSubscriptionManager.class);\n-\tSubscriptionDataManager subManager;\n-\n-    public MMSubscriptionManager(ServerConfiguration cfg,\n-                                 MetadataManagerFactory metaManagerFactory,\n-                                 TopicManager topicMgr, PersistenceManager pm,\n-                                 DeliveryManager dm,\n-                                 ScheduledExecutorService scheduler) {\n-        super(cfg, topicMgr, pm, dm, scheduler);\n-        this.subManager = metaManagerFactory.newSubscriptionDataManager();\n-    }\n-\n-    @Override\n-    protected void readSubscriptions(final ByteString topic,\n-                                     final Callback<Map<ByteString, InMemorySubscriptionState>> cb, final Object ctx) {\n-        subManager.readSubscriptions(topic, new Callback<Map<ByteString, Versioned<SubscriptionData>>>() {\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException pse) {\n-                cb.operationFailed(ctx, pse);\n-            }\n-            @Override\n-            public void operationFinished(Object ctx, Map<ByteString, Versioned<SubscriptionData>> subs) {\n-                Map<ByteString, InMemorySubscriptionState> results = new ConcurrentHashMap<ByteString, InMemorySubscriptionState>();\n-                for (Map.Entry<ByteString, Versioned<SubscriptionData>> subEntry : subs.entrySet()) {\n-                    Versioned<SubscriptionData> vv = subEntry.getValue();\n-                    results.put(subEntry.getKey(), new InMemorySubscriptionState(vv.getValue(), vv.getVersion()));\n-                }\n-                cb.operationFinished(ctx, results);\n-            }\n-        }, ctx);\n-    }\n-\n-    @Override\n-    protected void readSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                                        final Callback<InMemorySubscriptionState> cb, final Object ctx) {\n-        subManager.readSubscriptionData(topic, subscriberId, new Callback<Versioned<SubscriptionData>>() {\n-            @Override\n-            public void operationFinished(Object ctx,\n-                    Versioned<SubscriptionData> subData) {\n-                if (null != subData) {\n-                    cb.operationFinished(ctx, \n-                            new InMemorySubscriptionState(subData.getValue(), subData.getVersion()));\n-                } else {\n-                    cb.operationFinished(ctx, new InMemorySubscriptionState(\n-                            SubscriptionData.getDefaultInstance(), Version.NEW));\n-                }\n-            }\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                cb.operationFailed(ctx, exception);\n-            }\n-        }, ctx);\n-    }\n-\n-    @Override\n-    protected boolean isPartialUpdateSupported() {\n-        return subManager.isPartialUpdateSupported();\n-    }\n-\n-    @Override\n-    protected void createSubscriptionData(final ByteString topic, final ByteString subscriberId,\n-                                          final SubscriptionData subData, final Callback<Version> callback, final Object ctx) {\n-        subManager.createSubscriptionData(topic, subscriberId, subData, callback, ctx);\n-    }\n-\n-    @Override\n-    protected void replaceSubscriptionData(final ByteString topic, final ByteString subscriberId, final SubscriptionData subData, \n-                                           final Version version, final Callback<Version> callback, final Object ctx) {\n-        subManager.replaceSubscriptionData(topic, subscriberId, subData, version, callback, ctx);\n-    }\n-\n-    @Override\n-    protected void updateSubscriptionData(final ByteString topic, final ByteString subscriberId, final SubscriptionData subData, \n-                                          final Version version, final Callback<Version> callback, final Object ctx) {\n-        subManager.updateSubscriptionData(topic, subscriberId, subData, version, callback, ctx);\n-    }\n-\n-    @Override\n-    protected void deleteSubscriptionData(final ByteString topic, final ByteString subscriberId, Version version,\n-                                          final Callback<Void> callback, final Object ctx) {\n-        subManager.deleteSubscriptionData(topic, subscriberId, version, callback, ctx);\n-    }\n-\n-    @Override\n-    public void stop() {\n-        super.stop();\n-        try {\n-            subManager.close();\n-        } catch (IOException ioe) {\n-            logger.warn(\"Exception closing subscription data manager : \", ioe);\n-        }\n-    }\n-}"},{"sha":"6c6e626dd22c8e92d2203bb0c4b34eb933972b52","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionEventListener.java","status":"removed","additions":0,"deletions":57,"changes":57,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionEventListener.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionEventListener.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionEventListener.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,57 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * For listening to events that are issued by a SubscriptionManager.\n- *\n- */\n-public interface SubscriptionEventListener {\n-\n-    /**\n-     * Called by the subscription manager when it previously had zero local\n-     * subscribers for a topic and is currently accepting its first local\n-     * subscriber.\n-     *\n-     * @param topic\n-     *            The topic of interest.\n-     * @param synchronous\n-     *            Whether this request was actually initiated by a new local\n-     *            subscriber, or whether it was an existing subscription\n-     *            inherited by the hub (e.g. when recovering the state from ZK).\n-     * @param cb\n-     *            The subscription will not complete until success is called on\n-     *            this callback. An error on cb will result in a subscription\n-     *            error.\n-     */\n-    public void onFirstLocalSubscribe(ByteString topic, boolean synchronous, Callback<Void> cb);\n-\n-    /**\n-     * Called by the SubscriptionManager when it previously had non-zero local\n-     * subscribers for a topic and is currently dropping its last local\n-     * subscriber. This is fully asynchronous so there is no callback.\n-     *\n-     * @param topic\n-     *            The topic of interest.\n-     */\n-    public void onLastLocalUnsubscribe(ByteString topic);\n-\n-}"},{"sha":"eadebcb50bc5e2a1a895e9728124d02799b0d390","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionManager.java","status":"removed","additions":0,"deletions":123,"changes":123,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/subscriptions/SubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,123 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.subscriptions;\n-\n-import com.google.protobuf.ByteString;\n-import org.apache.hedwig.protocol.PubSubProtocol.MessageSeqId;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscribeRequest;\n-import org.apache.hedwig.protocol.PubSubProtocol.SubscriptionData;\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * All methods are thread-safe.\n- */\n-public interface SubscriptionManager {\n-\n-    /**\n-     *\n-     * Register a new subscription for the given subscriber for the given topic.\n-     * This method should reliably persist the existence of the subscription in\n-     * a way that it can't be lost. If the subscription already exists,\n-     * depending on the create or attach flag in the subscribe request, an\n-     * exception may be returned.\n-     *\n-     * This is an asynchronous method.\n-     *\n-     * @param topic\n-     * @param subRequest\n-     * @param consumeSeqId\n-     *            The seqId to start serving the subscription from, if this is a\n-     *            brand new subscription\n-     * @param callback\n-     *            The subscription data returned by the callback.\n-     * @param ctx\n-     */\n-    public void serveSubscribeRequest(ByteString topic, SubscribeRequest subRequest, MessageSeqId consumeSeqId,\n-                                      Callback<SubscriptionData> callback, Object ctx);\n-\n-    /**\n-     * Set the consume position of a given subscriber on a given topic. Note\n-     * that this method need not persist the consume position immediately but\n-     * can be lazy and persist it later asynchronously, if that is more\n-     * efficient.\n-     *\n-     * @param topic\n-     * @param subscriberId\n-     * @param consumeSeqId\n-     */\n-    public void setConsumeSeqIdForSubscriber(ByteString topic, ByteString subscriberId, MessageSeqId consumeSeqId,\n-            Callback<Void> callback, Object ctx);\n-\n-    /**\n-     * Close a particular subscription\n-     *\n-     * @param topic\n-     *          Topic Name\n-     * @param subscriberId\n-     *          Subscriber Id\n-     * @param callback\n-     *          Callback\n-     * @param ctx\n-     *          Callback context\n-     */\n-    public void closeSubscription(ByteString topic, ByteString subscriberId,\n-                                  Callback<Void> callback, Object ctx);\n-\n-    /**\n-     * Delete a particular subscription\n-     *\n-     * @param topic\n-     * @param subscriberId\n-     */\n-    public void unsubscribe(ByteString topic, ByteString subscriberId, Callback<Void> callback, Object ctx);\n-\n-    // Management API methods that we will fill in later\n-    // /**\n-    // * Get the ids of all subscribers for a given topic\n-    // *\n-    // * @param topic\n-    // * @return A list of subscriber ids that are currently subscribed to the\n-    // * given topic\n-    // */\n-    // public List<ByteString> getSubscriptionsForTopic(ByteString topic);\n-    //\n-    // /**\n-    // * Get the topics to which a given subscriber is subscribed to\n-    // *\n-    // * @param subscriberId\n-    // * @return A list of the topics to which the given subscriber is\n-    // subscribed\n-    // * to\n-    // * @throws ServiceDownException\n-    // * If there is an error in looking up the subscription\n-    // * information\n-    // */\n-    // public List<ByteString> getTopicsForSubscriber(ByteString subscriberId)\n-    // throws ServiceDownException;\n-\n-    /**\n-     * Add a listener that is notified when topic-subscription pairs are added\n-     * or removed.\n-     */\n-    public void addListener(SubscriptionEventListener listener);\n-\n-    /**\n-     * Stop Subscription Manager\n-     */\n-    public void stop();\n-}"},{"sha":"2d9aba23e71a2ac9166f3706681d8f4961c64356","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","status":"removed","additions":0,"deletions":314,"changes":314,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/AbstractTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,314 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.topics;\n-\n-import java.net.UnknownHostException;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.List;\n-import java.util.concurrent.ScheduledExecutorService;\n-import java.util.concurrent.TimeUnit;\n-\n-import org.apache.hedwig.exceptions.PubSubException;\n-import org.apache.hedwig.server.common.ServerConfiguration;\n-import org.apache.hedwig.server.common.TopicOpQueuer;\n-import org.apache.hedwig.util.Callback;\n-import org.apache.hedwig.util.CallbackUtils;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import com.google.common.cache.Cache;\n-import com.google.common.cache.CacheBuilder;\n-import com.google.common.cache.RemovalListener;\n-import com.google.common.cache.RemovalNotification;\n-import com.google.common.collect.Lists;\n-import com.google.protobuf.ByteString;\n-\n-public abstract class AbstractTopicManager implements TopicManager {\n-\n-    /**\n-     * Stats for a topic. For now it just an empty stub class.\n-     */\n-    static class TopicStats {\n-    }\n-\n-    final static TopicStats STUB_TOPIC_STATS = new TopicStats();\n-\n-    /**\n-     * My name.\n-     */\n-    protected HedwigSocketAddress addr;\n-\n-    /**\n-     * Topic change listeners.\n-     */\n-    protected ArrayList<TopicOwnershipChangeListener> listeners = new ArrayList<TopicOwnershipChangeListener>();\n-\n-    /**\n-     * List of topics I believe I am responsible for.\n-     */\n-    protected Cache<ByteString, TopicStats> topics;\n-\n-    protected TopicOpQueuer queuer;\n-    protected ServerConfiguration cfg;\n-    protected ScheduledExecutorService scheduler;\n-\n-    private static final Logger logger = LoggerFactory.getLogger(AbstractTopicManager.class);\n-\n-    private class GetOwnerOp extends TopicOpQueuer.AsynchronousOp<HedwigSocketAddress> {\n-        public boolean shouldClaim;\n-\n-        public GetOwnerOp(final ByteString topic, boolean shouldClaim,\n-                          final Callback<HedwigSocketAddress> cb, Object ctx) {\n-            queuer.super(topic, cb, ctx);\n-            this.shouldClaim = shouldClaim;\n-        }\n-\n-        @Override\n-        public void run() {\n-            realGetOwner(topic, shouldClaim, cb, ctx);\n-        }\n-    }\n-\n-    private class ReleaseOp extends TopicOpQueuer.AsynchronousOp<Void> {\n-        final boolean checkExistence;\n-\n-        public ReleaseOp(ByteString topic, Callback<Void> cb, Object ctx) {\n-            this(topic, cb, ctx, true);\n-        }\n-\n-        ReleaseOp(ByteString topic, Callback<Void> cb, Object ctx,\n-                  boolean checkExistence) {\n-            queuer.super(topic, cb, ctx);\n-            this.checkExistence = checkExistence;\n-        }\n-\n-        @Override\n-        public void run() {\n-            if (checkExistence) {\n-                TopicStats stats = topics.getIfPresent(topic);\n-                if (null == stats) {\n-                    cb.operationFinished(ctx, null);\n-                    return;\n-                }\n-            }\n-            realReleaseTopic(topic, cb, ctx);\n-        }\n-    }\n-\n-    /**\n-     * Release topic when the topic is removed from topics cache.\n-     */\n-    class ReleaseTopicListener implements RemovalListener<ByteString, TopicStats> {\n-        @Override\n-        public void onRemoval(RemovalNotification<ByteString, TopicStats> notification) {\n-            if (notification.wasEvicted()) {\n-                logger.info(\"topic {} is evicted\", notification.getKey().toStringUtf8());\n-                // if the topic is evicted, we need to release the topic.\n-                releaseTopicInternally(notification.getKey(), false);\n-            }\n-        }\n-    }\n-\n-    public AbstractTopicManager(ServerConfiguration cfg, ScheduledExecutorService scheduler)\n-            throws UnknownHostException {\n-        this.cfg = cfg;\n-        this.queuer = new TopicOpQueuer(scheduler);\n-        this.scheduler = scheduler;\n-        addr = cfg.getServerAddr();\n-\n-        // build the topic cache\n-        CacheBuilder<ByteString, TopicStats> cacheBuilder = CacheBuilder.newBuilder()\n-            .maximumSize(cfg.getMaxNumTopics())\n-            .initialCapacity(cfg.getInitNumTopics())\n-            // TODO: change to same number as topic op queuer threads\n-            .concurrencyLevel(Runtime.getRuntime().availableProcessors())\n-            .removalListener(new ReleaseTopicListener());\n-        if (cfg.getRetentionSecsAfterAccess() > 0) {\n-            cacheBuilder.expireAfterAccess(cfg.getRetentionSecsAfterAccess(), TimeUnit.SECONDS);\n-        }\n-        topics = cacheBuilder.build();\n-    }\n-\n-    @Override\n-    public void incrementTopicAccessTimes(ByteString topic) {\n-        // let guava cache handle hits counting\n-        topics.getIfPresent(topic);\n-    }\n-\n-    @Override\n-    public synchronized void addTopicOwnershipChangeListener(TopicOwnershipChangeListener listener) {\n-        listeners.add(listener);\n-    }\n-\n-    private void releaseTopicInternally(final ByteString topic, boolean checkExistence) {\n-        // Enqueue a release operation. (Recall that release\n-        // doesn't \"fail\" even if the topic is missing.)\n-        queuer.pushAndMaybeRun(topic, new ReleaseOp(topic, new Callback<Void>() {\n-\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException exception) {\n-                logger.error(\"failure that should never happen when releasing topic \"\n-                             + topic, exception);\n-            }\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                    logger.info(\"successfully release of topic \"\n-                        + topic.toStringUtf8());\n-                if (logger.isDebugEnabled()) {\n-                    logger.debug(\"successfully release of topic \"\n-                        + topic.toStringUtf8());\n-                }\n-            }\n-\n-        }, null, checkExistence));\n-    }\n-\n-    protected final synchronized void notifyListenersAndAddToOwnedTopics(final ByteString topic,\n-            final Callback<HedwigSocketAddress> originalCallback, final Object originalContext) {\n-\n-        Callback<Void> postCb = new Callback<Void>() {\n-\n-            @Override\n-            public void operationFinished(Object ctx, Void resultOfOperation) {\n-                topics.put(topic, STUB_TOPIC_STATS);\n-                if (cfg.getRetentionSecs() > 0) {\n-                    scheduler.schedule(new Runnable() {\n-                        @Override\n-                        public void run() {\n-                            releaseTopicInternally(topic, true);\n-                        }\n-                    }, cfg.getRetentionSecs(), TimeUnit.SECONDS);\n-                }\n-                originalCallback.operationFinished(originalContext, addr);\n-            }\n-\n-            @Override\n-            public void operationFailed(final Object ctx, final PubSubException exception) {\n-                // TODO: optimization: we can release this as soon as we experience the first error.\n-                Callback<Void> cb = new Callback<Void>() {\n-                    @Override\n-                    public void operationFinished(Object _ctx, Void _resultOfOperation) {\n-                        originalCallback.operationFailed(ctx, exception);\n-                    }\n-                    @Override\n-                    public void operationFailed(Object _ctx, PubSubException _exception) {\n-                        logger.error(\"Exception releasing topic\", _exception);\n-                        originalCallback.operationFailed(ctx, exception);\n-                    }\n-                };\n-\n-                realReleaseTopic(topic, cb, originalContext);\n-            }\n-        };\n-\n-        Callback<Void> mcb = CallbackUtils.multiCallback(listeners.size(), postCb, null);\n-        for (TopicOwnershipChangeListener listener : listeners) {\n-            listener.acquiredTopic(topic, mcb, null);\n-        }\n-    }\n-\n-    private void realReleaseTopic(ByteString topic, Callback<Void> callback, Object ctx) {\n-        for (TopicOwnershipChangeListener listener : listeners)\n-            listener.lostTopic(topic);\n-        topics.invalidate(topic);\n-        postReleaseCleanup(topic, callback, ctx);\n-    }\n-\n-    @Override\n-    public final void getOwner(ByteString topic, boolean shouldClaim,\n-                               Callback<HedwigSocketAddress> cb, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new GetOwnerOp(topic, shouldClaim, cb, ctx));\n-    }\n-\n-    @Override\n-    public final void releaseTopic(ByteString topic, Callback<Void> cb, Object ctx) {\n-        queuer.pushAndMaybeRun(topic, new ReleaseOp(topic, cb, ctx));\n-    }\n-\n-    @Override\n-    public final void releaseTopics(int numTopics, final Callback<Long> callback, final Object ctx) {\n-        // This is a best effort function. We sacrifice accuracy to not hold a lock on the topics set.\n-        List<ByteString> topicList = getTopicList();\n-        // Make sure we release only as many topics as we own.\n-        final long numTopicsToRelease = Math.min(topicList.size(), numTopics);\n-        // Shuffle the list of topics we own, so that we release a random subset.\n-        Collections.shuffle(topicList);\n-        Callback<Void> mcb = CallbackUtils.multiCallback((int)numTopicsToRelease, new Callback<Void>() {\n-            @Override\n-            public void operationFinished(Object ctx, Void ignoreVal) {\n-                callback.operationFinished(ctx, numTopicsToRelease);\n-            }\n-\n-            @Override\n-            public void operationFailed(Object ctx, PubSubException e) {\n-                long notReleased = 0;\n-                if (e instanceof PubSubException.CompositeException) {\n-                    notReleased = ((PubSubException.CompositeException)e).getExceptions().size();\n-                }\n-                callback.operationFinished(ctx, numTopicsToRelease - notReleased);\n-            }\n-        }, ctx);\n-\n-        // Try to release \"numTopicsToRelease\" topics. It's okay if we're not\n-        // able to release some topics. We signal that we tried by invoking the callback's\n-        // operationFinished() with the actual number of topics released.\n-        logger.info(\"This hub is releasing {} topics\", numTopicsToRelease);\n-        long releaseCount = 0;\n-        for (ByteString topic : topicList) {\n-            if (++releaseCount > numTopicsToRelease) {\n-                break;\n-            }\n-            releaseTopic(topic, mcb, ctx);\n-        }\n-    }\n-\n-    @Override\n-    public List<ByteString> getTopicList() {\n-        List<ByteString> topicList;\n-        synchronized (this.topics) {\n-            topicList = Lists.newArrayList(this.topics.asMap().keySet());\n-        }\n-        return topicList;\n-    }\n-\n-    /**\n-     * This method should \"return\" the owner of the topic if one has been chosen\n-     * already. If there is no pre-chosen owner, either this hub or some other\n-     * should be chosen based on the shouldClaim parameter. If its ends up\n-     * choosing this hub as the owner, the {@code\n-     * AbstractTopicManager#notifyListenersAndAddToOwnedTopics(ByteString,\n-     * OperationCallback, Object)} method must be called.\n-     *\n-     */\n-    protected abstract void realGetOwner(ByteString topic, boolean shouldClaim,\n-                                         Callback<HedwigSocketAddress> cb, Object ctx);\n-\n-    /**\n-     * The method should do any cleanup necessary to indicate to other hubs that\n-     * this topic has been released\n-     */\n-    protected abstract void postReleaseCleanup(ByteString topic, Callback<Void> cb, Object ctx);\n-\n-    @Override\n-    public void stop() {\n-        // do nothing now\n-    }\n-}"},{"sha":"9a4cb3d6d32e77e5f22f9ff4b29e8c7efcd51b7a","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubInfo.java","status":"removed","additions":0,"deletions":162,"changes":162,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubInfo.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,162 +0,0 @@\n-package org.apache.hedwig.server.topics;\n-\n-/*\n- *\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- *\n- */\n-\n-import java.io.BufferedReader;\n-import java.io.IOException;\n-import java.io.StringReader;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.HubInfoData;\n-import org.apache.hedwig.util.HedwigSocketAddress;\n-\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import com.google.protobuf.TextFormat;\n-\n-/**\n- * Info identifies a hub server.\n- */\n-public class HubInfo {\n-\n-    public static class InvalidHubInfoException extends Exception {\n-        public InvalidHubInfoException(String msg) {\n-            super(msg);\n-        }\n-\n-        public InvalidHubInfoException(String msg, Throwable t) {\n-            super(msg, t);\n-        }\n-    }\n-\n-    // address identify a hub server\n-    final HedwigSocketAddress addr;\n-    // its znode czxid\n-    final long czxid;\n-    // protobuf encoded hub info data to be serialized\n-    HubInfoData hubInfoData;\n-\n-    public HubInfo(HedwigSocketAddress addr, long czxid) {\n-        this(addr, czxid, null);\n-    }\n-\n-    protected HubInfo(HedwigSocketAddress addr, long czxid,\n-                      HubInfoData data) {\n-        this.addr = addr;\n-        this.czxid = czxid;\n-        this.hubInfoData = data;\n-    }\n-\n-    public HedwigSocketAddress getAddress() {\n-        return addr;\n-    }\n-\n-    public long getZxid() {\n-        return czxid;\n-    }\n-\n-    private synchronized HubInfoData getHubInfoData() {\n-        if (null == hubInfoData) {\n-            hubInfoData = HubInfoData.newBuilder().setHostname(addr.toString())\n-                                     .setCzxid(czxid).build();\n-        }\n-        return hubInfoData;\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return TextFormat.printToString(getHubInfoData());\n-    }\n-\n-    @Override\n-    public boolean equals(Object o) {\n-        if (null == o) {\n-            return false;\n-        }\n-        if (!(o instanceof HubInfo)) {\n-            return false;\n-        }\n-        HubInfo other = (HubInfo)o;\n-        if (null == addr) {\n-            if (null == other.addr) {\n-                return true;\n-            } else {\n-                return czxid == other.czxid;\n-            }\n-        } else {\n-            if (addr.equals(other.addr)) {\n-                return czxid == other.czxid;\n-            } else {\n-                return false;\n-            }\n-        }\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return addr.hashCode();\n-    }\n-\n-    /**\n-     * Parse hub info from a string.\n-     *\n-     * @param hubInfoStr\n-     *          String representation of hub info\n-     * @return hub info\n-     * @throws InvalidHubInfoException when <code>hubInfoStr</code> is not a valid\n-     *         string representation of hub info.\n-     */\n-    public static HubInfo parse(String hubInfoStr) throws InvalidHubInfoException {\n-        // it is not protobuf encoded hub info, it might be generated by ZkTopicManager\n-        if (!hubInfoStr.startsWith(\"hostname\")) {\n-            final HedwigSocketAddress owner;\n-            try {\n-                owner = new HedwigSocketAddress(hubInfoStr);\n-            } catch (Exception e) {\n-                throw new InvalidHubInfoException(\"Corrupted hub server address : \" + hubInfoStr, e);\n-            }\n-            return new HubInfo(owner, 0L);\n-        }\n-\n-        // it is a protobuf encoded hub info.\n-        HubInfoData hubInfoData;\n-\n-        try {\n-            BufferedReader reader = new BufferedReader(\n-                new StringReader(hubInfoStr));\n-            HubInfoData.Builder dataBuilder = HubInfoData.newBuilder();\n-            TextFormat.merge(reader, dataBuilder);\n-            hubInfoData = dataBuilder.build();\n-        } catch (InvalidProtocolBufferException ipbe) {\n-            throw new InvalidHubInfoException(\"Corrupted hub info : \" + hubInfoStr, ipbe);\n-        } catch (IOException ie) {\n-            throw new InvalidHubInfoException(\"Corrupted hub info : \" + hubInfoStr, ie);\n-        }\n-\n-        final HedwigSocketAddress owner;\n-        try {\n-            owner = new HedwigSocketAddress(hubInfoData.getHostname().trim());\n-        } catch (Exception e) {\n-            throw new InvalidHubInfoException(\"Corrupted hub server address : \" + hubInfoData.getHostname(), e);\n-        }\n-        long ownerZxid = hubInfoData.getCzxid();\n-        return new HubInfo(owner, ownerZxid, hubInfoData);\n-    }\n-}"},{"sha":"2f76020408120c289d8d3c7821e6a2acebbd6f2c","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","status":"removed","additions":0,"deletions":137,"changes":137,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubLoad.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,137 +0,0 @@\n-/*\n- *\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- *\n- */\n-package org.apache.hedwig.server.topics;\n-\n-import java.io.BufferedReader;\n-import java.io.IOException;\n-import java.io.StringReader;\n-\n-import org.apache.hedwig.protocol.PubSubProtocol.HubLoadData;\n-\n-import com.google.protobuf.InvalidProtocolBufferException;\n-import com.google.protobuf.TextFormat;\n-\n-/**\n- * This class encapsulates metrics for determining the load on a hub server.\n- */\n-public class HubLoad implements Comparable<HubLoad> {\n-\n-    public static final HubLoad MAX_LOAD = new HubLoad(Long.MAX_VALUE);\n-    public static final HubLoad MIN_LOAD = new HubLoad(0);\n-\n-    public static class InvalidHubLoadException extends Exception {\n-        private static final long serialVersionUID = 5870487176956413387L;\n-\n-        public InvalidHubLoadException(String msg) {\n-            super(msg);\n-        }\n-\n-        public InvalidHubLoadException(String msg, Throwable t) {\n-            super(msg, t);\n-        }\n-    }\n-\n-    // how many topics that a hub server serves\n-    long numTopics;\n-\n-    public HubLoad(long num) {\n-        this.numTopics = num;\n-    }\n-\n-    public HubLoad(HubLoadData data) {\n-        this.numTopics = data.getNumTopics();\n-    }\n-\n-    // TODO: Make this threadsafe (BOOKKEEPER-379)\n-    public HubLoad setNumTopics(long numTopics) {\n-        this.numTopics = numTopics;\n-        return this;\n-    }\n-\n-    public long getNumTopics() {\n-        return this.numTopics;\n-    }\n-\n-    public HubLoadData toHubLoadData() {\n-        return HubLoadData.newBuilder().setNumTopics(numTopics).build();\n-    }\n-\n-    @Override\n-    public String toString() {\n-        return TextFormat.printToString(toHubLoadData());\n-    }\n-\n-    @Override\n-    public boolean equals(Object o) {\n-        if (null == o ||\n-            !(o instanceof HubLoad)) {\n-            return false;\n-        }\n-        return 0 == compareTo((HubLoad)o);\n-    }\n-\n-    @Override\n-    public int compareTo(HubLoad other) {\n-        return numTopics > other.numTopics ?\n-               1 : (numTopics < other.numTopics ? -1 : 0);\n-    }\n-\n-    @Override\n-    public int hashCode() {\n-        return (int)numTopics;\n-    }\n-\n-    /**\n-     * Parse hub load from a string.\n-     *\n-     * @param hubLoadStr\n-     *          String representation of hub load\n-     * @return hub load\n-     * @throws InvalidHubLoadException when <code>hubLoadStr</code> is not a valid\n-     *         string representation of hub load.\n-     */\n-    public static HubLoad parse(String hubLoadStr) throws InvalidHubLoadException {\n-        // it is no protobuf encoded hub info, it might be generated by ZkTopicManager\n-        if (!hubLoadStr.startsWith(\"numTopics\")) {\n-            try {\n-                long numTopics = Long.parseLong(hubLoadStr, 10);\n-                return new HubLoad(numTopics);\n-            } catch (NumberFormatException nfe) {\n-                throw new InvalidHubLoadException(\"Corrupted hub load data : \" + hubLoadStr, nfe);\n-            }\n-        }\n-        // it it a protobuf encoded hub load data.\n-        HubLoadData hubLoadData;\n-        try {\n-            BufferedReader reader = new BufferedReader(\n-                new StringReader(hubLoadStr));\n-            HubLoadData.Builder dataBuilder = HubLoadData.newBuilder();\n-            TextFormat.merge(reader, dataBuilder);\n-            hubLoadData = dataBuilder.build();\n-        } catch (InvalidProtocolBufferException ipbe) {\n-            throw new InvalidHubLoadException(\"Corrupted hub load data : \" + hubLoadStr, ipbe);\n-        } catch (IOException ie) {\n-            throw new InvalidHubLoadException(\"Corrupted hub load data : \" + hubLoadStr, ie);\n-        }\n-\n-        return new HubLoad(hubLoadData);\n-    }\n-}"},{"sha":"12524c924e2cda88f8a8280419681e0ef3bc8340","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","status":"removed","additions":0,"deletions":124,"changes":124,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/HubServerManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9","patch":"@@ -1,124 +0,0 @@\n-/**\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *     http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing, software\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n- * See the License for the specific language governing permissions and\n- * limitations under the License.\n- */\n-package org.apache.hedwig.server.topics;\n-\n-import java.io.IOException;\n-\n-import org.apache.hedwig.util.Callback;\n-\n-/**\n- * The HubServerManager class manages info about hub servers.\n- */\n-interface HubServerManager {\n-\n-    static interface ManagerListener {\n-\n-        /**\n-         * Server manager is suspended if encountering some transient errors.\n-         * {@link #onResume()} would be called if those errors could be fixed.\n-         * {@link #onShutdown()} would be called if those errors could not be fixed.\n-         */\n-        public void onSuspend();\n-\n-        /**\n-         * Server manager is resumed after fixing some transient errors.\n-         */\n-        public void onResume();\n-\n-        /**\n-         * Server manager had to shutdown due to unrecoverable errors.\n-         */\n-        public void onShutdown();\n-    }\n-\n-    /**\n-     * Register a listener to listen events of server manager\n-     *\n-     * @param listener\n-     *          Server Manager Listener\n-     */\n-    public void registerListener(ManagerListener listener);\n-\n-    /**\n-     * Register itself to the cluster.\n-     *\n-     * @param selfLoad\n-     *          Self load data\n-     * @param callback\n-     *          Callback when itself registered.\n-     * @param ctx\n-     *          Callback context.\n-     */\n-    public void registerSelf(HubLoad selfLoad, Callback<HubInfo> callback, Object ctx);\n-\n-    /**\n-     * Unregister itself from the cluster.\n-     */\n-    public void unregisterSelf() throws IOException;\n-\n-    /**\n-     * Uploading self server load data.\n-     *\n-     * It is an asynchrounous call which should not block other operations.\n-     * Currently we don't need to care about whether it succeed or not.\n-     *\n-     * @param selfLoad\n-     *          Hub server load data.\n-     */\n-    public void uploadSelfLoadData(HubLoad selfLoad);\n-\n-    /**\n-     * Check whether a hub server is alive as the id\n-     *\n-     * @param hub\n-     *          Hub id to identify a lifecycle of a hub server\n-     * @param callback\n-     *          Callback of check result. If the hub server is still\n-     *          alive as the provided id <code>hub</code>, return true.\n-     *          Otherwise return false.\n-     * @param ctx\n-     *          Callback context\n-     */\n-    public void isHubAlive(HubInfo hub, Callback<Boolean> callback, Object ctx);\n-\n-    /**\n-     * Choose a least loaded hub server from available hub servers.\n-     *\n-     * @param callback\n-     *          Callback to return least loaded hub server.\n-     * @param ctx\n-     *          Callback context.\n-     */\n-    public void chooseLeastLoadedHub(Callback<HubInfo> callback, Object ctx);\n-\n-    /**\n-     * Try to rebalance the load within the cluster. This function will get\n-     * the {@link HubLoad} from all available hubs within the cluster, and then\n-     * shed additional load.\n-     *\n-     * @param tolerancePercentage\n-     *          the percentage of load above average that is permissible.\n-     * @param maxLoadToShed\n-     *          the maximum amount of load to shed per call.\n-     * @param callback\n-     *          Callback indicating whether we reduced load or not.\n-     * @param ctx\n-     */\n-    public void rebalanceCluster(double tolerancePercentage, HubLoad maxLoadToShed,\n-                                 Callback<Boolean> callback, Object ctx);\n-}"},{"sha":"65cc9c4da1a60a22d91fea500bd4d89d17880911","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","status":"removed","additions":0,"deletions":0,"changes":0,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/MMTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"2a0dcc04b09f8694c86063b6427650ab72c8519c","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","status":"removed","additions":0,"deletions":151,"changes":151,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicBasedLoadShedder.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"4ed2e59e04214200ab330ac40a6bb0323ac63782","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","status":"removed","additions":0,"deletions":107,"changes":107,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"b0fe2c9f152726ae14f4961c9338e92f9a45dea5","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicOwnershipChangeListener.java","status":"removed","additions":0,"deletions":28,"changes":28,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicOwnershipChangeListener.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicOwnershipChangeListener.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TopicOwnershipChangeListener.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"6b3a417621c376ac245ec29f399093277bc9bcce","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/TrivialOwnAllTopicManager.java","status":"removed","additions":0,"deletions":58,"changes":58,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TrivialOwnAllTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TrivialOwnAllTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/TrivialOwnAllTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"9651058394eae394c3c7b1f5c62f96f1a3f3d8a4","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","status":"removed","additions":0,"deletions":470,"changes":470,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkHubServerManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"2424d27fb85d414cd772755c23eb1a0b15640898","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","status":"removed","additions":0,"deletions":345,"changes":345,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/topics/ZkTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"b708ab9f8dd1d617b437be7404a17b1eadbea11f","filename":"hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsynBKCallback.java","status":"removed","additions":0,"deletions":104,"changes":104,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsynBKCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsynBKCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsynBKCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"11ca3ff1e4b60a27fab7f7003e38dbdf380e0f06","filename":"hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncCallback.java","status":"removed","additions":0,"deletions":35,"changes":35,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"4e519f3b75db24c95967990a32c39227264bd876","filename":"hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncZKCallback.java","status":"removed","additions":0,"deletions":98,"changes":98,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncZKCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncZKCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/SafeAsyncZKCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"d3dcfd6755c353feb7b830a346464a7c94ff6fc8","filename":"hedwig-server/src/main/java/org/apache/hedwig/zookeeper/ZkUtils.java","status":"removed","additions":0,"deletions":117,"changes":117,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/ZkUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/ZkUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/zookeeper/ZkUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"129943423fb222d7a9fa659efe3007f3692d0a3b","filename":"hedwig-server/src/main/resources/LICENSE.bin.txt","status":"removed","additions":0,"deletions":302,"changes":302,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/LICENSE.bin.txt","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/LICENSE.bin.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/resources/LICENSE.bin.txt?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"81c576e25f11ca5630fb1d72fe515dff1dc458d2","filename":"hedwig-server/src/main/resources/NOTICE.bin.txt","status":"removed","additions":0,"deletions":40,"changes":40,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/NOTICE.bin.txt","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/NOTICE.bin.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/resources/NOTICE.bin.txt?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"9d6d431bcd25133b2a5b034319d93d34df77a6df","filename":"hedwig-server/src/main/resources/findbugsExclude.xml","status":"removed","additions":0,"deletions":25,"changes":25,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/findbugsExclude.xml","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/findbugsExclude.xml","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/resources/findbugsExclude.xml?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"e7a8bf7e7f6d23bcaacd69c4c4e54671712ac06f","filename":"hedwig-server/src/main/resources/p12.pass","status":"removed","additions":0,"deletions":1,"changes":1,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/p12.pass","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/p12.pass","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/resources/p12.pass?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"b7043b85630c8988c6b20bff335fb6f6589c7621","filename":"hedwig-server/src/main/resources/server.p12","status":"removed","additions":0,"deletions":0,"changes":0,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/server.p12","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/main/resources/server.p12","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/resources/server.p12?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"972e145a8ec327a3b154bdca74ba96e059bc3c5e","filename":"hedwig-server/src/test/java/org/apache/hedwig/HelperMethods.java","status":"removed","additions":0,"deletions":58,"changes":58,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/HelperMethods.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/HelperMethods.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/HelperMethods.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"89790aab4e24530e499e676bfc0db5108ee449e1","filename":"hedwig-server/src/test/java/org/apache/hedwig/StubCallback.java","status":"removed","additions":0,"deletions":51,"changes":51,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/StubCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/StubCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/StubCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"776a7f50a79a4a1470b3f39634d93aefee5ea08b","filename":"hedwig-server/src/test/java/org/apache/hedwig/StubScanCallback.java","status":"removed","additions":0,"deletions":57,"changes":57,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/StubScanCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/StubScanCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/StubScanCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"c206ce41f7603e7fab815d1703bd63717eae6b84","filename":"hedwig-server/src/test/java/org/apache/hedwig/client/TestPubSubClient.java","status":"removed","additions":0,"deletions":708,"changes":708,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/TestPubSubClient.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/TestPubSubClient.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/client/TestPubSubClient.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"6fa34076133dc90b3495637459cbffe4b18284ba","filename":"hedwig-server/src/test/java/org/apache/hedwig/client/TestSubAfterCloseSub.java","status":"removed","additions":0,"deletions":209,"changes":209,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/TestSubAfterCloseSub.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/TestSubAfterCloseSub.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/client/TestSubAfterCloseSub.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"e93ecae64810a8dd79adaac3f22a1e8f92d56b28","filename":"hedwig-server/src/test/java/org/apache/hedwig/client/netty/TestMultiplexing.java","status":"removed","additions":0,"deletions":439,"changes":439,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/netty/TestMultiplexing.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/client/netty/TestMultiplexing.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/client/netty/TestMultiplexing.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"81e03140f96eeea3f5699e63d2b03e876f5c4a50","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/HedwigHubTestBase.java","status":"removed","additions":0,"deletions":192,"changes":192,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigHubTestBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigHubTestBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigHubTestBase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"0a574b6e005cb56606eab546ce018700bd3919ba","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/HedwigRegionTestBase.java","status":"removed","additions":0,"deletions":282,"changes":282,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigRegionTestBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigRegionTestBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/HedwigRegionTestBase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"5ea09907c6799ab1a527013e372a4cd6eb0712b5","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/LoggingExceptionHandler.java","status":"removed","additions":0,"deletions":35,"changes":35,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/LoggingExceptionHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/LoggingExceptionHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/LoggingExceptionHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"02d1f4651b7e18a1e191d3e6143d502ed49a698b","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/PubSubServerStandAloneTestBase.java","status":"removed","additions":0,"deletions":98,"changes":98,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/PubSubServerStandAloneTestBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/PubSubServerStandAloneTestBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/PubSubServerStandAloneTestBase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"0150a11fab97397dc64cb28312e53ceb8995724b","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/TestBackwardCompat.java","status":"removed","additions":0,"deletions":1320,"changes":1320,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/TestBackwardCompat.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/TestBackwardCompat.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/TestBackwardCompat.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"632ea43429e8da5871a19bcc2efa11eb23657f7c","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/TestPubSubServerStartup.java","status":"removed","additions":0,"deletions":138,"changes":138,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/TestPubSubServerStartup.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/TestPubSubServerStartup.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/TestPubSubServerStartup.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"978649a4597aa1fdd980f415f33ae6ed902d5412","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/delivery/StubDeliveryManager.java","status":"removed","additions":0,"deletions":90,"changes":90,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/StubDeliveryManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/StubDeliveryManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/StubDeliveryManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"ebc26f13f7a32d26588c2fd4519a28f732b01bf4","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestFIFODeliveryManager.java","status":"removed","additions":0,"deletions":298,"changes":298,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestFIFODeliveryManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestFIFODeliveryManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestFIFODeliveryManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"46c0c17758af78a9dd540af9baa96effbb8791c4","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestThrottlingDelivery.java","status":"removed","additions":0,"deletions":375,"changes":375,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestThrottlingDelivery.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestThrottlingDelivery.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/delivery/TestThrottlingDelivery.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"8e9b8f6689a235dc8c68f2b75fb13e400c2c84c7","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/filter/TestMessageFilter.java","status":"removed","additions":0,"deletions":415,"changes":415,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/filter/TestMessageFilter.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/filter/TestMessageFilter.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/filter/TestMessageFilter.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"4a5c63d4b35b6848c6cc90dd0ff6838482be2fd9","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestBaseHandler.java","status":"removed","additions":0,"deletions":116,"changes":116,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestBaseHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestBaseHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestBaseHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"93f5c2e720cea96656117dedde47891f10f8ba17","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestSubUnsubHandler.java","status":"removed","additions":0,"deletions":178,"changes":178,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestSubUnsubHandler.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestSubUnsubHandler.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/handlers/TestSubUnsubHandler.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"1867f9c27d52dd309eadf5d0078e6b267686a25e","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHub.java","status":"removed","additions":0,"deletions":777,"changes":777,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHub.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHub.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHub.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"64e5b4ed3690d6fdf14781eafb470e2e1578e0f6","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubProxy.java","status":"removed","additions":0,"deletions":36,"changes":36,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubProxy.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubProxy.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubProxy.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"2e370c0136e69109eee0e47a857211c61ef3a94e","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubRegular.java","status":"removed","additions":0,"deletions":36,"changes":36,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubRegular.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubRegular.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubRegular.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"98d36b6e9b217d0be9b19fc246e285daf5a4b380","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubSSL.java","status":"removed","additions":0,"deletions":36,"changes":36,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubSSL.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubSSL.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigHubSSL.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"bce41e57525dc593e9fe65a45e32004b99ee0cfc","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigRegion.java","status":"removed","additions":0,"deletions":304,"changes":304,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigRegion.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigRegion.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/integration/TestHedwigRegion.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"644500d056d171fd6b9084aae9e0202cbc7acab3","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/meta/MetadataManagerFactoryTestCase.java","status":"removed","additions":0,"deletions":78,"changes":78,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/MetadataManagerFactoryTestCase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/MetadataManagerFactoryTestCase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/meta/MetadataManagerFactoryTestCase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"7e15135e0bc087f1494e1beb7b63b97f39d8a02e","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestFactoryLayout.java","status":"removed","additions":0,"deletions":83,"changes":83,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestFactoryLayout.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestFactoryLayout.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestFactoryLayout.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"7e395e944ca4b6d0c97f799cd070e2b4afab4b1e","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManager.java","status":"removed","additions":0,"deletions":365,"changes":365,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"8b9016aeb7d0fa9e7bfbc4d010cbd70add9f74cc","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManagerFactory.java","status":"removed","additions":0,"deletions":299,"changes":299,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManagerFactory.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManagerFactory.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/meta/TestMetadataManagerFactory.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"241f45bbcb88e54f96be30c222ab1a9c6b65924b","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestPubSubServer.java","status":"removed","additions":0,"deletions":265,"changes":265,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestPubSubServer.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestPubSubServer.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestPubSubServer.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"08f5ad88ea458673118a5bc7159e0e888959d64a","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestServerStats.java","status":"removed","additions":0,"deletions":41,"changes":41,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestServerStats.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestServerStats.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/netty/TestServerStats.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"91cf2fe2054e2863c325e46024962a8ae122225c","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/netty/WriteRecordingChannel.java","status":"removed","additions":0,"deletions":175,"changes":175,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/WriteRecordingChannel.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/netty/WriteRecordingChannel.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/netty/WriteRecordingChannel.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"b71d037ee0df3932e9246ac6e80d745d94677d78","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/BookKeeperTestBase.java","status":"removed","additions":0,"deletions":267,"changes":267,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/BookKeeperTestBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/BookKeeperTestBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/BookKeeperTestBase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"08f287c0f53279e1d23dc9deac5ecfefa33d727a","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/MessageBoundedPersistenceTest.java","status":"removed","additions":0,"deletions":288,"changes":288,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/MessageBoundedPersistenceTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/MessageBoundedPersistenceTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/MessageBoundedPersistenceTest.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"827677f14094a13cb8a28bad559897e3e1adfbc0","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubPersistenceManager.java","status":"removed","additions":0,"deletions":137,"changes":137,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubPersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubPersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubPersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"e9fbd0877559952f14a665127964fad6bdbb6aa0","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubScanCallback.java","status":"removed","additions":0,"deletions":48,"changes":48,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubScanCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubScanCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/StubScanCallback.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"d65750bb200e6e2e6020bac1e9cfb270abdc94b3","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManager.java","status":"removed","additions":0,"deletions":798,"changes":798,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"1f30b5b3ef54ba436b2121dc42a9a8a7b19f0b0a","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManagerBlackBox.java","status":"removed","additions":0,"deletions":79,"changes":79,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManagerBlackBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManagerBlackBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookKeeperPersistenceManagerBlackBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"da2b06cd190aefb30bc035e422217f87b79c63ec","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookkeeperPersistenceManagerWhiteBox.java","status":"removed","additions":0,"deletions":355,"changes":355,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookkeeperPersistenceManagerWhiteBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookkeeperPersistenceManagerWhiteBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookkeeperPersistenceManagerWhiteBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"90c1817af6e68e221e3ecc241b7dbe658a8f1a41","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestDeadlock.java","status":"removed","additions":0,"deletions":276,"changes":276,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestDeadlock.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestDeadlock.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestDeadlock.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"856eab4610678893f81371bb1f883320a42a8ab7","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestLocalDBPersistenceManagerBlackBox.java","status":"removed","additions":0,"deletions":53,"changes":53,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestLocalDBPersistenceManagerBlackBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestLocalDBPersistenceManagerBlackBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestLocalDBPersistenceManagerBlackBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"52a5874fd36b23c64dcee361bd8d39d9314fdc04","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestPersistenceManagerBlackBox.java","status":"removed","additions":0,"deletions":305,"changes":305,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestPersistenceManagerBlackBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestPersistenceManagerBlackBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestPersistenceManagerBlackBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"2e59a8a2e43e37cca7768efb5f9061593ddf6a20","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheBlackBox.java","status":"removed","additions":0,"deletions":57,"changes":57,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheBlackBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheBlackBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheBlackBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"ae080052a8c53717d286770568e0978708b62c49","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","status":"removed","additions":0,"deletions":302,"changes":302,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"26b2ce3417d5f35d5b82d42ab888287076c281cb","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/StubSubscriptionManager.java","status":"removed","additions":0,"deletions":55,"changes":55,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/StubSubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/StubSubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/StubSubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"0e0f670fdcd32dfba2587be95ca1467cf0229752","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestMMSubscriptionManager.java","status":"removed","additions":0,"deletions":214,"changes":214,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestMMSubscriptionManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestMMSubscriptionManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestMMSubscriptionManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"d5569de4f17430d75e0eee0e3d3b7108576bba2c","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestUpdateSubscriptionState.java","status":"removed","additions":0,"deletions":250,"changes":250,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestUpdateSubscriptionState.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestUpdateSubscriptionState.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/subscriptions/TestUpdateSubscriptionState.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"b66196e69b56c9a2c0190dc0ebcdb2b0a2655053","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/StubTopicManager.java","status":"removed","additions":0,"deletions":64,"changes":64,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/StubTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/StubTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/StubTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"04fb4519f562766f95bdafa91e98e69387fb7dd0","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestConcurrentTopicAcquisition.java","status":"removed","additions":0,"deletions":208,"changes":208,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestConcurrentTopicAcquisition.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestConcurrentTopicAcquisition.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestConcurrentTopicAcquisition.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"77c6fad49e0d2195d2ef1a16c0b457a4fec21bd6","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubInfo.java","status":"removed","additions":0,"deletions":62,"changes":62,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubInfo.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"f14d6014e5221e67ec86b2255086c43eff7750f1","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubLoad.java","status":"removed","additions":0,"deletions":60,"changes":60,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubLoad.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubLoad.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestHubLoad.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"c75ff05d60ce55ef222a4c948827beb2ba40ba21","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestMMTopicManager.java","status":"removed","additions":0,"deletions":354,"changes":354,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestMMTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestMMTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestMMTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"a54d0d45629c505f84563d516638689e9f997dee","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","status":"removed","additions":0,"deletions":194,"changes":194,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestTopicBasedLoadShedder.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"90e77b2d168e16e41ccac7f0c82e1c4e8c58e628","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestZkTopicManager.java","status":"removed","additions":0,"deletions":376,"changes":376,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestZkTopicManager.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestZkTopicManager.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/topics/TestZkTopicManager.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"e025e769f688af8afb1c880ecfc1696fadbc3924","filename":"hedwig-server/src/test/java/org/apache/hedwig/zookeeper/TestZkUtils.java","status":"removed","additions":0,"deletions":47,"changes":47,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/TestZkUtils.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/TestZkUtils.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/TestZkUtils.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"4213059af0fb2cfedc21b1cfe7d1684637735846","filename":"hedwig-server/src/test/java/org/apache/hedwig/zookeeper/ZooKeeperTestBase.java","status":"removed","additions":0,"deletions":94,"changes":94,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/ZooKeeperTestBase.java","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/ZooKeeperTestBase.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/zookeeper/ZooKeeperTestBase.java?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"5983f0b5c3e6cef951dcca084e24ea62711ed60f","filename":"hedwig-server/src/test/resources/log4j.properties","status":"removed","additions":0,"deletions":72,"changes":72,"blob_url":"https://github.com/apache/bookkeeper/blob/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/resources/log4j.properties","raw_url":"https://github.com/apache/bookkeeper/raw/410ff7263a477d4b75a43d006adde3549225a4b9/hedwig-server/src/test/resources/log4j.properties","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/resources/log4j.properties?ref=410ff7263a477d4b75a43d006adde3549225a4b9"},{"sha":"3b8b233aeddfbdf33b9f3d767414cec788e479a9","filename":"pom.xml","status":"modified","additions":1,"deletions":10,"changes":11,"blob_url":"https://github.com/apache/bookkeeper/blob/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5/pom.xml","raw_url":"https://github.com/apache/bookkeeper/raw/9a8d62b1d1231f2fe6feca7e0c407a426a1278d5/pom.xml","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/pom.xml?ref=9a8d62b1d1231f2fe6feca7e0c407a426a1278d5"}]}

