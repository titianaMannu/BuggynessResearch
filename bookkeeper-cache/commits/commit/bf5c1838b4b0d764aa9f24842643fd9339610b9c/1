{"sha":"bf5c1838b4b0d764aa9f24842643fd9339610b9c","node_id":"MDY6Q29tbWl0MTU3NTk1NjpiZjVjMTgzOGI0YjBkNzY0YWE5ZjI0ODQyNjQzZmQ5MzM5NjEwYjlj","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-10-22T14:21:28Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-10-22T14:21:28Z"},"message":"BOOKKEEPER-659: LRU page management in ledger cache. (Aniruddha, Robin Dhamankar & sijie via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1534640 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"0fdd91807a28bf458a476a4e83cb884d6a36989d","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/0fdd91807a28bf458a476a4e83cb884d6a36989d"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/bf5c1838b4b0d764aa9f24842643fd9339610b9c","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/bf5c1838b4b0d764aa9f24842643fd9339610b9c","html_url":"https://github.com/apache/bookkeeper/commit/bf5c1838b4b0d764aa9f24842643fd9339610b9c","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/bf5c1838b4b0d764aa9f24842643fd9339610b9c/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"9602c32f16184e10873d53c269e270e3cd0ebeed","url":"https://api.github.com/repos/apache/bookkeeper/commits/9602c32f16184e10873d53c269e270e3cd0ebeed","html_url":"https://github.com/apache/bookkeeper/commit/9602c32f16184e10873d53c269e270e3cd0ebeed"}],"stats":{"total":1292,"additions":843,"deletions":449},"files":[{"sha":"f9c036b3ed142af4bf9f79afcb71f5e0d640999c","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -114,6 +114,8 @@ Trunk (unreleased changes)\n \n         BOOKKEEPER-688: NPE exception in PerChannelBookieClient (ivank via sijie)\n \n+        BOOKKEEPER-659: LRU page management in ledger cache. (Aniruddha, Robin Dhamankar & sijie via ivank)\n+\n       hedwig-server:\n \n         BOOKKEEPER-601: readahead cache size isn't updated correctly (sijie via fpj)"},{"sha":"f7384c9090142703657ceec19db0e04ec6956568","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","status":"modified","additions":9,"deletions":6,"changes":15,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -35,6 +35,8 @@\n import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.Future;\n import java.util.concurrent.TimeUnit;\n@@ -114,15 +116,15 @@\n     BookieBean jmxBookieBean;\n     BKMBeanInfo jmxLedgerStorageBean;\n \n-    Map<Long, byte[]> masterKeyCache = Collections.synchronizedMap(new HashMap<Long, byte[]>());\n+    final ConcurrentMap<Long, byte[]> masterKeyCache = new ConcurrentHashMap<Long, byte[]>();\n \n     final private String zkBookieRegPath;\n \n     final private AtomicBoolean readOnly = new AtomicBoolean(false);\n \n     public static class NoLedgerException extends IOException {\n         private static final long serialVersionUID = 1L;\n-        private long ledgerId;\n+        private final long ledgerId;\n         public NoLedgerException(long ledgerId) {\n             super(\"Ledger \" + ledgerId + \" not found\");\n             this.ledgerId = ledgerId;\n@@ -133,8 +135,8 @@ public long getLedgerId() {\n     }\n     public static class NoEntryException extends IOException {\n         private static final long serialVersionUID = 1L;\n-        private long ledgerId;\n-        private long entryId;\n+        private final long ledgerId;\n+        private final long entryId;\n         public NoEntryException(long ledgerId, long entryId) {\n             this(\"Entry \" + entryId + \" not found in \" + ledgerId, ledgerId, entryId);\n         }\n@@ -885,8 +887,9 @@ private LedgerDescriptor getLedgerForEntry(ByteBuffer entry, byte[] masterKey)\n             bb.put(masterKey);\n             bb.flip();\n \n-            journal.logAddEntry(bb, new NopWriteCallback(), null);\n-            masterKeyCache.put(ledgerId, masterKey);\n+            if (null == masterKeyCache.putIfAbsent(ledgerId, masterKey)) {\n+                journal.logAddEntry(bb, new NopWriteCallback(), null);\n+            }\n         }\n         return l;\n     }"},{"sha":"ca751a8c8a30013b704545e9b88ab1e410a72911","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","status":"modified","additions":1,"deletions":2,"changes":3,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -859,8 +859,7 @@ protected void readLedgerIndexEntries(long ledgerId) throws IOException {\n         lep.usePage();\n         try {\n             while (curSize < size) {\n-                lep.setLedger(ledgerId);\n-                lep.setFirstEntry(curEntry);\n+                lep.setLedgerAndFirstEntry(ledgerId, curEntry);\n                 lep.readPage(fi);\n \n                 // process a page"},{"sha":"8dc68b88a780a31b53f3972285a1b5a32a168af3","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","status":"modified","additions":6,"deletions":4,"changes":10,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BufferedChannel.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -28,8 +28,10 @@\n /**\n  * Provides a buffering layer in front of a FileChannel.\n  */\n-public class BufferedChannel\n-{\n+public class BufferedChannel {\n+\n+    static final byte zeroPage[] = new byte[64 * 1024];\n+\n     ByteBuffer writeBuffer;\n     ByteBuffer readBuffer;\n     private FileChannel bc;\n@@ -193,15 +195,15 @@ synchronized public int read(ByteBuffer buff, long pos) throws IOException {\n                 if (readBufferStartPosition + readBuffer.capacity() >= writeBufferStartPosition) {\n                     readBufferStartPosition = writeBufferStartPosition - readBuffer.capacity();\n                     if (readBufferStartPosition < 0) {\n-                        readBuffer.put(LedgerEntryPage.zeroPage, 0, (int)-readBufferStartPosition);\n+                        readBuffer.put(zeroPage, 0, (int) -readBufferStartPosition);\n                     }\n                 }\n                 while(readBuffer.remaining() > 0) {\n                     if (bc.read(readBuffer, readBufferStartPosition+readBuffer.position()) <= 0) {\n                         throw new IOException(\"Short read\");\n                     }\n                 }\n-                readBuffer.put(LedgerEntryPage.zeroPage, 0, readBuffer.remaining());\n+                readBuffer.put(zeroPage, 0, readBuffer.remaining());\n                 readBuffer.clear();\n             }\n         }"},{"sha":"0107d7a1e6248516369310a15dd9aa65e8ba6fab","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryKey.java","status":"added","additions":83,"deletions":0,"changes":83,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryKey.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryKey.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryKey.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -0,0 +1,83 @@\n+/**\n+ * Copyright The Apache Software Foundation\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.io.Serializable;\n+import java.util.Comparator;\n+\n+public class EntryKey {\n+    long ledgerId;\n+    long entryId;\n+\n+    public EntryKey() {\n+        this(0, 0);\n+    }\n+\n+    public EntryKey(long ledgerId, long entryId) {\n+        this.ledgerId = ledgerId;\n+        this.entryId = entryId;\n+    }\n+\n+    public long getLedgerId() {\n+        return ledgerId;\n+    }\n+\n+    public long getEntryId() {\n+        return entryId;\n+    }\n+\n+    /**\n+    * Comparator for the key portion\n+    */\n+    public static final KeyComparator COMPARATOR = new KeyComparator();\n+\n+    // Only compares the key portion\n+    @Override\n+    public boolean equals(Object other) {\n+        if (!(other instanceof EntryKey)) {\n+          return false;\n+        }\n+        EntryKey key = (EntryKey)other;\n+        return ledgerId == key.ledgerId &&\n+            entryId == key.entryId;\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+        return (int)(ledgerId * 13 ^ entryId * 17);\n+    }\n+}\n+\n+/**\n+* Compare EntryKey.\n+*/\n+class KeyComparator implements Comparator<EntryKey>, Serializable {\n+\n+    private static final long serialVersionUID = 0L;\n+\n+    @Override\n+    public int compare(EntryKey left, EntryKey right) {\n+        long ret = left.ledgerId - right.ledgerId;\n+        if (ret == 0) {\n+            ret = left.entryId - right.entryId;\n+        }\n+        return (ret < 0)? -1 : ((ret > 0)? 1 : 0);\n+    }\n+}"},{"sha":"f96627b1f2d35ba56012ed26710468e2ee037f0e","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","status":"modified","additions":61,"deletions":49,"changes":110,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -29,6 +29,7 @@\n import java.nio.BufferUnderflowException;\n import java.nio.ByteBuffer;\n import java.nio.channels.FileChannel;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n@@ -71,7 +72,7 @@\n \n     static final long START_OF_DATA = 1024;\n     private long size;\n-    private int useCount;\n+    private AtomicInteger useCount = new AtomicInteger(0);\n     private boolean isClosed;\n     private long sizeSinceLastwrite;\n \n@@ -144,7 +145,7 @@ synchronized private void checkOpen(boolean create) throws IOException {\n             throw new IOException(lf + \" not found\");\n         }\n \n-        if (!exists) { \n+        if (!exists) {\n             if (create) {\n                 // delayed the creation of parents directories\n                 checkParents(lf);\n@@ -221,18 +222,23 @@ synchronized public long size() throws IOException {\n         return rc;\n     }\n \n-    synchronized public int read(ByteBuffer bb, long position) throws IOException {\n+    public int read(ByteBuffer bb, long position) throws IOException {\n         return readAbsolute(bb, position + START_OF_DATA);\n     }\n \n     private int readAbsolute(ByteBuffer bb, long start) throws IOException {\n         checkOpen(false);\n-        if (fc == null) {\n-            return 0;\n+        synchronized (this) {\n+            if (fc == null) {\n+                return 0;\n+            }\n         }\n         int total = 0;\n+        int rc = 0;\n         while(bb.remaining() > 0) {\n-            int rc = fc.read(bb, start);\n+            synchronized (this) {\n+                rc = fc.read(bb, start);\n+            }\n             if (rc <= 0) {\n                 throw new IOException(\"Short read\");\n             }\n@@ -253,7 +259,7 @@ private int readAbsolute(ByteBuffer bb, long start) throws IOException {\n     synchronized public void close(boolean force) throws IOException {\n         isClosed = true;\n         checkOpen(force);\n-        if (useCount == 0 && fc != null) {\n+        if (useCount.get() == 0 && fc != null) {\n             fc.close();\n         }\n     }\n@@ -288,49 +294,51 @@ synchronized public long write(ByteBuffer[] buffs, long position) throws IOExcep\n      */\n     public synchronized void moveToNewLocation(File newFile, long size) throws IOException {\n         checkOpen(false);\n-        if (fc != null) {\n-            if (size > fc.size()) {\n-                size = fc.size();\n-            }\n-            File rlocFile = new File(newFile.getParentFile(), newFile.getName() + IndexPersistenceMgr.RLOC);\n-            if (!rlocFile.exists()) {\n-                checkParents(rlocFile);\n-                if (!rlocFile.createNewFile()) {\n-                    throw new IOException(\"Creating new cache index file \" + rlocFile + \" failed \");\n-                }\n+        // If the channel is null, or same file path, just return.\n+        if (null == fc || isSameFile(newFile)) {\n+            return;\n+        }\n+        if (size > fc.size()) {\n+            size = fc.size();\n+        }\n+        File rlocFile = new File(newFile.getParentFile(), newFile.getName() + IndexPersistenceMgr.RLOC);\n+        if (!rlocFile.exists()) {\n+            checkParents(rlocFile);\n+            if (!rlocFile.createNewFile()) {\n+                throw new IOException(\"Creating new cache index file \" + rlocFile + \" failed \");\n             }\n-            // copy contents from old.idx to new.idx.rloc\n-            FileChannel newFc = new RandomAccessFile(rlocFile, \"rw\").getChannel();\n-            try {\n-                long written = 0;\n-                while (written < size) {\n-                    long count = fc.transferTo(written, size, newFc);\n-                    if (count <= 0) {\n-                        throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n-                    }\n-                    written += count;\n-                }\n-                if (written <= 0 && size > 0) {\n+        }\n+        // copy contents from old.idx to new.idx.rloc\n+        FileChannel newFc = new RandomAccessFile(rlocFile, \"rw\").getChannel();\n+        try {\n+            long written = 0;\n+            while (written < size) {\n+                long count = fc.transferTo(written, size, newFc);\n+                if (count <= 0) {\n                     throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n                 }\n-            } finally {\n-                newFc.force(true);\n-                newFc.close();\n+                written += count;\n             }\n-            // delete old.idx\n-            fc.close();\n-            if (!delete()) {\n-                LOG.error(\"Failed to delete the previous index file \" + lf);\n-                throw new IOException(\"Failed to delete the previous index file \" + lf);\n+            if (written <= 0 && size > 0) {\n+                throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n             }\n+        } finally {\n+            newFc.force(true);\n+            newFc.close();\n+        }\n+        // delete old.idx\n+        fc.close();\n+        if (!delete()) {\n+            LOG.error(\"Failed to delete the previous index file \" + lf);\n+            throw new IOException(\"Failed to delete the previous index file \" + lf);\n+        }\n \n-            // rename new.idx.rloc to new.idx\n-            if (!rlocFile.renameTo(newFile)) {\n-                LOG.error(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n-                throw new IOException(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n-            }\n-            fc = new RandomAccessFile(newFile, mode).getChannel();\n+        // rename new.idx.rloc to new.idx\n+        if (!rlocFile.renameTo(newFile)) {\n+            LOG.error(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n+            throw new IOException(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n         }\n+        fc = new RandomAccessFile(newFile, mode).getChannel();\n         lf = newFile;\n     }\n \n@@ -339,18 +347,18 @@ public synchronized void moveToNewLocation(File newFile, long size) throws IOExc\n         return masterKey;\n     }\n \n-    synchronized public void use() {\n-        useCount++;\n+    public void use() {\n+        useCount.incrementAndGet();\n     }\n \n     @VisibleForTesting\n-    synchronized int getUseCount() {\n-        return useCount;\n+    int getUseCount() {\n+        return useCount.get();\n     }\n \n     synchronized public void release() {\n-        useCount--;\n-        if (isClosed && useCount == 0 && fc != null) {\n+        int count = useCount.decrementAndGet();\n+        if (isClosed && (count == 0) && fc != null) {\n             try {\n                 fc.close();\n             } catch (IOException e) {\n@@ -372,4 +380,8 @@ static final private void checkParents(File f) throws IOException {\n             throw new IOException(\"Counldn't mkdirs for \" + parent);\n         }\n     }\n+\n+    public boolean isSameFile(File f) {\n+        return this.lf.equals(f);\n+    }\n }"},{"sha":"45be76397a02b1e32df02eb0a8b16d50ebdd7e00","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/HandleFactoryImpl.java","status":"modified","additions":18,"deletions":16,"changes":34,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/HandleFactoryImpl.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/HandleFactoryImpl.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/HandleFactoryImpl.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -22,12 +22,13 @@\n package org.apache.bookkeeper.bookie;\n \n import java.io.IOException;\n-import java.util.HashMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n \n class HandleFactoryImpl implements HandleFactory {\n-    HashMap<Long, LedgerDescriptor> ledgers = new HashMap<Long, LedgerDescriptor>();\n-    HashMap<Long, LedgerDescriptor> readOnlyLedgers\n-        = new HashMap<Long, LedgerDescriptor>();\n+    ConcurrentMap<Long, LedgerDescriptor> ledgers = new ConcurrentHashMap<Long, LedgerDescriptor>();\n+    ConcurrentMap<Long, LedgerDescriptor> readOnlyLedgers\n+        = new ConcurrentHashMap<Long, LedgerDescriptor>();\n \n     final LedgerStorage ledgerStorage;\n \n@@ -39,28 +40,29 @@\n     public LedgerDescriptor getHandle(long ledgerId, byte[] masterKey)\n             throws IOException, BookieException {\n         LedgerDescriptor handle = null;\n-        synchronized (ledgers) {\n-            handle = ledgers.get(ledgerId);\n-            if (handle == null) {\n-                handle = LedgerDescriptor.create(masterKey, ledgerId, ledgerStorage);\n-                ledgers.put(ledgerId, handle);\n+        if (null == (handle = ledgers.get(ledgerId))) {\n+            // LedgerDescriptor#create sets the master key in the ledger storage, calling it\n+            // twice on the same ledgerId is safe because it eventually puts a value in the ledger cache\n+            // that guarantees synchronized access across all cached entries.\n+            handle = ledgers.putIfAbsent(ledgerId, LedgerDescriptor.create(masterKey, ledgerId, ledgerStorage));\n+            if (null == handle) {\n+                handle = ledgers.get(ledgerId);\n             }\n-            handle.checkAccess(masterKey);\n         }\n+        handle.checkAccess(masterKey);\n         return handle;\n     }\n \n     @Override\n     public LedgerDescriptor getReadOnlyHandle(long ledgerId)\n             throws IOException, Bookie.NoLedgerException {\n         LedgerDescriptor handle = null;\n-        synchronized (ledgers) {\n-            handle = readOnlyLedgers.get(ledgerId);\n-            if (handle == null) {\n-                handle = LedgerDescriptor.createReadOnly(ledgerId, ledgerStorage);\n-                readOnlyLedgers.put(ledgerId, handle);\n+        if (null == (handle = readOnlyLedgers.get(ledgerId))) {\n+            handle = readOnlyLedgers.putIfAbsent(ledgerId, LedgerDescriptor.createReadOnly(ledgerId, ledgerStorage));\n+            if (null == handle) {\n+                handle = readOnlyLedgers.get(ledgerId);\n             }\n         }\n         return handle;\n     }\n-}\n\\ No newline at end of file\n+}"},{"sha":"56487aac26d4811b8adf09cec935a62c3cfc582c","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","status":"modified","additions":348,"deletions":205,"changes":553,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexInMemPageMgr.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -20,28 +20,293 @@\n  */\n package org.apache.bookkeeper.bookie;\n \n+import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n import java.io.IOException;\n import java.util.ArrayList;\n-import java.util.HashMap;\n+import java.util.Collections;\n import java.util.Iterator;\n+import java.util.LinkedHashMap;\n import java.util.LinkedList;\n import java.util.List;\n import java.util.Map;\n-\n-import org.apache.bookkeeper.conf.ServerConfiguration;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ConcurrentSkipListSet;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n class IndexInMemPageMgr {\n     private final static Logger LOG = LoggerFactory.getLogger(IndexInMemPageMgr.class);\n+    private final static ConcurrentHashMap<Long, LedgerEntryPage> EMPTY_PAGE_MAP\n+        = new ConcurrentHashMap<Long, LedgerEntryPage>();\n+\n+    private static class InMemPageCollection implements LEPStateChangeCallback {\n+\n+        ConcurrentMap<Long, ConcurrentMap<Long,LedgerEntryPage>> pages;\n+\n+        Map<EntryKey, LedgerEntryPage> lruCleanPageMap;\n+\n+        public InMemPageCollection() {\n+            pages = new ConcurrentHashMap<Long, ConcurrentMap<Long,LedgerEntryPage>>();\n+            lruCleanPageMap =\n+                Collections.synchronizedMap(new LinkedHashMap<EntryKey, LedgerEntryPage>(16, 0.75f, true));\n+        }\n+\n+        /**\n+         * Retrieve the LedgerEntryPage corresponding to the ledger and firstEntry\n+         *\n+         * @param ledgerId\n+         *          Ledger id\n+         * @param firstEntry\n+         *          Id of the first entry in the page\n+         * @returns LedgerEntryPage if present\n+         */\n+        private LedgerEntryPage getPage(long ledgerId, long firstEntry) {\n+            ConcurrentMap<Long, LedgerEntryPage> map = pages.get(ledgerId);\n+            if (null != map) {\n+                return map.get(firstEntry);\n+            }\n+            return null;\n+        }\n+\n+        /**\n+         * Add a LedgerEntryPage to the page map\n+         *\n+         * @param lep\n+         *          Ledger Entry Page object\n+         */\n+        private LedgerEntryPage putPage(LedgerEntryPage lep) {\n+            // Do a get here to avoid too many new ConcurrentHashMaps() as putIntoTable is called frequently.\n+            ConcurrentMap<Long, LedgerEntryPage> map = pages.get(lep.getLedger());\n+            if (null == map) {\n+                ConcurrentMap<Long, LedgerEntryPage> mapToPut = new ConcurrentHashMap<Long, LedgerEntryPage>();\n+                map = pages.putIfAbsent(lep.getLedger(), mapToPut);\n+                if (null == map) {\n+                    map = mapToPut;\n+                }\n+            }\n+            LedgerEntryPage oldPage = map.putIfAbsent(lep.getFirstEntry(), lep);\n+            if (null == oldPage) {\n+                oldPage = lep;\n+                // Also include this in the clean page map if it qualifies.\n+                // Note: This is done for symmetry and correctness, however it should never\n+                // get exercised since we shouldn't attempt a put without the page being in use\n+                addToCleanPagesList(lep);\n+            }\n+            return oldPage;\n+        }\n+\n+        /**\n+         * Traverse the pages for a given ledger in memory and find the highest\n+         * entry amongst these pages\n+         *\n+         * @param ledgerId\n+         *          Ledger id\n+         * @returns last entry in the in memory pages\n+         */\n+        private long getLastEntryInMem(long ledgerId) {\n+            long lastEntry = 0;\n+            // Find the last entry in the cache\n+            ConcurrentMap<Long, LedgerEntryPage> map = pages.get(ledgerId);\n+            if (map != null) {\n+                for(LedgerEntryPage lep: map.values()) {\n+                    if (lep.getMaxPossibleEntry() < lastEntry) {\n+                        continue;\n+                    }\n+                    lep.usePage();\n+                    long highest = lep.getLastEntry();\n+                    if (highest > lastEntry) {\n+                        lastEntry = highest;\n+                    }\n+                    lep.releasePage();\n+                }\n+            }\n+            return lastEntry;\n+        }\n+\n+        /**\n+         * Removes ledger entry pages for a given ledger\n+         *\n+         * @param ledgerId\n+         *          Ledger id\n+         * @returns number of pages removed\n+         */\n+        private int removeEntriesForALedger(long ledgerId) {\n+            // remove pages first to avoid page flushed when deleting file info\n+            ConcurrentMap<Long, LedgerEntryPage> lPages = pages.remove(ledgerId);\n+            if (null != lPages) {\n+                for (long entryId: lPages.keySet()) {\n+                    synchronized(lruCleanPageMap) {\n+                        lruCleanPageMap.remove(new EntryKey(ledgerId, entryId));\n+                    }\n+                }\n+                return lPages.size();\n+            }\n+            return 0;\n+        }\n+\n+        /**\n+         * Gets the list of pages in memory that have been changed and hence need to\n+         * be written as a part of the flush operation that is being issued\n+         *\n+         * @param ledgerId\n+         *          Ledger id\n+         * @returns last entry in the in memory pages.\n+         */\n+        private LinkedList<Long> getFirstEntryListToBeFlushed(long ledgerId) {\n+            ConcurrentMap<Long, LedgerEntryPage> pageMap = pages.get(ledgerId);\n+            if (pageMap == null || pageMap.isEmpty()) {\n+                return null;\n+            }\n+\n+            LinkedList<Long> firstEntryList = new LinkedList<Long>();\n+            for(ConcurrentMap.Entry<Long, LedgerEntryPage> entry: pageMap.entrySet()) {\n+                LedgerEntryPage lep = entry.getValue();\n+                if (lep.isClean()) {\n+                    if (!lep.inUse()) {\n+                        addToCleanPagesList(lep);\n+                    }\n+                    if (LOG.isTraceEnabled()) {\n+                        LOG.trace(\"Page is clean \" + lep);\n+                    }\n+                } else {\n+                    firstEntryList.add(lep.getFirstEntry());\n+                }\n+            }\n+            return firstEntryList;\n+        }\n+\n+        /**\n+         * Add the LedgerEntryPage to the clean page LRU map\n+         *\n+         * @param lep\n+         *          Ledger Entry Page object\n+         */\n+        private void addToCleanPagesList(LedgerEntryPage lep) {\n+            synchronized(lruCleanPageMap) {\n+                if (lep.isClean() && !lep.inUse()) {\n+                    lruCleanPageMap.put(lep.getEntryKey(), lep);\n+                }\n+            }\n+        }\n+\n+        /**\n+         * Remove the LedgerEntryPage from the clean page LRU map\n+         *\n+         * @param lep\n+         *          Ledger Entry Page object\n+         */\n+        private void removeFromCleanPageList(LedgerEntryPage lep) {\n+            synchronized(lruCleanPageMap) {\n+                if (!lep.isClean() || lep.inUse()) {\n+                    lruCleanPageMap.remove(lep.getEntryKey());\n+                }\n+            }\n+        }\n+\n+        /**\n+         * Get the set of active ledgers\n+         *\n+         */\n+        Set<Long> getActiveLedgers() {\n+            return pages.keySet();\n+        }\n+\n+        /**\n+         * Get a clean page and provision it for the specified ledger and firstEntry within\n+         * the ledger\n+         *\n+         * @param ledgerId\n+         *          Ledger id\n+         * @param firstEntry\n+         *          Id of the first entry in the page\n+         * @returns LedgerEntryPage if present\n+         */\n+        LedgerEntryPage grabCleanPage(long ledgerId, long firstEntry) {\n+            LedgerEntryPage lep = null;\n+            while (lruCleanPageMap.size() > 0) {\n+                lep = null;\n+                synchronized(lruCleanPageMap) {\n+                    Iterator<Map.Entry<EntryKey,LedgerEntryPage>> iterator = lruCleanPageMap.entrySet().iterator();\n+\n+                    Map.Entry<EntryKey,LedgerEntryPage> entry = null;\n+                    while (iterator.hasNext())\n+                    {\n+                        entry = iterator.next();\n+                        iterator.remove();\n+                        if (entry.getValue().isClean() &&\n+                                !entry.getValue().inUse()) {\n+                            lep = entry.getValue();\n+                            break;\n+                        }\n+                    }\n+\n+                    if (null == lep) {\n+                        LOG.debug(\"Did not find eligible page in the first pass\");\n+                        return null;\n+                    }\n+                }\n+\n+                // We found a candidate page, lets see if we can reclaim it before its re-used\n+                ConcurrentMap<Long, LedgerEntryPage> pageMap = pages.get(lep.getLedger());\n+                // Remove from map only if nothing has changed since we checked this lep.\n+                // Its possible for the ledger to have been deleted or the page to have already\n+                // been reclaimed. The page map is the definitive source of information, if anything\n+                // has changed we should leave this page along and continue iterating to find\n+                // another suitable page.\n+                if ((null != pageMap) && (pageMap.remove(lep.getFirstEntry(), lep))) {\n+                    if (!lep.isClean()) {\n+                        // Someone wrote to this page while we were reclaiming it.\n+                        pageMap.put(lep.getFirstEntry(), lep);\n+                        lep = null;\n+                    } else {\n+                        // Do some bookkeeping on the page table\n+                        pages.remove(lep.getLedger(), EMPTY_PAGE_MAP);\n+                        // We can now safely reset this lep and return it.\n+                        lep.usePage();\n+                        lep.zeroPage();\n+                        lep.setLedgerAndFirstEntry(ledgerId, firstEntry);\n+                        return lep;\n+                    }\n+                } else {\n+                    lep = null;\n+                }\n+            }\n+            return lep;\n+        }\n+\n+        @Override\n+        public void onSetInUse(LedgerEntryPage lep) {\n+            removeFromCleanPageList(lep);\n+        }\n+\n+        @Override\n+        public void onResetInUse(LedgerEntryPage lep) {\n+            addToCleanPagesList(lep);\n+        }\n+\n+        @Override\n+        public void onSetClean(LedgerEntryPage lep) {\n+            addToCleanPagesList(lep);\n+        }\n+\n+        @Override\n+        public void onSetDirty(LedgerEntryPage lep) {\n+            removeFromCleanPageList(lep);\n+        }\n+    }\n \n     final int pageSize;\n-    final int pageLimit;\n     final int entriesPerPage;\n-    final HashMap<Long, HashMap<Long, LedgerEntryPage>> pages;\n+    final int pageLimit;\n+    final InMemPageCollection pageMapAndList;\n \n     // The number of pages that have actually been used\n-    private int pageCount = 0;\n+    private final AtomicInteger pageCount = new AtomicInteger(0);\n \n     // The persistence manager that this page manager uses to\n     // flush and read pages\n@@ -50,20 +315,17 @@\n     /**\n      * the list of potentially dirty ledgers\n      */\n-    LinkedList<Long> dirtyLedgers = new LinkedList<Long>();\n-    /**\n-     * the list of potentially clean ledgers\n-     */\n-    LinkedList<Long> cleanLedgers = new LinkedList<Long>();\n+    private final ConcurrentLinkedQueue<Long> ledgersToFlush = new ConcurrentLinkedQueue<Long>();\n+    private final ConcurrentSkipListSet<Long> ledgersFlushing = new ConcurrentSkipListSet<Long>();\n \n     public IndexInMemPageMgr(int pageSize,\n                              int entriesPerPage,\n-                             ServerConfiguration conf, \n+                             ServerConfiguration conf,\n                              IndexPersistenceMgr indexPersistenceManager) {\n         this.pageSize = pageSize;\n         this.entriesPerPage = entriesPerPage;\n         this.indexPersistenceManager = indexPersistenceManager;\n-        this.pages = new HashMap<Long, HashMap<Long, LedgerEntryPage>>();\n+        this.pageMapAndList = new InMemPageCollection();\n \n         if (conf.getPageLimit() <= 0) {\n             // allocate half of the memory to the page cache\n@@ -100,51 +362,21 @@ public int getPageLimit() {\n      * @return number of page used in ledger cache\n      */\n     public int getNumUsedPages() {\n-        return pageCount;\n-    }\n-\n-    public int getNumCleanLedgers() {\n-        return cleanLedgers.size();\n+        return pageCount.get();\n     }\n \n-    public int getNumDirtyLedgers() {\n-        return dirtyLedgers.size();\n-    }\n-\n-    private void putIntoTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table, LedgerEntryPage lep) {\n-        HashMap<Long, LedgerEntryPage> map = table.get(lep.getLedger());\n-        if (map == null) {\n-            map = new HashMap<Long, LedgerEntryPage>();\n-            table.put(lep.getLedger(), map);\n-        }\n-        map.put(lep.getFirstEntry(), lep);\n-    }\n-\n-    private static LedgerEntryPage getFromTable(HashMap<Long, HashMap<Long,LedgerEntryPage>> table,\n-                                                Long ledger, Long firstEntry) {\n-        HashMap<Long, LedgerEntryPage> map = table.get(ledger);\n-        if (map != null) {\n-            return map.get(firstEntry);\n-        }\n-        return null;\n-    }\n-\n-    synchronized protected LedgerEntryPage getLedgerEntryPage(Long ledger, Long firstEntry, boolean onlyDirty) {\n-        LedgerEntryPage lep = getFromTable(pages, ledger, firstEntry);\n-        if (lep == null) {\n+    LedgerEntryPage getLedgerEntryPage(Long ledger, Long firstEntry, boolean onlyDirty) {\n+        LedgerEntryPage lep = pageMapAndList.getPage(ledger, firstEntry);\n+        if (onlyDirty && null != lep && lep.isClean()) {\n             return null;\n         }\n-\n-        lep.usePage();\n-\n-        if (onlyDirty && lep.isClean()) {\n-            return null;\n-        } else {\n-            return lep;\n+        if (null != lep) {\n+            lep.usePage();\n         }\n+        return lep;\n     }\n \n-    /** \n+    /**\n      * Grab ledger entry page whose first entry is <code>pageEntry</code>.\n      *\n      * If the page doesn't existed before, we allocate a memory page.\n@@ -158,198 +390,108 @@ synchronized protected LedgerEntryPage getLedgerEntryPage(Long ledger, Long firs\n     private LedgerEntryPage grabLedgerEntryPage(long ledger, long pageEntry) throws IOException {\n         LedgerEntryPage lep = grabCleanPage(ledger, pageEntry);\n         try {\n-            // should update page before we put it into table\n-            // otherwise we would put an empty page in it\n+            // should get the up to date page from the persistence manager\n+            // before we put it into table otherwise we would put\n+            // an empty page in it\n             indexPersistenceManager.updatePage(lep);\n-            synchronized (this) {\n-                putIntoTable(pages, lep);\n+            LedgerEntryPage oldLep;\n+            if (lep != (oldLep = pageMapAndList.putPage(lep))) {\n+                lep.releasePage();\n+                // Decrement the page count because we couldn't put this lep in the page cache.\n+                pageCount.decrementAndGet();\n+                // Increment the use count of the old lep because this is unexpected\n+                oldLep.usePage();\n+                lep = oldLep;\n             }\n         } catch (IOException ie) {\n             // if we grab a clean page, but failed to update the page\n             // we are exhausting the count of ledger entry pages.\n             // since this page will be never used, so we need to decrement\n             // page count of ledger cache.\n             lep.releasePage();\n-            synchronized (this) {\n-                --pageCount;\n-            }\n+            pageCount.decrementAndGet();\n             throw ie;\n         }\n         return lep;\n     }\n \n     void removePagesForLedger(long ledgerId) {\n-        // remove pages first to avoid page flushed when deleting file info\n-        synchronized (this) {\n-            Map<Long, LedgerEntryPage> lpages = pages.remove(ledgerId);\n-            if (null != lpages) {\n-                pageCount -= lpages.size();\n-                if (pageCount < 0) {\n-                    LOG.error(\"Page count of ledger cache has been decremented to be less than zero.\");\n-                }\n-            }\n+        int removedPageCount = pageMapAndList.removeEntriesForALedger(ledgerId);\n+        if (pageCount.addAndGet(-removedPageCount) < 0) {\n+            throw new RuntimeException(\"Page count of ledger cache has been decremented to be less than zero.\");\n         }\n+        ledgersToFlush.remove(ledgerId);\n     }\n \n     long getLastEntryInMem(long ledgerId) {\n-        long lastEntry = 0;\n-        // Find the last entry in the cache\n-        synchronized (this) {\n-            Map<Long, LedgerEntryPage> map = pages.get(ledgerId);\n-            if (map != null) {\n-                for (LedgerEntryPage lep : map.values()) {\n-                    if (lep.getFirstEntry() + entriesPerPage < lastEntry) {\n-                        continue;\n-                    }\n-                    lep.usePage();\n-                    long highest = lep.getLastEntry();\n-                    if (highest > lastEntry) {\n-                        lastEntry = highest;\n-                    }\n-                    lep.releasePage();\n-                }\n-            }\n-        }\n-        return lastEntry;\n+        return pageMapAndList.getLastEntryInMem(ledgerId);\n     }\n \n     private LedgerEntryPage grabCleanPage(long ledger, long entry) throws IOException {\n         if (entry % entriesPerPage != 0) {\n             throw new IllegalArgumentException(entry + \" is not a multiple of \" + entriesPerPage);\n         }\n-        outerLoop: while (true) {\n-            synchronized (this) {\n-                if (pageCount < pageLimit) {\n-                    // let's see if we can allocate something\n-                    LedgerEntryPage lep = new LedgerEntryPage(pageSize, entriesPerPage);\n-                    lep.setLedger(ledger);\n-                    lep.setFirstEntry(entry);\n-\n-                    // note, this will not block since it is a new page\n-                    lep.usePage();\n-                    pageCount++;\n-                    return lep;\n-                }\n+\n+        while(true) {\n+            boolean canAllocate = false;\n+            if (pageCount.incrementAndGet() <= pageLimit) {\n+                canAllocate = true;\n+            } else {\n+                pageCount.decrementAndGet();\n             }\n \n-            synchronized (cleanLedgers) {\n-                if (cleanLedgers.isEmpty()) {\n-                    flushOneOrMoreLedgers(false);\n-                    synchronized (this) {\n-                        for (Long l : pages.keySet()) {\n-                            cleanLedgers.add(l);\n-                        }\n-                    }\n-                }\n-                synchronized (this) {\n-                    // if ledgers deleted between checking pageCount and putting\n-                    // ledgers into cleanLedgers list, the cleanLedgers list would be empty.\n-                    // so give it a chance to go back to check pageCount again because\n-                    // deleteLedger would decrement pageCount to return the number of pages\n-                    // occupied by deleted ledgers.\n-                    if (cleanLedgers.isEmpty()) {\n-                        continue outerLoop;\n-                    }\n-                    Long cleanLedger = cleanLedgers.getFirst();\n-                    Map<Long, LedgerEntryPage> map = pages.get(cleanLedger);\n-                    while (map == null || map.isEmpty()) {\n-                        cleanLedgers.removeFirst();\n-                        if (cleanLedgers.isEmpty()) {\n-                            continue outerLoop;\n-                        }\n-                        cleanLedger = cleanLedgers.getFirst();\n-                        map = pages.get(cleanLedger);\n-                    }\n-                    Iterator<Map.Entry<Long, LedgerEntryPage>> it = map.entrySet().iterator();\n-                    LedgerEntryPage lep = it.next().getValue();\n-                    while ((lep.inUse() || !lep.isClean())) {\n-                        if (!it.hasNext()) {\n-                            // no clean page found in this ledger\n-                            cleanLedgers.removeFirst();\n-                            continue outerLoop;\n-                        }\n-                        lep = it.next().getValue();\n-                    }\n-                    it.remove();\n-                    if (map.isEmpty()) {\n-                        pages.remove(lep.getLedger());\n-                    }\n-                    lep.usePage();\n-                    lep.zeroPage();\n-                    lep.setLedger(ledger);\n-                    lep.setFirstEntry(entry);\n-                    return lep;\n-                }\n+            if (canAllocate) {\n+                LedgerEntryPage lep = new LedgerEntryPage(pageSize, entriesPerPage, pageMapAndList);\n+                lep.setLedgerAndFirstEntry(ledger, entry);\n+                lep.usePage();\n+                return lep;\n+            }\n+\n+            LedgerEntryPage lep = pageMapAndList.grabCleanPage(ledger, entry);\n+            if (null != lep) {\n+                return lep;\n             }\n+            LOG.info(\"Could not grab a clean page for ledger {}, entry {}, force flushing dirty ledgers.\",\n+                    ledger, entry);\n+            flushOneOrMoreLedgers(false);\n         }\n     }\n \n     void flushOneOrMoreLedgers(boolean doAll) throws IOException {\n-        synchronized (dirtyLedgers) {\n-            if (dirtyLedgers.isEmpty()) {\n-                synchronized (this) {\n-                    for (Long l : pages.keySet()) {\n-                        if (LOG.isTraceEnabled()) {\n-                            LOG.trace(\"Adding {} to dirty pages\", Long.toHexString(l));\n-                        }\n-                        dirtyLedgers.add(l);\n-                    }\n-                }\n+        if (ledgersToFlush.isEmpty()) {\n+            ledgersToFlush.addAll(pageMapAndList.getActiveLedgers());\n+        }\n+        Long potentiallyDirtyLedger;\n+        while (null != (potentiallyDirtyLedger = ledgersToFlush.poll())) {\n+            if (!ledgersFlushing.add(potentiallyDirtyLedger)) {\n+                continue;\n             }\n-            if (dirtyLedgers.isEmpty()) {\n-                return;\n+            try {\n+                flushSpecificLedger(potentiallyDirtyLedger);\n+            } finally {\n+                ledgersFlushing.remove(potentiallyDirtyLedger);\n             }\n-\n-            indexPersistenceManager.relocateIndexFileIfDirFull(dirtyLedgers);\n-\n-            while (!dirtyLedgers.isEmpty()) {\n-                Long l = dirtyLedgers.removeFirst();\n-\n-                flushSpecificLedger(l);\n-\n-                if (!doAll) {\n-                    break;\n-                }\n-                // Yield. if we are doing all the ledgers we don't want to block other flushes that\n-                // need to happen\n-                try {\n-                    dirtyLedgers.wait(1);\n-                } catch (InterruptedException e) {\n-                    // just pass it on\n-                    Thread.currentThread().interrupt();\n-                }\n+            if (!doAll) {\n+                break;\n             }\n         }\n     }\n \n     /**\n      * Flush a specified ledger\n      *\n-     * @param l \n+     * @param ledger\n      *          Ledger Id\n      * @throws IOException\n      */\n-    private void flushSpecificLedger(long l) throws IOException {\n-        LinkedList<Long> firstEntryList;\n-        synchronized(this) {\n-            HashMap<Long, LedgerEntryPage> pageMap = pages.get(l);\n-            if (pageMap == null || pageMap.isEmpty()) {\n-                indexPersistenceManager.flushLedgerHeader(l);\n-                return;\n-            }\n-            firstEntryList = new LinkedList<Long>();\n-            for(Map.Entry<Long, LedgerEntryPage> entry: pageMap.entrySet()) {\n-                LedgerEntryPage lep = entry.getValue();\n-                if (lep.isClean()) {\n-                    LOG.trace(\"Page is clean {}\", lep);\n-                    continue;\n-                }\n-                firstEntryList.add(lep.getFirstEntry());\n-            }\n-        }\n+    private void flushSpecificLedger(long ledger) throws IOException {\n+        LinkedList<Long> firstEntryList = pageMapAndList.getFirstEntryListToBeFlushed(ledger);\n+\n+        // flush ledger index file header if necessary\n+        indexPersistenceManager.flushLedgerHeader(ledger);\n \n-        if (firstEntryList.size() == 0) {\n-            LOG.debug(\"Nothing to flush for ledger {}.\", l);\n+        if (null == firstEntryList || firstEntryList.size() == 0) {\n+            LOG.debug(\"Nothing to flush for ledger {}.\", ledger);\n             // nothing to do\n             return;\n         }\n@@ -358,12 +500,12 @@ private void flushSpecificLedger(long l) throws IOException {\n         List<LedgerEntryPage> entries = new ArrayList<LedgerEntryPage>(firstEntryList.size());\n         try {\n             for(Long firstEntry: firstEntryList) {\n-                LedgerEntryPage lep = getLedgerEntryPage(l, firstEntry, true);\n+                LedgerEntryPage lep = getLedgerEntryPage(ledger, firstEntry, true);\n                 if (lep != null) {\n                     entries.add(lep);\n                 }\n             }\n-            indexPersistenceManager.flushLedgerEntries(l, entries);\n+            indexPersistenceManager.flushLedgerEntries(ledger, entries);\n         } finally {\n             for(LedgerEntryPage lep: entries) {\n                 lep.releasePage();\n@@ -380,7 +522,8 @@ void putEntryOffset(long ledger, long entry, long offset) throws IOException {\n         if (lep == null) {\n             lep = grabLedgerEntryPage(ledger, pageEntry);\n         }\n-        lep.setOffset(offset, offsetInPage * 8);\n+        assert lep != null;\n+        lep.setOffset(offset, offsetInPage * LedgerEntryPage.getIndexEntrySize());\n         lep.releasePage();\n     }\n \n@@ -394,7 +537,7 @@ long getEntryOffset(long ledger, long entry) throws IOException {\n             if (lep == null) {\n                 lep = grabLedgerEntryPage(ledger, pageEntry);\n             }\n-            return lep.getOffset(offsetInPage * 8);\n+            return lep.getOffset(offsetInPage * LedgerEntryPage.getIndexEntrySize());\n         } finally {\n             if (lep != null) {\n                 lep.releasePage();"},{"sha":"ada717342b45e45d38d82ec35c94f57390a9564d","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","status":"modified","additions":105,"deletions":102,"changes":207,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/IndexPersistenceMgr.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -23,15 +23,13 @@\n import java.io.File;\n import java.io.IOException;\n import java.nio.ByteBuffer;\n-import java.util.ArrayList;\n-import java.util.Collection;\n import java.util.Collections;\n import java.util.Comparator;\n-import java.util.HashMap;\n import java.util.LinkedList;\n import java.util.List;\n import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n \n import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;\n import org.apache.bookkeeper.bookie.LedgerDirsManager.NoWritableLedgerDirException;\n@@ -62,7 +60,7 @@ public static final String getLedgerName(long ledgerId) {\n         return sb.toString();\n     }\n \n-    final HashMap<Long, FileInfo> fileInfoCache = new HashMap<Long, FileInfo>();\n+    final ConcurrentMap<Long, FileInfo> fileInfoCache = new ConcurrentHashMap<Long, FileInfo>();\n     final int openFileLimit;\n     final int pageSize;\n     final int entriesPerPage;\n@@ -72,7 +70,6 @@ public static final String getLedgerName(long ledgerId) {\n     final SnapshotMap<Long, Boolean> activeLedgers;\n     private LedgerDirsManager ledgerDirsManager;\n     final LinkedList<Long> openLedgers = new LinkedList<Long>();\n-    final private AtomicBoolean shouldRelocateIndexFile = new AtomicBoolean(false);\n \n     public IndexPersistenceMgr(int pageSize,\n                                int entriesPerPage,\n@@ -91,30 +88,53 @@ public IndexPersistenceMgr(int pageSize,\n     }\n \n     FileInfo getFileInfo(Long ledger, byte masterKey[]) throws IOException {\n-        synchronized (fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledger);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledger);\n-                if (lf == null) {\n-                    if (masterKey == null) {\n+        FileInfo fi = fileInfoCache.get(ledger);\n+        if (null == fi) {\n+            boolean createdNewFile = false;\n+            File lf = null;\n+            synchronized (this) {\n+                // Check if the index file exists on disk.\n+                lf = findIndexFile(ledger);\n+                if (null == lf) {\n+                    if (null == masterKey) {\n                         throw new Bookie.NoLedgerException(ledger);\n                     }\n+                    // We don't have a ledger index file on disk, so create it.\n                     lf = getNewLedgerIndexFile(ledger, null);\n-                    // A new ledger index file has been created for this Bookie.\n-                    // Add this new ledger to the set of active ledgers.\n-                    LOG.debug(\"New ledger index file created for ledgerId: {}\", ledger);\n-                    activeLedgers.put(ledger, true);\n+                    createdNewFile = true;\n                 }\n-                evictFileInfoIfNecessary();\n-                fi = new FileInfo(lf, masterKey);\n-                fileInfoCache.put(ledger, fi);\n-                openLedgers.add(ledger);\n             }\n-            if (fi != null) {\n-                fi.use();\n+            fi = putFileInfo(ledger, masterKey, lf, createdNewFile);\n+        }\n+\n+        assert null != fi;\n+        fi.use();\n+        return fi;\n+    }\n+\n+    private FileInfo putFileInfo(Long ledger, byte masterKey[], File lf, boolean createdNewFile) throws IOException {\n+        FileInfo fi = new FileInfo(lf, masterKey);\n+        FileInfo oldFi = fileInfoCache.putIfAbsent(ledger, fi);\n+        if (null != oldFi) {\n+            // Some other thread won the race. We should delete our file if we created\n+            // a new one and the paths are different.\n+            if (createdNewFile && !oldFi.isSameFile(lf)) {\n+                fi.delete();\n+            }\n+            fi = oldFi;\n+        } else {\n+            if (createdNewFile) {\n+                // Else, we won and the active ledger manager should know about this.\n+                LOG.debug(\"New ledger index file created for ledgerId: {}\", ledger);\n+                activeLedgers.put(ledger, true);\n+            }\n+            // Evict cached items from the file info cache if necessary\n+            evictFileInfoIfNecessary();\n+            synchronized (openLedgers) {\n+                openLedgers.offer(ledger);\n             }\n-            return fi;\n         }\n+        return fi;\n     }\n \n     /**\n@@ -205,10 +225,7 @@ void removeLedger(long ledgerId) throws IOException {\n         activeLedgers.remove(ledgerId);\n \n         // Now remove it from all the other lists and maps.\n-        // These data structures need to be synchronized first before removing entries.\n-        synchronized (fileInfoCache) {\n-            fileInfoCache.remove(ledgerId);\n-        }\n+        fileInfoCache.remove(ledgerId);\n         synchronized (openLedgers) {\n             openLedgers.remove(ledgerId);\n         }\n@@ -226,13 +243,11 @@ private File findIndexFile(long ledgerId) throws IOException {\n     }\n \n     boolean ledgerExists(long ledgerId) throws IOException {\n-        synchronized (fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledgerId);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledgerId);\n-                if (lf == null) {\n-                    return false;\n-                }\n+        FileInfo fi = fileInfoCache.get(ledgerId);\n+        if (fi == null) {\n+            File lf = findIndexFile(ledgerId);\n+            if (lf == null) {\n+                return false;\n             }\n         }\n         return true;\n@@ -244,45 +259,47 @@ int getNumOpenLedgers() {\n \n     // evict file info if necessary\n     private void evictFileInfoIfNecessary() throws IOException {\n-        synchronized (fileInfoCache) {\n-            if (openLedgers.size() > openFileLimit) {\n-                long ledgerToRemove = openLedgers.removeFirst();\n-                // TODO Add a statistic here, we don't care really which\n-                // ledger is evicted, but the rate at which they get evicted \n-                fileInfoCache.remove(ledgerToRemove).close(true);\n+        if (openLedgers.size() > openFileLimit) {\n+            Long ledgerToRemove;\n+            synchronized (openLedgers) {\n+                ledgerToRemove = openLedgers.poll();\n             }\n-        }\n+            if (null == ledgerToRemove) {\n+                // Should not reach here. We probably cleared this while the thread\n+                // was executing.\n+                return;\n+            }\n+            // TODO Add a statistic here, we don't care really which\n+            // ledger is evicted, but the rate at which they get evicted\n+            FileInfo fi = fileInfoCache.remove(ledgerToRemove);\n+            if (null == fi) {\n+                // Seems like someone else already closed the file.\n+                return;\n+            }\n+            fi.close(true);\n+         }\n     }\n \n     void close() throws IOException {\n-        synchronized (fileInfoCache) {\n-            for (Entry<Long, FileInfo> fileInfo : fileInfoCache.entrySet()) {\n-                FileInfo value = fileInfo.getValue();\n-                if (value != null) {\n-                    value.close(true);\n-                }\n+        for (Entry<Long, FileInfo> fileInfo : fileInfoCache.entrySet()) {\n+            FileInfo value = fileInfo.getValue();\n+            if (value != null) {\n+                value.close(true);\n             }\n-            fileInfoCache.clear();\n         }\n+        fileInfoCache.clear();\n     }\n \n     byte[] readMasterKey(long ledgerId) throws IOException, BookieException {\n-        synchronized (fileInfoCache) {\n-            FileInfo fi = fileInfoCache.get(ledgerId);\n-            if (fi == null) {\n-                File lf = findIndexFile(ledgerId);\n-                if (lf == null) {\n-                    throw new Bookie.NoLedgerException(ledgerId);\n-                }\n-                evictFileInfoIfNecessary();\n-                fi = new FileInfo(lf, null);\n-                byte[] key = fi.getMasterKey();\n-                fileInfoCache.put(ledgerId, fi);\n-                openLedgers.add(ledgerId);\n-                return key;\n-            }\n-            return fi.getMasterKey();\n+        FileInfo fi = fileInfoCache.get(ledgerId);\n+        if (fi == null) {\n+            File lf = findIndexFile(ledgerId);\n+            if (lf == null) {\n+                throw new Bookie.NoLedgerException(ledgerId);\n+            }\n+            fi = putFileInfo(ledgerId, null, lf, false);\n         }\n+        return fi.getMasterKey();\n     }\n \n     void setMasterKey(long ledgerId, byte[] masterKey) throws IOException {\n@@ -328,9 +345,7 @@ private LedgerDirsListener getLedgerDirsListener() {\n         return new LedgerDirsListener() {\n             @Override\n             public void diskFull(File disk) {\n-                // If the current entry log disk is full, then create new entry\n-                // log.\n-                shouldRelocateIndexFile.set(true);\n+                // Nothing to handle here. Will be handled in Bookie\n             }\n \n             @Override\n@@ -350,26 +365,12 @@ public void fatalError() {\n         };\n     }\n \n-    void relocateIndexFileIfDirFull(Collection<Long> dirtyLedgers) throws IOException {\n-        if (shouldRelocateIndexFile.get()) {\n-            // if some new dir detected as full, then move all corresponding\n-            // open index files to new location\n-            for (Long l : dirtyLedgers) {\n-                FileInfo fi = null;\n-                try {\n-                    fi = getFileInfo(l, null);\n-                    File currentDir = getLedgerDirForLedger(fi);\n-                    if (ledgerDirsManager.isDirFull(currentDir)) {\n-                        moveLedgerIndexFile(l, fi);\n-                    }\n-                } finally {\n-                    if (null != fi) {\n-                        fi.release();\n-                    }\n-                }\n-            }\n-            shouldRelocateIndexFile.set(false);\n+    private void relocateIndexFileAndFlushHeader(long ledger, FileInfo fi) throws IOException {\n+        File currentDir = getLedgerDirForLedger(fi);\n+        if (ledgerDirsManager.isDirFull(currentDir)) {\n+            moveLedgerIndexFile(ledger, fi);\n         }\n+        fi.flushHeader();\n     }\n \n     /**\n@@ -391,16 +392,16 @@ void flushLedgerHeader(long ledger) throws IOException {\n         FileInfo fi = null;\n         try {\n             fi = getFileInfo(ledger, null);\n-            fi.flushHeader();\n+            relocateIndexFileAndFlushHeader(ledger, fi);\n         } catch (Bookie.NoLedgerException nle) {\n             // ledger has been deleted\n+            LOG.info(\"No ledger {} found when flushing header.\", ledger);\n             return;\n         } finally {\n             if (null != fi) {\n                 fi.release();\n             }\n         }\n-        return;\n     }\n \n     void flushLedgerEntries(long l, List<LedgerEntryPage> entries) throws IOException {\n@@ -412,20 +413,21 @@ public int compare(LedgerEntryPage o1, LedgerEntryPage o2) {\n                     return (int) (o1.getFirstEntry() - o2.getFirstEntry());\n                 }\n             });\n-            ArrayList<Integer> versions = new ArrayList<Integer>(entries.size());\n+            int[] versions = new int[entries.size()];\n             try {\n                 fi = getFileInfo(l, null);\n             } catch (Bookie.NoLedgerException nle) {\n                 // ledger has been deleted\n+                LOG.info(\"No ledger {} found when flushing entries.\", l);\n                 return;\n             }\n \n             // flush the header if necessary\n-            fi.flushHeader();\n+            relocateIndexFileAndFlushHeader(l, fi);\n             int start = 0;\n             long lastOffset = -1;\n             for (int i = 0; i < entries.size(); i++) {\n-                versions.add(i, entries.get(i).getVersion());\n+                versions[i] = entries.get(i).getVersion();\n                 if (lastOffset != -1 && (entries.get(i).getFirstEntry() - lastOffset) != entriesPerPage) {\n                     // send up a sequential list\n                     int count = i - start;\n@@ -441,11 +443,12 @@ public int compare(LedgerEntryPage o1, LedgerEntryPage o2) {\n                 LOG.warn(\"Nothing to write, but there were entries!\");\n             }\n             writeBuffers(l, entries, fi, start, entries.size() - start);\n-            synchronized (this) {\n-                for (int i = 0; i < entries.size(); i++) {\n-                    LedgerEntryPage lep = entries.get(i);\n-                    lep.setClean(versions.get(i));\n-                }\n+            for (int i = 0; i < entries.size(); i++) {\n+                LedgerEntryPage lep = entries.get(i);\n+                lep.setClean(versions[i]);\n+            }\n+            if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"Flushed ledger {} with {} pages.\", l, entries.size());\n             }\n         } finally {\n             if (fi != null) {\n@@ -473,7 +476,7 @@ private void writeBuffers(Long ledger,\n         }\n         long totalWritten = 0;\n         while (buffs[buffs.length - 1].remaining() > 0) {\n-            long rc = fi.write(buffs, entries.get(start + 0).getFirstEntry() * 8);\n+            long rc = fi.write(buffs, entries.get(start + 0).getFirstEntryPosition());\n             if (rc <= 0) {\n                 throw new IOException(\"Short write to ledger \" + ledger + \" rc = \" + rc);\n             }\n@@ -492,7 +495,7 @@ void updatePage(LedgerEntryPage lep) throws IOException {\n         FileInfo fi = null;\n         try {\n             fi = getFileInfo(lep.getLedger(), null);\n-            long pos = lep.getFirstEntry() * 8;\n+            long pos = lep.getFirstEntryPosition();\n             if (pos >= fi.size()) {\n                 lep.zeroPage();\n             } else {\n@@ -513,22 +516,22 @@ long getPersistEntryBeyondInMem(long ledgerId, long lastEntryInMem) throws IOExc\n             long size = fi.size();\n             // make sure the file size is aligned with index entry size\n             // otherwise we may read incorret data\n-            if (0 != size % 8) {\n+            if (0 != size % LedgerEntryPage.getIndexEntrySize()) {\n                 LOG.warn(\"Index file of ledger {} is not aligned with index entry size.\", ledgerId);\n-                size = size - size % 8;\n+                size = size - size % LedgerEntryPage.getIndexEntrySize();\n             }\n             // we may not have the last entry in the cache\n-            if (size > lastEntry * 8) {\n+            if (size > lastEntry * LedgerEntryPage.getIndexEntrySize()) {\n                 ByteBuffer bb = ByteBuffer.allocate(pageSize);\n                 long position = size - pageSize;\n                 if (position < 0) {\n                     position = 0;\n                 }\n                 fi.read(bb, position);\n                 bb.flip();\n-                long startingEntryId = position / 8;\n+                long startingEntryId = position / LedgerEntryPage.getIndexEntrySize();\n                 for (int i = entriesPerPage - 1; i >= 0; i--) {\n-                    if (bb.getLong(i * 8) != 0) {\n+                    if (bb.getLong(i * LedgerEntryPage.getIndexEntrySize()) != 0) {\n                         if (lastEntry < startingEntryId + i) {\n                             lastEntry = startingEntryId + i;\n                         }"},{"sha":"9f4fbc6edb43cb090b97b0496bb1dbc31e79f328","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LEPStateChangeCallback.java","status":"added","additions":31,"deletions":0,"changes":31,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LEPStateChangeCallback.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LEPStateChangeCallback.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LEPStateChangeCallback.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -0,0 +1,31 @@\n+/*\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+/**\n+ * Callback interface when state of ledger entry page changed.\n+ */\n+interface LEPStateChangeCallback {\n+    public void onSetInUse(LedgerEntryPage lep);\n+    public void onResetInUse(LedgerEntryPage lep);\n+    public void onSetClean(LedgerEntryPage lep);\n+    public void onSetDirty(LedgerEntryPage lep);\n+}"},{"sha":"cff9459807b70344bb36f67d0f6dbd810884a4d8","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","status":"modified","additions":0,"deletions":10,"changes":10,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheImpl.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -161,16 +161,6 @@ public int getPageLimit() {\n                 return LedgerCacheImpl.this.indexPageManager.getPageLimit();\n             }\n \n-            @Override\n-            public int getNumCleanLedgers() {\n-                return LedgerCacheImpl.this.indexPageManager.getNumCleanLedgers();\n-            }\n-\n-            @Override\n-            public int getNumDirtyLedgers() {\n-                return LedgerCacheImpl.this.indexPageManager.getNumDirtyLedgers();\n-            }\n-\n             @Override\n             public int getNumOpenLedgers() {\n                 return LedgerCacheImpl.this.indexPersistenceManager.getNumOpenLedgers();"},{"sha":"c24e3489426e0c4c4e985c14e78a5e3e0b7d0edb","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheMXBean.java","status":"modified","additions":0,"deletions":10,"changes":10,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheMXBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheMXBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerCacheMXBean.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -43,16 +43,6 @@\n      */\n     public int getPageLimit();\n \n-    /**\n-     * @return number of clean ledgers\n-     */\n-    public int getNumCleanLedgers();\n-\n-    /**\n-     * @return number of dirty ledgers\n-     */\n-    public int getNumDirtyLedgers();\n-\n     /**\n      * @return number of open ledgers\n      */"},{"sha":"2d6f80d7c162c7f47c923065107c61ebebfc342b","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerEntryPage.java","status":"modified","additions":106,"deletions":45,"changes":151,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerEntryPage.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerEntryPage.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerEntryPage.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -21,30 +21,45 @@\n \n package org.apache.bookkeeper.bookie;\n \n+import org.apache.bookkeeper.proto.BookieProtocol;\n+import org.apache.bookkeeper.util.ZeroBuffer;\n+\n import java.io.IOException;\n import java.nio.ByteBuffer;\n-\n-import org.apache.bookkeeper.proto.BookieProtocol;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n /**\n  * This is a page in the LedgerCache. It holds the locations\n  * (entrylogfile, offset) for entry ids.\n  */\n public class LedgerEntryPage {\n+    private final static int indexEntrySize = 8;\n     private final int pageSize;\n     private final int entriesPerPage;\n-    private long ledger = -1;\n-    private long firstEntry = BookieProtocol.INVALID_ENTRY_ID;\n+    volatile private EntryKey entryKey = new EntryKey(-1, BookieProtocol.INVALID_ENTRY_ID);\n     private final ByteBuffer page;\n-    private boolean clean = true;\n-    private boolean pinned = false;\n-    private int useCount;\n-    private int version;\n+    volatile private boolean clean = true;\n+    private final AtomicInteger useCount = new AtomicInteger();\n+    private final AtomicInteger version = new AtomicInteger(0);\n+    volatile private int last = -1; // Last update position\n+    private final LEPStateChangeCallback callback;\n+\n+    public static int getIndexEntrySize() {\n+        return indexEntrySize;\n+    }\n \n     public LedgerEntryPage(int pageSize, int entriesPerPage) {\n+        this(pageSize, entriesPerPage, null);\n+    }\n+\n+    public LedgerEntryPage(int pageSize, int entriesPerPage, LEPStateChangeCallback callback) {\n         this.pageSize = pageSize;\n         this.entriesPerPage = entriesPerPage;\n         page = ByteBuffer.allocateDirect(pageSize);\n+        this.callback = callback;\n+        if (null != this.callback) {\n+            callback.onResetInUse(this);\n+        }\n     }\n \n     @Override\n@@ -54,32 +69,33 @@ public String toString() {\n         sb.append('@');\n         sb.append(getFirstEntry());\n         sb.append(clean ? \" clean \" : \" dirty \");\n-        sb.append(useCount);\n+        sb.append(useCount.get());\n         return sb.toString();\n     }\n-    synchronized public void usePage() {\n-        useCount++;\n-    }\n-    synchronized public void pin() {\n-        pinned = true;\n-    }\n-    synchronized public void unpin() {\n-        pinned = false;\n-    }\n-    synchronized public boolean isPinned() {\n-        return pinned;\n+\n+    public void usePage() {\n+        int oldVal = useCount.getAndIncrement();\n+        if ((0 == oldVal) && (null != callback)) {\n+            callback.onSetInUse(this);\n+        }\n     }\n-    synchronized public void releasePage() {\n-        useCount--;\n-        if (useCount < 0) {\n+\n+    public void releasePage() {\n+        int newUseCount = useCount.decrementAndGet();\n+        if (newUseCount < 0) {\n             throw new IllegalStateException(\"Use count has gone below 0\");\n         }\n+        if ((null != callback) && (newUseCount == 0)) {\n+            callback.onResetInUse(this);\n+        }\n     }\n-    synchronized private void checkPage() {\n-        if (useCount <= 0) {\n+\n+    private void checkPage() {\n+        if (useCount.get() <= 0) {\n             throw new IllegalStateException(\"Page not marked in use\");\n         }\n     }\n+\n     @Override\n     public boolean equals(Object other) {\n         if (other instanceof LedgerEntryPage) {\n@@ -89,75 +105,120 @@ public boolean equals(Object other) {\n             return false;\n         }\n     }\n+\n     @Override\n     public int hashCode() {\n         return (int)getLedger() ^ (int)(getFirstEntry());\n     }\n+\n     void setClean(int versionOfCleaning) {\n-        this.clean = (versionOfCleaning == version);\n+        this.clean = (versionOfCleaning == version.get());\n+\n+        if ((null != callback) && clean) {\n+            callback.onSetClean(this);\n+        }\n     }\n+\n     boolean isClean() {\n         return clean;\n     }\n+\n     public void setOffset(long offset, int position) {\n         checkPage();\n-        version++;\n-        this.clean = false;\n         page.putLong(position, offset);\n+        version.incrementAndGet();\n+        if (last < position/getIndexEntrySize()) {\n+            last = position/getIndexEntrySize();\n+        }\n+        this.clean = false;\n+\n+        if (null != callback) {\n+            callback.onSetDirty(this);\n+        }\n     }\n+\n     public long getOffset(int position) {\n         checkPage();\n         return page.getLong(position);\n     }\n-    static final byte zeroPage[] = new byte[64*1024];\n+\n     public void zeroPage() {\n         checkPage();\n         page.clear();\n-        page.put(zeroPage, 0, page.remaining());\n+        ZeroBuffer.put(page);\n+        last = -1;\n         clean = true;\n     }\n+\n     public void readPage(FileInfo fi) throws IOException {\n         checkPage();\n         page.clear();\n         while(page.remaining() != 0) {\n-            if (fi.read(page, getFirstEntry()*8) <= 0) {\n-                throw new IOException(\"Short page read of ledger \" + getLedger() + \" tried to get \" + page.capacity() + \" from position \" + getFirstEntry()*8 + \" still need \" + page.remaining());\n+            if (fi.read(page, getFirstEntryPosition()) <= 0) {\n+                throw new IOException(\"Short page read of ledger \" + getLedger()\n+                                + \" tried to get \" + page.capacity() + \" from position \" + getFirstEntryPosition()\n+                                + \" still need \" + page.remaining());\n             }\n         }\n+        last = getLastEntryIndex();\n         clean = true;\n     }\n+\n     public ByteBuffer getPageToWrite() {\n         checkPage();\n         page.clear();\n         return page;\n     }\n-    void setLedger(long ledger) {\n-        this.ledger = ledger;\n-    }\n+\n     long getLedger() {\n-        return ledger;\n+        return entryKey.getLedgerId();\n     }\n+\n     int getVersion() {\n-        return version;\n+        return version.get();\n     }\n-    void setFirstEntry(long firstEntry) {\n+\n+    public EntryKey getEntryKey() {\n+        return entryKey;\n+    }\n+\n+    void setLedgerAndFirstEntry(long ledgerId, long firstEntry) {\n         if (firstEntry % entriesPerPage != 0) {\n             throw new IllegalArgumentException(firstEntry + \" is not a multiple of \" + entriesPerPage);\n         }\n-        this.firstEntry = firstEntry;\n+        this.entryKey = new EntryKey(ledgerId, firstEntry);\n     }\n     long getFirstEntry() {\n-        return firstEntry;\n+        return entryKey.getEntryId();\n     }\n+\n+    long getMaxPossibleEntry() {\n+        return entryKey.getEntryId() + entriesPerPage;\n+    }\n+\n+    long getFirstEntryPosition() {\n+        return entryKey.getEntryId() * indexEntrySize;\n+    }\n+\n     public boolean inUse() {\n-        return useCount > 0;\n+        return useCount.get() > 0;\n     }\n-    public long getLastEntry() {\n+\n+    private int getLastEntryIndex() {\n         for(int i = entriesPerPage - 1; i >= 0; i--) {\n-            if (getOffset(i*8) > 0) {\n-                return i + firstEntry;\n+            if (getOffset(i*getIndexEntrySize()) > 0) {\n+                return i;\n             }\n         }\n-        return 0;\n+        return -1;\n+    }\n+\n+    public long getLastEntry() {\n+        if (last >= 0) {\n+            return last + entryKey.getEntryId();\n+        } else {\n+            int index = getLastEntryIndex();\n+            return index >= 0 ? (index + entryKey.getEntryId()) : 0;\n+        }\n     }\n }"},{"sha":"1109da2b71baf69ae14e9eb69907686055a54d66","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/util/ZeroBuffer.java","status":"added","additions":73,"deletions":0,"changes":73,"blob_url":"https://github.com/apache/bookkeeper/blob/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/util/ZeroBuffer.java","raw_url":"https://github.com/apache/bookkeeper/raw/bf5c1838b4b0d764aa9f24842643fd9339610b9c/bookkeeper-server/src/main/java/org/apache/bookkeeper/util/ZeroBuffer.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/util/ZeroBuffer.java?ref=bf5c1838b4b0d764aa9f24842643fd9339610b9c","patch":"@@ -0,0 +1,73 @@\n+/**\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.bookkeeper.util;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Zero buffer utility.\n+ *\n+ */\n+\n+public class ZeroBuffer {\n+    static final byte zeroBytes[] = new byte[64*1024];\n+\n+    /**\n+     * fill zeros into given buffer\n+     * @param dst\n+     */\n+    public static void put(ByteBuffer dst) {\n+        put(dst, dst.remaining());\n+    }\n+\n+    /**\n+     * fill zeros into given buffer up to given length\n+     * @param dst\n+     * @param length\n+     */\n+    public static void put(ByteBuffer dst, int length) {\n+        while (length > zeroBytes.length) {\n+            dst.put(zeroBytes);\n+            length -= zeroBytes.length;\n+        }\n+        if (length > 0) {\n+            dst.put(zeroBytes, 0, length);\n+        }\n+    }\n+\n+    /**\n+     * returns read-only zero-filled buffer,\n+     * @param length\n+     * @return ByteBuffer\n+     */\n+    public static ByteBuffer readOnlyBuffer(int length) {\n+        ByteBuffer buffer;\n+        if (length <= zeroBytes.length) {\n+            buffer = ByteBuffer.wrap(zeroBytes, 0, length);\n+        }\n+        else {\n+            buffer = ByteBuffer.allocate(length);\n+            put(buffer);\n+        }\n+        return buffer.asReadOnlyBuffer();\n+    }\n+}"}]}

