{"sha":"cc467bd5880c2879e6c0355469d51759f89bbabc","node_id":"MDY6Q29tbWl0MTU3NTk1NjpjYzQ2N2JkNTg4MGMyODc5ZTZjMDM1NTQ2OWQ1MTc1OWY4OWJiYWJj","commit":{"author":{"name":"Flavio Paiva Junqueira","email":"fpj@apache.org","date":"2011-11-11T10:24:19Z"},"committer":{"name":"Flavio Paiva Junqueira","email":"fpj@apache.org","date":"2011-11-11T10:24:19Z"},"message":"BOOKKEEPER-82: support journal rolling (Sijie Guo via fpj)\n\n\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1200806 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"4333d2dc565dd6e7941e8ea432aca3d3b981b4c1","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/4333d2dc565dd6e7941e8ea432aca3d3b981b4c1"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/cc467bd5880c2879e6c0355469d51759f89bbabc","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/cc467bd5880c2879e6c0355469d51759f89bbabc","html_url":"https://github.com/apache/bookkeeper/commit/cc467bd5880c2879e6c0355469d51759f89bbabc","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/cc467bd5880c2879e6c0355469d51759f89bbabc/comments","author":{"login":"fpj","id":572920,"node_id":"MDQ6VXNlcjU3MjkyMA==","avatar_url":"https://avatars.githubusercontent.com/u/572920?v=4","gravatar_id":"","url":"https://api.github.com/users/fpj","html_url":"https://github.com/fpj","followers_url":"https://api.github.com/users/fpj/followers","following_url":"https://api.github.com/users/fpj/following{/other_user}","gists_url":"https://api.github.com/users/fpj/gists{/gist_id}","starred_url":"https://api.github.com/users/fpj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fpj/subscriptions","organizations_url":"https://api.github.com/users/fpj/orgs","repos_url":"https://api.github.com/users/fpj/repos","events_url":"https://api.github.com/users/fpj/events{/privacy}","received_events_url":"https://api.github.com/users/fpj/received_events","type":"User","site_admin":false},"committer":{"login":"fpj","id":572920,"node_id":"MDQ6VXNlcjU3MjkyMA==","avatar_url":"https://avatars.githubusercontent.com/u/572920?v=4","gravatar_id":"","url":"https://api.github.com/users/fpj","html_url":"https://github.com/fpj","followers_url":"https://api.github.com/users/fpj/followers","following_url":"https://api.github.com/users/fpj/following{/other_user}","gists_url":"https://api.github.com/users/fpj/gists{/gist_id}","starred_url":"https://api.github.com/users/fpj/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/fpj/subscriptions","organizations_url":"https://api.github.com/users/fpj/orgs","repos_url":"https://api.github.com/users/fpj/repos","events_url":"https://api.github.com/users/fpj/events{/privacy}","received_events_url":"https://api.github.com/users/fpj/received_events","type":"User","site_admin":false},"parents":[{"sha":"6e3b195d16ef4b24618d7bb13b3eede6b9126e74","url":"https://api.github.com/repos/apache/bookkeeper/commits/6e3b195d16ef4b24618d7bb13b3eede6b9126e74","html_url":"https://github.com/apache/bookkeeper/commit/6e3b195d16ef4b24618d7bb13b3eede6b9126e74"}],"stats":{"total":618,"additions":536,"deletions":82},"files":[{"sha":"c845d48412e1fb06aff78176aba41dc1d7be5d60","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/cc467bd5880c2879e6c0355469d51759f89bbabc/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/cc467bd5880c2879e6c0355469d51759f89bbabc/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=cc467bd5880c2879e6c0355469d51759f89bbabc","patch":"@@ -62,6 +62,8 @@ BUGFIXES:\n \n   BOOKKEEPER-50: NullPointException at LedgerDescriptor#cmpMasterKey (Sijie Guo via ivank)\n \n+  BOOKKEEPER-82: support journal rolling (Sijie Guo via fpj)\n+\n  hedwig-server/\n \n   BOOKKEEPER-43: NullPointException when releasing topic (Sijie Guo via breed)"},{"sha":"3186fc3fc472603bac880de6c2c7b9fd3f2d3b60","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","status":"modified","additions":275,"deletions":81,"changes":356,"blob_url":"https://github.com/apache/bookkeeper/blob/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","raw_url":"https://github.com/apache/bookkeeper/raw/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java?ref=cc467bd5880c2879e6c0355469d51759f89bbabc","patch":"@@ -35,7 +35,9 @@\n import java.util.Collections;\n import java.util.HashMap;\n import java.util.LinkedList;\n+import java.util.List;\n import java.util.concurrent.LinkedBlockingQueue;\n+import java.util.concurrent.atomic.AtomicBoolean;\n \n import org.apache.bookkeeper.bookie.BookieException;\n import org.apache.bookkeeper.proto.BookieServer;\n@@ -57,6 +59,11 @@\n public class Bookie extends Thread {\n     HashMap<Long, LedgerDescriptor> ledgers = new HashMap<Long, LedgerDescriptor>();\n     static Logger LOG = Logger.getLogger(Bookie.class);\n+    final static long MB = 1024 * 1024L;\n+    // max journal file size\n+    final static long MAX_JOURNAL_SIZE = Long.getLong(\"journal_max_size_mb\", 2 * 1024) * MB;\n+    // number journal files kept before marked journal\n+    final static int MAX_BACKUP_JOURNALS = Integer.getInteger(\"journal_max_backups\", 5);\n \n     final File journalDirectory;\n \n@@ -101,8 +108,34 @@ public long getEntry() {\n \n     EntryLogger entryLogger;\n     LedgerCache ledgerCache;\n+    /**\n+     * SyncThread is a background thread which flushes ledger index pages periodically.\n+     * Also it takes responsibility of garbage collecting journal files.\n+     *\n+     * <p>\n+     * Before flushing, SyncThread first records a log marker {journalId, journalPos} in memory,\n+     * which indicates entries before this log marker would be persisted to ledger files.\n+     * Then sync thread begans flush ledger index pages to ledger index files, flush entry\n+     * logger to ensure all entries persisted to entry loggers for future reads.\n+     * </p>\n+     * <p>\n+     * After all data has been persisted to ledger index files and entry loggers, it is safe\n+     * to persist the log marker to disk. If bookie failed after persist log mark,\n+     * bookie is able to relay journal entries started from last log mark without lossing\n+     * any entries.\n+     * </p>\n+     * <p>\n+     * Those journal files whose id are less than the log id in last log mark, could be\n+     * removed safely after persisting last log mark. We provide a setting to let user keeping\n+     * number of old journal files which may be used for munually recovery in critical disaster.\n+     * </p>\n+     */\n     class SyncThread extends Thread {\n         volatile boolean running = true;\n+        // flag to ensure sync thread will not be interrupted during flush\n+        final AtomicBoolean flushing = new AtomicBoolean(false);\n+        // make flush interval as a parameter\n+        final int flushInterval = Integer.getInteger(\"flush_interval\", 100);\n         public SyncThread() {\n             super(\"SyncThread\");\n         }\n@@ -111,7 +144,7 @@ public void run() {\n             while(running) {\n                 synchronized(this) {\n                     try {\n-                        wait(100);\n+                        wait(flushInterval);\n                         if (!entryLogger.testAndClearSomethingWritten()) {\n                             continue;\n                         }\n@@ -120,6 +153,17 @@ public void run() {\n                         continue;\n                     }\n                 }\n+\n+                // try to mark flushing flag to make sure it would not be interrupted\n+                // by shutdown during flushing. otherwise it will receive\n+                // ClosedByInterruptException which may cause index file & entry logger\n+                // closed and corrupted.\n+                if (!flushing.compareAndSet(false, true)) {\n+                    // set flushing flag failed, means flushing is true now\n+                    // indicates another thread wants to interrupt sync thread to exit\n+                    break;\n+                }\n+\n                 lastLogMark.markLog();\n                 try {\n                     ledgerCache.flushLedger(true);\n@@ -132,7 +176,47 @@ public void run() {\n                     LOG.error(\"Exception flushing entry logger\", e);\n                 }\n                 lastLogMark.rollLog();\n+\n+                // list the journals whose has been marked\n+                List<Long> logs = listJournalIds(journalDirectory, new JournalIdFilter() {\n+                    @Override\n+                    public boolean accept(long journalId) {\n+                        if (journalId < lastLogMark.lastMark.txnLogId) {\n+                            return true;\n+                        } else {\n+                            return false;\n+                        }\n+                    }\n+                });\n+\n+                // keep MAX_BACKUP_JOURNALS journal files before marked journal\n+                if (logs.size() >= MAX_BACKUP_JOURNALS) {\n+                    int maxIdx = logs.size() - MAX_BACKUP_JOURNALS;\n+                    for (int i=0; i<maxIdx; i++) {\n+                        long id = logs.get(i);\n+                        // make sure the journal id is smaller than marked journal id\n+                        if (id < lastLogMark.lastMark.txnLogId) {\n+                            File journalFile = new File(journalDirectory, Long.toHexString(id) + \".txn\");\n+                            journalFile.delete();\n+                            LOG.info(\"garbage collected journal \" + journalFile.getName());\n+                        }\n+                    }\n+                }\n+\n+                // clear flushing flag\n+                flushing.set(false);\n+            }\n+        }\n+\n+        // shutdown sync thread\n+        void shutdown() throws InterruptedException {\n+            running = false;\n+            if (flushing.compareAndSet(false, true)) {\n+                // if setting flushing flag succeed, means syncThread is not flushing now\n+                // it is safe to interrupt itself now \n+                this.interrupt();\n             }\n+            this.join();\n         }\n     }\n     SyncThread syncThread = new SyncThread();\n@@ -143,63 +227,75 @@ public Bookie(int port, String zkServers, File journalDirectory, File ledgerDire\n         entryLogger = new EntryLogger(ledgerDirectories, this);\n         ledgerCache = new LedgerCache(ledgerDirectories);\n         lastLogMark.readLog();\n+        if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Last Log Mark : \" + lastLogMark);\n+        }\n         final long markedLogId = lastLogMark.txnLogId;\n-        if (markedLogId > 0) {\n-            File logFiles[] = journalDirectory.listFiles();\n-            ArrayList<Long> logs = new ArrayList<Long>();\n-            for(File f: logFiles) {\n-                String name = f.getName();\n-                if (!name.endsWith(\".txn\")) {\n-                    continue;\n-                }\n-                String idString = name.split(\"\\\\.\")[0];\n-                long id = Long.parseLong(idString, 16);\n-                if (id < markedLogId) {\n-                    continue;\n+        List<Long> logs = listJournalIds(journalDirectory, new JournalIdFilter() {\n+            @Override\n+            public boolean accept(long journalId) {\n+                if (journalId < markedLogId) {\n+                    return false;\n                 }\n-                logs.add(id);\n+                return true;\n             }\n-            Collections.sort(logs);\n+        });\n+        // last log mark may be missed due to no sync up before\n+        // validate filtered log ids only when we have markedLogId\n+        if (markedLogId > 0) {\n             if (logs.size() == 0 || logs.get(0) != markedLogId) {\n                 throw new IOException(\"Recovery log \" + markedLogId + \" is missing\");\n             }\n-            // TODO: When reading in the journal logs that need to be synced, we\n-            // should use BufferedChannels instead to minimize the amount of\n-            // system calls done.\n-            ByteBuffer lenBuff = ByteBuffer.allocate(4);\n-            ByteBuffer recBuff = ByteBuffer.allocate(64*1024);\n-            for(Long id: logs) {\n-                FileChannel recLog = openChannel(id);\n-                while(true) {\n-                    lenBuff.clear();\n-                    fullRead(recLog, lenBuff);\n-                    if (lenBuff.remaining() != 0) {\n-                        break;\n-                    }\n-                    lenBuff.flip();\n-                    int len = lenBuff.getInt();\n-                    if (len == 0) {\n-                        break;\n-                    }\n-                    recBuff.clear();\n-                    if (recBuff.remaining() < len) {\n-                        recBuff = ByteBuffer.allocate(len);\n-                    }\n-                    recBuff.limit(len);\n-                    if (fullRead(recLog, recBuff) != len) {\n-                        // This seems scary, but it just means that this is where we\n-                        // left off writing\n-                        break;\n-                    }\n-                    recBuff.flip();\n-                    long ledgerId = recBuff.getLong();\n-                    LedgerDescriptor handle = getHandle(ledgerId, false);\n-                    try {\n-                        recBuff.rewind();\n-                        handle.addEntry(recBuff);\n-                    } finally {\n-                        putHandle(handle);\n-                    }\n+        }\n+        if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Try to relay journal logs : \" + logs);\n+        }\n+        // TODO: When reading in the journal logs that need to be synced, we\n+        // should use BufferedChannels instead to minimize the amount of\n+        // system calls done.\n+        ByteBuffer lenBuff = ByteBuffer.allocate(4);\n+        ByteBuffer recBuff = ByteBuffer.allocate(64*1024);\n+        for(Long id: logs) {\n+            FileChannel recLog ;\n+            if(id == markedLogId) {\n+              long markedLogPosition = lastLogMark.txnLogPosition;\n+              recLog = openChannel(id, markedLogPosition);\n+            } else {\n+              recLog = openChannel(id);\n+            }\n+\n+            while(true) {\n+                lenBuff.clear();\n+                fullRead(recLog, lenBuff);\n+                if (lenBuff.remaining() != 0) {\n+                    break;\n+                }\n+                lenBuff.flip();\n+                int len = lenBuff.getInt();\n+                if (len == 0) {\n+                    break;\n+                }\n+                recBuff.clear();\n+                if (recBuff.remaining() < len) {\n+                    recBuff = ByteBuffer.allocate(len);\n+                }\n+                recBuff.limit(len);\n+                if (fullRead(recLog, recBuff) != len) {\n+                    // This seems scary, but it just means that this is where we\n+                    // left off writing\n+                    break;\n+                }\n+                recBuff.flip();\n+                long ledgerId = recBuff.getLong();\n+                if (LOG.isDebugEnabled()) {\n+                    LOG.debug(\"Relay journal - ledger id : \" + ledgerId);\n+                }\n+                LedgerDescriptor handle = getHandle(ledgerId, false);\n+                try {\n+                    recBuff.rewind();\n+                    handle.addEntry(recBuff);\n+                } finally {\n+                    putHandle(handle);\n                 }\n             }\n         }\n@@ -214,6 +310,39 @@ public Bookie(int port, String zkServers, File journalDirectory, File ledgerDire\n         running = true;\n     }\n \n+    public static interface JournalIdFilter {\n+        public boolean accept(long journalId);\n+    }\n+\n+    /**\n+     * List all journal ids by a specified journal id filer\n+     *\n+     * @param journalDir journal dir\n+     * @param filter journal id filter\n+     * @return list of filtered ids\n+     */\n+    public static List<Long> listJournalIds(File journalDir, JournalIdFilter filter) {\n+        File logFiles[] = journalDir.listFiles();\n+        List<Long> logs = new ArrayList<Long>();\n+        for(File f: logFiles) {\n+            String name = f.getName();\n+            if (!name.endsWith(\".txn\")) {\n+                continue;\n+            }\n+            String idString = name.split(\"\\\\.\")[0];\n+            long id = Long.parseLong(idString, 16);\n+            if (filter != null) {\n+                if (filter.accept(id)) {\n+                    logs.add(id);\n+                }\n+            } else {\n+                logs.add(id);\n+            }\n+        }\n+        Collections.sort(logs);\n+        return logs;\n+    }\n+    \n     /**\n      * Instantiate the ZooKeeper client for the Bookie.\n      */\n@@ -426,8 +555,14 @@ synchronized void markLog() {\n         synchronized void rollLog() {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n-            bb.putLong(txnLogId);\n-            bb.putLong(txnLogPosition);\n+            // we should record <logId, logPosition> marked in markLog\n+            // which is safe since records before lastMark have been\n+            // persisted to disk (both index & entry logger)\n+            bb.putLong(lastMark.txnLogId);\n+            bb.putLong(lastMark.txnLogPosition);\n+            if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"RollLog to persist last marked log : \" + lastMark);\n+            }\n             for(File dir: ledgerDirectories) {\n                 File file = new File(dir, \"lastMark\");\n                 try {\n@@ -440,6 +575,12 @@ synchronized void rollLog() {\n                 }\n             }\n         }\n+\n+        /**\n+         * Read last mark from lastMark file.\n+         * The last mark should first be max journal log id,\n+         * and then max log position in max journal log.\n+         */\n         synchronized void readLog() {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n@@ -454,56 +595,100 @@ synchronized void readLog() {\n                     long p = bb.getLong();\n                     if (i > txnLogId) {\n                         txnLogId = i;\n-                    }\n-                    if (p > txnLogPosition) {\n-                        txnLogPosition = p;\n+                        if(p > txnLogPosition) {\n+                          txnLogPosition = p;\n+                        }\n                     }\n                 } catch (IOException e) {\n                     LOG.error(\"Problems reading from \" + file + \" (this is okay if it is the first time starting this bookie\");\n                 }\n             }\n         }\n+\n+        @Override\n+        public String toString() {\n+            StringBuilder sb = new StringBuilder();\n+            \n+            sb.append(\"LastMark: logId - \").append(txnLogId)\n+              .append(\" , position - \").append(txnLogPosition);\n+            \n+            return sb.toString();\n+        }\n     }\n \n     private LastLogMark lastLogMark = new LastLogMark(0, 0);\n \n+    LastLogMark getLastLogMark() {\n+        return lastLogMark;\n+    }\n+\n     public boolean isRunning() {\n         return running;\n     }\n \n+    /**\n+     * A thread used for persisting journal entries to journal files.\n+     * \n+     * <p>\n+     * Besides persisting journal entries, it also takes responsibility of\n+     * rolling journal files when a journal file reaches journal file size\n+     * limitation.\n+     * </p>\n+     * <p>\n+     * During journal rolling, it first closes the writing journal, generates\n+     * new journal file using current timestamp, and continue persistence logic.\n+     * Those journals will be garbage collected in SyncThread.\n+     * </p>\n+     */\n     @Override\n     public void run() {\n         LinkedList<QueueEntry> toFlush = new LinkedList<QueueEntry>();\n         ByteBuffer lenBuff = ByteBuffer.allocate(4);\n         try {\n-            long logId = System.currentTimeMillis();\n-            FileChannel logFile = openChannel(logId);\n-            BufferedChannel bc = new BufferedChannel(logFile, 65536);\n-            zeros.clear();\n-            long nextPrealloc = preAllocSize;\n+            long logId = 0;\n+            FileChannel logFile = null;\n+            BufferedChannel bc = null;\n+            long nextPrealloc = 0;\n             long lastFlushPosition = 0;\n-            logFile.write(zeros, nextPrealloc);\n \n-            // TODO: Currently, when we roll over the journal logs, the older\n-            // ones are never garbage collected. We should remove a journal log\n-            // once all of its entries have been synced with the entry logs.\n+            QueueEntry qe = null;\n             while (true) {\n-                QueueEntry qe = null;\n-                if (toFlush.isEmpty()) {\n-                    qe = queue.take();\n-                } else {\n-                    qe = queue.poll();\n-                    if (qe == null || bc.position() > lastFlushPosition + 512*1024) {\n-                        //logFile.force(false);\n-                        bc.flush(true);\n-                        lastFlushPosition = bc.position();\n-                        lastLogMark.setLastLogMark(logId, lastFlushPosition);\n-                        for (QueueEntry e : toFlush) {\n-                            e.cb.writeComplete(0, e.ledgerId, e.entryId, null, e.ctx);\n+                // new journal file to write\n+                if (null == logFile) {\n+                    logId = System.currentTimeMillis();\n+                    logFile = openChannel(logId);\n+                    bc = new BufferedChannel(logFile, 65536);\n+                    zeros.clear();\n+                    nextPrealloc = preAllocSize;\n+                    lastFlushPosition = 0;\n+                    logFile.write(zeros, nextPrealloc);\n+                }\n+\n+                if (qe == null) {\n+                    if (toFlush.isEmpty()) {\n+                        qe = queue.take();\n+                    } else {\n+                        qe = queue.poll();\n+                        if (qe == null || bc.position() > lastFlushPosition + 512*1024) {\n+                            //logFile.force(false);\n+                            bc.flush(true);\n+                            lastFlushPosition = bc.position();\n+                            lastLogMark.setLastLogMark(logId, lastFlushPosition);\n+                            for (QueueEntry e : toFlush) {\n+                                e.cb.writeComplete(0, e.ledgerId, e.entryId, null, e.ctx);\n+                            }\n+                            toFlush.clear();\n+\n+                            // check wether journal file is over file limit\n+                            if (bc.position() > MAX_JOURNAL_SIZE) {\n+                                logFile.close();\n+                                logFile = null;\n+                                continue;\n+                            }\n                         }\n-                        toFlush.clear();\n                     }\n                 }\n+\n                 if (isZkExpired) {\n                     LOG.warn(\"Exiting... zk client has expired.\");\n                     break;\n@@ -526,16 +711,26 @@ public void run() {\n                     logFile.write(zeros, nextPrealloc);\n                 }\n                 toFlush.add(qe);\n+                qe = null;\n             }\n         } catch (Exception e) {\n             LOG.fatal(\"Bookie thread exiting\", e);\n         }\n     }\n \n     private FileChannel openChannel(long logId) throws FileNotFoundException {\n+        return openChannel(logId, 0);\n+    }\n+\n+    private FileChannel openChannel(long logId, long position) throws FileNotFoundException {\n         FileChannel logFile = new RandomAccessFile(new File(journalDirectory,\n                 Long.toHexString(logId) + \".txn\"),\n                 \"rw\").getChannel();\n+        try {\n+            logFile.position(position);\n+        } catch (IOException e) {\n+            LOG.fatal(\"Bookie journal file can seek to position :\", e);\n+        }\n         return logFile;\n     }\n \n@@ -547,8 +742,7 @@ public synchronized void shutdown() throws InterruptedException {\n         if(zk != null) zk.close();\n         this.interrupt();\n         this.join();\n-        syncThread.running = false;\n-        syncThread.join();\n+        syncThread.shutdown(); \n         for(LedgerDescriptor d: ledgers.values()) {\n             d.close();\n         }"},{"sha":"1fafac175a5e0cdde20e3da9fae0097635446ad4","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","status":"modified","additions":7,"deletions":0,"changes":7,"blob_url":"https://github.com/apache/bookkeeper/blob/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","raw_url":"https://github.com/apache/bookkeeper/raw/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java?ref=cc467bd5880c2879e6c0355469d51759f89bbabc","patch":"@@ -482,6 +482,13 @@ public void shutdown() throws InterruptedException {\n         gcThread.running = false;\n         gcThread.interrupt();\n         gcThread.join();\n+        // since logChannel is buffered channel, do flush when shutting down\n+        try {\n+            flush();\n+        } catch (IOException ie) {\n+            // we have no idea how to avoid io exception during shutting down, so just ignore it\n+            LOG.fatal(\"Error flush entry log during shutting down, which may cause entry log corrupted.\", ie);\n+        }\n     }\n \n }"},{"sha":"2a62f991920c0a38915bd4a6d178417a5a4775e9","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/test/BookieJournalRollingTest.java","status":"added","additions":222,"deletions":0,"changes":222,"blob_url":"https://github.com/apache/bookkeeper/blob/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/BookieJournalRollingTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/cc467bd5880c2879e6c0355469d51759f89bbabc/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/BookieJournalRollingTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/BookieJournalRollingTest.java?ref=cc467bd5880c2879e6c0355469d51759f89bbabc","patch":"@@ -0,0 +1,222 @@\n+package org.apache.bookkeeper.test;\n+\n+/*\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+import java.io.File;\n+import java.util.Enumeration;\n+import java.util.List;\n+\n+import org.apache.bookkeeper.bookie.Bookie;\n+import org.apache.bookkeeper.bookie.Bookie.JournalIdFilter;\n+import org.apache.bookkeeper.client.LedgerEntry;\n+import org.apache.bookkeeper.client.LedgerHandle;\n+import org.apache.bookkeeper.client.BookKeeper.DigestType;\n+import org.apache.bookkeeper.proto.BookieServer;\n+import org.apache.log4j.Logger;\n+import org.junit.Assert;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+/**\n+ * This class tests that bookie rolling journals\n+ */\n+public class BookieJournalRollingTest extends BaseTestCase {\n+    static Logger LOG = Logger.getLogger(BookieJournalRollingTest.class);\n+\n+    DigestType digestType;\n+\n+    public BookieJournalRollingTest(DigestType digestType) {\n+        super(3);\n+        this.digestType = digestType;\n+    }\n+\n+    @Before\n+    @Override\n+    public void setUp() throws Exception {\n+        // Set up the configuration properties needed.\n+        System.setProperty(\"journal_max_size_mb\", \"1\");\n+        System.setProperty(\"journal_max_backups\", \"1\");\n+        super.setUp();\n+    }\n+\n+    @After\n+    @Override\n+    public void tearDown() throws Exception {\n+        try {\n+            super.tearDown();\n+        } finally {\n+            System.setProperty(\"journal_max_size_mb\", \"2048\");\n+            System.setProperty(\"journal_max_backups\", \"5\");\n+        }\n+    }\n+\n+    /**\n+     * Common method to create ledgers and write entries to them.\n+     */\n+    private LedgerHandle[] writeLedgerEntries(int numLedgers, int msgSize, int numMsgs) throws Exception {\n+        // Create the ledgers\n+        LedgerHandle[] lhs = new LedgerHandle[numLedgers];\n+        long[] ledgerIds = new long[numLedgers];\n+        for (int i = 0; i < numLedgers; i++) {\n+            lhs[i] = bkc.createLedger(digestType, \"\".getBytes());\n+            ledgerIds[i] = lhs[i].getId();\n+        }\n+\n+        // Create a dummy message string to write as ledger entries\n+        StringBuilder msgSB = new StringBuilder();\n+        for (int i = 0; i < msgSize; i++) {\n+            msgSB.append(\"a\");\n+        }\n+        String msg = msgSB.toString();\n+\n+        // Write all of the entries for all of the ledgers\n+        for (int i = 0; i < numMsgs; i++) {\n+            for (int j = 0; j < numLedgers; j++) {\n+                StringBuilder sb = new StringBuilder();\n+                sb.append(ledgerIds[j]).append('-').append(i).append('-')\n+                  .append(msg);\n+                lhs[j].addEntry(sb.toString().getBytes());\n+            }\n+        }\n+\n+        // Return the ledger handles to the inserted ledgers and entries\n+        return lhs;\n+    }\n+\n+    private void validLedgerEntries(long[] ledgerIds, int msgSize, int numMsgs) throws Exception {\n+        // Open the ledgers\n+        LedgerHandle[] lhs = new LedgerHandle[ledgerIds.length];\n+        for (int i = 0; i < lhs.length; i++) {\n+            lhs[i] = bkc.openLedger(ledgerIds[i], digestType, \"\".getBytes());\n+        }\n+\n+        StringBuilder msgSB = new StringBuilder();\n+        for (int i = 0; i < msgSize; i++) {\n+            msgSB.append(\"a\");\n+        }\n+        String msg = msgSB.toString();\n+\n+        int numToRead = 10;\n+        // read all of the entries for all the ledgers\n+        for (int j = 0; j < lhs.length; j++) {\n+            int start = 0;\n+            int read = Math.min(numToRead, numMsgs - start);\n+            int end = start + read - 1;\n+            int entryId = 0;\n+            if (LOG.isDebugEnabled()) {\n+                LOG.debug(\"Validating Entries of Ledger \" + ledgerIds[j]);\n+            }\n+            while (start < numMsgs) {\n+                Enumeration<LedgerEntry> seq = lhs[j].readEntries(start, end);\n+                assertTrue(\"Enumeration of ledger entries has no element\", seq.hasMoreElements() == true);\n+                while (seq.hasMoreElements()) {\n+                    LedgerEntry e = seq.nextElement();\n+                    assertEquals(entryId, e.getEntryId());\n+\n+                    StringBuilder sb = new StringBuilder();\n+                    sb.append(ledgerIds[j]).append('-').append(entryId).append('-')\n+                      .append(msg);\n+                    Assert.assertArrayEquals(sb.toString().getBytes(), e.getEntry());\n+                    entryId++;\n+                }\n+                assertEquals(entryId - 1, end);\n+                start = end + 1;\n+                read = Math.min(numToRead, numMsgs - start);\n+                end = start + read - 1;\n+            }\n+        }\n+    }\n+\n+    /**\n+     * This test writes enough ledger entries to roll over the journals\n+     *\n+     * It will then keep only 1 journal file before last marked journal\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testJournalRolling() throws Exception {\n+        if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Testing Journal Rolling\");\n+        }\n+        // Write enough ledger entries so that we roll over journals\n+        LedgerHandle[] lhs = writeLedgerEntries(4, 1024, 1024);\n+        long[] ledgerIds = new long[lhs.length];\n+        for (int i=0; i<lhs.length; i++) {\n+            ledgerIds[i] = lhs[i].getId();\n+        }\n+\n+        // Sleep for a while to ensure data are flushed\n+        Thread.sleep(2000);\n+\n+        // verify that we only keep at most journal files \n+        for (File journalDir : tmpDirs) {\n+            List<Long> logs = Bookie.listJournalIds(journalDir, new JournalIdFilter() {\n+                @Override\n+                public boolean accept(long journalId) {\n+                    return true;\n+                }\n+            });\n+            assertTrue(logs.size() <= 2);\n+        }\n+\n+        // restart bookies \n+        // ensure after restart we can read the entries since journals rolls\n+        restartBookies();\n+        validLedgerEntries(ledgerIds, 1024, 1024);\n+    }\n+\n+    /**\n+     * This test writes enough ledger entries to roll over the journals\n+     * without sync up\n+     *\n+     * @throws Exception\n+     */\n+    @Test\n+    public void testJournalRollingWithoutSyncup() throws Exception {\n+        if (LOG.isDebugEnabled()) {\n+            LOG.debug(\"Testing Journal Rolling without sync up\");\n+        }\n+        // set flush interval to a large value\n+        System.setProperty(\"flush_interval\", \"999999999\");\n+        try {\n+            // restart bookies\n+            restartBookies();\n+\n+            // Write enough ledger entries so that we roll over journals\n+            LedgerHandle[] lhs = writeLedgerEntries(4, 1024, 1024);\n+            long[] ledgerIds = new long[lhs.length];\n+            for (int i=0; i<lhs.length; i++) {\n+                ledgerIds[i] = lhs[i].getId();\n+            }\n+\n+            // ledger indexes are not flushed\n+            // and after bookies restarted, journals will be relayed\n+            // ensure that we can still read the entries\n+            restartBookies();\n+            validLedgerEntries(ledgerIds, 1024, 1024);\n+        } finally {\n+            System.setProperty(\"flush_interval\", \"100\");\n+        }\n+    }\n+\n+}"},{"sha":"d6aef089186c2d4a1032d3fd4aad87eafc0d7efc","filename":"doc/bookkeeperConfig.textile","status":"modified","additions":30,"deletions":1,"changes":31,"blob_url":"https://github.com/apache/bookkeeper/blob/cc467bd5880c2879e6c0355469d51759f89bbabc/doc/bookkeeperConfig.textile","raw_url":"https://github.com/apache/bookkeeper/raw/cc467bd5880c2879e6c0355469d51759f89bbabc/doc/bookkeeperConfig.textile","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/doc/bookkeeperConfig.textile?ref=cc467bd5880c2879e6c0355469d51759f89bbabc","patch":"@@ -41,6 +41,35 @@ p. The configuration parameters, which can be set in bookkeeper-server/conf/bken\n \n p. Ideally, @/path_to_log_device/@ and @/path_to_ledger_device/@ are each in a different device. \n \n+h1. Bookie Configuration\n+\n+p. Bookie server stores its data in multiple ledger directories and its journal files in a journal directory. Ideally, storing journal files in a separate directory than data files would increase throughput and decrease latency.\n+\n+h2. Journal Configuration\n+\n+p. Journal directory has one kind of files in it:\n+\n+* {timestamp}.txn - holds transactions executed in the bookie server.\n+\n+p. Before persisting ledger index and data to disk, a bookie ensures that the transaction that represents the update is written to a journal in non-volatile storage. A new journal file is created using current timestamp when a bookie starts or an old journal file reaches its maximum size.\n+\n+p. A bookie supports journal rolling to remove old journal files. In order to remove old journal files safely, bookie server records LastLogMark in Ledger Device, which indicates all updates (including index and data) before LastLogMark has been persisted to the Ledger Device.\n+\n+p. LastLogMark contains two parts:\n+\n+* LastLogId - indicates which journal file the transaction persisted.\n+* LastLogPos - indicates the position the transaction persisted in LastLogId journal file.\n+\n+p. You may use following settings to further fine tune the behavior of your Bookie servers. Currently these configuration settings are set using Java system properties.\n+\n+* journal_max_size_mb\n+** journal file size limitation. when a journal reaches this limitation, it will be closed and new journal file be created.\n+\n+* journal_max_backups\n+** how many old journal files whose id is less than LastLogMark 's journal id.\n+\n+bq. NOTE: keeping number of old journal files would be useful for manually recovery in special case.\n+\n h1. ZooKeeper Metadata\n \n-p. For BookKeeper, we require a ZooKeeper installation to store metadata, and to pass the list of ZooKeeper servers as parameter to the constructor of the BookKeeper class ( @org.apache.bookkeeper.client,BookKeeper@ ). To setup ZooKeeper, please check the \"ZooKeeper documentation\":index.html. \n+p. For BookKeeper, we require a ZooKeeper installation to store metadata, and to pass the list of ZooKeeper servers as parameter to the constructor of the BookKeeper class ( @org.apache.bookkeeper.client,BookKeeper@ ). To setup ZooKeeper, please check the \"ZooKeeper documentation\":index.html. \n\\ No newline at end of file"}]}

