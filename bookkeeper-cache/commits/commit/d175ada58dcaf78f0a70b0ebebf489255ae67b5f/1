{"sha":"d175ada58dcaf78f0a70b0ebebf489255ae67b5f","node_id":"MDY6Q29tbWl0MTU3NTk1NjpkMTc1YWRhNThkY2FmNzhmMGE3MGIwZWJlYmY0ODkyNTVhZTY3YjVm","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-05-04T12:22:10Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-05-04T12:22:10Z"},"message":"BOOKKEEPER-564: Better checkpoint mechanism (sijie & ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1479085 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"dba5fecdf9563f22ec400d2761aff7ec27f6cb01","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/dba5fecdf9563f22ec400d2761aff7ec27f6cb01"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/d175ada58dcaf78f0a70b0ebebf489255ae67b5f","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/d175ada58dcaf78f0a70b0ebebf489255ae67b5f","html_url":"https://github.com/apache/bookkeeper/commit/d175ada58dcaf78f0a70b0ebebf489255ae67b5f","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"685ca079690f8be2cbcfacb615fc0eb5a798b8da","url":"https://api.github.com/repos/apache/bookkeeper/commits/685ca079690f8be2cbcfacb615fc0eb5a798b8da","html_url":"https://github.com/apache/bookkeeper/commit/685ca079690f8be2cbcfacb615fc0eb5a798b8da"}],"stats":{"total":888,"additions":624,"deletions":264},"files":[{"sha":"f8a8831070a2f272299a6f3562d44122a559193c","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -10,6 +10,8 @@ Trunk (unreleased changes)\n \n     BUGFIXES:\n \n+      BOOKKEEPER-564: Better checkpoint mechanism (sijie & ivank)\n+\n       BOOKKEEPER-596: Ledgers are gc'ed by mistake in MSLedgerManagerFactory. (sijie & ivank)\n \n       BOOKKEEPER-595: Crash of inprocess autorecovery daemon should not take down the bookie (ivank)"},{"sha":"670d8cf23cf27180ae504e4e3d115b8cc9a553f5","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","status":"modified","additions":65,"deletions":58,"changes":123,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -45,6 +45,7 @@\n import org.apache.bookkeeper.bookie.BookieException;\n import org.apache.bookkeeper.bookie.GarbageCollectorThread.SafeEntryAdder;\n import org.apache.bookkeeper.bookie.Journal.JournalScanner;\n+import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;\n import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;\n import org.apache.bookkeeper.bookie.LedgerDirsManager.NoWritableLedgerDirException;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n@@ -239,39 +240,70 @@ public void writeComplete(int rc, long ledgerId, long entryId,\n     }\n \n     /**\n-     * SyncThread is a background thread which flushes ledger index pages periodically.\n-     * Also it takes responsibility of garbage collecting journal files.\n-     *\n-     * <p>\n-     * Before flushing, SyncThread first records a log marker {journalId, journalPos} in memory,\n-     * which indicates entries before this log marker would be persisted to ledger files.\n-     * Then sync thread begins flushing ledger index pages to ledger index files, flush entry\n-     * logger to ensure all entries persisted to entry loggers for future reads.\n-     * </p>\n+     * SyncThread is a background thread which help checkpointing ledger storage\n+     * when a checkpoint is requested. After a ledger storage is checkpointed,\n+     * the journal files added before checkpoint will be garbage collected.\n      * <p>\n-     * After all data has been persisted to ledger index files and entry loggers, it is safe\n-     * to persist the log marker to disk. If bookie failed after persist log mark,\n-     * bookie is able to relay journal entries started from last log mark without losing\n-     * any entries.\n+     * After all data has been persisted to ledger index files and entry\n+     * loggers, it is safe to complete a checkpoint by persisting the log marker\n+     * to disk. If bookie failed after persist log mark, bookie is able to relay\n+     * journal entries started from last log mark without losing any entries.\n      * </p>\n      * <p>\n-     * Those journal files whose id are less than the log id in last log mark, could be\n-     * removed safely after persisting last log mark. We provide a setting to let user keeping\n-     * number of old journal files which may be used for manual recovery in critical disaster.\n+     * Those journal files whose id are less than the log id in last log mark,\n+     * could be removed safely after persisting last log mark. We provide a\n+     * setting to let user keeping number of old journal files which may be used\n+     * for manual recovery in critical disaster.\n      * </p>\n      */\n     class SyncThread extends Thread {\n         volatile boolean running = true;\n         // flag to ensure sync thread will not be interrupted during flush\n         final AtomicBoolean flushing = new AtomicBoolean(false);\n-        // make flush interval as a parameter\n         final int flushInterval;\n+\n         public SyncThread(ServerConfiguration conf) {\n             super(\"SyncThread\");\n             flushInterval = conf.getFlushInterval();\n             LOG.debug(\"Flush Interval : {}\", flushInterval);\n         }\n \n+        /**\n+         * flush data up to given logMark and roll log if success\n+         * @param checkpoint\n+         */\n+        @VisibleForTesting\n+        public void checkpoint(Checkpoint checkpoint) {\n+            boolean flushFailed = false;\n+            try {\n+                if (running) {\n+                    checkpoint = ledgerStorage.checkpoint(checkpoint);\n+                } else {\n+                    ledgerStorage.flush();\n+                }\n+            } catch (NoWritableLedgerDirException e) {\n+                LOG.error(\"No writeable ledger directories\");\n+                flushFailed = true;\n+                flushing.set(false);\n+                transitionToReadOnlyMode();\n+            } catch (IOException e) {\n+                LOG.error(\"Exception flushing Ledger\", e);\n+                flushFailed = true;\n+            }\n+\n+            // if flush failed, we should not roll last mark, otherwise we would\n+            // have some ledgers are not flushed and their journal entries were lost\n+            if (!flushFailed) {\n+                try {\n+                    journal.checkpointComplete(checkpoint, running);\n+                } catch (IOException e) {\n+                    flushing.set(false);\n+                    LOG.error(\"Marking checkpoint as complete failed\", e);\n+                    transitionToReadOnlyMode();\n+                }\n+            }\n+        }\n+\n         private Object suspensionLock = new Object();\n         private boolean suspended = false;\n \n@@ -299,61 +331,35 @@ public void resumeSync() {\n         @Override\n         public void run() {\n             try {\n-                while (running) {\n+                while(running) {\n                     synchronized (this) {\n                         try {\n                             wait(flushInterval);\n-                            if (!ledgerStorage.isFlushRequired()) {\n-                                continue;\n-                            }\n                         } catch (InterruptedException e) {\n                             Thread.currentThread().interrupt();\n                             continue;\n                         }\n                     }\n+\n                     synchronized (suspensionLock) {\n                         while (suspended) {\n-                            suspensionLock.wait();\n+                            try {\n+                                suspensionLock.wait();\n+                            } catch (InterruptedException e) {\n+                                Thread.currentThread().interrupt();\n+                                continue;\n+                            }\n                         }\n                     }\n-                    // try to mark flushing flag to make sure it would not be interrupted\n-                    // by shutdown during flushing. otherwise it will receive\n-                    // ClosedByInterruptException which may cause index file & entry logger\n-                    // closed and corrupted.\n+\n+                    // try to mark flushing flag to check if interrupted\n                     if (!flushing.compareAndSet(false, true)) {\n                         // set flushing flag failed, means flushing is true now\n                         // indicates another thread wants to interrupt sync thread to exit\n                         break;\n                     }\n+                    checkpoint(journal.newCheckpoint());\n \n-                    // journal mark log\n-                    journal.markLog();\n-\n-                    boolean flushFailed = false;\n-                    try {\n-                        ledgerStorage.flush();\n-                    } catch (NoWritableLedgerDirException e) {\n-                        flushFailed = true;\n-                        flushing.set(false);\n-                        transitionToReadOnlyMode();\n-                    } catch (IOException e) {\n-                        LOG.error(\"Exception flushing Ledger\", e);\n-                        flushFailed = true;\n-                    }\n-\n-                    // if flush failed, we should not roll last mark, otherwise we would\n-                    // have some ledgers are not flushed and their journal entries were lost\n-                    if (!flushFailed) {\n-                        try {\n-                            journal.rollLog();\n-                            journal.gcJournals();\n-                        } catch (NoWritableLedgerDirException e) {\n-                            flushing.set(false);\n-                            transitionToReadOnlyMode();\n-                        }\n-                    }\n-\n-                    // clear flushing flag\n                     flushing.set(false);\n                 }\n             } catch (Throwable t) {\n@@ -365,9 +371,10 @@ public void run() {\n \n         // shutdown sync thread\n         void shutdown() throws InterruptedException {\n+            // Wake up and finish sync thread\n             running = false;\n+            // make a checkpoint when shutdown\n             if (flushing.compareAndSet(false, true)) {\n-                // if setting flushing flag succeed, means syncThread is not flushing now\n                 // it is safe to interrupt itself now \n                 this.interrupt();\n             }\n@@ -532,12 +539,12 @@ public Bookie(ServerConfiguration conf)\n         LOG.info(\"instantiate ledger manager {}\", ledgerManagerFactory.getClass().getName());\n         ledgerManager = ledgerManagerFactory.newLedgerManager();\n         syncThread = new SyncThread(conf);\n+        // instantiate the journal\n+        journal = new Journal(conf, ledgerDirsManager);\n         ledgerStorage = new InterleavedLedgerStorage(conf, ledgerManager,\n-                                                     ledgerDirsManager,\n+                                                     ledgerDirsManager, journal,\n                                                      new BookieSafeEntryAdder());\n         handles = new HandleFactoryImpl(ledgerStorage);\n-        // instantiate the journal\n-        journal = new Journal(conf, ledgerDirsManager);\n \n         // ZK ephemeral node for this Bookie.\n         zkBookieRegPath = this.bookieRegistrationPath + getMyId();"},{"sha":"79e71c1579d9a4b8b3dd3f8dd5df042eb0f577de","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","status":"modified","additions":4,"deletions":4,"changes":8,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/BookieShell.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -916,10 +916,10 @@ public void process(int journalVersion, long offset, ByteBuffer entry) throws IO\n      * Print last log mark\n      */\n     protected void printLastLogMark() throws IOException {\n-        LastLogMark lastLogMark = getJournal().getLastLogMark();\n-        System.out.println(\"LastLogMark: Journal Id - \" + lastLogMark.getTxnLogId() + \"(\"\n-                + Long.toHexString(lastLogMark.getTxnLogId()) + \".txn), Pos - \"\n-                + lastLogMark.getTxnLogPosition());\n+        LogMark lastLogMark = getJournal().getLastLogMark().getCurMark();\n+        System.out.println(\"LastLogMark: Journal Id - \" + lastLogMark.getLogFileId() + \"(\"\n+                + Long.toHexString(lastLogMark.getLogFileId()) + \".txn), Pos - \"\n+                + lastLogMark.getLogFileOffset());\n     }\n \n     /**"},{"sha":"a8f128d77351968c822d680207c81769c1bc7fd3","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/CheckpointSource.java","status":"added","additions":83,"deletions":0,"changes":83,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/CheckpointSource.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/CheckpointSource.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/CheckpointSource.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.io.IOException;\n+\n+/**\n+ * Interface to communicate checkpoint progress.\n+ */\n+public interface CheckpointSource {\n+\n+    /**\n+     * A checkpoint presented a time point. All entries added before this checkpoint are already persisted.\n+     */\n+    public static interface Checkpoint extends Comparable<Checkpoint> {\n+\n+        public static final Checkpoint MAX = new Checkpoint() {\n+\n+            @Override\n+            public int compareTo(Checkpoint o) {\n+                if (o == MAX) {\n+                    return 0;\n+                }\n+                return 1;\n+            }\n+\n+            @Override\n+            public boolean equals(Object o) {\n+                return this == o;\n+            }\n+\n+        };\n+\n+        public static final Checkpoint MIN = new Checkpoint() {\n+            @Override\n+            public int compareTo(Checkpoint o) {\n+                if (o == MIN) {\n+                    return 0;\n+                }\n+                return 1;\n+            }\n+\n+            @Override\n+            public boolean equals(Object o) {\n+                return this == o;\n+            }\n+        };\n+    }\n+\n+    /**\n+     * Request a new a checkpoint.\n+     *\n+     * @return checkpoint.\n+     */\n+    public Checkpoint newCheckpoint();\n+\n+    /**\n+     * Tell checkpoint source that the checkpoint is completed.\n+     * If <code>compact</code> is true, the implementation could compact\n+     * to reduce size of data containing old checkpoints.\n+     *\n+     * @param checkpoint\n+     *          The checkpoint that has been completed\n+     * @param compact\n+     *          Flag to compact old checkpoints.\n+     */\n+    public void checkpointComplete(Checkpoint checkpoint, boolean compact) throws IOException;\n+}"},{"sha":"50a501b257853a4f2f346ca815188fa7276e9a2c","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","status":"modified","additions":113,"deletions":23,"changes":136,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/EntryLogger.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -21,6 +21,8 @@\n \n package org.apache.bookkeeper.bookie;\n \n+import static com.google.common.base.Charsets.UTF_8;\n+\n import java.io.BufferedReader;\n import java.io.BufferedWriter;\n import java.io.File;\n@@ -36,19 +38,23 @@\n import java.nio.channels.FileChannel;\n import java.util.ArrayList;\n import java.util.Collections;\n+import java.util.LinkedList;\n import java.util.List;\n import java.util.Map.Entry;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CancellationException;\n import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n import java.util.concurrent.atomic.AtomicBoolean;\n \n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-\n-import static com.google.common.base.Charsets.UTF_8;\n-\n import org.apache.bookkeeper.bookie.LedgerDirsManager.LedgerDirsListener;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.apache.bookkeeper.util.IOUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n /**\n  * This class manages the writing of the bookkeeper entries. All the new\n@@ -65,12 +71,16 @@\n     private AtomicBoolean shouldCreateNewEntryLog = new AtomicBoolean(false);\n \n     private long logId;\n+    private volatile long leastUnflushedLogId;\n \n     /**\n      * The maximum size of a entry logger file.\n      */\n     final long logSizeLimit;\n+    private List<BufferedChannel> logChannelsToFlush;\n     private volatile BufferedChannel logChannel;\n+    private final EntryLogListener listener;\n+\n     /**\n      * The 1K block at the head of the entry logger file\n      * that contains the fingerprint and (future) meta-data\n@@ -109,13 +119,30 @@\n         public void process(long ledgerId, long offset, ByteBuffer entry) throws IOException;\n     }\n \n+    /**\n+     * Entry Log Listener\n+     */\n+    static interface EntryLogListener {\n+        /**\n+         * Rotate a new entry log to write.\n+         */\n+        public void onRotateEntryLog();\n+    }\n+\n     /**\n      * Create an EntryLogger that stores it's log files in the given\n      * directories\n      */\n     public EntryLogger(ServerConfiguration conf,\n             LedgerDirsManager ledgerDirsManager) throws IOException {\n+        this(conf, ledgerDirsManager, null);\n+    }\n+\n+    public EntryLogger(ServerConfiguration conf,\n+            LedgerDirsManager ledgerDirsManager, EntryLogListener listener)\n+                    throws IOException {\n         this.ledgerDirsManager = ledgerDirsManager;\n+        this.listener = listener;\n         // log size limit\n         this.logSizeLimit = conf.getEntryLogSizeLimit();\n \n@@ -138,7 +165,7 @@ public EntryLogger(ServerConfiguration conf,\n                 logId = lastLogId;\n             }\n         }\n-\n+        this.leastUnflushedLogId = logId + 1;\n         initialize();\n     }\n \n@@ -147,6 +174,16 @@ public EntryLogger(ServerConfiguration conf,\n      */\n     private ConcurrentHashMap<Long, BufferedChannel> channels = new ConcurrentHashMap<Long, BufferedChannel>();\n \n+    /**\n+     * Get the least unflushed log id. Garbage collector thread should not process\n+     * unflushed entry log file.\n+     *\n+     * @return least unflushed log id.\n+     */\n+    synchronized long getLeastUnflushedLogId() {\n+        return leastUnflushedLogId;\n+    }\n+\n     synchronized long getCurrentLogId() {\n         return logId;\n     }\n@@ -186,23 +223,37 @@ public void fatalError() {\n         };\n     }\n \n+    /**\n+     * Rolling a new log file to write.\n+     */\n+    synchronized void rollLog() throws IOException {\n+        createNewLog();\n+    }\n+\n     /**\n      * Creates a new log file\n      */\n     void createNewLog() throws IOException {\n-        if (logChannel != null) {\n-            logChannel.flush(true);\n+        if (null != logChannel) {\n+            if (null == logChannelsToFlush) {\n+                logChannelsToFlush = new LinkedList<BufferedChannel>();\n+            }\n+            // flush the internal buffer back to filesystem but not sync disk\n+            // so the readers could access the data from filesystem.\n+            logChannel.flush(false);\n+            logChannelsToFlush.add(logChannel);\n+            if (null != listener) {\n+                listener.onRotateEntryLog();\n+            }\n         }\n-\n-        // It would better not to overwrite existing entry log files\n         String logFileName = null;\n         do {\n             logFileName = Long.toHexString(++logId) + \".log\";\n             for (File dir : ledgerDirsManager.getAllLedgerDirs()) {\n                 File newLogFile = new File(dir, logFileName);\n                 if (newLogFile.exists()) {\n                     LOG.warn(\"Found existed entry log \" + newLogFile\n-                           + \" when trying to create it as a new log.\");\n+                             + \" when trying to create it as a new log.\");\n                     logFileName = null;\n                     break;\n                 }\n@@ -324,21 +375,57 @@ private long readLastLogId(File f) {\n         }\n     }\n \n-    synchronized void flush() throws IOException {\n+    /**\n+     * Flushes all rotated log channels. After log channels are flushed,\n+     * move leastUnflushedLogId ptr to current logId.\n+     */\n+    void checkpoint() throws IOException {\n+        flushRotatedLogs();\n+    }\n+\n+    void flushRotatedLogs() throws IOException {\n+        List<BufferedChannel> tmpChannels = null;\n+        long newUnflushedLogId;\n+        synchronized (this) {\n+            tmpChannels = logChannelsToFlush;\n+            logChannelsToFlush = null;\n+            newUnflushedLogId = logId;\n+        }\n+        if (null == tmpChannels) {\n+            return;\n+        }\n+        for (BufferedChannel channel : tmpChannels) {\n+            channel.flush(true);\n+        }\n+        // move the leastUnflushedLogId ptr\n+        leastUnflushedLogId = newUnflushedLogId;\n+    }\n+\n+    void flush() throws IOException {\n+        flushRotatedLogs();\n+        flushCurrentLog();\n+    }\n+\n+    synchronized void flushCurrentLog() throws IOException {\n         if (logChannel != null) {\n             logChannel.flush(true);\n         }\n     }\n-    synchronized long addEntry(long ledger, ByteBuffer entry) throws IOException {\n-        // Create new log if logSizeLimit reached or current disk is full\n-        boolean createNewLog = shouldCreateNewEntryLog.get();\n-        if (createNewLog\n-                || (logChannel.position() + entry.remaining() + 4 > logSizeLimit)) {\n-            createNewLog();\n-\n-            // Reset the flag\n-            if (createNewLog) {\n-                shouldCreateNewEntryLog.set(false);\n+\n+    long addEntry(long ledger, ByteBuffer entry) throws IOException {\n+        return addEntry(ledger, entry, true);\n+    }\n+\n+    synchronized long addEntry(long ledger, ByteBuffer entry, boolean rollLog) throws IOException {\n+        if (rollLog) {\n+            // Create new log if logSizeLimit reached or current disk is full\n+            boolean createNewLog = shouldCreateNewEntryLog.get();\n+            if (createNewLog || reachEntryLogLimit(entry.remaining() + 4)) {\n+                createNewLog();\n+                // Reset the flag\n+                if (createNewLog) {\n+                    shouldCreateNewEntryLog.set(false);\n+                }\n             }\n         }\n         ByteBuffer buff = ByteBuffer.allocate(4);\n@@ -347,11 +434,14 @@ synchronized long addEntry(long ledger, ByteBuffer entry) throws IOException {\n         logChannel.write(buff);\n         long pos = logChannel.position();\n         logChannel.write(entry);\n-        //logChannel.flush(false);\n \n         return (logId << 32L) | pos;\n     }\n \n+    synchronized boolean reachEntryLogLimit(long size) {\n+        return logChannel.position() + size > logSizeLimit;\n+    }\n+\n     byte[] readEntry(long ledgerId, long entryId, long location) throws IOException, Bookie.NoEntryException {\n         long entryLogId = location >> 32L;\n         long pos = location & 0xffffffffL;"},{"sha":"96cfd81afbe6bb443707c1c683d715e485acb1df","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","status":"modified","additions":39,"deletions":34,"changes":73,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/FileInfo.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -226,6 +226,9 @@ synchronized public int read(ByteBuffer bb, long position) throws IOException {\n \n     private int readAbsolute(ByteBuffer bb, long start) throws IOException {\n         checkOpen(false);\n+        if (fc == null) {\n+            return 0;\n+        }\n         int total = 0;\n         while(bb.remaining() > 0) {\n             int rc = fc.read(bb, start);\n@@ -284,47 +287,49 @@ synchronized public long write(ByteBuffer[] buffs, long position) throws IOExcep\n      */\n     public synchronized void moveToNewLocation(File newFile, long size) throws IOException {\n         checkOpen(false);\n-        if (size > fc.size()) {\n-            size = fc.size();\n-        }\n-        File rlocFile = new File(newFile.getParentFile(), newFile.getName() + LedgerCacheImpl.RLOC);\n-        if (!rlocFile.exists()) {\n-            checkParents(rlocFile);\n-            if (!rlocFile.createNewFile()) {\n-                throw new IOException(\"Creating new cache index file \" + rlocFile + \" failed \");\n+        if (fc != null) {\n+            if (size > fc.size()) {\n+                size = fc.size();\n             }\n-        }\n-        // copy contents from old.idx to new.idx.rloc\n-        FileChannel newFc = new RandomAccessFile(rlocFile, \"rw\").getChannel();\n-        try {\n-            long written = 0;\n-            while (written < size) {\n-                long count = fc.transferTo(written, size, newFc);\n-                if (count <= 0) {\n+            File rlocFile = new File(newFile.getParentFile(), newFile.getName() + LedgerCacheImpl.RLOC);\n+            if (!rlocFile.exists()) {\n+                checkParents(rlocFile);\n+                if (!rlocFile.createNewFile()) {\n+                    throw new IOException(\"Creating new cache index file \" + rlocFile + \" failed \");\n+                }\n+            }\n+            // copy contents from old.idx to new.idx.rloc\n+            FileChannel newFc = new RandomAccessFile(rlocFile, \"rw\").getChannel();\n+            try {\n+                long written = 0;\n+                while (written < size) {\n+                    long count = fc.transferTo(written, size, newFc);\n+                    if (count <= 0) {\n+                        throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n+                    }\n+                    written += count;\n+                }\n+                if (written <= 0 && size > 0) {\n                     throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n                 }\n-                written += count;\n+            } finally {\n+                newFc.force(true);\n+                newFc.close();\n             }\n-            if (written <= 0 && size > 0) {\n-                throw new IOException(\"Copying to new location \" + rlocFile + \" failed\");\n+            // delete old.idx\n+            fc.close();\n+            if (!delete()) {\n+                LOG.error(\"Failed to delete the previous index file \" + lf);\n+                throw new IOException(\"Failed to delete the previous index file \" + lf);\n             }\n-        } finally {\n-            newFc.force(true);\n-            newFc.close();\n-        }\n-        // delete old.idx\n-        fc.close();\n-        if (!delete()) {\n-            LOG.error(\"Failed to delete the previous index file \" + lf);\n-            throw new IOException(\"Failed to delete the previous index file \" + lf);\n-        }\n \n-        // rename new.idx.rloc to new.idx\n-        if (!rlocFile.renameTo(newFile)) {\n-            LOG.error(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n-            throw new IOException(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n+            // rename new.idx.rloc to new.idx\n+            if (!rlocFile.renameTo(newFile)) {\n+                LOG.error(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n+                throw new IOException(\"Failed to rename \" + rlocFile + \" to \" + newFile);\n+            }\n+            fc = new RandomAccessFile(newFile, mode).getChannel();\n         }\n-        fc = new RandomAccessFile(newFile, mode).getChannel();\n         lf = newFile;\n     }\n "},{"sha":"76f0d871e4ad0c5a51df877ea4c4c0a7146a7ed3","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -528,7 +528,7 @@ public void process(long ledgerId, long offset, ByteBuffer entry) {\n         // Extract it for every entry log except for the current one.\n         // Entry Log ID's are just a long value that starts at 0 and increments\n         // by 1 when the log fills up and we roll to a new one.\n-        long curLogId = entryLogger.getCurrentLogId();\n+        long curLogId = entryLogger.getLeastUnflushedLogId();\n         boolean hasExceptionWhenScan = false;\n         for (long entryLogId = scannedLogId; entryLogId < curLogId; entryLogId++) {\n             // Comb the current entry log file if it has not already been extracted."},{"sha":"eee313de9b1ccef1e751d4acf4267d80eb5c119f","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java","status":"modified","additions":106,"deletions":35,"changes":141,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -21,16 +21,16 @@\n \n package org.apache.bookkeeper.bookie;\n \n-import java.nio.ByteBuffer;\n import java.io.IOException;\n+import java.nio.ByteBuffer;\n \n-import org.apache.bookkeeper.jmx.BKMBeanInfo;\n+import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;\n+import org.apache.bookkeeper.bookie.EntryLogger.EntryLogListener;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n+import org.apache.bookkeeper.jmx.BKMBeanInfo;\n import org.apache.bookkeeper.meta.LedgerManager;\n import org.apache.bookkeeper.proto.BookieProtocol;\n import org.apache.bookkeeper.util.SnapshotMap;\n-import org.apache.zookeeper.ZooKeeper;\n-\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n@@ -39,11 +39,34 @@\n  * This ledger storage implementation stores all entries in a single\n  * file and maintains an index file for each ledger.\n  */\n-class InterleavedLedgerStorage implements LedgerStorage {\n+class InterleavedLedgerStorage implements LedgerStorage, EntryLogListener {\n     final static Logger LOG = LoggerFactory.getLogger(InterleavedLedgerStorage.class);\n \n+    // Hold the last checkpoint\n+    static class CheckpointHolder {\n+        Checkpoint lastCheckpoint = Checkpoint.MAX;\n+\n+        synchronized void setNextCheckpoint(Checkpoint cp) {\n+            if (Checkpoint.MAX.equals(lastCheckpoint) || lastCheckpoint.compareTo(cp) < 0) {\n+                lastCheckpoint = cp;\n+            }\n+        }\n+\n+        synchronized void clearLastCheckpoint(Checkpoint done) {\n+            if (0 == lastCheckpoint.compareTo(done)) {\n+                lastCheckpoint = Checkpoint.MAX;\n+            }\n+        }\n+\n+        synchronized Checkpoint getLastCheckpoint() {\n+            return lastCheckpoint;\n+        }\n+    }\n+\n     EntryLogger entryLogger;\n     LedgerCache ledgerCache;\n+    private final CheckpointSource checkpointSource;\n+    private final CheckpointHolder checkpointHolder = new CheckpointHolder();\n \n     // A sorted map to stored all active ledger ids\n     protected final SnapshotMap<Long, Boolean> activeLedgers;\n@@ -56,12 +79,12 @@\n     // this indicates that a write has happened since the last flush\n     private volatile boolean somethingWritten = false;\n \n-    InterleavedLedgerStorage(ServerConfiguration conf,\n-                             LedgerManager ledgerManager, LedgerDirsManager ledgerDirsManager,\n-                             GarbageCollectorThread.SafeEntryAdder safeEntryAdder)\n-\t\t\tthrows IOException {\n+    InterleavedLedgerStorage(ServerConfiguration conf, LedgerManager ledgerManager,\n+            LedgerDirsManager ledgerDirsManager, CheckpointSource checkpointSource,\n+            GarbageCollectorThread.SafeEntryAdder safeEntryAdder) throws IOException {\n         activeLedgers = new SnapshotMap<Long, Boolean>();\n-        entryLogger = new EntryLogger(conf, ledgerDirsManager);\n+        this.checkpointSource = checkpointSource;\n+        entryLogger = new EntryLogger(conf, ledgerDirsManager, this);\n         ledgerCache = new LedgerCacheImpl(conf, activeLedgers, ledgerDirsManager);\n         gcThread = new GarbageCollectorThread(conf, ledgerCache, entryLogger,\n                 activeLedgers, safeEntryAdder, ledgerManager);\n@@ -115,19 +138,8 @@ synchronized public long addEntry(ByteBuffer entry) throws IOException {\n         long ledgerId = entry.getLong();\n         long entryId = entry.getLong();\n         entry.rewind();\n-        \n-        /*\n-         * Log the entry\n-         */\n-        long pos = entryLogger.addEntry(ledgerId, entry);\n-        \n-        \n-        /*\n-         * Set offset of entry id to be the current ledger position\n-         */\n-        ledgerCache.putEntryOffset(ledgerId, entryId, pos);\n \n-        somethingWritten = true;\n+        processEntry(ledgerId, entryId, entry);\n \n         return entryId;\n     }\n@@ -149,29 +161,29 @@ public ByteBuffer getEntry(long ledgerId, long entryId) throws IOException {\n         return ByteBuffer.wrap(entryLogger.readEntry(ledgerId, entryId, offset));\n     }\n \n-    @Override\n-    public boolean isFlushRequired() {\n-        return somethingWritten;\n-    };\n+    private void flushOrCheckpoint(boolean isCheckpointFlush)\n+            throws IOException {\n \n-    @Override\n-    public void flush() throws IOException {\n-\n-        if (!somethingWritten) {\n-            return;\n-        }\n-        somethingWritten = false;\n         boolean flushFailed = false;\n-\n         try {\n             ledgerCache.flushLedger(true);\n+        } catch (LedgerDirsManager.NoWritableLedgerDirException e) {\n+            throw e;\n         } catch (IOException ioe) {\n             LOG.error(\"Exception flushing Ledger cache\", ioe);\n             flushFailed = true;\n         }\n \n         try {\n-            entryLogger.flush();\n+            // if it is just a checkpoint flush, we just flush rotated entry log files\n+            // in entry logger.\n+            if (isCheckpointFlush) {\n+                entryLogger.checkpoint();\n+            } else {\n+                entryLogger.flush();\n+            }\n+        } catch (LedgerDirsManager.NoWritableLedgerDirException e) {\n+            throw e;\n         } catch (IOException ioe) {\n             LOG.error(\"Exception flushing Ledger\", ioe);\n             flushFailed = true;\n@@ -181,8 +193,67 @@ public void flush() throws IOException {\n         }\n     }\n \n+    @Override\n+    public Checkpoint checkpoint(Checkpoint checkpoint) throws IOException {\n+        Checkpoint lastCheckpoint = checkpointHolder.getLastCheckpoint();\n+        // if checkpoint is less than last checkpoint, we don't need to do checkpoint again.\n+        if (lastCheckpoint.compareTo(checkpoint) > 0) {\n+            return lastCheckpoint;\n+        }\n+        // we don't need to check somethingwritten since checkpoint\n+        // is scheduled when rotate an entry logger file. and we could\n+        // not set somethingWritten to false after checkpoint, since\n+        // current entry logger file isn't flushed yet.\n+        flushOrCheckpoint(true);\n+        // after the ledger storage finished checkpointing, try to clear the done checkpoint\n+        checkpointHolder.clearLastCheckpoint(lastCheckpoint);\n+        return lastCheckpoint;\n+    }\n+\n+    @Override\n+    synchronized public void flush() throws IOException {\n+        if (!somethingWritten) {\n+            return;\n+        }\n+        somethingWritten = false;\n+        flushOrCheckpoint(false);\n+    }\n+\n     @Override\n     public BKMBeanInfo getJMXBean() {\n         return ledgerCache.getJMXBean();\n     }\n+\n+    protected void processEntry(long ledgerId, long entryId, ByteBuffer entry) throws IOException {\n+        processEntry(ledgerId, entryId, entry, true);\n+    }\n+\n+    synchronized protected void processEntry(long ledgerId, long entryId, ByteBuffer entry, boolean rollLog)\n+            throws IOException {\n+        /*\n+         * Touch dirty flag\n+         */\n+        somethingWritten = true;\n+\n+        /*\n+         * Log the entry\n+         */\n+        long pos = entryLogger.addEntry(ledgerId, entry, rollLog);\n+\n+        /*\n+         * Set offset of entry id to be the current ledger position\n+         */\n+        ledgerCache.putEntryOffset(ledgerId, entryId, pos);\n+    }\n+\n+    @Override\n+    public void onRotateEntryLog() {\n+        // for interleaved ledger storage, we request a checkpoint when rotating a entry log file.\n+        // the checkpoint represent the point that all the entries added before this point are already\n+        // in ledger storage and ready to be synced to disk.\n+        // TODO: we could consider remove checkpointSource and checkpointSouce#newCheckpoint\n+        // later if we provide kind of LSN (Log/Journal Squeuence Number)\n+        // mechanism when adding entry.\n+        checkpointHolder.setNextCheckpoint(checkpointSource.newCheckpoint());\n+    }\n }"},{"sha":"2b5165b0dd7aaa7010bd648aca89a0f6d4c1f72e","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","status":"modified","additions":104,"deletions":102,"changes":206,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -32,6 +32,7 @@\n import java.util.List;\n import java.util.concurrent.LinkedBlockingQueue;\n \n+import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;\n import org.apache.bookkeeper.bookie.LedgerDirsManager.NoWritableLedgerDirException;\n import org.apache.bookkeeper.conf.ServerConfiguration;\n import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks.WriteCallback;\n@@ -43,7 +44,7 @@\n /**\n  * Provide journal related management.\n  */\n-class Journal extends Thread {\n+class Journal extends Thread implements CheckpointSource {\n \n     static Logger LOG = LoggerFactory.getLogger(Journal.class);\n \n@@ -83,44 +84,70 @@\n         return logs;\n     }\n \n+    /**\n+     * A wrapper over log mark to provide a checkpoint for users of journal\n+     * to do checkpointing.\n+     */\n+    private static class LogMarkCheckpoint implements Checkpoint {\n+        final LastLogMark mark;\n+\n+        public LogMarkCheckpoint(LastLogMark checkpoint) {\n+            this.mark = checkpoint;\n+        }\n+\n+        @Override\n+        public int compareTo(Checkpoint o) {\n+            if (o == Checkpoint.MAX) {\n+                return -1;\n+            } else if (o == Checkpoint.MIN) {\n+                return 1;\n+            }\n+            return mark.getCurMark().compare(((LogMarkCheckpoint)o).mark.getCurMark());\n+        }\n+\n+        @Override\n+        public boolean equals(Object o) {\n+            if (!(o instanceof LogMarkCheckpoint)) {\n+                return false;\n+            }\n+            return 0 == compareTo((LogMarkCheckpoint)o);\n+        }\n+\n+        @Override\n+        public int hashCode() {\n+            return mark.hashCode();\n+        }\n+    }\n+\n     /**\n      * Last Log Mark\n      */\n     class LastLogMark {\n-        private long txnLogId;\n-        private long txnLogPosition;\n-        private LastLogMark lastMark;\n+        private LogMark curMark;\n         LastLogMark(long logId, long logPosition) {\n-            this.txnLogId = logId;\n-            this.txnLogPosition = logPosition;\n-        }\n-        synchronized void setLastLogMark(long logId, long logPosition) {\n-            txnLogId = logId;\n-            txnLogPosition = logPosition;\n-        }\n-        synchronized void markLog() {\n-            lastMark = new LastLogMark(txnLogId, txnLogPosition);\n+            this.curMark = new LogMark(logId, logPosition);\n         }\n \n-        synchronized LastLogMark getLastMark() {\n-            return lastMark;\n+        synchronized void setCurLogMark(long logId, long logPosition) {\n+            curMark.setLogMark(logId, logPosition);\n         }\n-        synchronized long getTxnLogId() {\n-            return txnLogId;\n+\n+        synchronized LastLogMark markLog() {\n+            return new LastLogMark(curMark.getLogFileId(), curMark.getLogFileOffset());\n         }\n-        synchronized long getTxnLogPosition() {\n-            return txnLogPosition;\n+\n+        synchronized LogMark getCurMark() {\n+            return curMark;\n         }\n \n-        synchronized void rollLog() throws NoWritableLedgerDirException {\n+        synchronized void rollLog(LastLogMark lastMark) throws NoWritableLedgerDirException {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n             // we should record <logId, logPosition> marked in markLog\n             // which is safe since records before lastMark have been\n             // persisted to disk (both index & entry logger)\n-            bb.putLong(lastMark.getTxnLogId());\n-            bb.putLong(lastMark.getTxnLogPosition());\n-            LOG.debug(\"RollLog to persist last marked log : {}\", lastMark);\n+            lastMark.getCurMark().writeLogMark(bb);\n+            LOG.debug(\"RollLog to persist last marked log : {}\", lastMark.getCurMark());\n             List<File> writableLedgerDirs = ledgerDirsManager\n                     .getWritableLedgerDirs();\n             for (File dir : writableLedgerDirs) {\n@@ -151,6 +178,7 @@ synchronized void rollLog() throws NoWritableLedgerDirException {\n         synchronized void readLog() {\n             byte buff[] = new byte[16];\n             ByteBuffer bb = ByteBuffer.wrap(buff);\n+            LogMark mark = new LogMark();\n             for(File dir: ledgerDirsManager.getAllLedgerDirs()) {\n                 File file = new File(dir, \"lastMark\");\n                 try {\n@@ -165,38 +193,31 @@ synchronized void readLog() {\n                         fis.close();\n                     }\n                     bb.clear();\n-                    long i = bb.getLong();\n-                    long p = bb.getLong();\n-                    if (i > txnLogId) {\n-                        txnLogId = i;\n-                        if(p > txnLogPosition) {\n-                          txnLogPosition = p;\n-                        }\n+                    mark.readLogMark(bb);\n+                    if (curMark.compare(mark) < 0) {\n+                        curMark.setLogMark(mark.getLogFileId(), mark.logFileOffset);\n                     }\n                 } catch (IOException e) {\n                     LOG.error(\"Problems reading from \" + file + \" (this is okay if it is the first time starting this bookie\");\n                 }\n             }\n         }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder sb = new StringBuilder();\n-\n-            sb.append(\"LastMark: logId - \").append(txnLogId)\n-              .append(\" , position - \").append(txnLogPosition);\n-\n-            return sb.toString();\n-        }\n     }\n \n     /**\n      * Filter to return list of journals for rolling\n      */\n-    private class JournalRollingFilter implements JournalIdFilter {\n+    private static class JournalRollingFilter implements JournalIdFilter {\n+\n+        final LastLogMark lastMark;\n+\n+        JournalRollingFilter(LastLogMark lastMark) {\n+            this.lastMark = lastMark;\n+        }\n+\n         @Override\n         public boolean accept(long journalId) {\n-            if (journalId < lastLogMark.getLastMark().getTxnLogId()) {\n+            if (journalId < lastMark.getCurMark().getLogFileId()) {\n                 return true;\n             } else {\n                 return false;\n@@ -273,72 +294,53 @@ public Journal(ServerConfiguration conf, LedgerDirsManager ledgerDirsManager) {\n \n         // read last log mark\n         lastLogMark.readLog();\n-        LOG.debug(\"Last Log Mark : {}\", lastLogMark);\n+        LOG.debug(\"Last Log Mark : {}\", lastLogMark.getCurMark());\n     }\n \n     LastLogMark getLastLogMark() {\n         return lastLogMark;\n     }\n \n     /**\n-     * Records a <i>LastLogMark</i> in memory.\n-     *\n-     * <p>\n-     * The <i>LastLogMark</i> contains two parts: first one is <i>txnLogId</i>\n-     * (file id of a journal) and the second one is <i>txnLogPos</i> (offset in\n-     *  a journal). The <i>LastLogMark</i> indicates that those entries before\n-     * it have been persisted to both index and entry log files.\n-     * </p>\n-     *\n-     * <p>\n-     * This method is called before flushing entry log files and ledger cache.\n-     * </p>\n+     * Application tried to schedule a checkpoint. After all the txns added\n+     * before checkpoint are persisted, a <i>checkpoint</i> will be returned\n+     * to application. Application could use <i>checkpoint</i> to do its logic.\n      */\n-    public void markLog() {\n-        lastLogMark.markLog();\n+    @Override\n+    public Checkpoint newCheckpoint() {\n+        return new LogMarkCheckpoint(lastLogMark.markLog());\n     }\n \n     /**\n-     * Persists the <i>LastLogMark</i> marked by #markLog() to disk.\n+     * Telling journal a checkpoint is finished.\n      *\n-     * <p>\n-     * This action means entries added before <i>LastLogMark</i> whose entry data\n-     * and index pages were already persisted to disk. It is the time to safely\n-     * remove journal files created earlier than <i>LastLogMark.txnLogId</i>.\n-     * </p>\n-     * <p>\n-     * If the bookie has crashed before persisting <i>LastLogMark</i> to disk,\n-     * it still has journal files contains entries for which index pages may not\n-     * have been persisted. Consequently, when the bookie restarts, it inspects\n-     * journal files to restore those entries; data isn't lost.\n-     * </p>\n-     * <p>\n-     * This method is called after flushing entry log files and ledger cache successfully, which is to ensure <i>LastLogMark</i> is pesisted.\n-     * </p>\n-     * @see #markLog()\n-     */\n-    public void rollLog() throws NoWritableLedgerDirException {\n-        lastLogMark.rollLog();\n-    }\n-\n-    /**\n-     * Garbage collect older journals\n+     * @throws IOException\n      */\n-    public void gcJournals() {\n-        // list the journals that have been marked\n-        List<Long> logs = listJournalIds(journalDirectory, new JournalRollingFilter());\n-        // keep MAX_BACKUP_JOURNALS journal files before marked journal\n-        if (logs.size() >= maxBackupJournals) {\n-            int maxIdx = logs.size() - maxBackupJournals;\n-            for (int i=0; i<maxIdx; i++) {\n-                long id = logs.get(i);\n-                // make sure the journal id is smaller than marked journal id\n-                if (id < lastLogMark.getLastMark().getTxnLogId()) {\n-                    File journalFile = new File(journalDirectory, Long.toHexString(id) + \".txn\");\n-                    if (!journalFile.delete()) {\n-                        LOG.warn(\"Could not delete old journal file {}\", journalFile);\n+    @Override\n+    public void checkpointComplete(Checkpoint checkpoint, boolean compact) throws IOException {\n+        if (!(checkpoint instanceof LogMarkCheckpoint)) {\n+            return; // we didn't create this checkpoint, so dont do anything with it\n+        }\n+        LogMarkCheckpoint lmcheckpoint = (LogMarkCheckpoint)checkpoint;\n+        LastLogMark mark = lmcheckpoint.mark;\n+\n+        mark.rollLog(mark);\n+        if (compact) {\n+            // list the journals that have been marked\n+            List<Long> logs = listJournalIds(journalDirectory, new JournalRollingFilter(mark));\n+            // keep MAX_BACKUP_JOURNALS journal files before marked journal\n+            if (logs.size() >= maxBackupJournals) {\n+                int maxIdx = logs.size() - maxBackupJournals;\n+                for (int i=0; i<maxIdx; i++) {\n+                    long id = logs.get(i);\n+                    // make sure the journal id is smaller than marked journal id\n+                    if (id < mark.getCurMark().getLogFileId()) {\n+                        File journalFile = new File(journalDirectory, Long.toHexString(id) + \".txn\");\n+                        if (!journalFile.delete()) {\n+                            LOG.warn(\"Could not delete old journal file {}\", journalFile);\n+                        }\n+                        LOG.info(\"garbage collected journal \" + journalFile.getName());\n                     }\n-                    LOG.info(\"garbage collected journal \" + journalFile.getName());\n                 }\n             }\n         }\n@@ -407,21 +409,21 @@ public void scanJournal(long journalId, long journalPos, JournalScanner scanner)\n      * @throws IOException\n      */\n     public void replay(JournalScanner scanner) throws IOException {\n-        final long markedLogId = lastLogMark.getTxnLogId();\n+        final LogMark markedLog = lastLogMark.getCurMark();\n         List<Long> logs = listJournalIds(journalDirectory, new JournalIdFilter() {\n             @Override\n             public boolean accept(long journalId) {\n-                if (journalId < markedLogId) {\n+                if (journalId < markedLog.getLogFileId()) {\n                     return false;\n                 }\n                 return true;\n             }\n         });\n         // last log mark may be missed due to no sync up before\n         // validate filtered log ids only when we have markedLogId\n-        if (markedLogId > 0) {\n-            if (logs.size() == 0 || logs.get(0) != markedLogId) {\n-                throw new IOException(\"Recovery log \" + markedLogId + \" is missing\");\n+        if (markedLog.getLogFileId() > 0) {\n+            if (logs.size() == 0 || logs.get(0) != markedLog.getLogFileId()) {\n+                throw new IOException(\"Recovery log \" + markedLog.getLogFileId() + \" is missing\");\n             }\n         }\n         LOG.debug(\"Try to relay journal logs : {}\", logs);\n@@ -430,8 +432,8 @@ public boolean accept(long journalId) {\n         // system calls done.\n         for(Long id: logs) {\n             long logPosition = 0L;\n-            if(id == markedLogId) {\n-                logPosition = lastLogMark.getTxnLogPosition();\n+            if(id == markedLog.getLogFileId()) {\n+                logPosition = markedLog.getLogFileOffset();\n             }\n             scanJournal(id, logPosition, scanner);\n         }\n@@ -501,7 +503,7 @@ public void run() {\n                             //logFile.force(false);\n                             bc.flush(true);\n                             lastFlushPosition = bc.position();\n-                            lastLogMark.setLastLogMark(logId, lastFlushPosition);\n+                            lastLogMark.setCurLogMark(logId, lastFlushPosition);\n                             for (QueueEntry e : toFlush) {\n                                 e.cb.writeComplete(BookieException.Code.OK,\n                                                    e.ledgerId, e.entryId, null, e.ctx);"},{"sha":"e992d03ddb2d704ec7f326bb120dc50d0b1f2767","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerStorage.java","status":"modified","additions":14,"deletions":5,"changes":19,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerStorage.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerStorage.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LedgerStorage.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -24,6 +24,7 @@\n import java.io.IOException;\n import java.nio.ByteBuffer;\n \n+import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;\n import org.apache.bookkeeper.jmx.BKMBeanInfo;\n \n /**\n@@ -90,18 +91,26 @@\n      */\n     ByteBuffer getEntry(long ledgerId, long entryId) throws IOException;\n \n-    /**\n-     * Whether there is data in the storage which needs to be flushed\n-     */\n-    boolean isFlushRequired();\n-\n     /**\n      * Flushes all data in the storage. Once this is called,\n      * add data written to the LedgerStorage up until this point\n      * has been persisted to perminant storage\n      */\n     void flush() throws IOException;\n \n+    /**\n+     * Ask the ledger storage to sync data until the given <i>checkpoint</i>.\n+     * The ledger storage implementation do checkpoint and return the real checkpoint\n+     * that it finished. The returned the checkpoint indicates that all entries added\n+     * before that point already persist.\n+     *\n+     * @param checkpoint\n+     *          Check Point that {@link Checkpointer} proposed.\n+     * @throws IOException\n+     * @return the checkpoint that the ledger storage finished.\n+     */\n+    Checkpoint checkpoint(Checkpoint checkpoint) throws IOException;\n+\n     /**\n      * Get the JMX management bean for this LedgerStorage\n      */"},{"sha":"103e41968ffae0ffd5a5b05829eb07a67c411eba","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","status":"added","additions":83,"deletions":0,"changes":83,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/LogMark.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -0,0 +1,83 @@\n+/**\n+ * Copyright The Apache Software Foundation\n+ *\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.bookkeeper.bookie;\n+\n+import java.nio.ByteBuffer;\n+\n+/**\n+ * Journal stream position\n+ */\n+class LogMark {\n+    long logFileId;\n+    long logFileOffset;\n+\n+    public LogMark() {\n+        setLogMark(0, 0);\n+    }\n+\n+    public LogMark(LogMark other) {\n+        setLogMark(other.logFileId, other.logFileOffset);\n+    }\n+\n+    public LogMark(long logFileId, long logFileOffset) {\n+        setLogMark(logFileId, logFileOffset);\n+    }\n+\n+    public long getLogFileId() {\n+        return logFileId;\n+    }\n+\n+    public long getLogFileOffset() {\n+        return logFileOffset;\n+    }\n+\n+    public void readLogMark(ByteBuffer bb) {\n+        logFileId = bb.getLong();\n+        logFileOffset = bb.getLong();\n+    }\n+\n+    public void writeLogMark(ByteBuffer bb) {\n+        bb.putLong(logFileId);\n+        bb.putLong(logFileOffset);\n+    }\n+\n+    public void setLogMark(long logFileId, long logFileOffset) {\n+        this.logFileId = logFileId;\n+        this.logFileOffset = logFileOffset;\n+    }\n+\n+    public int compare(LogMark other) {\n+        long ret = this.logFileId - other.logFileId;\n+        if (ret == 0) {\n+            ret = this.logFileOffset - other.logFileOffset;\n+        }\n+        return (ret < 0)? -1 : ((ret > 0)? 1 : 0);\n+    }\n+\n+    @Override\n+    public String toString() {\n+        StringBuilder sb = new StringBuilder();\n+\n+        sb.append(\"LogMark: logFileId - \").append(logFileId)\n+                .append(\" , logFileOffset - \").append(logFileOffset);\n+\n+        return sb.toString();\n+    }\n+}"},{"sha":"2e0f18f1bca06d32fc5c6b9eb02fa5e506c41154","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieAccessor.java","status":"modified","additions":5,"deletions":1,"changes":6,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieAccessor.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieAccessor.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/BookieAccessor.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -22,6 +22,8 @@\n \n import java.io.IOException;\n \n+import org.apache.bookkeeper.bookie.CheckpointSource.Checkpoint;\n+\n /**\n  * Accessor class to avoid making Bookie internals public\n  */\n@@ -30,6 +32,8 @@\n      * Force a bookie to flush its ledger storage\n      */\n     public static void forceFlush(Bookie b) throws IOException {\n+        Checkpoint cp = b.journal.newCheckpoint();\n         b.ledgerStorage.flush();\n+        b.journal.checkpointComplete(cp, true);\n     }\n-}\n\\ No newline at end of file\n+}"},{"sha":"57f9e73bf886c420b4012ff96fc184560e19cc52","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/bookie/CompactionTest.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -276,6 +276,8 @@ public void testCompactionSmallEntryLogs() throws Exception {\n         bkc.deleteLedger(lhs[1].getId());\n         bkc.deleteLedger(lhs[2].getId());\n         LOG.info(\"Finished deleting the ledgers contains most entries.\");\n+        // restart bookies again to roll entry log files.\n+        restartBookies();\n         Thread.sleep(baseConf.getMajorCompactionInterval() * 1000\n                    + baseConf.getGcWaitTime());\n "},{"sha":"8a964395d83bf182d7dc7349d389d558f53089ee","filename":"bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","status":"modified","additions":3,"deletions":1,"changes":4,"blob_url":"https://github.com/apache/bookkeeper/blob/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","raw_url":"https://github.com/apache/bookkeeper/raw/d175ada58dcaf78f0a70b0ebebf489255ae67b5f/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LedgerDeleteTest.java?ref=d175ada58dcaf78f0a70b0ebebf489255ae67b5f","patch":"@@ -96,6 +96,8 @@ public void setUp() throws Exception {\n     public void testLedgerDelete() throws Exception {\n         // Write enough ledger entries so that we roll over the initial entryLog (0.log)\n         LedgerHandle[] lhs = writeLedgerEntries(3, 1024, 1024);\n+        // restart bookies to force rolling entry log files\n+        restartBookies();\n \n         // Delete all of these ledgers from the BookKeeper client\n         for (LedgerHandle lh : lhs) {\n@@ -136,7 +138,7 @@ public void testLedgerDeleteWithExistingEntryLogs() throws Exception {\n             bkc.deleteLedger(lh.getId());\n         }\n         LOG.info(\"Finished deleting all ledgers so waiting for the GC thread to clean up the entryLogs\");\n-        Thread.sleep(2000);\n+        Thread.sleep(2 * baseConf.getGcWaitTime());\n \n         /*\n          * Verify that the first two entry logs ([0,1].log) have been deleted"}]}

