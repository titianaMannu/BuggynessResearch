{"sha":"d5fc00dc6b0a888b68131b7dff7309687c96d07e","node_id":"MDY6Q29tbWl0MTU3NTk1NjpkNWZjMDBkYzZiMGE4ODhiNjgxMzFiN2RmZjczMDk2ODdjOTZkMDdl","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2012-02-01T12:01:49Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2012-02-01T12:01:49Z"},"message":"Removing file accidentally added in r1239096\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1239098 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"6d190177dac751683e0837f95b6678304dd3916d","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/6d190177dac751683e0837f95b6678304dd3916d"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/d5fc00dc6b0a888b68131b7dff7309687c96d07e","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/d5fc00dc6b0a888b68131b7dff7309687c96d07e","html_url":"https://github.com/apache/bookkeeper/commit/d5fc00dc6b0a888b68131b7dff7309687c96d07e","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/d5fc00dc6b0a888b68131b7dff7309687c96d07e/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"5a7f4991610ad60d277830b72dc5d890c63a0f07","url":"https://api.github.com/repos/apache/bookkeeper/commits/5a7f4991610ad60d277830b72dc5d890c63a0f07","html_url":"https://github.com/apache/bookkeeper/commit/5a7f4991610ad60d277830b72dc5d890c63a0f07"}],"stats":{"total":1027,"additions":0,"deletions":1027},"files":[{"sha":"fecc6262978786018b5de209e1f469fa6e08e266","filename":"bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java.orig","status":"removed","additions":0,"deletions":1027,"changes":1027,"blob_url":"https://github.com/apache/bookkeeper/blob/5a7f4991610ad60d277830b72dc5d890c63a0f07/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java.orig","raw_url":"https://github.com/apache/bookkeeper/raw/5a7f4991610ad60d277830b72dc5d890c63a0f07/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java.orig","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java.orig?ref=5a7f4991610ad60d277830b72dc5d890c63a0f07","patch":"@@ -1,1027 +0,0 @@\n-/*\n- *\n- * Licensed to the Apache Software Foundation (ASF) under one\n- * or more contributor license agreements.  See the NOTICE file\n- * distributed with this work for additional information\n- * regarding copyright ownership.  The ASF licenses this file\n- * to you under the Apache License, Version 2.0 (the\n- * \"License\"); you may not use this file except in compliance\n- * with the License.  You may obtain a copy of the License at\n- *\n- *   http://www.apache.org/licenses/LICENSE-2.0\n- *\n- * Unless required by applicable law or agreed to in writing,\n- * software distributed under the License is distributed on an\n- * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n- * KIND, either express or implied.  See the License for the\n- * specific language governing permissions and limitations\n- * under the License.\n- *\n- */\n-\n-package org.apache.bookkeeper.bookie;\n-\n-import java.io.BufferedReader;\n-import java.io.BufferedWriter;\n-import java.io.InputStreamReader;\n-import java.io.OutputStreamWriter;\n-import java.io.File;\n-import java.io.FileInputStream;\n-import java.io.FileNotFoundException;\n-import java.io.FileOutputStream;\n-import java.io.IOException;\n-import java.io.RandomAccessFile;\n-import java.net.InetAddress;\n-import java.net.InetSocketAddress;\n-import java.nio.ByteBuffer;\n-import java.nio.channels.FileChannel;\n-import java.util.ArrayList;\n-import java.util.Collections;\n-import java.util.HashMap;\n-import java.util.LinkedList;\n-import java.util.List;\n-import java.util.concurrent.LinkedBlockingQueue;\n-import java.util.concurrent.atomic.AtomicBoolean;\n-\n-import org.apache.bookkeeper.meta.LedgerManager;\n-import org.apache.bookkeeper.meta.LedgerManagerFactory;\n-import org.apache.bookkeeper.bookie.BookieException;\n-import org.apache.bookkeeper.conf.ServerConfiguration;\n-import org.apache.bookkeeper.proto.BookkeeperInternalCallbacks.WriteCallback;\n-import org.slf4j.Logger;\n-import org.slf4j.LoggerFactory;\n-import org.apache.zookeeper.KeeperException;\n-import org.apache.zookeeper.CreateMode;\n-import org.apache.zookeeper.WatchedEvent;\n-import org.apache.zookeeper.Watcher;\n-import org.apache.zookeeper.ZooKeeper;\n-import org.apache.zookeeper.ZooDefs.Ids;\n-\n-/**\n- * Implements a bookie.\n- *\n- */\n-\n-public class Bookie extends Thread {\n-    HashMap<Long, LedgerDescriptor> ledgers = new HashMap<Long, LedgerDescriptor>();\n-    static Logger LOG = LoggerFactory.getLogger(Bookie.class);\n-    final static long MB = 1024 * 1024L;\n-    // max journal file size\n-    final long maxJournalSize;\n-    // number journal files kept before marked journal\n-    final int maxBackupJournals;\n-\n-    final File journalDirectory;\n-\n-    final File ledgerDirectories[];\n-\n-    final ServerConfiguration conf;\n-\n-    final SyncThread syncThread;\n-    final LedgerManager ledgerManager;\n-\n-    /**\n-     * Current directory layout version. Increment this \n-     * when you make a change to the format of any of the files in \n-     * this directory or to the general layout of the directory.\n-     */\n-    static final int CURRENT_DIRECTORY_LAYOUT_VERSION = 1;\n-    static final String VERSION_FILENAME = \"VERSION\";\n-    \n-    // ZK registration path for this bookie\n-    static final String BOOKIE_REGISTRATION_PATH = \"/ledgers/available/\";\n-\n-    // ZooKeeper client instance for the Bookie\n-    ZooKeeper zk;\n-    private volatile boolean isZkExpired = true;\n-\n-    // Running flag\n-    private volatile boolean running = false;\n-\n-    public static class NoLedgerException extends IOException {\n-        private static final long serialVersionUID = 1L;\n-        private long ledgerId;\n-        public NoLedgerException(long ledgerId) {\n-            this.ledgerId = ledgerId;\n-        }\n-        public long getLedgerId() {\n-            return ledgerId;\n-        }\n-    }\n-    public static class NoEntryException extends IOException {\n-        private static final long serialVersionUID = 1L;\n-        private long ledgerId;\n-        private long entryId;\n-        public NoEntryException(long ledgerId, long entryId) {\n-            super(\"Entry \" + entryId + \" not found in \" + ledgerId);\n-            this.ledgerId = ledgerId;\n-            this.entryId = entryId;\n-        }\n-        public long getLedger() {\n-            return ledgerId;\n-        }\n-        public long getEntry() {\n-            return entryId;\n-        }\n-    }\n-\n-    EntryLogger entryLogger;\n-    LedgerCache ledgerCache;\n-    /**\n-     * SyncThread is a background thread which flushes ledger index pages periodically.\n-     * Also it takes responsibility of garbage collecting journal files.\n-     *\n-     * <p>\n-     * Before flushing, SyncThread first records a log marker {journalId, journalPos} in memory,\n-     * which indicates entries before this log marker would be persisted to ledger files.\n-     * Then sync thread begins flushing ledger index pages to ledger index files, flush entry\n-     * logger to ensure all entries persisted to entry loggers for future reads.\n-     * </p>\n-     * <p>\n-     * After all data has been persisted to ledger index files and entry loggers, it is safe\n-     * to persist the log marker to disk. If bookie failed after persist log mark,\n-     * bookie is able to relay journal entries started from last log mark without losing\n-     * any entries.\n-     * </p>\n-     * <p>\n-     * Those journal files whose id are less than the log id in last log mark, could be\n-     * removed safely after persisting last log mark. We provide a setting to let user keeping\n-     * number of old journal files which may be used for manual recovery in critical disaster.\n-     * </p>\n-     */\n-    class SyncThread extends Thread {\n-        volatile boolean running = true;\n-        // flag to ensure sync thread will not be interrupted during flush\n-        final AtomicBoolean flushing = new AtomicBoolean(false);\n-        // make flush interval as a parameter\n-        final int flushInterval;\n-        public SyncThread(ServerConfiguration conf) {\n-            super(\"SyncThread\");\n-            flushInterval = conf.getFlushInterval();\n-            if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"Flush Interval : \" + flushInterval);\n-            }\n-        }\n-        @Override\n-        public void run() {\n-            while(running) {\n-                synchronized(this) {\n-                    try {\n-                        wait(flushInterval);\n-                        if (!entryLogger.testAndClearSomethingWritten()) {\n-                            continue;\n-                        }\n-                    } catch (InterruptedException e) {\n-                        Thread.currentThread().interrupt();\n-                        continue;\n-                    }\n-                }\n-\n-                // try to mark flushing flag to make sure it would not be interrupted\n-                // by shutdown during flushing. otherwise it will receive\n-                // ClosedByInterruptException which may cause index file & entry logger\n-                // closed and corrupted.\n-                if (!flushing.compareAndSet(false, true)) {\n-                    // set flushing flag failed, means flushing is true now\n-                    // indicates another thread wants to interrupt sync thread to exit\n-                    break;\n-                }\n-\n-                lastLogMark.markLog();\n-                try {\n-                    ledgerCache.flushLedger(true);\n-                } catch (IOException e) {\n-                    LOG.error(\"Exception flushing Ledger\", e);\n-                }\n-                try {\n-                    entryLogger.flush();\n-                } catch (IOException e) {\n-                    LOG.error(\"Exception flushing entry logger\", e);\n-                }\n-                lastLogMark.rollLog();\n-\n-                // list the journals that have been marked\n-                List<Long> logs = listJournalIds(journalDirectory, new JournalIdFilter() {\n-                    @Override\n-                    public boolean accept(long journalId) {\n-                        if (journalId < lastLogMark.lastMark.txnLogId) {\n-                            return true;\n-                        } else {\n-                            return false;\n-                        }\n-                    }\n-                });\n-\n-                // keep MAX_BACKUP_JOURNALS journal files before marked journal\n-                if (logs.size() >= maxBackupJournals) {\n-                    int maxIdx = logs.size() - maxBackupJournals;\n-                    for (int i=0; i<maxIdx; i++) {\n-                        long id = logs.get(i);\n-                        // make sure the journal id is smaller than marked journal id\n-                        if (id < lastLogMark.lastMark.txnLogId) {\n-                            File journalFile = new File(journalDirectory, Long.toHexString(id) + \".txn\");\n-                            journalFile.delete();\n-                            LOG.info(\"garbage collected journal \" + journalFile.getName());\n-                        }\n-                    }\n-                }\n-\n-                // clear flushing flag\n-                flushing.set(false);\n-            }\n-        }\n-\n-        // shutdown sync thread\n-        void shutdown() throws InterruptedException {\n-            running = false;\n-            if (flushing.compareAndSet(false, true)) {\n-                // if setting flushing flag succeed, means syncThread is not flushing now\n-                // it is safe to interrupt itself now \n-                this.interrupt();\n-            }\n-            this.join();\n-        }\n-    }\n-\n-    public Bookie(ServerConfiguration conf) \n-            throws IOException, KeeperException, InterruptedException {\n-        super(\"Bookie-\" + conf.getBookiePort());\n-        this.conf = conf;\n-        this.journalDirectory = conf.getJournalDir();\n-        this.ledgerDirectories = conf.getLedgerDirs();\n-        this.maxJournalSize = conf.getMaxJournalSize() * MB;\n-        this.maxBackupJournals = conf.getMaxBackupJournals();\n-\n-        // check directory layouts\n-        checkDirectoryLayoutVersion(journalDirectory);\n-        for (File dir : ledgerDirectories) {\n-            checkDirectoryLayoutVersion(dir);\n-        }\n-\n-        // instantiate zookeeper client to initialize ledger manager\n-        ZooKeeper newZk = instantiateZookeeperClient(conf.getZkServers());\n-        ledgerManager = LedgerManagerFactory.newLedgerManager(conf, newZk);\n-\n-        syncThread = new SyncThread(conf);\n-        entryLogger = new EntryLogger(conf, this);\n-        ledgerCache = new LedgerCache(conf, ledgerManager);\n-\n-        lastLogMark.readLog();\n-        if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Last Log Mark : \" + lastLogMark);\n-        }\n-        final long markedLogId = lastLogMark.txnLogId;\n-        List<Long> logs = listJournalIds(journalDirectory, new JournalIdFilter() {\n-            @Override\n-            public boolean accept(long journalId) {\n-                if (journalId < markedLogId) {\n-                    return false;\n-                }\n-                return true;\n-            }\n-        });\n-        // last log mark may be missed due to no sync up before\n-        // validate filtered log ids only when we have markedLogId\n-        if (markedLogId > 0) {\n-            if (logs.size() == 0 || logs.get(0) != markedLogId) {\n-                throw new IOException(\"Recovery log \" + markedLogId + \" is missing\");\n-            }\n-        }\n-        if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Try to relay journal logs : \" + logs);\n-        }\n-        // TODO: When reading in the journal logs that need to be synced, we\n-        // should use BufferedChannels instead to minimize the amount of\n-        // system calls done.\n-        ByteBuffer lenBuff = ByteBuffer.allocate(4);\n-        ByteBuffer recBuff = ByteBuffer.allocate(64*1024);\n-        for(Long id: logs) {\n-            FileChannel recLog ;\n-            if(id == markedLogId) {\n-              long markedLogPosition = lastLogMark.txnLogPosition;\n-              recLog = openChannel(id, markedLogPosition);\n-            } else {\n-              recLog = openChannel(id);\n-            }\n-\n-            while(true) {\n-                lenBuff.clear();\n-                fullRead(recLog, lenBuff);\n-                if (lenBuff.remaining() != 0) {\n-                    break;\n-                }\n-                lenBuff.flip();\n-                int len = lenBuff.getInt();\n-                if (len == 0) {\n-                    break;\n-                }\n-                recBuff.clear();\n-                if (recBuff.remaining() < len) {\n-                    recBuff = ByteBuffer.allocate(len);\n-                }\n-                recBuff.limit(len);\n-                if (fullRead(recLog, recBuff) != len) {\n-                    // This seems scary, but it just means that this is where we\n-                    // left off writing\n-                    break;\n-                }\n-                recBuff.flip();\n-                long ledgerId = recBuff.getLong();\n-                if (LOG.isDebugEnabled()) {\n-                    LOG.debug(\"Relay journal - ledger id : \" + ledgerId);\n-                }\n-                LedgerDescriptor handle = getHandle(ledgerId, false);\n-                try {\n-                    recBuff.rewind();\n-                    handle.addEntry(recBuff);\n-                } finally {\n-                    putHandle(handle);\n-                }\n-            }\n-        }\n-        // pass zookeeper instance here\n-        // since GarbageCollector thread should only start after journal\n-        // finished replay\n-        this.zk = newZk;\n-        // make the bookie available\n-        registerBookie(conf.getBookiePort());\n-        setDaemon(true);\n-        LOG.debug(\"I'm starting a bookie with journal directory \" + journalDirectory.getName());\n-        start();\n-        syncThread.start();\n-        // set running here.\n-        // since bookie server use running as a flag to tell bookie server whether it is alive\n-        // if setting it in bookie thread, the watcher might run before bookie thread.\n-        running = true;\n-    }\n-\n-    public static interface JournalIdFilter {\n-        public boolean accept(long journalId);\n-    }\n-\n-    /**\n-     * List all journal ids by a specified journal id filer\n-     *\n-     * @param journalDir journal dir\n-     * @param filter journal id filter\n-     * @return list of filtered ids\n-     */\n-    public static List<Long> listJournalIds(File journalDir, JournalIdFilter filter) {\n-        File logFiles[] = journalDir.listFiles();\n-        List<Long> logs = new ArrayList<Long>();\n-        for(File f: logFiles) {\n-            String name = f.getName();\n-            if (!name.endsWith(\".txn\")) {\n-                continue;\n-            }\n-            String idString = name.split(\"\\\\.\")[0];\n-            long id = Long.parseLong(idString, 16);\n-            if (filter != null) {\n-                if (filter.accept(id)) {\n-                    logs.add(id);\n-                }\n-            } else {\n-                logs.add(id);\n-            }\n-        }\n-        Collections.sort(logs);\n-        return logs;\n-    }\n-\n-    /**\n-     * Instantiate the ZooKeeper client for the Bookie.\n-     */\n-    private ZooKeeper instantiateZookeeperClient(String zkServers) throws IOException {\n-        if (zkServers == null) {\n-            LOG.warn(\"No ZK servers passed to Bookie constructor so BookKeeper clients won't know about this server!\");\n-            isZkExpired = false;\n-            return null;\n-        }\n-        int zkTimeout = conf.getZkTimeout();\n-        // Create the ZooKeeper client instance\n-        return newZookeeper(zkServers, zkTimeout);\n-    }\n-\n-    /**\n-     * Register as an available bookie\n-     */\n-    private void registerBookie(int port) throws IOException {\n-        if (null == zk) {\n-            // zookeeper instance is null, means not register itself to zk\n-            return;\n-        }\n-        // Create the ZK ephemeral node for this Bookie.\n-        try {\n-            zk.create(BOOKIE_REGISTRATION_PATH + InetAddress.getLocalHost().getHostAddress() + \":\" + port, new byte[0],\n-                      Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n-        } catch (Exception e) {\n-            LOG.error(\"ZK exception registering ephemeral Znode for Bookie!\", e);\n-            // Throw an IOException back up. This will cause the Bookie\n-            // constructor to error out. Alternatively, we could do a System\n-            // exit here as this is a fatal error.\n-            throw new IOException(e);\n-        }\n-    }\n-\n-    /**\n-     * Create a new zookeeper client to zk cluster.\n-     *\n-     * <p>\n-     * Bookie Server just used zk client when syncing ledgers for garbage collection.\n-     * So when zk client is expired, it means this bookie server is not available in\n-     * bookie server list. The bookie client will be notified for its expiration. No\n-     * more bookie request will be sent to this server. So it's better to exit when zk\n-     * expired.\n-     * </p>\n-     * <p>\n-     * Since there are lots of bk operations cached in queue, so we wait for all the operations\n-     * are processed and quit. It is done by calling <b>shutdown</b>.\n-     * </p>\n-     *\n-     * @param zkServers the quorum list of zk servers\n-     * @param sessionTimeout session timeout of zk connection\n-     *\n-     * @return zk client instance\n-     */\n-    private ZooKeeper newZookeeper(final String zkServers,\n-                                   final int sessionTimeout) throws IOException {\n-        ZooKeeper newZk = new ZooKeeper(zkServers, sessionTimeout,\n-        new Watcher() {\n-            @Override\n-            public void process(WatchedEvent event) {\n-                // handle session disconnects and expires\n-                if (event.getType()\n-                .equals(Watcher.Event.EventType.None)) {\n-                    if (event.getState().equals(\n-                    Watcher.Event.KeeperState.Disconnected)) {\n-                        LOG.warn(\"ZK client has been disconnected to the ZK server!\");\n-                    } else if (event.getState().equals(\n-                    Watcher.Event.KeeperState.SyncConnected)) {\n-                        LOG.info(\"ZK client has been reconnected to the ZK server!\");\n-                    }\n-                }\n-                // Check for expired connection.\n-                if (event.getState().equals(\n-                Watcher.Event.KeeperState.Expired)) {\n-                    LOG.error(\"ZK client connection to the ZK server has expired!\");\n-                    isZkExpired = true;\n-                    try {\n-                        shutdown();\n-                    } catch (InterruptedException ie) {\n-                        System.exit(-1);\n-                    }\n-                }\n-            }\n-        });\n-        isZkExpired = false;\n-        return newZk;\n-    }\n-\n-    /**\n-     * Check the layout version of a directory. If it is outside of the \n-     * range which this version of the software can handle, throw an\n-     * exception.\n-     *\n-     * @param dir Directory to check\n-     * @throws IOException if layout version if is outside usable range\n-     *               or if there is a problem reading the version file\n-     */\n-    private void checkDirectoryLayoutVersion(File dir) \n-            throws IOException {\n-        if (!dir.isDirectory()) {\n-            throw new IOException(\"Directory(\"+dir+\") isn't a directory\");\n-        }\n-        File versionFile = new File(dir, VERSION_FILENAME);\n-        \n-        FileInputStream fis;\n-        try {\n-            fis = new FileInputStream(versionFile);\n-        } catch (FileNotFoundException e) {\n-            /* \n-             * If the version file is not found, this must\n-             * either be the first time we've used this directory,\n-             * or it must date from before layout versions were introduced.\n-             * In both cases, we just create the version file\n-             */\n-            LOG.info(\"No version file found, creating\");\n-            createDirectoryLayoutVersionFile(dir);\n-            return;\n-        }\n-        \n-        BufferedReader br = new BufferedReader(new InputStreamReader(fis));\n-        try {\n-            String layoutVersionStr = br.readLine();\n-            int layoutVersion = Integer.parseInt(layoutVersionStr);\n-            if (layoutVersion != CURRENT_DIRECTORY_LAYOUT_VERSION) {\n-                String errmsg = \"Directory has an invalid version, expected \" \n-                    + CURRENT_DIRECTORY_LAYOUT_VERSION + \", found \" + layoutVersion;\n-                LOG.error(errmsg);\n-                throw new IOException(errmsg);\n-            }\n-        } catch(NumberFormatException e) {\n-            throw new IOException(\"Version file has invalid content\", e);\n-        } finally {\n-            try {\n-                fis.close();\n-            } catch (IOException e) {\n-                LOG.warn(\"Error closing version file\", e);\n-            }\n-        }\n-    }\n-    \n-    /**\n-     * Create the directory layout version file with the current\n-     * directory layout version\n-     */\n-    private void createDirectoryLayoutVersionFile(File dir) throws IOException {\n-        File versionFile = new File(dir, VERSION_FILENAME);\n-\n-        FileOutputStream fos = new FileOutputStream(versionFile);\n-        BufferedWriter bw = null;\n-        try {\n-            bw = new BufferedWriter(new OutputStreamWriter(fos));\n-            bw.write(String.valueOf(CURRENT_DIRECTORY_LAYOUT_VERSION));\n-        } finally {\n-            if (bw != null) {\n-                bw.close();\n-            }\n-            fos.close();\n-        }\n-    }\n-\n-    private static int fullRead(FileChannel fc, ByteBuffer bb) throws IOException {\n-        int total = 0;\n-        while(bb.remaining() > 0) {\n-            int rc = fc.read(bb);\n-            if (rc <= 0) {\n-                return total;\n-            }\n-            total += rc;\n-        }\n-        return total;\n-    }\n-    private void putHandle(LedgerDescriptor handle) {\n-        synchronized (ledgers) {\n-            handle.decRef();\n-        }\n-    }\n-\n-    private LedgerDescriptor getHandle(long ledgerId, boolean readonly, byte[] masterKey) throws IOException {\n-        LedgerDescriptor handle = null;\n-        synchronized (ledgers) {\n-            handle = ledgers.get(ledgerId);\n-            if (handle == null) {\n-                FileInfo fi = null;\n-                try {\n-                    // get file info will throw NoLedgerException\n-                    fi = ledgerCache.getFileInfo(ledgerId, !readonly);\n-\n-                    // if an existed ledger index file, we can get its master key\n-                    // if an new created ledger index file, we will get a null master key\n-                    byte[] existingMasterKey = fi.readMasterKey();\n-                    ByteBuffer masterKeyToSet = ByteBuffer.wrap(masterKey);\n-                    if (existingMasterKey == null) {\n-                        // no master key set before\n-                        fi.writeMasterKey(masterKey);\n-                    } else if (!masterKeyToSet.equals(ByteBuffer.wrap(existingMasterKey))) {\n-                        throw new IOException(\"Wrong master key for ledger \" + ledgerId);\n-                    }\n-                    handle = createHandle(ledgerId, readonly);\n-                    ledgers.put(ledgerId, handle);\n-                    handle.setMasterKey(masterKeyToSet);\n-                } finally {\n-                    if (fi != null) {\n-                        fi.release();\n-                    }\n-                }\n-            }\n-            handle.incRef();\n-        }\n-        return handle;\n-    }\n-\n-    private LedgerDescriptor getHandle(long ledgerId, boolean readonly) throws IOException {\n-        LedgerDescriptor handle = null;\n-        synchronized (ledgers) {\n-            handle = ledgers.get(ledgerId);\n-            if (handle == null) {\n-                FileInfo fi = null;\n-                try {\n-                    // get file info will throw NoLedgerException\n-                    fi = ledgerCache.getFileInfo(ledgerId, !readonly);\n-\n-                    // if an existed ledger index file, we can get its master key\n-                    // if an new created ledger index file, we will get a null master key\n-                    byte[] existingMasterKey = fi.readMasterKey();\n-                    if (existingMasterKey == null) {\n-                        throw new IOException(\"Weird! No master key found in ledger \" + ledgerId);\n-                    }\n-\n-                    handle = createHandle(ledgerId, readonly);\n-                    ledgers.put(ledgerId, handle);\n-                    handle.setMasterKey(ByteBuffer.wrap(existingMasterKey));\n-                } finally {\n-                    if (fi != null) {\n-                        fi.release();\n-                    }\n-                }\n-            }\n-            handle.incRef();\n-        }\n-        return handle;\n-    }\n-\n-\n-    private LedgerDescriptor createHandle(long ledgerId, boolean readOnly) throws IOException {\n-        return new LedgerDescriptor(ledgerId, entryLogger, ledgerCache);\n-    }\n-\n-    static class QueueEntry {\n-        QueueEntry(ByteBuffer entry, long ledgerId, long entryId,\n-                   WriteCallback cb, Object ctx) {\n-            this.entry = entry.duplicate();\n-            this.cb = cb;\n-            this.ctx = ctx;\n-            this.ledgerId = ledgerId;\n-            this.entryId = entryId;\n-        }\n-\n-        ByteBuffer entry;\n-\n-        long ledgerId;\n-\n-        long entryId;\n-\n-        WriteCallback cb;\n-\n-        Object ctx;\n-    }\n-\n-    LinkedBlockingQueue<QueueEntry> queue = new LinkedBlockingQueue<QueueEntry>();\n-\n-    public final static long preAllocSize = 4*1024*1024;\n-\n-    public final static ByteBuffer zeros = ByteBuffer.allocate(512);\n-\n-    class LastLogMark {\n-        long txnLogId;\n-        long txnLogPosition;\n-        LastLogMark lastMark;\n-        LastLogMark(long logId, long logPosition) {\n-            this.txnLogId = logId;\n-            this.txnLogPosition = logPosition;\n-        }\n-        synchronized void setLastLogMark(long logId, long logPosition) {\n-            txnLogId = logId;\n-            txnLogPosition = logPosition;\n-        }\n-        synchronized void markLog() {\n-            lastMark = new LastLogMark(txnLogId, txnLogPosition);\n-        }\n-        synchronized void rollLog() {\n-            byte buff[] = new byte[16];\n-            ByteBuffer bb = ByteBuffer.wrap(buff);\n-            // we should record <logId, logPosition> marked in markLog\n-            // which is safe since records before lastMark have been\n-            // persisted to disk (both index & entry logger)\n-            bb.putLong(lastMark.txnLogId);\n-            bb.putLong(lastMark.txnLogPosition);\n-            if (LOG.isDebugEnabled()) {\n-                LOG.debug(\"RollLog to persist last marked log : \" + lastMark);\n-            }\n-            for(File dir: ledgerDirectories) {\n-                File file = new File(dir, \"lastMark\");\n-                try {\n-                    FileOutputStream fos = new FileOutputStream(file);\n-                    fos.write(buff);\n-                    fos.getChannel().force(true);\n-                    fos.close();\n-                } catch (IOException e) {\n-                    LOG.error(\"Problems writing to \" + file, e);\n-                }\n-            }\n-        }\n-\n-        /**\n-         * Read last mark from lastMark file.\n-         * The last mark should first be max journal log id,\n-         * and then max log position in max journal log.\n-         */\n-        synchronized void readLog() {\n-            byte buff[] = new byte[16];\n-            ByteBuffer bb = ByteBuffer.wrap(buff);\n-            for(File dir: ledgerDirectories) {\n-                File file = new File(dir, \"lastMark\");\n-                try {\n-                    FileInputStream fis = new FileInputStream(file);\n-                    fis.read(buff);\n-                    fis.close();\n-                    bb.clear();\n-                    long i = bb.getLong();\n-                    long p = bb.getLong();\n-                    if (i > txnLogId) {\n-                        txnLogId = i;\n-                        if(p > txnLogPosition) {\n-                          txnLogPosition = p;\n-                        }\n-                    }\n-                } catch (IOException e) {\n-                    LOG.error(\"Problems reading from \" + file + \" (this is okay if it is the first time starting this bookie\");\n-                }\n-            }\n-        }\n-\n-        @Override\n-        public String toString() {\n-            StringBuilder sb = new StringBuilder();\n-            \n-            sb.append(\"LastMark: logId - \").append(txnLogId)\n-              .append(\" , position - \").append(txnLogPosition);\n-            \n-            return sb.toString();\n-        }\n-    }\n-\n-    private LastLogMark lastLogMark = new LastLogMark(0, 0);\n-\n-    LastLogMark getLastLogMark() {\n-        return lastLogMark;\n-    }\n-\n-    public boolean isRunning() {\n-        return running;\n-    }\n-\n-    /**\n-     * A thread used for persisting journal entries to journal files.\n-     * \n-     * <p>\n-     * Besides persisting journal entries, it also takes responsibility of\n-     * rolling journal files when a journal file reaches journal file size\n-     * limitation.\n-     * </p>\n-     * <p>\n-     * During journal rolling, it first closes the writing journal, generates\n-     * new journal file using current timestamp, and continue persistence logic.\n-     * Those journals will be garbage collected in SyncThread.\n-     * </p>\n-     */\n-    @Override\n-    public void run() {\n-        LinkedList<QueueEntry> toFlush = new LinkedList<QueueEntry>();\n-        ByteBuffer lenBuff = ByteBuffer.allocate(4);\n-        try {\n-            long logId = 0;\n-            FileChannel logFile = null;\n-            BufferedChannel bc = null;\n-            long nextPrealloc = 0;\n-            long lastFlushPosition = 0;\n-\n-            QueueEntry qe = null;\n-            while (true) {\n-                // new journal file to write\n-                if (null == logFile) {\n-                    logId = System.currentTimeMillis();\n-                    logFile = openChannel(logId);\n-                    bc = new BufferedChannel(logFile, 65536);\n-                    zeros.clear();\n-                    nextPrealloc = preAllocSize;\n-                    lastFlushPosition = 0;\n-                    logFile.write(zeros, nextPrealloc);\n-                }\n-\n-                if (qe == null) {\n-                    if (toFlush.isEmpty()) {\n-                        qe = queue.take();\n-                    } else {\n-                        qe = queue.poll();\n-                        if (qe == null || bc.position() > lastFlushPosition + 512*1024) {\n-                            //logFile.force(false);\n-                            bc.flush(true);\n-                            lastFlushPosition = bc.position();\n-                            lastLogMark.setLastLogMark(logId, lastFlushPosition);\n-                            for (QueueEntry e : toFlush) {\n-                                e.cb.writeComplete(0, e.ledgerId, e.entryId, null, e.ctx);\n-                            }\n-                            toFlush.clear();\n-\n-                            // check whether journal file is over file limit\n-                            if (bc.position() > maxJournalSize) {\n-                                logFile.close();\n-                                logFile = null;\n-                                continue;\n-                            }\n-                        }\n-                    }\n-                }\n-\n-                if (isZkExpired) {\n-                    LOG.warn(\"Exiting... zk client has expired.\");\n-                    break;\n-                }\n-                if (qe == null) { // no more queue entry\n-                    continue;\n-                }\n-                lenBuff.clear();\n-                lenBuff.putInt(qe.entry.remaining());\n-                lenBuff.flip();\n-                //\n-                // we should be doing the following, but then we run out of\n-                // direct byte buffers\n-                // logFile.write(new ByteBuffer[] { lenBuff, qe.entry });\n-                bc.write(lenBuff);\n-                bc.write(qe.entry);\n-                if (bc.position() > nextPrealloc) {\n-                    nextPrealloc = (logFile.size() / preAllocSize + 1) * preAllocSize;\n-                    zeros.clear();\n-                    logFile.write(zeros, nextPrealloc);\n-                }\n-                toFlush.add(qe);\n-                qe = null;\n-            }\n-        } catch (Exception e) {\n-            LOG.error(\"Bookie thread exiting\", e);\n-        }\n-    }\n-\n-    private FileChannel openChannel(long logId) throws FileNotFoundException {\n-        return openChannel(logId, 0);\n-    }\n-\n-    private FileChannel openChannel(long logId, long position) throws FileNotFoundException {\n-        FileChannel logFile = new RandomAccessFile(new File(journalDirectory,\n-                Long.toHexString(logId) + \".txn\"),\n-                \"rw\").getChannel();\n-        try {\n-            logFile.position(position);\n-        } catch (IOException e) {\n-            LOG.error(\"Bookie journal file can seek to position :\", e);\n-        }\n-        return logFile;\n-    }\n-\n-    public synchronized void shutdown() throws InterruptedException {\n-        if (!running) { // avoid shutdown twice\n-            return;\n-        }\n-        // Shutdown the ZK client\n-        if(zk != null) zk.close();\n-        this.interrupt();\n-        this.join();\n-        syncThread.shutdown(); \n-        for(LedgerDescriptor d: ledgers.values()) {\n-            d.close();\n-        }\n-        // Shutdown the EntryLogger which has the GarbageCollector Thread running\n-        entryLogger.shutdown();\n-        // close Ledger Manager\n-        ledgerManager.close();\n-        // setting running to false here, so watch thread in bookie server know it only after bookie shut down\n-        running = false;\n-    }\n-\n-    /** \n-     * Retrieve the ledger descriptor for the ledger which entry should be added to.\n-     * The LedgerDescriptor returned from this method should be eventually freed with \n-     * #putHandle().\n-     *\n-     * @throws BookieException if masterKey does not match the master key of the ledger\n-     */\n-    private LedgerDescriptor getLedgerForEntry(ByteBuffer entry, byte[] masterKey) \n-            throws IOException, BookieException {\n-        long ledgerId = entry.getLong();\n-        LedgerDescriptor handle = getHandle(ledgerId, false, masterKey);\n-\n-        if(!handle.cmpMasterKey(ByteBuffer.wrap(masterKey))) {\n-            putHandle(handle);\n-            throw BookieException.create(BookieException.Code.UnauthorizedAccessException);\n-        }\n-        return handle;\n-    }\n-\n-    /**\n-     * Add an entry to a ledger as specified by handle. \n-     */\n-    private void addEntryInternal(LedgerDescriptor handle, ByteBuffer entry, WriteCallback cb, Object ctx)\n-            throws IOException, BookieException {\n-        long ledgerId = handle.getLedgerId();\n-        entry.rewind();\n-        long entryId = handle.addEntry(entry);\n-\n-        entry.rewind();\n-        if (LOG.isTraceEnabled()) {\n-            LOG.trace(\"Adding \" + entryId + \"@\" + ledgerId);\n-        }\n-        queue.add(new QueueEntry(entry, ledgerId, entryId, cb, ctx));\n-    }\n-\n-    /**\n-     * Add entry to a ledger, even if the ledger has previous been fenced. This should only\n-     * happen in bookie recovery or ledger recovery cases, where entries are being replicates \n-     * so that they exist on a quorum of bookies. The corresponding client side call for this\n-     * is not exposed to users.\n-     */\n-    public void recoveryAddEntry(ByteBuffer entry, WriteCallback cb, Object ctx, byte[] masterKey) \n-            throws IOException, BookieException {\n-        LedgerDescriptor handle = getLedgerForEntry(entry, masterKey);\n-        synchronized (handle) {\n-            try {\n-                addEntryInternal(handle, entry, cb, ctx);\n-            } finally {\n-                putHandle(handle);\n-            }\n-        }\n-    }\n-    \n-    /** \n-     * Add entry to a ledger.\n-     * @throws BookieException.LedgerFencedException if the ledger is fenced\n-     */\n-    public void addEntry(ByteBuffer entry, WriteCallback cb, Object ctx, byte[] masterKey)\n-            throws IOException, BookieException {\n-        LedgerDescriptor handle = getLedgerForEntry(entry, masterKey);\n-        synchronized (handle) {\n-            try {\n-                if (handle.isFenced()) {\n-                    throw BookieException.create(BookieException.Code.LedgerFencedException);\n-                }\n-                \n-                addEntryInternal(handle, entry, cb, ctx);\n-            } finally {\n-                putHandle(handle);\n-            }\n-        }\n-    }\n-\n-    /**\n-     * Fences a ledger. From this point on, clients will be unable to \n-     * write to this ledger. Only recoveryAddEntry will be\n-     * able to add entries to the ledger.\n-     * This method is idempotent. Once a ledger is fenced, it can\n-     * never be unfenced. Fencing a fenced ledger has no effect.\n-     */\n-    public void fenceLedger(long ledgerId) throws IOException {\n-        LedgerDescriptor handle = getHandle(ledgerId, true);\n-        synchronized (handle) {\n-            handle.setFenced();\n-        }\n-    }\n-\n-    public ByteBuffer readEntry(long ledgerId, long entryId) throws IOException {\n-        LedgerDescriptor handle = getHandle(ledgerId, true);\n-        try {\n-            if (LOG.isTraceEnabled()) {\n-                LOG.trace(\"Reading \" + entryId + \"@\" + ledgerId);\n-            }\n-            return handle.readEntry(entryId);\n-        } finally {\n-            putHandle(handle);\n-        }\n-    }\n-\n-    // The rest of the code is test stuff\n-    static class CounterCallback implements WriteCallback {\n-        int count;\n-\n-        synchronized public void writeComplete(int rc, long l, long e, InetSocketAddress addr, Object ctx) {\n-            count--;\n-            if (count == 0) {\n-                notifyAll();\n-            }\n-        }\n-\n-        synchronized public void incCount() {\n-            count++;\n-        }\n-\n-        synchronized public void waitZero() throws InterruptedException {\n-            while (count > 0) {\n-                wait();\n-            }\n-        }\n-    }\n-\n-    /**\n-     * @param args\n-     * @throws IOException\n-     * @throws InterruptedException\n-     */\n-    public static void main(String[] args) \n-            throws IOException, InterruptedException, BookieException, KeeperException {\n-        Bookie b = new Bookie(new ServerConfiguration());\n-        CounterCallback cb = new CounterCallback();\n-        long start = System.currentTimeMillis();\n-        for (int i = 0; i < 100000; i++) {\n-            ByteBuffer buff = ByteBuffer.allocate(1024);\n-            buff.putLong(1);\n-            buff.putLong(i);\n-            buff.limit(1024);\n-            buff.position(0);\n-            cb.incCount();\n-            b.addEntry(buff, cb, null, new byte[0]);\n-        }\n-        cb.waitZero();\n-        long end = System.currentTimeMillis();\n-        System.out.println(\"Took \" + (end-start) + \"ms\");\n-    }\n-}"}]}

