{"sha":"faf407d5d40e9d476bab2a926f41b993bf87098f","node_id":"MDY6Q29tbWl0MTU3NTk1NjpmYWY0MDdkNWQ0MGU5ZDQ3NmJhYjJhOTI2ZjQxYjk5M2JmODcwOThm","commit":{"author":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-01-09T11:29:39Z"},"committer":{"name":"Ivan Brendan Kelly","email":"ivank@apache.org","date":"2013-01-09T11:29:39Z"},"message":"BOOKKEEPER-531: Cache thread should wait until old entries are collected (sijie via ivank)\n\ngit-svn-id: https://svn.apache.org/repos/asf/zookeeper/bookkeeper/trunk@1430795 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"7d399d4fc5b19ce93007edabdd4f82ae15aa2aed","url":"https://api.github.com/repos/apache/bookkeeper/git/trees/7d399d4fc5b19ce93007edabdd4f82ae15aa2aed"},"url":"https://api.github.com/repos/apache/bookkeeper/git/commits/faf407d5d40e9d476bab2a926f41b993bf87098f","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/bookkeeper/commits/faf407d5d40e9d476bab2a926f41b993bf87098f","html_url":"https://github.com/apache/bookkeeper/commit/faf407d5d40e9d476bab2a926f41b993bf87098f","comments_url":"https://api.github.com/repos/apache/bookkeeper/commits/faf407d5d40e9d476bab2a926f41b993bf87098f/comments","author":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"committer":{"login":"ivankelly","id":54955,"node_id":"MDQ6VXNlcjU0OTU1","avatar_url":"https://avatars.githubusercontent.com/u/54955?v=4","gravatar_id":"","url":"https://api.github.com/users/ivankelly","html_url":"https://github.com/ivankelly","followers_url":"https://api.github.com/users/ivankelly/followers","following_url":"https://api.github.com/users/ivankelly/following{/other_user}","gists_url":"https://api.github.com/users/ivankelly/gists{/gist_id}","starred_url":"https://api.github.com/users/ivankelly/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/ivankelly/subscriptions","organizations_url":"https://api.github.com/users/ivankelly/orgs","repos_url":"https://api.github.com/users/ivankelly/repos","events_url":"https://api.github.com/users/ivankelly/events{/privacy}","received_events_url":"https://api.github.com/users/ivankelly/received_events","type":"User","site_admin":false},"parents":[{"sha":"ed9b6037be51845f7cab2446593df695ffcede59","url":"https://api.github.com/repos/apache/bookkeeper/commits/ed9b6037be51845f7cab2446593df695ffcede59","html_url":"https://github.com/apache/bookkeeper/commit/ed9b6037be51845f7cab2446593df695ffcede59"}],"stats":{"total":332,"additions":194,"deletions":138},"files":[{"sha":"43b9e71f5d169fc8f55eeded9804cd54f2fce5d2","filename":"CHANGES.txt","status":"modified","additions":2,"deletions":0,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/CHANGES.txt","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/CHANGES.txt","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/CHANGES.txt?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -220,6 +220,8 @@ Trunk (unreleased changes)\n \n \tBOOKKEEPER-532: AbstractSubscriptionManager#AcquireOp read subscriptions every time even it already owned the topic. (sijie via fpj)\n \n+        BOOKKEEPER-531: Cache thread should wait until old entries are collected (sijie via ivank)\n+\n     IMPROVEMENTS:\n \n       BOOKKEEPER-467: Allocate ports for testing dynamically (ivank)"},{"sha":"ea01be671a7481532b1a49a49820b38b16f81119","filename":"doc/hedwigParams.textile","status":"modified","additions":1,"deletions":0,"changes":1,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/doc/hedwigParams.textile","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/doc/hedwigParams.textile","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/doc/hedwigParams.textile?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -43,6 +43,7 @@ h3. Read-ahead cache parameters\n bq. Upon a range scan request for a given topic, two hints are provided as to when scanning should stop: the number of messages scanned and the total size of messages scanned. Scanning stops whenever one of these limits is exceeded.\n \n | @cache_size@ | Sets the size of the read-ahead cache. Default is the smallest of 2G or half the heap size. | \n+| @cache_entry_ttl@ | Sets TTL for cache entries. Each time adding new entry into the cache, those expired cache entries would be discarded. If the value is set to zero or less than zero, cache entry will not be evicted until the cache is fullfilled or the messages are already consumed. Default is 0. |\n | @scan_backoff_ms@ | The backoff time (in milliseconds) to retry scans after failures. Default value is 1s (1000ms). Default is 1s. |\n | @num_readahead_cache_threads@ | Sets the number of threads to be used for the read-ahead mechanism. Default is the number of cores as returned with a call to <code>Runtime.getRuntime().availableProcessors()</code>.|\n "},{"sha":"2ca2d5462a9dbdcaaf4b0bfaa4f63f5709256cdd","filename":"hedwig-server/conf/hw_server.conf","status":"modified","additions":7,"deletions":0,"changes":7,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/conf/hw_server.conf","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/conf/hw_server.conf","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/conf/hw_server.conf?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -132,6 +132,13 @@ ssl_enabled=false\n # <code>Runtime.getRuntime().availableProcessors()</code>.\n # num_readahead_cache_threads=\n \n+# Set TTL for cache entries. Each time adding new entry into the cache,\n+# those expired cache entries would be discarded. If the value is set\n+# to zero or less than zero, cache entry will not be evicted until the\n+# cache is fullfilled or the messages are already consumed. By default\n+# the value is zero.\n+# cache_entry_ttl=\n+\n ################################\n # Metadata Settings\n ################################"},{"sha":"0bb21062aa5127de2d37822dacbc26b4c4ea9868","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","status":"modified","additions":12,"deletions":0,"changes":12,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/common/ServerConfiguration.java?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -41,6 +41,7 @@\n     protected final static String READAHEAD_COUNT = \"readahead_count\";\n     protected final static String READAHEAD_SIZE = \"readahead_size\";\n     protected final static String CACHE_SIZE = \"cache_size\";\n+    protected final static String CACHE_ENTRY_TTL = \"cache_entry_ttl\";\n     protected final static String SCAN_BACKOFF_MSEC = \"scan_backoff_ms\";\n     protected final static String SERVER_PORT = \"server_port\";\n     protected final static String SSL_SERVER_PORT = \"ssl_server_port\";\n@@ -174,6 +175,17 @@ public long getMaximumCacheSize() {\n         return conf.getLong(CACHE_SIZE, Math.min(2 * 1024L * 1024L * 1024L, Runtime.getRuntime().maxMemory() / 2));\n     }\n \n+    /**\n+     * Cache Entry TTL. By default is 0, cache entry will not be evicted\n+     * until the cache is fullfilled or the messages are already consumed.\n+     * The TTL is only checked when trying adding a new entry into the cache.\n+     *\n+     * @return cache entry ttl.\n+     */\n+    public long getCacheEntryTTL() {\n+        return conf.getLong(CACHE_ENTRY_TTL, 0L);\n+    }\n+\n     /**\n      * After a scan of a log fails, how long before we retry (in msec)\n      * "},{"sha":"c3ca93404d5400b8d0463d161f97f275f25b3b0b","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","status":"modified","additions":126,"deletions":124,"changes":250,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCache.java?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -34,6 +34,7 @@\n import java.util.concurrent.LinkedBlockingQueue;\n import java.util.concurrent.RejectedExecutionException;\n import java.util.concurrent.atomic.AtomicLong;\n+import java.util.concurrent.atomic.AtomicInteger;\n \n import org.apache.hedwig.protocol.PubSubProtocol;\n import org.slf4j.Logger;\n@@ -57,7 +58,7 @@\n import org.apache.hedwig.server.persistence.ReadAheadCacheBean;\n import org.apache.hedwig.util.Callback;\n \n-public class ReadAheadCache implements PersistenceManager, Runnable, HedwigJMXService {\n+public class ReadAheadCache implements PersistenceManager, HedwigJMXService {\n \n     static Logger logger = LoggerFactory.getLogger(ReadAheadCache.class);\n \n@@ -78,31 +79,54 @@\n         new ConcurrentHashMap<CacheKey, CacheValue>();\n \n     /**\n-     * To simplify synchronization, the cache will be maintained by a single\n-     * cache maintainer thread. This is the queue that will hold requests that\n-     * need to be served by this thread\n+     * We also want to track the entries in seq-id order so that we can clean up\n+     * entries after the last subscriber\n      */\n-    protected BlockingQueue<CacheRequest> requestQueue = new LinkedBlockingQueue<CacheRequest>();\n+    protected ConcurrentMap<ByteString, SortedSet<Long>> orderedIndexOnSeqId =\n+        new ConcurrentHashMap<ByteString, SortedSet<Long>>();\n \n     /**\n-     * We want to keep track of when entries were added in the cache, so that we\n-     * can remove them in a FIFO fashion\n+     * Partition Cache into Serveral Segments for simplify synchronization.\n+     * Each segment maintains its time index and segment size.\n      */\n-    protected SortedMap<Long, Set<CacheKey>> timeIndexOfAddition = new TreeMap<Long, Set<CacheKey>>();\n+    static class CacheSegment {\n \n-    /**\n-     * We also want to track the entries in seq-id order so that we can clean up\n-     * entries after the last subscriber\n-     */\n-    protected Map<ByteString, SortedSet<Long>> orderedIndexOnSeqId =\n-        new HashMap<ByteString, SortedSet<Long>>();\n+        /**\n+         * We want to keep track of when entries were added in the cache, so that we\n+         * can remove them in a FIFO fashion\n+         */\n+        protected SortedMap<Long, Set<CacheKey>> timeIndexOfAddition = new TreeMap<Long, Set<CacheKey>>();\n+\n+        /**\n+         * We maintain an estimate of the current size of each cache segment,\n+         * so that the thread know when to evict entries from cache segment.\n+         */\n+        protected AtomicLong presentSegmentSize = new AtomicLong(0);\n+\n+    }\n \n     /**\n      * We maintain an estimate of the current size of the cache, so that we know\n      * when to evict entries.\n      */\n     protected AtomicLong presentCacheSize = new AtomicLong(0);\n \n+    /**\n+     * Num pending requests.\n+     */\n+    protected AtomicInteger numPendingRequests = new AtomicInteger(0);\n+\n+    /**\n+     * Cache segment for different threads\n+     */\n+    protected final ThreadLocal<CacheSegment> cacheSegment =\n+        new ThreadLocal<CacheSegment>() {\n+            @Override\n+            protected CacheSegment initialValue() {\n+                return new CacheSegment();\n+            }\n+        };\n+\n     /**\n      * One instance of a callback that we will pass to the underlying\n      * persistence manager when asking it to persist messages\n@@ -116,13 +140,14 @@\n     protected ReadAheadException readAheadExceptionInstance = new ReadAheadException();\n \n     protected ServerConfiguration cfg;\n-    protected Thread cacheThread;\n     // Boolean indicating if this thread should continue running. This is used\n     // when we want to stop the thread during a PubSubServer shutdown.\n     protected volatile boolean keepRunning = true;\n \n     protected final OrderedSafeExecutor cacheWorkers;\n-    protected final long maxCacheSize;\n+    protected final int numCacheWorkers;\n+    protected volatile long maxSegmentSize;\n+    protected volatile long cacheEntryTTL;\n \n     // JMX Beans\n     ReadAheadCacheBean jmxCacheBean = null;\n@@ -135,13 +160,23 @@\n     public ReadAheadCache(PersistenceManagerWithRangeScan realPersistenceManager, ServerConfiguration cfg) {\n         this.realPersistenceManager = realPersistenceManager;\n         this.cfg = cfg;\n-        cacheThread = new Thread(this, \"CacheThread\");\n-        cacheWorkers = new OrderedSafeExecutor(cfg.getNumReadAheadCacheThreads());\n-        maxCacheSize = cfg.getMaximumCacheSize();\n+        numCacheWorkers = cfg.getNumReadAheadCacheThreads();\n+        cacheWorkers = new OrderedSafeExecutor(numCacheWorkers);\n+        reloadConf(cfg);\n+    }\n+\n+    /**\n+     * Reload configuration\n+     *\n+     * @param conf\n+     *          Server configuration object\n+     */\n+    protected void reloadConf(ServerConfiguration cfg) {\n+        maxSegmentSize = cfg.getMaximumCacheSize() / numCacheWorkers;\n+        cacheEntryTTL = cfg.getCacheEntryTTL();\n     }\n \n     public ReadAheadCache start() {\n-        cacheThread.start();\n         return this;\n     }\n \n@@ -229,9 +264,11 @@ protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest\n             return;\n         }\n         try {\n+            numPendingRequests.incrementAndGet();\n             cacheWorkers.submitOrdered(topic, new SafeRunnable() {\n                 @Override\n                 public void safeRun() {\n+                    numPendingRequests.decrementAndGet();\n                     obj.performRequest();\n                 }\n             });\n@@ -240,22 +277,6 @@ public void safeRun() {\n         }\n     }\n \n-    /**\n-     * Too complicated to deal with enqueue failures from the context of our\n-     * callbacks. Its just simpler to quit and restart afresh. Moreover, this\n-     * should not happen as the request queue for the cache maintainer is\n-     * unbounded.\n-     *\n-     * @param obj\n-     */\n-    protected void enqueueWithoutFailure(CacheRequest obj) {\n-        if (!requestQueue.offer(obj)) {\n-            throw new UnexpectedError(\"Could not enqueue object: \" + obj.toString()\n-                                      + \" to cache request queue. Exiting.\");\n-\n-        }\n-    }\n-\n     /**\n      * Another method from {@link PersistenceManager}.\n      *\n@@ -275,7 +296,7 @@ public void scanSingleMessage(ScanRequest request) {\n      * message-ids older than the one specified\n      */\n     public void deliveredUntil(ByteString topic, Long seqId) {\n-        enqueueWithoutFailure(new DeliveredUntil(topic, seqId));\n+        enqueueWithoutFailureByTopic(topic, new DeliveredUntil(topic, seqId));\n     }\n \n     /**\n@@ -304,31 +325,15 @@ public void consumeToBound(ByteString topic) {\n     }\n \n     /**\n-     * ========================================================================\n-     * BEGINNING OF CODE FOR THE CACHE MAINTAINER THREAD\n-     *\n-     * 1. The run method. It simply dequeues from the request queue, checks the\n-     * type of object and acts accordingly\n-     */\n-    public void run() {\n-        while (keepRunning) {\n-            CacheRequest obj;\n-            try {\n-                obj = requestQueue.take();\n-            } catch (InterruptedException e) {\n-                Thread.currentThread().interrupt();\n-                return;\n-            }\n-            obj.performRequest();\n-        }\n-\n-    }\n-\n-    /**\n-     * Stop method which will enqueue a ShutdownCacheRequest.\n+     * Stop the readahead cache.\n      */\n     public void stop() {\n-        enqueueWithoutFailure(new ShutdownCacheRequest());\n+        try {\n+            keepRunning = false;\n+            cacheWorkers.shutdown();\n+        } catch (Exception e) {\n+            logger.warn(\"Failed to shut down cache workers : \", e);\n+        }\n     }\n \n     /**\n@@ -533,31 +538,28 @@ protected void addMessageToCache(final CacheKey cacheKey,\n             }\n         }\n \n+        CacheSegment segment = cacheSegment.get();\n+        int size = message.getBody().size();\n+\n         // update the cache size\n-        final long newCacheSize = presentCacheSize.addAndGet(message.getBody().size());\n+        segment.presentSegmentSize.addAndGet(size);\n+        presentCacheSize.addAndGet(size);\n \n         synchronized (cacheValue) {\n             // finally add the message to the cache\n             cacheValue.setMessageAndInvokeCallbacks(message, currTime);\n         }\n \n-        // if overgrown, collect old entries\n-        enqueueWithoutFailure(new CacheRequest() {\n-            @Override\n-            public void performRequest() {\n-                // maintain the index of seq-id\n-                MapMethods.addToMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n-                                         cacheKey.getSeqId(), TreeSetLongFactory.instance);\n-\n-                // maintain the time index of addition\n-                MapMethods.addToMultiMap(timeIndexOfAddition, currTime,\n-                                         cacheKey, HashSetCacheKeyFactory.instance);\n-                // update time index\n-                if (newCacheSize > maxCacheSize) {\n-                    collectOldCacheEntries();\n-                }\n-            }\n-        });\n+        // maintain the index of seq-id\n+        // no lock since threads are partitioned by topics\n+        MapMethods.addToMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n+                                 cacheKey.getSeqId(), TreeSetLongFactory.instance);\n+\n+        // maintain the time index of addition\n+        MapMethods.addToMultiMap(segment.timeIndexOfAddition, currTime,\n+                                 cacheKey, HashSetCacheKeyFactory.instance);\n+\n+        collectOldOrExpiredCacheEntries(segment);\n     }\n \n     protected void removeMessageFromCache(final CacheKey cacheKey, Exception exception,\n@@ -569,6 +571,8 @@ protected void removeMessageFromCache(final CacheKey cacheKey, Exception excepti\n             return;\n         }\n \n+        CacheSegment segment = cacheSegment.get();\n+\n         long timeOfAddition = 0;\n         synchronized (cacheValue) {\n             if (cacheValue.isStub()) {\n@@ -578,57 +582,65 @@ protected void removeMessageFromCache(final CacheKey cacheKey, Exception excepti\n                 return;\n             }\n \n-            presentCacheSize.addAndGet(0 - cacheValue.getMessage().getBody().size());\n+            int size = 0 - cacheValue.getMessage().getBody().size();\n+            presentCacheSize.addAndGet(size);\n+            segment.presentSegmentSize.addAndGet(size);\n             timeOfAddition = cacheValue.getTimeOfAddition();\n         }\n \n-        // maintain the 2 indexes lazily\n-        if (maintainSeqIdIndex || maintainTimeIndex) {\n-            final long additionTime = timeOfAddition;\n-            enqueueWithoutFailure(new CacheRequest() {\n-                @Override\n-                public void performRequest() {\n-                    if (maintainSeqIdIndex) {\n-                        MapMethods.removeFromMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n-                                                      cacheKey.getSeqId());\n-                    }\n-                    if (maintainTimeIndex) {\n-                        MapMethods.removeFromMultiMap(timeIndexOfAddition, additionTime,\n-                                                      cacheKey);\n-                    }\n-                }\n-            });\n+        if (maintainSeqIdIndex) {\n+            MapMethods.removeFromMultiMap(orderedIndexOnSeqId, cacheKey.getTopic(),\n+                                          cacheKey.getSeqId());\n+        }\n+        if (maintainTimeIndex) {\n+            MapMethods.removeFromMultiMap(segment.timeIndexOfAddition,\n+                                          timeOfAddition, cacheKey);\n         }\n     }\n \n     /**\n      * Collection of old entries is simple. Just collect in insert-time order,\n      * oldest to newest.\n      */\n-    protected void collectOldCacheEntries() {\n-        while (presentCacheSize.get() > cfg.getMaximumCacheSize () &&\n-               !timeIndexOfAddition.isEmpty()) {\n-            Long earliestTime = timeIndexOfAddition.firstKey();\n-            Set<CacheKey> oldCacheEntries = timeIndexOfAddition.get(earliestTime);\n-\n-            // Note: only concrete cache entries, and not stubs are in the time\n-            // index. Hence there can be no callbacks pending on these cache\n-            // entries. Hence safe to remove them directly.\n-            for (Iterator<CacheKey> iter = oldCacheEntries.iterator(); iter.hasNext();) {\n-                final CacheKey cacheKey = iter.next();\n-\n-                logger.debug(\"Removing {} from cache because it's the oldest.\", cacheKey);\n-                removeMessageFromCache(cacheKey, readAheadExceptionInstance, //\n-                                       // maintainTimeIndex=\n-                                       false,\n-                                       // maintainSeqIdIndex=\n-                                       true);\n+    protected void collectOldOrExpiredCacheEntries(CacheSegment segment) {\n+        if (cacheEntryTTL > 0) {\n+            // clear expired entries\n+            while (!segment.timeIndexOfAddition.isEmpty()) {\n+                Long earliestTime = segment.timeIndexOfAddition.firstKey();\n+                if (MathUtils.now() - earliestTime < cacheEntryTTL) {\n+                    break;\n+                }\n+                collectCacheEntriesAtTimestamp(segment, earliestTime);\n             }\n+        }\n \n-            timeIndexOfAddition.remove(earliestTime);\n+        while (segment.presentSegmentSize.get() > maxSegmentSize &&\n+               !segment.timeIndexOfAddition.isEmpty()) {\n+            Long earliestTime = segment.timeIndexOfAddition.firstKey();\n+            collectCacheEntriesAtTimestamp(segment, earliestTime);\n         }\n     }\n \n+    private void collectCacheEntriesAtTimestamp(CacheSegment segment, long timestamp) {\n+        Set<CacheKey> oldCacheEntries = segment.timeIndexOfAddition.get(timestamp);\n+\n+        // Note: only concrete cache entries, and not stubs are in the time\n+        // index. Hence there can be no callbacks pending on these cache\n+        // entries. Hence safe to remove them directly.\n+        for (Iterator<CacheKey> iter = oldCacheEntries.iterator(); iter.hasNext();) {\n+            final CacheKey cacheKey = iter.next();\n+\n+            logger.debug(\"Removing {} from cache because it's the oldest.\", cacheKey);\n+            removeMessageFromCache(cacheKey, readAheadExceptionInstance, //\n+                                   // maintainTimeIndex=\n+                                   false,\n+                                   // maintainSeqIdIndex=\n+                                   true);\n+        }\n+\n+        segment.timeIndexOfAddition.remove(timestamp);\n+    }\n+\n     /**\n      * ========================================================================\n      * The rest is just simple wrapper classes.\n@@ -775,16 +787,6 @@ public void performRequest() {\n         }\n     }\n \n-    protected class ShutdownCacheRequest implements CacheRequest {\n-        // This is a simple type of CacheRequest we will enqueue when\n-        // the PubSubServer is shut down and we want to stop the ReadAheadCache\n-        // thread.\n-        public void performRequest() {\n-            keepRunning = false;\n-            cacheWorkers.shutdown();\n-        }\n-    }\n-\n     @Override\n     public void registerJMX(HedwigMBeanInfo parent) {\n         try {"},{"sha":"1f43095e62b70872f006ddffd001dc25520159b1","filename":"hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","status":"modified","additions":1,"deletions":1,"changes":2,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/main/java/org/apache/hedwig/server/persistence/ReadAheadCacheBean.java?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -58,7 +58,7 @@ public int getNumCachedEntries() {\n \n     @Override\n     public int getNumPendingCacheRequests() {\n-        return cache.requestQueue.size();\n+        return cache.numPendingRequests.get();\n     }\n \n }"},{"sha":"10378060e345785b1fb37f5a763602c1d97ce132","filename":"hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","status":"modified","additions":45,"deletions":13,"changes":58,"blob_url":"https://github.com/apache/bookkeeper/blob/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","raw_url":"https://github.com/apache/bookkeeper/raw/faf407d5d40e9d476bab2a926f41b993bf87098f/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java","contents_url":"https://api.github.com/repos/apache/bookkeeper/contents/hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestReadAheadCacheWhiteBox.java?ref=faf407d5d40e9d476bab2a926f41b993bf87098f","patch":"@@ -49,17 +49,12 @@ public MyReadAheadCache(PersistenceManagerWithRangeScan persistenceManger, Serve\n             super(persistenceManger, cfg);\n         }\n \n-        @Override\n-        protected void enqueueWithoutFailure(CacheRequest obj) {\n-            // make it perform in the same thread\n-            obj.performRequest();\n-        }\n-\n         @Override\n         protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest obj) {\n             // make it perform in the same thread\n             obj.performRequest();\n         }\n+\n     }\n \n     class MyServerConfiguration extends ServerConfiguration {\n@@ -68,7 +63,8 @@ protected void enqueueWithoutFailureByTopic(ByteString topic, final CacheRequest\n         // the count limit\n         int readAheadCount = NUM_MESSAGES / 2;\n         long readAheadSize = (long) (MSG_SIZE * 2.5);\n-        long maxCacheSize = Long.MAX_VALUE;\n+        long maxCacheSize = Integer.MAX_VALUE;\n+        long cacheEntryTTL = 0L;\n \n         @Override\n         public int getReadAheadCount() {\n@@ -84,6 +80,12 @@ public long getReadAheadSizeBytes() {\n         public long getMaximumCacheSize() {\n             return maxCacheSize;\n         }\n+\n+        @Override\n+        public long getCacheEntryTTL() {\n+            return cacheEntryTTL;\n+        }\n+\n     }\n \n     @Before\n@@ -167,7 +169,8 @@ public void testDeliveredUntil() throws Exception {\n         cacheBasedPersistenceManager.deliveredUntil(topic, (long) messages.size());\n         // should have no effect\n         assertTrue(cacheBasedPersistenceManager.cache.isEmpty());\n-        assertTrue(cacheBasedPersistenceManager.timeIndexOfAddition.isEmpty());\n+        assertTrue(cacheBasedPersistenceManager.cacheSegment.get()\n+                   .timeIndexOfAddition.isEmpty());\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.isEmpty());\n         assertTrue(0 == cacheBasedPersistenceManager.presentCacheSize.get());\n \n@@ -245,7 +248,8 @@ public void testAddMessageToCache() {\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.get(topic).contains(1L));\n \n         CacheValue value = cacheBasedPersistenceManager.cache.get(key);\n-        assertTrue(cacheBasedPersistenceManager.timeIndexOfAddition.get(value.timeOfAddition).contains(key));\n+        assertTrue(cacheBasedPersistenceManager.cacheSegment.get()\n+                   .timeIndexOfAddition.get(value.timeOfAddition).contains(key));\n     }\n \n     @Test(timeout=60000)\n@@ -255,7 +259,8 @@ public void testRemoveMessageFromCache() {\n         cacheBasedPersistenceManager.removeMessageFromCache(key, new Exception(), true, true);\n         assertTrue(cacheBasedPersistenceManager.cache.isEmpty());\n         assertTrue(cacheBasedPersistenceManager.orderedIndexOnSeqId.isEmpty());\n-        assertTrue(cacheBasedPersistenceManager.timeIndexOfAddition.isEmpty());\n+        assertTrue(cacheBasedPersistenceManager.cacheSegment.get()\n+                   .timeIndexOfAddition.isEmpty());\n     }\n \n     @Test(timeout=60000)\n@@ -268,9 +273,36 @@ public void testCollectOldCacheEntries() {\n         }\n \n         int n = 2;\n-        myConf.maxCacheSize = n * MSG_SIZE;\n-        cacheBasedPersistenceManager.collectOldCacheEntries();\n+        myConf.maxCacheSize = n * MSG_SIZE * myConf.getNumReadAheadCacheThreads();\n+        cacheBasedPersistenceManager.reloadConf(myConf);\n+        cacheBasedPersistenceManager.collectOldOrExpiredCacheEntries(\n+                cacheBasedPersistenceManager.cacheSegment.get());\n+        assertEquals(n, cacheBasedPersistenceManager.cache.size());\n+        assertEquals(n, cacheBasedPersistenceManager.cacheSegment.get()\n+                     .timeIndexOfAddition.size());\n+    }\n+\n+    @Test(timeout=60000)\n+    public void testCollectExpiredCacheEntries() throws Exception {\n+        int i = 1;\n+        int n = 2;\n+        long ttl = 5000L;\n+        myConf.cacheEntryTTL = ttl;\n+        long curTime = MathUtils.now();\n+        cacheBasedPersistenceManager.reloadConf(myConf);\n+        for (Message m : messages) {\n+            CacheKey key = new CacheKey(topic, i);\n+            cacheBasedPersistenceManager.addMessageToCache(key, m, curTime++);\n+            if (i == NUM_MESSAGES - n) {\n+                Thread.sleep(2 * ttl);\n+                curTime += 2 * ttl;\n+            }\n+            i++;\n+        }\n+\n         assertEquals(n, cacheBasedPersistenceManager.cache.size());\n-        assertEquals(n, cacheBasedPersistenceManager.timeIndexOfAddition.size());\n+        assertEquals(n, cacheBasedPersistenceManager.cacheSegment.get()\n+                     .timeIndexOfAddition.size());\n     }\n+\n }"}]}

