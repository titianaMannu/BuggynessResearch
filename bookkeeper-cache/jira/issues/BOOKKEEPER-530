{"expand":"renderedFields,names,schema,operations,editmeta,changelog,versionedRepresentations","id":"12625473","self":"https://issues.apache.org/jira/rest/api/2/issue/12625473","key":"BOOKKEEPER-530","fields":{"fixVersions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12320244","id":"12320244","description":"Release 4.2.0","name":"4.2.0","archived":false,"released":true,"releaseDate":"2013-01-19"}],"resolution":{"self":"https://issues.apache.org/jira/rest/api/2/resolution/1","id":"1","description":"A fix for this issue is checked into the tree and tested.","name":"Fixed"},"customfield_12312322":null,"customfield_12312323":null,"customfield_12310420":"302015","customfield_12312320":null,"customfield_12312321":null,"customfield_12312328":null,"customfield_12312329":null,"customfield_12312326":null,"customfield_12310300":null,"customfield_12312327":null,"customfield_12312324":null,"customfield_12312720":null,"customfield_12312325":null,"lastViewed":null,"priority":{"self":"https://issues.apache.org/jira/rest/api/2/priority/3","iconUrl":"https://issues.apache.org/jira/images/icons/priorities/major.svg","name":"Major","id":"3"},"labels":[],"customfield_12312333":null,"customfield_12312334":null,"customfield_12313422":"false","customfield_12312331":null,"customfield_12312332":null,"aggregatetimeoriginalestimate":null,"timeestimate":null,"customfield_12312330":null,"versions":[{"self":"https://issues.apache.org/jira/rest/api/2/version/12319145","id":"12319145","name":"4.1.0","archived":false,"released":true,"releaseDate":"2012-06-13"}],"customfield_12311120":null,"customfield_12313826":null,"issuelinks":[],"customfield_12312339":null,"customfield_12313825":null,"assignee":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"customfield_12312337":null,"customfield_12313823":null,"customfield_12312338":null,"customfield_12311920":null,"customfield_12313822":null,"customfield_12312335":null,"customfield_12313821":null,"customfield_12312336":null,"customfield_12313820":null,"status":{"self":"https://issues.apache.org/jira/rest/api/2/status/6","description":"The issue is considered finished, the resolution is correct. Issues which are not closed can be reopened.","iconUrl":"https://issues.apache.org/jira/images/icons/statuses/closed.png","name":"Closed","id":"6","statusCategory":{"self":"https://issues.apache.org/jira/rest/api/2/statuscategory/3","id":3,"key":"done","colorName":"green","name":"Done"}},"components":[{"self":"https://issues.apache.org/jira/rest/api/2/component/12314394","id":"12314394","name":"bookkeeper-server","description":"Bookkeeper server."}],"customfield_12312026":null,"customfield_12312023":null,"customfield_12312024":null,"aggregatetimeestimate":null,"customfield_12312022":null,"customfield_12310921":null,"customfield_12310920":"248650","customfield_12312823":null,"creator":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"subtasks":[],"reporter":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"aggregateprogress":{"progress":0,"total":0},"customfield_12313520":null,"customfield_12310250":null,"progress":{"progress":0,"total":0},"customfield_12313924":null,"votes":{"self":"https://issues.apache.org/jira/rest/api/2/issue/BOOKKEEPER-530/votes","votes":0,"hasVoted":false},"worklog":{"startAt":0,"maxResults":20,"total":0,"worklogs":[]},"customfield_12313920":null,"issuetype":{"self":"https://issues.apache.org/jira/rest/api/2/issuetype/1","id":"1","description":"A problem which impairs or prevents the functions of the product.","iconUrl":"https://issues.apache.org/jira/secure/viewavatar?size=xsmall&avatarId=21133&avatarType=issuetype","name":"Bug","subtask":false,"avatarId":21133},"timespent":null,"customfield_12314020":"{summaryBean=com.atlassian.jira.plugin.devstatus.rest.SummaryBean@c627a28[summary={pullrequest=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@33cfbb5a[overall=PullRequestOverallBean{stateCount=0, state='OPEN', details=PullRequestOverallDetails{openCount=0, mergedCount=0, declinedCount=0}},byInstanceType={}], build=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@92d16f7[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BuildOverallBean@477679e3[failedBuildCount=0,successfulBuildCount=0,unknownBuildCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], review=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@9a4b3b3[overall=com.atlassian.jira.plugin.devstatus.summary.beans.ReviewsOverallBean@13d67f97[stateCount=0,state=<null>,dueDate=<null>,overDue=false,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], deployment-environment=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@72ad59b4[overall=com.atlassian.jira.plugin.devstatus.summary.beans.DeploymentOverallBean@6608f63[topEnvironments=[],showProjects=false,successfulCount=0,count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], repository=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@2a759d37[overall=com.atlassian.jira.plugin.devstatus.summary.beans.CommitOverallBean@a7f7529[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}], branch=com.atlassian.jira.plugin.devstatus.rest.SummaryItemBean@1207ed2b[overall=com.atlassian.jira.plugin.devstatus.summary.beans.BranchOverallBean@101e639f[count=0,lastUpdated=<null>,lastUpdatedTimestamp=<null>],byInstanceType={}]},errors=[],configErrors=[]], devSummaryJson={\"cachedValue\":{\"errors\":[],\"configErrors\":[],\"summary\":{\"pullrequest\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":\"OPEN\",\"details\":{\"openCount\":0,\"mergedCount\":0,\"declinedCount\":0,\"total\":0},\"open\":true},\"byInstanceType\":{}},\"build\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"failedBuildCount\":0,\"successfulBuildCount\":0,\"unknownBuildCount\":0},\"byInstanceType\":{}},\"review\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"stateCount\":0,\"state\":null,\"dueDate\":null,\"overDue\":false,\"completed\":false},\"byInstanceType\":{}},\"deployment-environment\":{\"overall\":{\"count\":0,\"lastUpdated\":null,\"topEnvironments\":[],\"showProjects\":false,\"successfulCount\":0},\"byInstanceType\":{}},\"repository\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}},\"branch\":{\"overall\":{\"count\":0,\"lastUpdated\":null},\"byInstanceType\":{}}}},\"isStale\":false}}","customfield_12314141":null,"customfield_12314140":null,"project":{"self":"https://issues.apache.org/jira/rest/api/2/project/12311293","id":"12311293","key":"BOOKKEEPER","name":"Bookkeeper","projectTypeKey":"software","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/projectavatar?pid=12311293&avatarId=10011","24x24":"https://issues.apache.org/jira/secure/projectavatar?size=small&pid=12311293&avatarId=10011","16x16":"https://issues.apache.org/jira/secure/projectavatar?size=xsmall&pid=12311293&avatarId=10011","32x32":"https://issues.apache.org/jira/secure/projectavatar?size=medium&pid=12311293&avatarId=10011"},"projectCategory":{"self":"https://issues.apache.org/jira/rest/api/2/projectCategory/14780","id":"14780","description":"BookKeeper","name":"BookKeeper"}},"aggregatetimespent":null,"customfield_12312520":null,"customfield_12314422":null,"customfield_12314421":null,"customfield_12314146":null,"customfield_12314420":null,"customfield_12314145":null,"customfield_12314144":null,"customfield_12314143":null,"resolutiondate":"2013-01-10T14:34:08.160+0000","workratio":-1,"customfield_12312923":null,"customfield_12312920":null,"customfield_12312921":null,"watches":{"self":"https://issues.apache.org/jira/rest/api/2/issue/BOOKKEEPER-530/watchers","watchCount":5,"isWatching":false},"created":"2012-12-29T07:38:31.068+0000","updated":"2013-02-13T15:46:35.826+0000","timeoriginalestimate":null,"description":"{code}\n        try {\n            entryLogger.scanEntryLog(entryLogId, new CompactionScanner(entryLogMeta));\n            // after moving entries to new entry log, remove this old one\n            removeEntryLog(entryLogId);\n        } catch (IOException e) {\n            LOG.info(\"Premature exception when compacting \" + entryLogId, e); \n        } finally {\n            // clear compacting flag\n            compacting.set(false);\n        }\n{code}\n\ncurrently compaction code has a bit problem: as the code described above, old entry log is removed after new entries are added to new entry log, but new entry log might not be flushed. if failures happened after removal but before flush, data would be lost.\n\nwhen I implemented compaction feature in BOOKKEEPER-160, I remembered that I took care of letting entry go back to normal addEntry flow to reflect journal and index. But seems that the addEntry doesn't go thru journal, just move entries between entry log files w/o any flush guarantee.\n\nthere are two ideas for this solution:\n\nsimple one is to let compaction going to normal addEntry flow (adding entry to ledger storage and putting it in journal). the other one is GC thread either wait for ledger storage to flush in sync thread in one flush interval or force a ledger storage flush before removing entry log files.\n\nBTW, it was hard to design a test case by simulating bookie abnormally shut down itself after entry log files are removed.","customfield_10010":null,"timetracking":{},"customfield_12314523":null,"customfield_12314127":null,"customfield_12314522":null,"customfield_12314126":null,"customfield_12314521":null,"customfield_12314125":null,"customfield_12314520":null,"customfield_12314124":null,"customfield_12312340":null,"attachment":[{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12563939","id":"12563939","filename":"0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-09T14:49:35.081+0000","size":14271,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12563939/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12563771","id":"12563771","filename":"0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-08T16:15:52.826+0000","size":13190,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12563771/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12563765","id":"12563765","filename":"0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-08T15:37:40.696+0000","size":13110,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12563765/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch"},{"self":"https://issues.apache.org/jira/rest/api/2/attachment/12563332","id":"12563332","filename":"0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-04T18:17:43.972+0000","size":12213,"mimeType":"text/x-patch","content":"https://issues.apache.org/jira/secure/attachment/12563332/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch"}],"customfield_12314123":null,"customfield_12312341":null,"customfield_12312220":null,"customfield_12314122":null,"customfield_12314121":null,"customfield_12314120":null,"customfield_12314129":null,"customfield_12314524":null,"customfield_12314128":null,"summary":"data might be lost during compaction.","customfield_12314130":null,"customfield_12310291":null,"customfield_12310290":null,"customfield_12311024":null,"customfield_12314138":null,"customfield_12314137":null,"environment":null,"customfield_12314136":null,"customfield_12314135":null,"customfield_12311020":null,"customfield_12314134":null,"duedate":null,"customfield_12314132":null,"customfield_12314131":null,"comment":{"comments":[{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13540799","id":"13540799","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"bq. But seems that the addEntry doesn't go thru journal, just move entries between entry log files w/o any flush guarantee.\n\nSijie, I don't understand what you're trying to say here, we do write and flush addEntry requests to the journal. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2012-12-29T07:50:00.930+0000","updated":"2012-12-29T07:50:00.930+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13540818","id":"13540818","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"{code}\n    /** \n     * Scanner used to do entry log compaction\n     */\n    class EntryLogCompactionScanner implements EntryLogger.EntryLogScanner {\n        @Override\n        public boolean accept(long ledgerId) {\n            // bookie has no knowledge about which ledger is deleted\n            // so just accept all ledgers.\n            return true;\n        }   \n\n        @Override\n        public void process(long ledgerId, long offset, ByteBuffer buffer)\n            throws IOException {\n            addEntry(buffer);\n        }   \n    }\n{code}\n\n[~fpj], in compaction scanner, we just call LedgerStorage#addEntry to move entry from old entry log file to new entry log file. we don't add this entry again to journal during moving entries. this is what I mean.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2012-12-29T08:45:58.499+0000","updated":"2012-12-29T08:45:58.499+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13542439","id":"13542439","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"I think it has to go through the journal, due to the issues we discussed on BOOKKEEPER-447. To recap, due to the design of LedgerCacheImpl, an index files may be flushed before the corresponding entrylog has been flushed. There is a possibility, that an index file is flushed but the entry logger is not and a crash occurs. The entry is now inaccessible, as the index file points to a bad location.\n\nWe can't use the stock Bookie#addEntry though, as this adds to the index before the journal, so the same issue could occur. We need an internal syncAddEntry which does the following sequence.\n# add to Journal\n# add to entryLogger\n# add to ledgerIndex\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-02T21:32:10.351+0000","updated":"2013-01-02T21:32:10.351+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13542486","id":"13542486","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"I'm a bit confused here, why do we need to write to the journal during compaction? Can't we write a shadow (compacted) entry log and swap with the original entry log once compaction completes? ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-02T22:23:44.142+0000","updated":"2013-01-02T22:23:44.142+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13542641","id":"13542641","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"> I'm a bit confused here, why do we need to write to the journal during compaction?\n\nI think the problem here is that we had separated index files with entry log files. during compaction, we had to modify index entries when moving entry data. if we used SSTable like structure to combine entry data and indices together like what HBase or leveldb did, we can do as you suggested. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-03T01:33:18.308+0000","updated":"2013-01-03T01:33:18.308+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13543472","id":"13543472","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"body":"Got it, it is using the journal for atomicity. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=fpj","name":"fpj","key":"fpj","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=fpj&avatarId=16030","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=fpj&avatarId=16030","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=fpj&avatarId=16030","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=fpj&avatarId=16030"},"displayName":"Flavio Paiva Junqueira","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-04T00:46:58.393+0000","updated":"2013-01-04T00:46:58.393+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13544093","id":"13544093","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"Attached patch which first writes to the journal and then to the ledger storage when compacting a log.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-04T18:17:43.975+0000","updated":"2013-01-04T18:17:43.975+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13544636","id":"13544636","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"looks good. some comments about log statements.\n\n{code}\n+    private class BookieSafeEntryAdder implements SafeEntryAdder {\n+        @Override\n+        public void safeAddEntry(final long ledgerId, final ByteBuffer buffer,\n+                                 final GenericCallback<Void> cb) {\n+            journal.logAddEntry(buffer, new WriteCallback() {\n+                    @Override\n+                    public void writeComplete(int rc, long ledgerId2, long entryId,\n+                                              InetSocketAddress addr, Object ctx) {\n+                        try {\n+                            addEntryByLedgerId(ledgerId, buffer);\n+                            cb.operationComplete(rc, null);\n+                        } catch (IOException ioe) {\n+                            LOG.error(\"Error adding to ledger storage\", ioe);\n+                            // couldn't add to ledger storage\n+                            cb.operationComplete(BookieException.Code.IllegalOpException, null);\n+                        } catch (BookieException bke) {\n+                            LOG.error(\"Bookie error adding to ledger storage\", bke);\n+                            // couldn't add to ledger storage\n+                            cb.operationComplete(bke.getCode(), null);\n+                        }\n+                    }\n+                }, null);\n+        }\n+    }\n{code}\n\nfirst, it would be better to check the return code 'rc' in #logAddEntry. Although currently it was just return 0, if future someone changed it, he might miss this place.\n\nsecond, it would be better to log more info in the log statements to indicate which ledger, which entry encountered errors.\n\nBTW, not related to this jira.\ncurrently we have two different addEntry flow in the code now, one is addEntry to ledger storage first and add to journal later. the other one is adding entry to journal first and addEntry to ledger storage later. In 4.3.0, we might need to consider consolidating these two flows, as my first proposed patch for bookkeeper-447. :-) ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-05T09:01:42.956+0000","updated":"2013-01-05T09:01:42.956+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13544637","id":"13544637","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"cancel patch until comments addressed.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-05T09:02:09.182+0000","updated":"2013-01-05T09:02:09.182+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13546208","id":"13546208","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"body":"Hi Ivan, patch looks nice. Adding entries to the journal is pretty good.\n\nJust adding few more comments...\n\n1) fix typo in log statements:\n\"Coundn't readd all entries\" -> \"Couldn't re-add all entries\"\n\n\n2) int IOException = -104;  is no where used, can we remove this?\n\n\n3)I'm bit confused about the usage of asynchronously sending all the entries to the journal#queue and awaitCompete() in the scanner. \nAssume there is a failure in between adding the entries, since we are adding all the entries to the journal#queue the awaitComplete() call would be unnecessarily waiting for all the entries to finish add operation. Anyway the compaction would finally throws IOException.\n\n{code}\n            synchronized(outstandingRequests) {\n                while (outstandingRequests.get() > 0) {\n                    outstandingRequests.wait();\n                }\n                if (allSuccessful.get() == false) {\n                    throw new IOException(\"Coundn't readd all entries\");\n                }\n            }                \n{code}\n\nIMHO, how about adding one by one entry to the journal, on writeComplete() add it to entrylogger?\nAlso, the scanner would see the return code and throws exception if it fails.\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-01-07T19:54:00.246+0000","updated":"2013-01-07T19:54:00.246+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13546947","id":"13546947","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"Patch addresses comments.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-08T15:37:40.700+0000","updated":"2013-01-08T15:37:40.700+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13546958","id":"13546958","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"{quote}\n3)I'm bit confused about the usage of asynchronously sending all the entries to the journal#queue and awaitCompete() in the scanner.\nAssume there is a failure in between adding the entries, since we are adding all the entries to the journal#queue the awaitComplete() call would be unnecessarily waiting for all the entries to finish add operation. Anyway the compaction would finally throws IOException.\nIMHO, how about adding one by one entry to the journal, on writeComplete() add it to entrylogger?{quote}\nThis is what we do. The code adds to the journal, and when the journal callback triggers it adds to the entrylogger and index. If the journal succeeds and the entrylogger or index fails, this is fine due to the order, as the entry remains in the same place until we write the index, which is the last thing.\n\n[~hustlmsp]\n{quote}\ncurrently we have two different addEntry flow in the code now, one is addEntry to ledger storage first and add to journal later. the other one is adding entry to journal first and addEntry to ledger storage later. In 4.3.0, we might need to consider consolidating these two flows, as my first proposed patch for bookkeeper-447. \n{quote}\nI agree.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-08T15:51:06.946+0000","updated":"2013-01-08T15:51:06.946+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13546974","id":"13546974","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"Testing JIRA BOOKKEEPER-530\n\n\nPatch [0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch|https://issues.apache.org/jira/secure/attachment/12563765/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch] downloaded at Tue Jan  8 16:05:31 UTC 2013\n\n----------------------------\n\n{color:green}+1 PATCH_APPLIES{color}\n{color:green}+1 CLEAN{color}\n{color:red}-1 RAW_PATCH_ANALYSIS{color}\n.    {color:green}+1{color} the patch does not introduce any @author tags\n.    {color:green}+1{color} the patch does not introduce any tabs\n.    {color:green}+1{color} the patch does not introduce any trailing spaces\n.    {color:green}+1{color} the patch does not introduce any line longer than 120\n.    {color:red}-1{color} the patch does not add/modify any testcase\n{color:green}+1 RAT{color}\n.    {color:green}+1{color} the patch does not seem to introduce new RAT warnings\n{color:green}+1 JAVADOC{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Javadoc warnings\n{color:red}-1 COMPILE{color}\n.    {color:green}+1{color} HEAD compiles\n.    {color:red}-1{color} patch does not compile\n.    {color:green}+1{color} the patch does not seem to introduce new javac warnings\n{color:red}-1 FINDBUGS{color}\n.    {color:red}-1{color} the patch seems to introduce 2 new Findbugs warning(s) in module(s) [bookkeeper-server]\n{color:red}-1 TESTS{color} - patch does not compile, cannot run testcases\n{color:red}-1 DISTRO{color}\n.    {color:red}-1{color} distro tarball fails with the patch\n\n----------------------------\n{color:red}*-1 Overall result, please check the reported -1(s)*{color}\n\n\nThe full output of the test-patch run is available at\n\n.   https://builds.apache.org/job/bookkeeper-trunk-precommit-build/216/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-08T16:10:19.338+0000","updated":"2013-01-08T16:10:19.338+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13546977","id":"13546977","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"Forgot to add one change to last patch. ","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-08T16:15:52.829+0000","updated":"2013-01-08T16:15:52.829+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13547000","id":"13547000","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"Testing JIRA BOOKKEEPER-530\n\n\nPatch [0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch|https://issues.apache.org/jira/secure/attachment/12563771/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch] downloaded at Tue Jan  8 16:21:21 UTC 2013\n\n----------------------------\n\n{color:green}+1 PATCH_APPLIES{color}\n{color:green}+1 CLEAN{color}\n{color:red}-1 RAW_PATCH_ANALYSIS{color}\n.    {color:green}+1{color} the patch does not introduce any @author tags\n.    {color:green}+1{color} the patch does not introduce any tabs\n.    {color:green}+1{color} the patch does not introduce any trailing spaces\n.    {color:green}+1{color} the patch does not introduce any line longer than 120\n.    {color:red}-1{color} the patch does not add/modify any testcase\n{color:green}+1 RAT{color}\n.    {color:green}+1{color} the patch does not seem to introduce new RAT warnings\n{color:green}+1 JAVADOC{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Javadoc warnings\n{color:green}+1 COMPILE{color}\n.    {color:green}+1{color} HEAD compiles\n.    {color:green}+1{color} patch compiles\n.    {color:green}+1{color} the patch does not seem to introduce new javac warnings\n{color:green}+1 FINDBUGS{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Findbugs warnings\n{color:green}+1 TESTS{color}\n.    Tests run: 781\n{color:green}+1 DISTRO{color}\n.    {color:green}+1{color} distro tarball builds with the patch \n\n----------------------------\n{color:red}*-1 Overall result, please check the reported -1(s)*{color}\n\n\nThe full output of the test-patch run is available at\n\n.   https://builds.apache.org/job/bookkeeper-trunk-precommit-build/217/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-08T16:51:31.724+0000","updated":"2013-01-08T16:51:31.724+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13547100","id":"13547100","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"body":"bq.This is what we do. The code adds to the journal, and when the journal callback triggers it adds to the entrylogger and index. If the journal succeeds and the entrylogger or index fails, this is fine due to the order, as the entry remains in the same place until we write the index, which is the last thing.\n\nOh! seems I hadn't explained clearly my idea. Could you please look at the below snippet of CompactionScanner#process() api. Here just tries to make await() logic simple and fail fast rather than waiting to finish all the entries in case of any failures.\n{code}\n        @Override\n        public void process(final long ledgerId, long offset, ByteBuffer entry)\n            throws IOException {\n            final CountDownLatch addEntryNotificationLatch = new CountDownLatch(1);\n            safeEntryAdder.safeAddEntry(ledgerId, entry, new GenericCallback<Void>() {\n                    @Override\n                    public void operationComplete(int rc, Void result) {\n                        if (rc != BookieException.Code.OK) {\n                            LOG.error(\"Error {} re-adding entry for ledger {})\",\n                                    rc, ledgerId);\n                            allSuccessful.set(false);\n                        }\n                        addEntryNotificationLatch.countDown();\n                    }\n                });\n            awaitComplete(addEntryNotificationLatch);\n        }\n\n        private void awaitComplete(CountDownLatch addEntryNotificationLatch) throws IOException {\n            try {\n                addEntryNotificationLatch.await();\n                if (allSuccessful.get() == false) {\n                    throw new IOException(\"Couldn't re-add all entries\");\n                }\n            } catch (InterruptedException ie) {\n                Thread.currentThread().interrupt();\n                LOG.error(\"Interrupted while compacting\", ie);\n                throw new IOException(\"Couldn't re-add all entries\", ie);\n            }        \n       }\n{code}\n\n-Rakesh","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-01-08T18:39:46.606+0000","updated":"2013-01-08T18:39:46.606+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13547730","id":"13547730","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"yeah, good point, Rakesh.\n\nCompaction should not overwhelm the journal thread which might affects normal adding operations. One by one might be better.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-09T07:42:20.539+0000","updated":"2013-01-09T07:42:20.539+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13548364","id":"13548364","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"with one by one it could take a very long time to compact a log. How about batching into 1000 entry chunks or something?","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-09T10:43:35.218+0000","updated":"2013-01-09T10:43:35.218+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13548447","id":"13548447","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"body":"Yeah, smaller chunks would be fine and would help in balancing.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=rakeshr","name":"rakeshr","key":"rakeshr","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=rakeshr&avatarId=29267","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=rakeshr&avatarId=29267","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=rakeshr&avatarId=29267","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=rakeshr&avatarId=29267"},"displayName":"Rakesh Radhakrishnan","active":true,"timeZone":"Asia/Kolkata"},"created":"2013-01-09T12:23:24.806+0000","updated":"2013-01-09T12:23:24.806+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13548548","id":"13548548","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"Latest patch limits the number of re-added entries to 1000 at a time, and stops processing if there is an error.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-09T14:49:35.085+0000","updated":"2013-01-09T14:49:35.085+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13548565","id":"13548565","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"body":"Testing JIRA BOOKKEEPER-530\n\n\nPatch [0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch|https://issues.apache.org/jira/secure/attachment/12563939/0001-BOOKKEEPER-530-data-might-be-lost-during-compaction.patch] downloaded at Wed Jan  9 14:51:23 UTC 2013\n\n----------------------------\n\n{color:green}+1 PATCH_APPLIES{color}\n{color:green}+1 CLEAN{color}\n{color:red}-1 RAW_PATCH_ANALYSIS{color}\n.    {color:green}+1{color} the patch does not introduce any @author tags\n.    {color:green}+1{color} the patch does not introduce any tabs\n.    {color:green}+1{color} the patch does not introduce any trailing spaces\n.    {color:green}+1{color} the patch does not introduce any line longer than 120\n.    {color:red}-1{color} the patch does not add/modify any testcase\n{color:green}+1 RAT{color}\n.    {color:green}+1{color} the patch does not seem to introduce new RAT warnings\n{color:green}+1 JAVADOC{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Javadoc warnings\n{color:green}+1 COMPILE{color}\n.    {color:green}+1{color} HEAD compiles\n.    {color:green}+1{color} patch compiles\n.    {color:green}+1{color} the patch does not seem to introduce new javac warnings\n{color:green}+1 FINDBUGS{color}\n.    {color:green}+1{color} the patch does not seem to introduce new Findbugs warnings\n{color:green}+1 TESTS{color}\n.    Tests run: 782\n{color:green}+1 DISTRO{color}\n.    {color:green}+1{color} distro tarball builds with the patch \n\n----------------------------\n{color:red}*-1 Overall result, please check the reported -1(s)*{color}\n\n\nThe full output of the test-patch run is available at\n\n.   https://builds.apache.org/job/bookkeeper-trunk-precommit-build/227/","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hadoopqa","name":"hadoopqa","key":"hadoopqa","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?ownerId=hadoopqa&avatarId=10393","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&ownerId=hadoopqa&avatarId=10393","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&ownerId=hadoopqa&avatarId=10393","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&ownerId=hadoopqa&avatarId=10393"},"displayName":"Hadoop QA","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-09T15:22:04.385+0000","updated":"2013-01-09T15:22:04.385+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13549482","id":"13549482","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"body":"+1 for the latest patch.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hustlmsp","name":"hustlmsp","key":"hustlmsp","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Sijie Guo","active":true,"timeZone":"America/Los_Angeles"},"created":"2013-01-10T09:44:05.907+0000","updated":"2013-01-10T09:44:05.907+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13549667","id":"13549667","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"body":"Committed as r1431378. Thanks for reviewing guys.","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=ikelly","name":"ikelly","key":"ikelly","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Ivan Kelly","active":true,"timeZone":"Europe/Berlin"},"created":"2013-01-10T14:34:08.188+0000","updated":"2013-01-10T14:34:08.188+0000"},{"self":"https://issues.apache.org/jira/rest/api/2/issue/12625473/comment/13549680","id":"13549680","author":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"body":"Integrated in bookkeeper-trunk2 #51 (See [https://builds.apache.org/job/bookkeeper-trunk2/51/])\n    BOOKKEEPER-530: data might be lost during compaction. (ivank) (Revision 1431378)\n\n     Result = SUCCESS\nivank : \nFiles : \n* /zookeeper/bookkeeper/trunk/CHANGES.txt\n* /zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Bookie.java\n* /zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java\n* /zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/InterleavedLedgerStorage.java\n* /zookeeper/bookkeeper/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/Journal.java\n","updateAuthor":{"self":"https://issues.apache.org/jira/rest/api/2/user?username=hudson","name":"hudson","key":"hudson","avatarUrls":{"48x48":"https://issues.apache.org/jira/secure/useravatar?avatarId=10452","24x24":"https://issues.apache.org/jira/secure/useravatar?size=small&avatarId=10452","16x16":"https://issues.apache.org/jira/secure/useravatar?size=xsmall&avatarId=10452","32x32":"https://issues.apache.org/jira/secure/useravatar?size=medium&avatarId=10452"},"displayName":"Hudson","active":true,"timeZone":"Etc/UTC"},"created":"2013-01-10T14:58:25.313+0000","updated":"2013-01-10T14:58:25.313+0000"}],"maxResults":24,"total":24,"startAt":0},"customfield_12311820":"0|i16y1r:","customfield_12314139":null}}

