{"sha":"64402ea7daab354dbffa85e029dc7df739c1df66","node_id":"MDY6Q29tbWl0MjA2MzY0OjY0NDAyZWE3ZGFhYjM1NGRiZmZhODVlMDI5ZGM3ZGY3MzljMWRmNjY=","commit":{"author":{"name":"Albert Lee","email":"allee8285@apache.org","date":"2008-03-03T22:59:07Z"},"committer":{"name":"Albert Lee","email":"allee8285@apache.org","date":"2008-03-03T22:59:07Z"},"message":"OPENJPA-530 - Change BatchingPreparedStatementManagerImpl to correctly batch dispatched statements in the same order requested by the update managers.\n\ngit-svn-id: https://svn.apache.org/repos/asf/openjpa/trunk@633317 13f79535-47bb-0310-9956-ffa450edef68","tree":{"sha":"d4337d86cadc2e0f28faaaa32a9218b158ed530e","url":"https://api.github.com/repos/apache/openjpa/git/trees/d4337d86cadc2e0f28faaaa32a9218b158ed530e"},"url":"https://api.github.com/repos/apache/openjpa/git/commits/64402ea7daab354dbffa85e029dc7df739c1df66","comment_count":0,"verification":{"verified":false,"reason":"unsigned","signature":null,"payload":null}},"url":"https://api.github.com/repos/apache/openjpa/commits/64402ea7daab354dbffa85e029dc7df739c1df66","html_url":"https://github.com/apache/openjpa/commit/64402ea7daab354dbffa85e029dc7df739c1df66","comments_url":"https://api.github.com/repos/apache/openjpa/commits/64402ea7daab354dbffa85e029dc7df739c1df66/comments","author":null,"committer":null,"parents":[{"sha":"c3ad06e8ff12a3f1836114695adfb8c4f9ddeaa7","url":"https://api.github.com/repos/apache/openjpa/commits/c3ad06e8ff12a3f1836114695adfb8c4f9ddeaa7","html_url":"https://github.com/apache/openjpa/commit/c3ad06e8ff12a3f1836114695adfb8c4f9ddeaa7"}],"stats":{"total":406,"additions":193,"deletions":213},"files":[{"sha":"35a2a25d62564c3375c440d9979547368c5e4418","filename":"openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingConstraintUpdateManager.java","status":"modified","additions":16,"deletions":12,"changes":28,"blob_url":"https://github.com/apache/openjpa/blob/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingConstraintUpdateManager.java","raw_url":"https://github.com/apache/openjpa/raw/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingConstraintUpdateManager.java","contents_url":"https://api.github.com/repos/apache/openjpa/contents/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingConstraintUpdateManager.java?ref=64402ea7daab354dbffa85e029dc7df739c1df66","patch":"@@ -19,19 +19,9 @@\n package org.apache.openjpa.jdbc.kernel;\n \n import java.sql.Connection;\n-import java.sql.SQLException;\n-import java.util.ArrayList;\n import java.util.Collection;\n-import java.util.Iterator;\n \n-import org.apache.openjpa.jdbc.schema.ForeignKey;\n-import org.apache.openjpa.jdbc.sql.PrimaryRow;\n-import org.apache.openjpa.jdbc.sql.Row;\n-import org.apache.openjpa.jdbc.sql.RowImpl;\n import org.apache.openjpa.jdbc.sql.RowManager;\n-import org.apache.openjpa.jdbc.sql.RowManagerImpl;\n-import org.apache.openjpa.jdbc.sql.SQLExceptions;\n-import org.apache.openjpa.kernel.OpenJPAStateManager;\n \n /**\n  * <P>Batch update manager that writes the SQL in object-level operation order. \n@@ -51,8 +41,22 @@\n public class BatchingConstraintUpdateManager extends ConstraintUpdateManager {\n \n     protected PreparedStatementManager newPreparedStatementManager(\n-            JDBCStore store, Connection conn) {\n+        JDBCStore store, Connection conn) {\n         int batchLimit = dict.getBatchLimit();\n-        return new BatchingPreparedStatementManagerImpl(store, conn, batchLimit);\n+        return new BatchingPreparedStatementManagerImpl(store, conn,\n+            batchLimit);\n+    }\n+\n+    /*\n+     * Override this method to flush any remaining batched row in the\n+     * PreparedStatementManager.\n+     */\n+    protected Collection flush(RowManager rowMgr,\n+        PreparedStatementManager psMgr, Collection exceps) {\n+        Collection rtnCol = super.flush(rowMgr, psMgr, exceps);\n+        BatchingPreparedStatementManagerImpl bPsMgr =\n+            (BatchingPreparedStatementManagerImpl) psMgr;\n+        bPsMgr.flushBatch();\n+        return rtnCol;\n     }\n }"},{"sha":"24fcadf9b87e6fe6f4efb09ad3f1a6240bce3e58","filename":"openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingOperationOrderUpdateManager.java","status":"modified","additions":20,"deletions":4,"changes":24,"blob_url":"https://github.com/apache/openjpa/blob/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingOperationOrderUpdateManager.java","raw_url":"https://github.com/apache/openjpa/raw/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingOperationOrderUpdateManager.java","contents_url":"https://api.github.com/repos/apache/openjpa/contents/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingOperationOrderUpdateManager.java?ref=64402ea7daab354dbffa85e029dc7df739c1df66","patch":"@@ -19,6 +19,9 @@\n package org.apache.openjpa.jdbc.kernel;\n \n import java.sql.Connection;\n+import java.util.Collection;\n+\n+import org.apache.openjpa.jdbc.sql.RowManager;\n \n /**\n  * <P>Batch update manager that writes the SQL in object-level operation order. \n@@ -37,12 +40,25 @@\n  */\n \n public class BatchingOperationOrderUpdateManager extends\n-        OperationOrderUpdateManager {\n+    OperationOrderUpdateManager {\n \n     protected PreparedStatementManager newPreparedStatementManager(\n-            JDBCStore store, Connection conn) {\n+        JDBCStore store, Connection conn) {\n         int batchLimit = dict.getBatchLimit();\n-        return new BatchingPreparedStatementManagerImpl(\n-                store, conn, batchLimit);\n+        return new BatchingPreparedStatementManagerImpl(store, conn,\n+            batchLimit);\n+    }\n+    \n+    /*\n+     * Override this method to flush any remaining batched row in the\n+     * PreparedStatementManager.\n+     */\n+    protected Collection flush(RowManager rowMgr,\n+        PreparedStatementManager psMgr, Collection exceps) {\n+        Collection rtnCol = super.flush(rowMgr, psMgr, exceps);\n+        BatchingPreparedStatementManagerImpl bPsMgr = \n+            (BatchingPreparedStatementManagerImpl) psMgr;\n+        bPsMgr.flushBatch();\n+        return rtnCol;\n     }\n }"},{"sha":"f25cdff8f1e9630a1d46c9bc16217527c7643a98","filename":"openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingPreparedStatementManagerImpl.java","status":"modified","additions":127,"deletions":179,"changes":306,"blob_url":"https://github.com/apache/openjpa/blob/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingPreparedStatementManagerImpl.java","raw_url":"https://github.com/apache/openjpa/raw/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingPreparedStatementManagerImpl.java","contents_url":"https://api.github.com/repos/apache/openjpa/contents/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/BatchingPreparedStatementManagerImpl.java?ref=64402ea7daab354dbffa85e029dc7df739c1df66","patch":"@@ -18,20 +18,13 @@\n  */\n package org.apache.openjpa.jdbc.kernel;\n \n-import java.sql.BatchUpdateException;\n import java.sql.Connection;\n import java.sql.PreparedStatement;\n-import java.sql.ResultSet;\n import java.sql.Statement;\n import java.sql.SQLException;\n import java.util.ArrayList;\n-import java.util.Collection;\n-import java.util.Collections;\n import java.util.Iterator;\n-import java.util.LinkedHashMap;\n-import java.util.LinkedList;\n-import java.util.Map;\n-import java.util.Set;\n+import java.util.List;\n \n import org.apache.openjpa.jdbc.conf.JDBCConfiguration;\n import org.apache.openjpa.jdbc.meta.ClassMapping;\n@@ -42,7 +35,6 @@\n import org.apache.openjpa.kernel.OpenJPAStateManager;\n import org.apache.openjpa.lib.log.Log;\n import org.apache.openjpa.lib.util.Localizer;\n-import org.apache.openjpa.util.ApplicationIds;\n import org.apache.openjpa.util.OptimisticException;\n \n /**\n@@ -59,7 +51,8 @@\n     private final static Localizer _loc = Localizer\n             .forPackage(BatchingPreparedStatementManagerImpl.class);\n \n-    private Map _cacheSql = null;\n+    private String _batchedSql = null;\n+    private List _batchedRows = new ArrayList();\n     private int _batchLimit;\n     private boolean _disableBatch = false;\n     private transient Log _log = null;\n@@ -68,8 +61,7 @@\n      * Constructor. Supply connection.\n      */\n     public BatchingPreparedStatementManagerImpl(JDBCStore store,\n-            Connection conn, int batchLimit) {\n-\n+        Connection conn, int batchLimit) {\n         super(store, conn);\n         _batchLimit = batchLimit;\n         _log = store.getConfiguration().getLog(JDBCConfiguration.LOG_JDBC);\n@@ -78,224 +70,180 @@ public BatchingPreparedStatementManagerImpl(JDBCStore store,\n     }\n \n     /**\n-     * Flush the given row. This method will cache the statement in a cache. The\n-     * statement will be executed in the flush() method.\n+     * Flush the given row immediately or deferred the flush in batch.\n      */\n-    protected void flushInternal(RowImpl row) throws SQLException {\n-        if (_batchLimit == 0 || _disableBatch) {\n-            super.flushInternal(row);\n-            return;\n-        }\n-        Column[] autoAssign = null;\n-        if (row.getAction() == Row.ACTION_INSERT)\n-            autoAssign = row.getTable().getAutoAssignedColumns();\n-\n-        // prepare statement\n-        String sql = row.getSQL(_dict);\n-        OpenJPAStateManager sm = row.getPrimaryKey();\n-        ClassMapping cmd = null;\n-        if (sm != null)\n-            cmd = (ClassMapping) sm.getMetaData();\n-        // validate batch capability\n-        _disableBatch = _dict.validateBatchProcess(row, autoAssign, sm, cmd);\n-\n-        // process the sql statement, either execute it immediately or\n-        // cache them.\n-        processSql(sql, row);\n-\n-        // set auto assign values\n-        if (autoAssign != null && autoAssign.length > 0 && sm != null) {\n-            Object val;\n-            for (int i = 0; i < autoAssign.length; i++) {\n-                val = _dict.getGeneratedKey(autoAssign[i], _conn);\n-                cmd.assertJoinable(autoAssign[i]).setAutoAssignedValue(sm,\n-                        _store, autoAssign[i], val);\n-            }\n-            sm.setObjectId(ApplicationIds.create(sm.getPersistenceCapable(),\n-                    cmd));\n-        }\n-    }\n-\n-    private void processSql(String sql, RowImpl row) throws SQLException {\n-        ArrayList temprow;\n-\n-        if (_cacheSql == null)\n-            _cacheSql = Collections.synchronizedMap(new LinkedHashMap());\n-        if (_disableBatch) {\n+    protected void flushAndUpdate(RowImpl row) throws SQLException {\n+        if (isBatchDisabled(row)) {\n             // if there were some statements batched before, then\n             // we need to flush them out first before processing the\n             // current non batch process.\n-            if (!_cacheSql.isEmpty())\n-                flush();\n-            execute(sql, row);\n+            flushBatch();\n \n+            super.flushAndUpdate(row);\n         } else {\n-            // else start batch support. If the sql string is in the cache,\n-            // just adds the row to the cache\n-            if (_cacheSql.containsKey(sql)) {\n-                temprow = (ArrayList) _cacheSql.get(sql);\n-                temprow.add(row);\n-                _cacheSql.put(sql, temprow);\n-            } else {\n-                // no sql exists in the cache, cache the sql string and its rows\n-                ArrayList inputrow = new ArrayList();\n-                inputrow.add(row);\n-                _cacheSql.put(sql, inputrow);\n-            }\n-        } // end of batch support\n-    }\n-\n-    private void execute(String sql, RowImpl row) throws SQLException {\n-        PreparedStatement stmnt = null;\n-        try {\n-            ResultSet rs = null;\n-            stmnt = _conn.prepareStatement(sql);\n-            row.flush(stmnt, _dict, _store);\n-            int count = stmnt.executeUpdate();\n-            if (count != 1) {\n-                Object failed = row.getFailedObject();\n-                if (failed != null)\n-                    _exceptions.add(new OptimisticException(failed));\n-                else if (row.getAction() == Row.ACTION_INSERT)\n-                    throw new SQLException(_loc.get(\n-                            \"update-failed-no-failed-obj\",\n-                            String.valueOf(count), sql).getMessage());\n-            }\n-        } catch (SQLException se) {\n-            throw SQLExceptions.getStore(se, row.getFailedObject(), _dict);\n-        } finally {\n-            try {\n-                if (stmnt != null)\n-                    stmnt.close();\n-            } catch (SQLException se) {\n-                // ignore the exception for this case.\n+            // process the SQL statement, either execute it immediately or\n+            // batch it for later execution.\n+            String sql = row.getSQL(_dict);\n+            if (_batchedSql == null) {\n+                // brand new SQL\n+                _batchedSql = sql;\n+            } else if (!sql.equals(_batchedSql)) {\n+                // SQL statements changed.\n+                switch (_batchedRows.size()) {\n+                case 0:\n+                    break;\n+                case 1:\n+                    // single entry in cache, direct SQL execution. \n+                    super.flushAndUpdate((RowImpl) _batchedRows.get(0));\n+                    _batchedRows.clear();\n+                    break;\n+                default:\n+                    // flush all entries in cache in batch.\n+                    flushBatch();\n+                }\n+                _batchedSql = sql;\n             }\n+            _batchedRows.add(row);\n         }\n     }\n \n-    public void flush() {\n-        PreparedStatement ps = null;\n-        ArrayList list;\n-        RowImpl onerow = null;\n-\n-        // go thru the cache to process all the sql stmt.\n-        if (_cacheSql == null || _cacheSql.isEmpty()) {\n-            super.flush();\n-            return;\n+    /*\n+     * Compute if batching is disabled, based on values of batch limit\n+     * and database characteristics.\n+     */\n+    private boolean isBatchDisabled(RowImpl row) {\n+        boolean rtnVal = true;\n+        if (_batchLimit != 0 && !_disableBatch) {\n+            String sql = row.getSQL(_dict);\n+            OpenJPAStateManager sm = row.getPrimaryKey();\n+            ClassMapping cmd = null;\n+            if (sm != null)\n+                cmd = (ClassMapping) sm.getMetaData();\n+            Column[] autoAssign = null;\n+            if (row.getAction() == Row.ACTION_INSERT)\n+                autoAssign = row.getTable().getAutoAssignedColumns();\n+            // validate batch capability\n+            _disableBatch = _dict\n+                .validateBatchProcess(row, autoAssign, sm, cmd);\n+            rtnVal = _disableBatch;\n         }\n-        Set e = _cacheSql.keySet();\n-\n-        for (Iterator itr = e.iterator(); itr.hasNext();) {\n-            String key = (String) itr.next();\n-            try {\n-                ps = _conn.prepareStatement(key);\n-            } catch (SQLException se) {\n-                throw SQLExceptions.getStore(se, ps, _dict);\n-            }\n-            list = (ArrayList) _cacheSql.get(key);\n-            if (list == null) {\n-                return;\n-            }\n-\n-            // if only 1 row for this statement, then execute it right away\n-            int rowsize = list.size();\n-\n+        return rtnVal;\n+    }\n+    \n+    /**\n+     * flush all cached up statements to be executed as a single or batched\n+     * prepared statements.\n+     */\n+    protected void flushBatch() {\n+        if (_batchedSql != null && _batchedRows.size() > 0) {\n+            PreparedStatement ps = null;\n             try {\n-                if (rowsize == 1) {\n-                    onerow = (RowImpl) list.get(0);\n-                    onerow.flush(ps, _dict, _store);\n-                    int count = ps.executeUpdate();\n-                    if (count != 1) {\n-                        Object failed = onerow.getFailedObject();\n-                        if (failed != null)\n-                            _exceptions.add(new OptimisticException(failed));\n-                        else if (onerow.getAction() == Row.ACTION_INSERT)\n-                            throw new SQLException(_loc.get(\n-                                    \"update-failed-no-failed-obj\",\n-                                    String.valueOf(count), key).getMessage());\n-                    }\n+                RowImpl onerow = null;\n+                ps = _conn.prepareStatement(_batchedSql);\n+                if (_batchedRows.size() == 1) {\n+                    // execute a single row.\n+                    onerow = (RowImpl) _batchedRows.get(0);\n+                    flushSingleRow(onerow, ps);\n                 } else {\n-                    // has more than one rows for this statement, use addBatch\n+                    // cache has more than one rows, execute as batch.\n                     int count = 0;\n-                    for (int i = 0; i < list.size(); i++) {\n-                        onerow = (RowImpl) list.get(i);\n-                        if (count < _batchLimit || _batchLimit == -1) {\n-                            onerow.flush(ps, _dict, _store);\n-                            ps.addBatch();\n-                            count++;\n-\n+                    int batchedRowsBaseIndex = 0;\n+                    Iterator itr = _batchedRows.iterator();\n+                    while (itr.hasNext()) {\n+                        onerow = (RowImpl) itr.next();\n+                        if (_batchLimit == 1) {\n+                            flushSingleRow(onerow, ps);\n                         } else {\n-                            // reach the batchLimit , execute it\n-                            try {\n+                            if (count < _batchLimit || _batchLimit == -1) {\n+                                onerow.flush(ps, _dict, _store);\n+                                ps.addBatch();\n+                                count++;\n+                            } else {\n+                                // reach the batchLimit, execute the batch\n                                 int[] rtn = ps.executeBatch();\n-                                checkUpdateCount(rtn, onerow, key);\n-                            } catch (BatchUpdateException bex) {\n-                                SQLException sqex = bex.getNextException();\n-                                if (sqex == null)\n-                                    sqex = bex;\n-                                throw SQLExceptions.getStore(sqex, ps, _dict);\n+                                checkUpdateCount(rtn, batchedRowsBaseIndex);\n+\n+                                batchedRowsBaseIndex += _batchLimit;\n+\n+                                onerow.flush(ps, _dict, _store);\n+                                ps.addBatch();\n+                                // reset the count to 1 for new batch\n+                                count = 1;\n                             }\n-                            onerow.flush(ps, _dict, _store);\n-                            ps.addBatch();\n-                            count = 1; // reset the count to 1 for new batch\n                         }\n                     }\n                     // end of the loop, execute the batch\n-                    try {\n-                        int[] rtn = ps.executeBatch();\n-                        checkUpdateCount(rtn, onerow, key);\n-                    } catch (BatchUpdateException bex) {\n-                        SQLException sqex = bex.getNextException();\n-                        if (sqex == null)\n-                            sqex = bex;\n-                        throw SQLExceptions.getStore(sqex, ps, _dict);\n-                    }\n+                    int[] rtn = ps.executeBatch();\n+                    checkUpdateCount(rtn, batchedRowsBaseIndex);\n                 }\n             } catch (SQLException se) {\n                 SQLException sqex = se.getNextException();\n                 if (sqex == null)\n                     sqex = se;\n                 throw SQLExceptions.getStore(sqex, ps, _dict);\n+            } finally {\n+                _batchedSql = null;\n+                _batchedRows.clear();\n+                if (ps != null) {\n+                    try {\n+                        ps.close();\n+                    } catch (SQLException sqex) {\n+                        throw SQLExceptions.getStore(sqex, ps, _dict);\n+                    }\n+                }\n             }\n-            try {\n-                ps.close();\n-            } catch (SQLException sqex) {\n-                throw SQLExceptions.getStore(sqex, ps, _dict);\n-            }\n         }\n-        // instead of calling _cacheSql.clear, null it out to improve the\n-        // performance.\n-        _cacheSql = null;\n     }\n \n-    private void checkUpdateCount(int[] count, RowImpl row, String sql)\n-            throws SQLException {\n+    /*\n+     * Execute an update of a single row.\n+     */\n+    private void flushSingleRow(RowImpl row, PreparedStatement ps)\n+        throws SQLException {\n+        row.flush(ps, _dict, _store);\n+        int count = ps.executeUpdate();\n+        if (count != 1) {\n+            Object failed = row.getFailedObject();\n+            if (failed != null)\n+                _exceptions.add(new OptimisticException(failed));\n+            else if (row.getAction() == Row.ACTION_INSERT)\n+                throw new SQLException(_loc.get(\"update-failed-no-failed-obj\",\n+                    String.valueOf(count), row.getSQL(_dict)).getMessage());\n+        }\n+    }\n+\n+    /*\n+     * Process executeBatch function array of return counts.\n+     */\n+    private void checkUpdateCount(int[] count, int batchedRowsBaseIndex)\n+        throws SQLException {\n         int cnt = 0;\n         Object failed = null;\n         for (int i = 0; i < count.length; i++) {\n             cnt = count[i];\n+            RowImpl row = (RowImpl) _batchedRows.get(batchedRowsBaseIndex + i);\n             switch (cnt) {\n             case Statement.EXECUTE_FAILED: // -3\n                 failed = row.getFailedObject();\n                 if (failed != null || row.getAction() == Row.ACTION_UPDATE)\n                     _exceptions.add(new OptimisticException(failed));\n                 else if (row.getAction() == Row.ACTION_INSERT)\n                     throw new SQLException(_loc.get(\n-                            \"update-failed-no-failed-obj\",\n-                            String.valueOf(count[i]), sql).getMessage());\n+                        \"update-failed-no-failed-obj\",\n+                        String.valueOf(count[i]), _batchedSql).getMessage());\n                 break;\n             case Statement.SUCCESS_NO_INFO: // -2\n                 if (_log.isTraceEnabled())\n                     _log.trace(_loc.get(\"batch_update_info\",\n-                            String.valueOf(cnt), sql).getMessage());\n+                        String.valueOf(cnt), _batchedSql).getMessage());\n                 break;\n             case 0: // no row is inserted, treats it as failed\n                 // case\n                 failed = row.getFailedObject();\n                 if ((failed != null || row.getAction() == Row.ACTION_INSERT))\n                     throw new SQLException(_loc.get(\n-                            \"update-failed-no-failed-obj\",\n-                            String.valueOf(count[i]), sql).getMessage());\n+                        \"update-failed-no-failed-obj\",\n+                        String.valueOf(count[i]), _batchedSql).getMessage());\n             }\n         }\n     }"},{"sha":"87908437f65898459fe10788eaf2b020dff15cba","filename":"openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/PreparedStatementManagerImpl.java","status":"modified","additions":30,"deletions":18,"changes":48,"blob_url":"https://github.com/apache/openjpa/blob/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/PreparedStatementManagerImpl.java","raw_url":"https://github.com/apache/openjpa/raw/64402ea7daab354dbffa85e029dc7df739c1df66/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/PreparedStatementManagerImpl.java","contents_url":"https://api.github.com/repos/apache/openjpa/contents/openjpa-jdbc/src/main/java/org/apache/openjpa/jdbc/kernel/PreparedStatementManagerImpl.java?ref=64402ea7daab354dbffa85e029dc7df739c1df66","patch":"@@ -86,10 +86,33 @@ protected void flushInternal(RowImpl row) throws SQLException {\n         if (row.getAction() == Row.ACTION_INSERT)\n             autoAssign = row.getTable().getAutoAssignedColumns();\n \n+        flushAndUpdate(row);\n+\n+        // set auto assign values\n+        if (autoAssign != null && autoAssign.length > 0\n+            && row.getPrimaryKey() != null) {\n+            OpenJPAStateManager sm = row.getPrimaryKey();\n+            ClassMapping mapping = (ClassMapping) sm.getMetaData();\n+            Object val;\n+            for (int i = 0; i < autoAssign.length; i++) {\n+                val = _dict.getGeneratedKey(autoAssign[i], _conn);\n+                mapping.assertJoinable(autoAssign[i]).setAutoAssignedValue(sm,\n+                    _store, autoAssign[i], val);\n+            }\n+            sm.setObjectId(\n+                ApplicationIds.create(sm.getPersistenceCapable(), mapping));\n+        }\n+    }\n+\n+    /**\n+     * Flush the given row immediately. \n+     */\n+    protected void flushAndUpdate(RowImpl row)\n+        throws SQLException {\n         // prepare statement\n         String sql = row.getSQL(_dict);\n         PreparedStatement stmnt = prepareStatement(sql);\n-        \n+\n         // setup parameters and execute statement\n         if (stmnt != null)\n             row.flush(stmnt, _dict, _store);\n@@ -107,23 +130,12 @@ else if (row.getAction() == Row.ACTION_INSERT)\n         } catch (SQLException se) {\n             throw SQLExceptions.getStore(se, row.getFailedObject(), _dict);\n         } finally {\n-            if (stmnt != null)\n-               try { stmnt.close(); } catch (SQLException se) {}\n-        }\n-\n-        // set auto assign values\n-        if (autoAssign != null && autoAssign.length > 0\n-            && row.getPrimaryKey() != null) {\n-            OpenJPAStateManager sm = row.getPrimaryKey();\n-            ClassMapping mapping = (ClassMapping) sm.getMetaData();\n-            Object val;\n-            for (int i = 0; i < autoAssign.length; i++) {\n-                val = _dict.getGeneratedKey(autoAssign[i], _conn);\n-                mapping.assertJoinable(autoAssign[i]).setAutoAssignedValue(sm,\n-                    _store, autoAssign[i], val);\n+            if (stmnt != null) {\n+                try {\n+                    stmnt.close();\n+                } catch (SQLException se) {\n+                }\n             }\n-            sm.setObjectId(\n-                ApplicationIds.create(sm.getPersistenceCapable(), mapping));\n         }\n     }\n \n@@ -146,5 +158,5 @@ protected int executeUpdate(PreparedStatement stmnt, String sql,\n     protected PreparedStatement prepareStatement(String sql)\n         throws SQLException {\n         return _conn.prepareStatement(sql);\n-    }    \n+    }\n }"}]}

